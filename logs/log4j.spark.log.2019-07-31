19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 402
19/07/31 00:19:03 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 912.1 MB)
19/07/31 00:19:03 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 912.1 MB)
19/07/31 00:19:03 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:53873 in memory (size: 31.6 KB, free: 912.1 MB)
19/07/31 00:19:03 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 912.1 MB)
19/07/31 00:19:03 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 912.1 MB)
19/07/31 00:19:03 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:53873 in memory (size: 31.7 KB, free: 912.2 MB)
19/07/31 00:19:03 INFO ContextCleaner: Cleaned shuffle 8
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 840
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 80
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 54
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 405
19/07/31 00:19:03 INFO ContextCleaner: Cleaned shuffle 5
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 481
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 763
19/07/31 00:19:03 INFO ContextCleaner: Cleaned shuffle 4
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 483
19/07/31 00:19:03 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:53873 in memory (size: 23.8 KB, free: 912.2 MB)
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 83
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 400
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 484
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 760
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 486
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 480
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 403
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 767
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 79
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 485
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 50
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 761
19/07/31 00:19:03 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:53873 in memory (size: 23.8 KB, free: 912.2 MB)
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 53
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 482
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 765
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 399
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 487
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 82
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 49
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 406
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 764
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 52
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 766
19/07/31 00:19:03 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:53873 in memory (size: 4.3 KB, free: 912.2 MB)
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 51
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 81
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 762
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 401
19/07/31 00:19:03 INFO ContextCleaner: Cleaned accumulator 404
19/07/31 00:26:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
19/07/31 00:26:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
LIMIT 1000
19/07/31 00:26:27 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 00:26:27 INFO DAGScheduler: Got job 22 (collect at utils.scala:204) with 1 output partitions
19/07/31 00:26:27 INFO DAGScheduler: Final stage: ResultStage 32 (collect at utils.scala:204)
19/07/31 00:26:27 INFO DAGScheduler: Parents of final stage: List()
19/07/31 00:26:27 INFO DAGScheduler: Missing parents: List()
19/07/31 00:26:27 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[110] at collect at utils.scala:204), which has no missing parents
19/07/31 00:26:27 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 12.3 KB, free 911.9 MB)
19/07/31 00:26:27 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 6.0 KB, free 911.9 MB)
19/07/31 00:26:27 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:53873 (size: 6.0 KB, free: 912.2 MB)
19/07/31 00:26:27 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
19/07/31 00:26:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[110] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 00:26:27 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
19/07/31 00:26:27 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 5530 bytes)
19/07/31 00:26:27 INFO Executor: Running task 0.0 in stage 32.0 (TID 50)
19/07/31 00:26:27 INFO BlockManager: Found block rdd_73_0 locally
19/07/31 00:26:27 INFO Executor: Finished task 0.0 in stage 32.0 (TID 50). 1851 bytes result sent to driver
19/07/31 00:26:27 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 50) in 10 ms on localhost (executor driver) (1/1)
19/07/31 00:26:27 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
19/07/31 00:26:27 INFO DAGScheduler: ResultStage 32 (collect at utils.scala:204) finished in 0.012 s
19/07/31 00:26:27 INFO DAGScheduler: Job 22 finished: collect at utils.scala:204, took 0.035666 s
19/07/31 00:27:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
19/07/31 00:27:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
19/07/31 00:27:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
19/07/31 00:27:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
19/07/31 00:27:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
19/07/31 00:27:59 INFO SparkSqlParser: Parsing command: sparklyr_tmp_615e780464aa
19/07/31 00:27:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_615e780464aa` AS `zzz3`
WHERE (0 = 1)
19/07/31 00:27:59 INFO SparkSqlParser: Parsing command: sparklyr_tmp_615e686d1274
19/07/31 00:27:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_615e686d1274` AS `zzz4`
WHERE (0 = 1)
19/07/31 00:27:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_615e780464aa`
19/07/31 00:27:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_615e686d1274`
19/07/31 00:27:59 INFO SparkSqlParser: Parsing command: sparklyr_tmp_615e50d6b33b
19/07/31 00:27:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_615e50d6b33b` AS `zzz5`
WHERE (0 = 1)
19/07/31 00:27:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_615e50d6b33b`
19/07/31 00:27:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_615e50d6b33b`
LIMIT 1000
19/07/31 00:27:59 INFO CodeGenerator: Code generated in 23.117201 ms
19/07/31 00:27:59 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 00:27:59 INFO DAGScheduler: Got job 23 (collect at utils.scala:204) with 1 output partitions
19/07/31 00:27:59 INFO DAGScheduler: Final stage: ResultStage 33 (collect at utils.scala:204)
19/07/31 00:27:59 INFO DAGScheduler: Parents of final stage: List()
19/07/31 00:27:59 INFO DAGScheduler: Missing parents: List()
19/07/31 00:27:59 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[116] at collect at utils.scala:204), which has no missing parents
19/07/31 00:27:59 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 18.9 KB, free 911.9 MB)
19/07/31 00:27:59 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 7.7 KB, free 911.9 MB)
19/07/31 00:27:59 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:53873 (size: 7.7 KB, free: 912.2 MB)
19/07/31 00:27:59 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
19/07/31 00:27:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[116] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 00:27:59 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
19/07/31 00:27:59 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 5639 bytes)
19/07/31 00:27:59 INFO Executor: Running task 0.0 in stage 33.0 (TID 51)
19/07/31 00:27:59 INFO BlockManager: Found block rdd_73_0 locally
19/07/31 00:27:59 INFO Executor: Finished task 0.0 in stage 33.0 (TID 51). 2035 bytes result sent to driver
19/07/31 00:27:59 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 51) in 10 ms on localhost (executor driver) (1/1)
19/07/31 00:27:59 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
19/07/31 00:27:59 INFO DAGScheduler: ResultStage 33 (collect at utils.scala:204) finished in 0.010 s
19/07/31 00:27:59 INFO DAGScheduler: Job 23 finished: collect at utils.scala:204, took 0.023099 s
19/07/31 00:27:59 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 00:27:59 INFO DAGScheduler: Got job 24 (collect at utils.scala:204) with 1 output partitions
19/07/31 00:27:59 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:204)
19/07/31 00:27:59 INFO DAGScheduler: Parents of final stage: List()
19/07/31 00:27:59 INFO DAGScheduler: Missing parents: List()
19/07/31 00:27:59 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[116] at collect at utils.scala:204), which has no missing parents
19/07/31 00:27:59 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 18.9 KB, free 911.9 MB)
19/07/31 00:27:59 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 7.7 KB, free 911.9 MB)
19/07/31 00:27:59 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:53873 (size: 7.7 KB, free: 912.2 MB)
19/07/31 00:27:59 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
19/07/31 00:27:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[116] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(1))
19/07/31 00:27:59 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
19/07/31 00:27:59 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 52, localhost, executor driver, partition 1, PROCESS_LOCAL, 5639 bytes)
19/07/31 00:27:59 INFO Executor: Running task 0.0 in stage 34.0 (TID 52)
19/07/31 00:27:59 INFO BlockManager: Found block rdd_73_0 locally
19/07/31 00:27:59 INFO Executor: Finished task 0.0 in stage 34.0 (TID 52). 2035 bytes result sent to driver
19/07/31 00:27:59 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 52) in 6 ms on localhost (executor driver) (1/1)
19/07/31 00:27:59 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
19/07/31 00:27:59 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:204) finished in 0.006 s
19/07/31 00:27:59 INFO DAGScheduler: Job 24 finished: collect at utils.scala:204, took 0.014493 s
19/07/31 00:29:34 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_049`) `dbplyr_050`
ORDER BY `date`) `dbplyr_051`) `dbplyr_052`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 00:29:34 INFO HiveMetaStore: 0: get_database: default
19/07/31 00:29:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 00:29:34 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_053`) `dbplyr_054`
ORDER BY `date`) `dbplyr_055`) `dbplyr_056`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 00:29:34 INFO HiveMetaStore: 0: get_database: default
19/07/31 00:29:35 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 00:29:35 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1284 - cust_prospect_ind.nullCount#1283) > 0)
19/07/31 00:29:35 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1289 - visit_device_type.nullCount#1288) > 0)
19/07/31 00:29:35 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#1282 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#1281))
19/07/31 00:29:35 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#1287 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#1286))
19/07/31 00:29:35 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 00:29:35 INFO DAGScheduler: Got job 25 (collect at utils.scala:204) with 1 output partitions
19/07/31 00:29:35 INFO DAGScheduler: Final stage: ResultStage 35 (collect at utils.scala:204)
19/07/31 00:29:35 INFO DAGScheduler: Parents of final stage: List()
19/07/31 00:29:35 INFO DAGScheduler: Missing parents: List()
19/07/31 00:29:35 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[121] at collect at utils.scala:204), which has no missing parents
19/07/31 00:29:35 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 71.9 KB, free 911.8 MB)
19/07/31 00:29:35 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.8 MB)
19/07/31 00:29:35 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:53873 (size: 30.4 KB, free: 912.2 MB)
19/07/31 00:29:35 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
19/07/31 00:29:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[121] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 00:29:35 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
19/07/31 00:29:35 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 00:29:35 INFO Executor: Running task 0.0 in stage 35.0 (TID 53)
19/07/31 00:29:35 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 00:29:35 INFO Executor: Finished task 0.0 in stage 35.0 (TID 53). 4738 bytes result sent to driver
19/07/31 00:29:35 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 53) in 9 ms on localhost (executor driver) (1/1)
19/07/31 00:29:35 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
19/07/31 00:29:35 INFO DAGScheduler: ResultStage 35 (collect at utils.scala:204) finished in 0.009 s
19/07/31 00:29:35 INFO DAGScheduler: Job 25 finished: collect at utils.scala:204, took 0.025661 s
19/07/31 00:29:35 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 00:29:35 INFO DAGScheduler: Registering RDD 122 (collect at utils.scala:204)
19/07/31 00:29:35 INFO DAGScheduler: Got job 26 (collect at utils.scala:204) with 4 output partitions
19/07/31 00:29:35 INFO DAGScheduler: Final stage: ResultStage 37 (collect at utils.scala:204)
19/07/31 00:29:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)
19/07/31 00:29:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 36)
19/07/31 00:29:35 INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[122] at collect at utils.scala:204), which has no missing parents
19/07/31 00:29:35 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 74.1 KB, free 911.7 MB)
19/07/31 00:29:35 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 31.6 KB, free 911.7 MB)
19/07/31 00:29:35 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:53873 (size: 31.6 KB, free: 912.1 MB)
19/07/31 00:29:35 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
19/07/31 00:29:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[122] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 00:29:35 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
19/07/31 00:29:35 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 00:29:35 INFO Executor: Running task 0.0 in stage 36.0 (TID 54)
19/07/31 00:29:35 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 00:29:35 INFO Executor: Finished task 0.0 in stage 36.0 (TID 54). 1687 bytes result sent to driver
19/07/31 00:29:35 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 54) in 14 ms on localhost (executor driver) (1/1)
19/07/31 00:29:35 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
19/07/31 00:29:35 INFO DAGScheduler: ShuffleMapStage 36 (collect at utils.scala:204) finished in 0.014 s
19/07/31 00:29:35 INFO DAGScheduler: looking for newly runnable stages
19/07/31 00:29:35 INFO DAGScheduler: running: Set()
19/07/31 00:29:35 INFO DAGScheduler: waiting: Set(ResultStage 37)
19/07/31 00:29:35 INFO DAGScheduler: failed: Set()
19/07/31 00:29:35 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[125] at collect at utils.scala:204), which has no missing parents
19/07/31 00:29:35 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 16.1 KB, free 911.7 MB)
19/07/31 00:29:35 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 7.8 KB, free 911.7 MB)
19/07/31 00:29:35 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 912.1 MB)
19/07/31 00:29:35 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
19/07/31 00:29:35 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 37 (MapPartitionsRDD[125] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 00:29:35 INFO TaskSchedulerImpl: Adding task set 37.0 with 4 tasks
19/07/31 00:29:35 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 55, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 00:29:35 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 56, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 00:29:35 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 57, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 00:29:35 INFO TaskSetManager: Starting task 3.0 in stage 37.0 (TID 58, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 00:29:35 INFO Executor: Running task 0.0 in stage 37.0 (TID 55)
19/07/31 00:29:35 INFO Executor: Running task 1.0 in stage 37.0 (TID 56)
19/07/31 00:29:35 INFO Executor: Running task 2.0 in stage 37.0 (TID 57)
19/07/31 00:29:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:29:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:29:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:29:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:29:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:29:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:29:35 INFO Executor: Running task 3.0 in stage 37.0 (TID 58)
19/07/31 00:29:35 INFO Executor: Finished task 0.0 in stage 37.0 (TID 55). 2299 bytes result sent to driver
19/07/31 00:29:35 INFO Executor: Finished task 2.0 in stage 37.0 (TID 57). 2297 bytes result sent to driver
19/07/31 00:29:35 INFO Executor: Finished task 1.0 in stage 37.0 (TID 56). 2299 bytes result sent to driver
19/07/31 00:29:35 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 55) in 46 ms on localhost (executor driver) (1/4)
19/07/31 00:29:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:29:35 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 57) in 45 ms on localhost (executor driver) (2/4)
19/07/31 00:29:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:29:35 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 56) in 46 ms on localhost (executor driver) (3/4)
19/07/31 00:29:35 INFO Executor: Finished task 3.0 in stage 37.0 (TID 58). 2275 bytes result sent to driver
19/07/31 00:29:35 INFO TaskSetManager: Finished task 3.0 in stage 37.0 (TID 58) in 48 ms on localhost (executor driver) (4/4)
19/07/31 00:29:35 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
19/07/31 00:29:35 INFO DAGScheduler: ResultStage 37 (collect at utils.scala:204) finished in 0.050 s
19/07/31 00:29:35 INFO DAGScheduler: Job 26 finished: collect at utils.scala:204, took 0.101399 s
19/07/31 00:31:33 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_057`) `dbplyr_058`
ORDER BY `date`) `dbplyr_059`) `dbplyr_060`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 00:31:33 INFO HiveMetaStore: 0: get_database: default
19/07/31 00:31:33 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 00:31:33 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_061`) `dbplyr_062`
ORDER BY `date`) `dbplyr_063`) `dbplyr_064`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 00:31:33 INFO HiveMetaStore: 0: get_database: default
19/07/31 00:31:33 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 00:31:33 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1378 - cust_prospect_ind.nullCount#1377) > 0)
19/07/31 00:31:33 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1383 - visit_device_type.nullCount#1382) > 0)
19/07/31 00:31:33 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#1376 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#1375))
19/07/31 00:31:33 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#1381 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#1380))
19/07/31 00:31:33 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 00:31:33 INFO DAGScheduler: Got job 27 (collect at utils.scala:204) with 1 output partitions
19/07/31 00:31:33 INFO DAGScheduler: Final stage: ResultStage 38 (collect at utils.scala:204)
19/07/31 00:31:33 INFO DAGScheduler: Parents of final stage: List()
19/07/31 00:31:33 INFO DAGScheduler: Missing parents: List()
19/07/31 00:31:33 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[130] at collect at utils.scala:204), which has no missing parents
19/07/31 00:31:33 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 71.9 KB, free 911.6 MB)
19/07/31 00:31:33 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.6 MB)
19/07/31 00:31:33 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:53873 (size: 30.4 KB, free: 912.1 MB)
19/07/31 00:31:33 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
19/07/31 00:31:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[130] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 00:31:33 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
19/07/31 00:31:33 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 59, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 00:31:33 INFO Executor: Running task 0.0 in stage 38.0 (TID 59)
19/07/31 00:31:33 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 00:31:33 INFO Executor: Finished task 0.0 in stage 38.0 (TID 59). 4695 bytes result sent to driver
19/07/31 00:31:33 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 59) in 8 ms on localhost (executor driver) (1/1)
19/07/31 00:31:33 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
19/07/31 00:31:33 INFO DAGScheduler: ResultStage 38 (collect at utils.scala:204) finished in 0.009 s
19/07/31 00:31:33 INFO DAGScheduler: Job 27 finished: collect at utils.scala:204, took 0.025343 s
19/07/31 00:31:33 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 00:31:33 INFO DAGScheduler: Registering RDD 131 (collect at utils.scala:204)
19/07/31 00:31:33 INFO DAGScheduler: Got job 28 (collect at utils.scala:204) with 4 output partitions
19/07/31 00:31:33 INFO DAGScheduler: Final stage: ResultStage 40 (collect at utils.scala:204)
19/07/31 00:31:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)
19/07/31 00:31:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 39)
19/07/31 00:31:33 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[131] at collect at utils.scala:204), which has no missing parents
19/07/31 00:31:33 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 74.1 KB, free 911.5 MB)
19/07/31 00:31:33 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 31.6 KB, free 911.5 MB)
19/07/31 00:31:33 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:53873 (size: 31.6 KB, free: 912.1 MB)
19/07/31 00:31:33 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
19/07/31 00:31:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[131] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 00:31:33 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
19/07/31 00:31:33 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 60, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 00:31:33 INFO Executor: Running task 0.0 in stage 39.0 (TID 60)
19/07/31 00:31:33 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 00:31:33 INFO Executor: Finished task 0.0 in stage 39.0 (TID 60). 1687 bytes result sent to driver
19/07/31 00:31:33 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 60) in 12 ms on localhost (executor driver) (1/1)
19/07/31 00:31:33 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
19/07/31 00:31:33 INFO DAGScheduler: ShuffleMapStage 39 (collect at utils.scala:204) finished in 0.012 s
19/07/31 00:31:33 INFO DAGScheduler: looking for newly runnable stages
19/07/31 00:31:33 INFO DAGScheduler: running: Set()
19/07/31 00:31:33 INFO DAGScheduler: waiting: Set(ResultStage 40)
19/07/31 00:31:33 INFO DAGScheduler: failed: Set()
19/07/31 00:31:33 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[134] at collect at utils.scala:204), which has no missing parents
19/07/31 00:31:33 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 16.1 KB, free 911.4 MB)
19/07/31 00:31:33 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 7.8 KB, free 911.4 MB)
19/07/31 00:31:33 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 912.1 MB)
19/07/31 00:31:33 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
19/07/31 00:31:33 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 40 (MapPartitionsRDD[134] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 00:31:33 INFO TaskSchedulerImpl: Adding task set 40.0 with 4 tasks
19/07/31 00:31:33 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 61, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 00:31:33 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 62, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 00:31:33 INFO TaskSetManager: Starting task 2.0 in stage 40.0 (TID 63, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 00:31:33 INFO TaskSetManager: Starting task 3.0 in stage 40.0 (TID 64, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 00:31:33 INFO Executor: Running task 0.0 in stage 40.0 (TID 61)
19/07/31 00:31:33 INFO Executor: Running task 1.0 in stage 40.0 (TID 62)
19/07/31 00:31:33 INFO Executor: Running task 2.0 in stage 40.0 (TID 63)
19/07/31 00:31:33 INFO Executor: Running task 3.0 in stage 40.0 (TID 64)
19/07/31 00:31:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:31:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:31:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:31:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:31:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:31:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:31:33 INFO Executor: Finished task 0.0 in stage 40.0 (TID 61). 2299 bytes result sent to driver
19/07/31 00:31:33 INFO Executor: Finished task 1.0 in stage 40.0 (TID 62). 2342 bytes result sent to driver
19/07/31 00:31:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:31:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:31:33 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 61) in 14 ms on localhost (executor driver) (1/4)
19/07/31 00:31:33 INFO Executor: Finished task 3.0 in stage 40.0 (TID 64). 2275 bytes result sent to driver
19/07/31 00:31:33 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 62) in 15 ms on localhost (executor driver) (2/4)
19/07/31 00:31:33 INFO TaskSetManager: Finished task 3.0 in stage 40.0 (TID 64) in 16 ms on localhost (executor driver) (3/4)
19/07/31 00:31:33 INFO Executor: Finished task 2.0 in stage 40.0 (TID 63). 2297 bytes result sent to driver
19/07/31 00:31:33 INFO TaskSetManager: Finished task 2.0 in stage 40.0 (TID 63) in 17 ms on localhost (executor driver) (4/4)
19/07/31 00:31:33 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
19/07/31 00:31:33 INFO DAGScheduler: ResultStage 40 (collect at utils.scala:204) finished in 0.017 s
19/07/31 00:31:33 INFO DAGScheduler: Job 28 finished: collect at utils.scala:204, took 0.059621 s
19/07/31 00:37:50 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_065`) `dbplyr_066`
ORDER BY `date`) `dbplyr_067`) `dbplyr_068`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 00:37:50 INFO HiveMetaStore: 0: get_database: default
19/07/31 00:37:50 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 00:37:50 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_069`) `dbplyr_070`
ORDER BY `date`) `dbplyr_071`) `dbplyr_072`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 00:37:50 INFO HiveMetaStore: 0: get_database: default
19/07/31 00:37:50 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 00:37:50 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1472 - cust_prospect_ind.nullCount#1471) > 0)
19/07/31 00:37:50 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1477 - visit_device_type.nullCount#1476) > 0)
19/07/31 00:37:50 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#1470 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#1469))
19/07/31 00:37:50 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#1475 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#1474))
19/07/31 00:37:50 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 00:37:50 INFO DAGScheduler: Got job 29 (collect at utils.scala:204) with 1 output partitions
19/07/31 00:37:50 INFO DAGScheduler: Final stage: ResultStage 41 (collect at utils.scala:204)
19/07/31 00:37:50 INFO DAGScheduler: Parents of final stage: List()
19/07/31 00:37:50 INFO DAGScheduler: Missing parents: List()
19/07/31 00:37:50 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[139] at collect at utils.scala:204), which has no missing parents
19/07/31 00:37:50 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 71.9 KB, free 911.4 MB)
19/07/31 00:37:51 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.3 MB)
19/07/31 00:37:51 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:53873 (size: 30.4 KB, free: 912.0 MB)
19/07/31 00:37:51 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
19/07/31 00:37:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[139] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 00:37:51 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
19/07/31 00:37:51 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 00:37:51 INFO Executor: Running task 0.0 in stage 41.0 (TID 65)
19/07/31 00:37:51 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 00:37:51 INFO Executor: Finished task 0.0 in stage 41.0 (TID 65). 4695 bytes result sent to driver
19/07/31 00:37:51 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 65) in 19 ms on localhost (executor driver) (1/1)
19/07/31 00:37:51 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
19/07/31 00:37:51 INFO DAGScheduler: ResultStage 41 (collect at utils.scala:204) finished in 0.021 s
19/07/31 00:37:51 INFO DAGScheduler: Job 29 finished: collect at utils.scala:204, took 0.054606 s
19/07/31 00:37:51 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 00:37:51 INFO DAGScheduler: Registering RDD 140 (collect at utils.scala:204)
19/07/31 00:37:51 INFO DAGScheduler: Got job 30 (collect at utils.scala:204) with 4 output partitions
19/07/31 00:37:51 INFO DAGScheduler: Final stage: ResultStage 43 (collect at utils.scala:204)
19/07/31 00:37:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)
19/07/31 00:37:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 42)
19/07/31 00:37:51 INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[140] at collect at utils.scala:204), which has no missing parents
19/07/31 00:37:51 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 74.1 KB, free 911.3 MB)
19/07/31 00:37:51 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 31.6 KB, free 911.2 MB)
19/07/31 00:37:51 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:53873 (size: 31.6 KB, free: 912.0 MB)
19/07/31 00:37:51 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
19/07/31 00:37:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[140] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 00:37:51 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
19/07/31 00:37:51 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 00:37:51 INFO Executor: Running task 0.0 in stage 42.0 (TID 66)
19/07/31 00:37:51 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 00:37:51 INFO Executor: Finished task 0.0 in stage 42.0 (TID 66). 1687 bytes result sent to driver
19/07/31 00:37:51 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 66) in 20 ms on localhost (executor driver) (1/1)
19/07/31 00:37:51 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
19/07/31 00:37:51 INFO DAGScheduler: ShuffleMapStage 42 (collect at utils.scala:204) finished in 0.021 s
19/07/31 00:37:51 INFO DAGScheduler: looking for newly runnable stages
19/07/31 00:37:51 INFO DAGScheduler: running: Set()
19/07/31 00:37:51 INFO DAGScheduler: waiting: Set(ResultStage 43)
19/07/31 00:37:51 INFO DAGScheduler: failed: Set()
19/07/31 00:37:51 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[143] at collect at utils.scala:204), which has no missing parents
19/07/31 00:37:51 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 16.1 KB, free 911.2 MB)
19/07/31 00:37:51 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 7.8 KB, free 911.2 MB)
19/07/31 00:37:51 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 912.0 MB)
19/07/31 00:37:51 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1006
19/07/31 00:37:51 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 43 (MapPartitionsRDD[143] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 00:37:51 INFO TaskSchedulerImpl: Adding task set 43.0 with 4 tasks
19/07/31 00:37:51 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 67, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 00:37:51 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 68, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 00:37:51 INFO TaskSetManager: Starting task 2.0 in stage 43.0 (TID 69, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 00:37:51 INFO TaskSetManager: Starting task 3.0 in stage 43.0 (TID 70, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 00:37:51 INFO Executor: Running task 0.0 in stage 43.0 (TID 67)
19/07/31 00:37:51 INFO Executor: Running task 1.0 in stage 43.0 (TID 68)
19/07/31 00:37:51 INFO Executor: Running task 2.0 in stage 43.0 (TID 69)
19/07/31 00:37:51 INFO Executor: Running task 3.0 in stage 43.0 (TID 70)
19/07/31 00:37:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:37:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:37:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:37:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:37:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 00:37:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:37:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:37:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:37:51 INFO Executor: Finished task 0.0 in stage 43.0 (TID 67). 2299 bytes result sent to driver
19/07/31 00:37:51 INFO Executor: Finished task 3.0 in stage 43.0 (TID 70). 2275 bytes result sent to driver
19/07/31 00:37:51 INFO TaskSetManager: Finished task 3.0 in stage 43.0 (TID 70) in 18 ms on localhost (executor driver) (1/4)
19/07/31 00:37:51 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 67) in 19 ms on localhost (executor driver) (2/4)
19/07/31 00:37:51 INFO Executor: Finished task 2.0 in stage 43.0 (TID 69). 2297 bytes result sent to driver
19/07/31 00:37:51 INFO TaskSetManager: Finished task 2.0 in stage 43.0 (TID 69) in 20 ms on localhost (executor driver) (3/4)
19/07/31 00:37:51 INFO Executor: Finished task 1.0 in stage 43.0 (TID 68). 2299 bytes result sent to driver
19/07/31 00:37:51 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 68) in 22 ms on localhost (executor driver) (4/4)
19/07/31 00:37:51 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
19/07/31 00:37:51 INFO DAGScheduler: ResultStage 43 (collect at utils.scala:204) finished in 0.022 s
19/07/31 00:37:51 INFO DAGScheduler: Job 30 finished: collect at utils.scala:204, took 0.096128 s
19/07/31 00:39:59 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_073`) `dbplyr_074`
ORDER BY `date`) `dbplyr_075`) `dbplyr_076`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 00:39:59 INFO HiveMetaStore: 0: get_database: default
19/07/31 00:39:59 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 00:40:00 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_077`) `dbplyr_078`
ORDER BY `date`) `dbplyr_079`) `dbplyr_080`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 00:40:00 INFO HiveMetaStore: 0: get_database: default
19/07/31 00:40:00 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 00:40:00 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1566 - cust_prospect_ind.nullCount#1565) > 0)
19/07/31 00:40:00 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1571 - visit_device_type.nullCount#1570) > 0)
19/07/31 00:40:00 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#1564 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#1563))
19/07/31 00:40:00 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#1569 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#1568))
19/07/31 00:40:00 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 00:40:00 INFO DAGScheduler: Got job 31 (collect at utils.scala:204) with 1 output partitions
19/07/31 00:40:00 INFO DAGScheduler: Final stage: ResultStage 44 (collect at utils.scala:204)
19/07/31 00:40:00 INFO DAGScheduler: Parents of final stage: List()
19/07/31 00:40:00 INFO DAGScheduler: Missing parents: List()
19/07/31 00:40:00 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[148] at collect at utils.scala:204), which has no missing parents
19/07/31 00:40:00 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 71.9 KB, free 911.1 MB)
19/07/31 00:40:00 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.1 MB)
19/07/31 00:40:00 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:53873 (size: 30.4 KB, free: 912.0 MB)
19/07/31 00:40:00 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
19/07/31 00:40:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[148] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 00:40:00 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
19/07/31 00:40:00 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 71, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 00:40:00 INFO Executor: Running task 0.0 in stage 44.0 (TID 71)
19/07/31 00:40:00 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 00:40:00 INFO Executor: Finished task 0.0 in stage 44.0 (TID 71). 4695 bytes result sent to driver
19/07/31 00:40:00 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 71) in 15 ms on localhost (executor driver) (1/1)
19/07/31 00:40:00 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
19/07/31 00:40:00 INFO DAGScheduler: ResultStage 44 (collect at utils.scala:204) finished in 0.017 s
19/07/31 00:40:00 INFO DAGScheduler: Job 31 finished: collect at utils.scala:204, took 0.043263 s
19/07/31 00:40:00 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 00:40:00 INFO DAGScheduler: Registering RDD 149 (collect at utils.scala:204)
19/07/31 00:40:00 INFO DAGScheduler: Got job 32 (collect at utils.scala:204) with 4 output partitions
19/07/31 00:40:00 INFO DAGScheduler: Final stage: ResultStage 46 (collect at utils.scala:204)
19/07/31 00:40:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)
19/07/31 00:40:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 45)
19/07/31 00:40:00 INFO DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[149] at collect at utils.scala:204), which has no missing parents
19/07/31 00:40:00 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 74.1 KB, free 911.0 MB)
19/07/31 00:40:00 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 31.6 KB, free 911.0 MB)
19/07/31 00:40:00 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:53873 (size: 31.6 KB, free: 911.9 MB)
19/07/31 00:40:00 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1006
19/07/31 00:40:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[149] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 00:40:00 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
19/07/31 00:40:00 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 72, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 00:40:00 INFO Executor: Running task 0.0 in stage 45.0 (TID 72)
19/07/31 00:40:00 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 00:40:00 INFO Executor: Finished task 0.0 in stage 45.0 (TID 72). 1687 bytes result sent to driver
19/07/31 00:40:00 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 72) in 16 ms on localhost (executor driver) (1/1)
19/07/31 00:40:00 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
19/07/31 00:40:00 INFO DAGScheduler: ShuffleMapStage 45 (collect at utils.scala:204) finished in 0.016 s
19/07/31 00:40:00 INFO DAGScheduler: looking for newly runnable stages
19/07/31 00:40:00 INFO DAGScheduler: running: Set()
19/07/31 00:40:00 INFO DAGScheduler: waiting: Set(ResultStage 46)
19/07/31 00:40:00 INFO DAGScheduler: failed: Set()
19/07/31 00:40:00 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[152] at collect at utils.scala:204), which has no missing parents
19/07/31 00:40:00 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 16.1 KB, free 911.0 MB)
19/07/31 00:40:00 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 7.8 KB, free 911.0 MB)
19/07/31 00:40:00 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 911.9 MB)
19/07/31 00:40:00 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
19/07/31 00:40:00 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 46 (MapPartitionsRDD[152] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 00:40:00 INFO TaskSchedulerImpl: Adding task set 46.0 with 4 tasks
19/07/31 00:40:00 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 73, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 00:40:00 INFO TaskSetManager: Starting task 1.0 in stage 46.0 (TID 74, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 00:40:00 INFO TaskSetManager: Starting task 2.0 in stage 46.0 (TID 75, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 00:40:00 INFO TaskSetManager: Starting task 3.0 in stage 46.0 (TID 76, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 00:40:00 INFO Executor: Running task 0.0 in stage 46.0 (TID 73)
19/07/31 00:40:00 INFO Executor: Running task 1.0 in stage 46.0 (TID 74)
19/07/31 00:40:00 INFO Executor: Running task 2.0 in stage 46.0 (TID 75)
19/07/31 00:40:00 INFO Executor: Running task 3.0 in stage 46.0 (TID 76)
19/07/31 00:40:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:40:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 00:40:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:40:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 00:40:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:40:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:40:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:40:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:40:00 INFO Executor: Finished task 1.0 in stage 46.0 (TID 74). 2299 bytes result sent to driver
19/07/31 00:40:00 INFO Executor: Finished task 0.0 in stage 46.0 (TID 73). 2299 bytes result sent to driver
19/07/31 00:40:00 INFO Executor: Finished task 2.0 in stage 46.0 (TID 75). 2297 bytes result sent to driver
19/07/31 00:40:00 INFO Executor: Finished task 3.0 in stage 46.0 (TID 76). 2275 bytes result sent to driver
19/07/31 00:40:00 INFO TaskSetManager: Finished task 1.0 in stage 46.0 (TID 74) in 16 ms on localhost (executor driver) (1/4)
19/07/31 00:40:00 INFO TaskSetManager: Finished task 2.0 in stage 46.0 (TID 75) in 17 ms on localhost (executor driver) (2/4)
19/07/31 00:40:00 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 73) in 17 ms on localhost (executor driver) (3/4)
19/07/31 00:40:00 INFO TaskSetManager: Finished task 3.0 in stage 46.0 (TID 76) in 17 ms on localhost (executor driver) (4/4)
19/07/31 00:40:00 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
19/07/31 00:40:00 INFO DAGScheduler: ResultStage 46 (collect at utils.scala:204) finished in 0.017 s
19/07/31 00:40:00 INFO DAGScheduler: Job 32 finished: collect at utils.scala:204, took 0.069370 s
19/07/31 00:41:52 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_081`) `dbplyr_082`
ORDER BY `date`) `dbplyr_083`) `dbplyr_084`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 00:41:52 INFO HiveMetaStore: 0: get_database: default
19/07/31 00:41:52 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 00:41:52 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_085`) `dbplyr_086`
ORDER BY `date`) `dbplyr_087`) `dbplyr_088`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 00:41:52 INFO HiveMetaStore: 0: get_database: default
19/07/31 00:41:52 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 00:41:52 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1660 - cust_prospect_ind.nullCount#1659) > 0)
19/07/31 00:41:52 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1665 - visit_device_type.nullCount#1664) > 0)
19/07/31 00:41:52 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#1658 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#1657))
19/07/31 00:41:52 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#1663 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#1662))
19/07/31 00:41:52 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 00:41:52 INFO DAGScheduler: Got job 33 (collect at utils.scala:204) with 1 output partitions
19/07/31 00:41:52 INFO DAGScheduler: Final stage: ResultStage 47 (collect at utils.scala:204)
19/07/31 00:41:52 INFO DAGScheduler: Parents of final stage: List()
19/07/31 00:41:52 INFO DAGScheduler: Missing parents: List()
19/07/31 00:41:52 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[157] at collect at utils.scala:204), which has no missing parents
19/07/31 00:41:52 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 71.9 KB, free 910.9 MB)
19/07/31 00:41:52 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.9 MB)
19/07/31 00:41:52 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:53873 (size: 30.4 KB, free: 911.9 MB)
19/07/31 00:41:52 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
19/07/31 00:41:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[157] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 00:41:52 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
19/07/31 00:41:52 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 77, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 00:41:52 INFO Executor: Running task 0.0 in stage 47.0 (TID 77)
19/07/31 00:41:52 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 00:41:52 INFO Executor: Finished task 0.0 in stage 47.0 (TID 77). 4695 bytes result sent to driver
19/07/31 00:41:52 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 77) in 7 ms on localhost (executor driver) (1/1)
19/07/31 00:41:52 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
19/07/31 00:41:52 INFO DAGScheduler: ResultStage 47 (collect at utils.scala:204) finished in 0.008 s
19/07/31 00:41:52 INFO DAGScheduler: Job 33 finished: collect at utils.scala:204, took 0.019714 s
19/07/31 00:41:52 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 00:41:52 INFO DAGScheduler: Registering RDD 158 (collect at utils.scala:204)
19/07/31 00:41:52 INFO DAGScheduler: Got job 34 (collect at utils.scala:204) with 4 output partitions
19/07/31 00:41:52 INFO DAGScheduler: Final stage: ResultStage 49 (collect at utils.scala:204)
19/07/31 00:41:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)
19/07/31 00:41:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 48)
19/07/31 00:41:52 INFO DAGScheduler: Submitting ShuffleMapStage 48 (MapPartitionsRDD[158] at collect at utils.scala:204), which has no missing parents
19/07/31 00:41:52 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 74.1 KB, free 910.8 MB)
19/07/31 00:41:52 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.8 MB)
19/07/31 00:41:52 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:53873 (size: 31.7 KB, free: 911.9 MB)
19/07/31 00:41:52 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
19/07/31 00:41:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[158] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 00:41:52 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
19/07/31 00:41:52 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 78, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 00:41:52 INFO Executor: Running task 0.0 in stage 48.0 (TID 78)
19/07/31 00:41:52 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 00:41:52 INFO Executor: Finished task 0.0 in stage 48.0 (TID 78). 1687 bytes result sent to driver
19/07/31 00:41:52 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 78) in 16 ms on localhost (executor driver) (1/1)
19/07/31 00:41:52 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
19/07/31 00:41:52 INFO DAGScheduler: ShuffleMapStage 48 (collect at utils.scala:204) finished in 0.017 s
19/07/31 00:41:52 INFO DAGScheduler: looking for newly runnable stages
19/07/31 00:41:52 INFO DAGScheduler: running: Set()
19/07/31 00:41:52 INFO DAGScheduler: waiting: Set(ResultStage 49)
19/07/31 00:41:52 INFO DAGScheduler: failed: Set()
19/07/31 00:41:52 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[161] at collect at utils.scala:204), which has no missing parents
19/07/31 00:41:52 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 16.1 KB, free 910.8 MB)
19/07/31 00:41:52 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 7.8 KB, free 910.7 MB)
19/07/31 00:41:52 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 911.9 MB)
19/07/31 00:41:52 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1006
19/07/31 00:41:52 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 49 (MapPartitionsRDD[161] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 00:41:52 INFO TaskSchedulerImpl: Adding task set 49.0 with 4 tasks
19/07/31 00:41:52 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 79, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 00:41:52 INFO TaskSetManager: Starting task 1.0 in stage 49.0 (TID 80, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 00:41:52 INFO TaskSetManager: Starting task 2.0 in stage 49.0 (TID 81, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 00:41:52 INFO TaskSetManager: Starting task 3.0 in stage 49.0 (TID 82, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 00:41:52 INFO Executor: Running task 0.0 in stage 49.0 (TID 79)
19/07/31 00:41:52 INFO Executor: Running task 1.0 in stage 49.0 (TID 80)
19/07/31 00:41:52 INFO Executor: Running task 2.0 in stage 49.0 (TID 81)
19/07/31 00:41:52 INFO Executor: Running task 3.0 in stage 49.0 (TID 82)
19/07/31 00:41:52 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:41:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:41:52 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:41:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:41:52 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:41:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 00:41:52 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:41:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:41:52 INFO Executor: Finished task 1.0 in stage 49.0 (TID 80). 2299 bytes result sent to driver
19/07/31 00:41:52 INFO Executor: Finished task 2.0 in stage 49.0 (TID 81). 2297 bytes result sent to driver
19/07/31 00:41:52 INFO TaskSetManager: Finished task 1.0 in stage 49.0 (TID 80) in 10 ms on localhost (executor driver) (1/4)
19/07/31 00:41:52 INFO Executor: Finished task 3.0 in stage 49.0 (TID 82). 2318 bytes result sent to driver
19/07/31 00:41:52 INFO TaskSetManager: Finished task 3.0 in stage 49.0 (TID 82) in 10 ms on localhost (executor driver) (2/4)
19/07/31 00:41:52 INFO TaskSetManager: Finished task 2.0 in stage 49.0 (TID 81) in 10 ms on localhost (executor driver) (3/4)
19/07/31 00:41:52 INFO Executor: Finished task 0.0 in stage 49.0 (TID 79). 2299 bytes result sent to driver
19/07/31 00:41:52 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 79) in 11 ms on localhost (executor driver) (4/4)
19/07/31 00:41:52 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
19/07/31 00:41:52 INFO DAGScheduler: ResultStage 49 (collect at utils.scala:204) finished in 0.012 s
19/07/31 00:41:52 INFO DAGScheduler: Job 34 finished: collect at utils.scala:204, took 0.049970 s
19/07/31 00:49:03 INFO ContextCleaner: Cleaned shuffle 9
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 948
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1078
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1166
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1162
19/07/31 00:49:03 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 911.9 MB)
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1003
19/07/31 00:49:03 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:53873 in memory (size: 7.7 KB, free: 911.9 MB)
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 947
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 946
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1161
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1164
19/07/31 00:49:03 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 911.9 MB)
19/07/31 00:49:03 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:53873 in memory (size: 31.6 KB, free: 911.9 MB)
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1081
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1085
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1002
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1001
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1165
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 997
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1240
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1000
19/07/31 00:49:03 INFO ContextCleaner: Cleaned shuffle 12
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1086
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1163
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 999
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1079
19/07/31 00:49:03 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 911.9 MB)
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1159
19/07/31 00:49:03 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:53873 in memory (size: 6.0 KB, free: 912.0 MB)
19/07/31 00:49:03 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 912.0 MB)
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1004
19/07/31 00:49:03 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 912.0 MB)
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1080
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1005
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1167
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1083
19/07/31 00:49:03 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 912.0 MB)
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1084
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1160
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 998
19/07/31 00:49:03 INFO ContextCleaner: Cleaned shuffle 11
19/07/31 00:49:03 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:53873 in memory (size: 7.7 KB, free: 912.0 MB)
19/07/31 00:49:03 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 912.1 MB)
19/07/31 00:49:03 INFO ContextCleaner: Cleaned shuffle 10
19/07/31 00:49:03 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:53873 in memory (size: 31.6 KB, free: 912.1 MB)
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1082
19/07/31 00:49:03 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 912.1 MB)
19/07/31 00:49:03 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:53873 in memory (size: 31.6 KB, free: 912.1 MB)
19/07/31 00:49:03 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 912.1 MB)
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 921
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 1321
19/07/31 00:49:03 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:53873 in memory (size: 31.7 KB, free: 912.2 MB)
19/07/31 00:49:03 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:53873 in memory (size: 31.6 KB, free: 912.2 MB)
19/07/31 00:49:03 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 912.2 MB)
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 842
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 843
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 841
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 845
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 844
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 846
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 848
19/07/31 00:49:03 INFO ContextCleaner: Cleaned accumulator 847
19/07/31 00:49:41 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_089`) `dbplyr_090`
ORDER BY `date`) `dbplyr_091`) `dbplyr_092`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 00:49:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 00:49:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 00:49:41 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_093`) `dbplyr_094`
ORDER BY `date`) `dbplyr_095`) `dbplyr_096`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 00:49:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 00:49:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 00:49:41 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1754 - cust_prospect_ind.nullCount#1753) > 0)
19/07/31 00:49:41 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1759 - visit_device_type.nullCount#1758) > 0)
19/07/31 00:49:41 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#1752 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#1751))
19/07/31 00:49:41 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#1757 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#1756))
19/07/31 00:49:41 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 00:49:41 INFO DAGScheduler: Got job 35 (collect at utils.scala:204) with 1 output partitions
19/07/31 00:49:41 INFO DAGScheduler: Final stage: ResultStage 50 (collect at utils.scala:204)
19/07/31 00:49:41 INFO DAGScheduler: Parents of final stage: List()
19/07/31 00:49:41 INFO DAGScheduler: Missing parents: List()
19/07/31 00:49:41 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[166] at collect at utils.scala:204), which has no missing parents
19/07/31 00:49:41 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 71.9 KB, free 911.9 MB)
19/07/31 00:49:41 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 30.3 KB, free 911.9 MB)
19/07/31 00:49:41 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:53873 (size: 30.3 KB, free: 912.2 MB)
19/07/31 00:49:41 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
19/07/31 00:49:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[166] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 00:49:41 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
19/07/31 00:49:41 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 83, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 00:49:41 INFO Executor: Running task 0.0 in stage 50.0 (TID 83)
19/07/31 00:49:41 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 00:49:41 INFO Executor: Finished task 0.0 in stage 50.0 (TID 83). 4738 bytes result sent to driver
19/07/31 00:49:41 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 83) in 10 ms on localhost (executor driver) (1/1)
19/07/31 00:49:41 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
19/07/31 00:49:41 INFO DAGScheduler: ResultStage 50 (collect at utils.scala:204) finished in 0.010 s
19/07/31 00:49:41 INFO DAGScheduler: Job 35 finished: collect at utils.scala:204, took 0.022689 s
19/07/31 00:49:41 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 00:49:41 INFO DAGScheduler: Registering RDD 167 (collect at utils.scala:204)
19/07/31 00:49:41 INFO DAGScheduler: Got job 36 (collect at utils.scala:204) with 4 output partitions
19/07/31 00:49:41 INFO DAGScheduler: Final stage: ResultStage 52 (collect at utils.scala:204)
19/07/31 00:49:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 51)
19/07/31 00:49:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 51)
19/07/31 00:49:41 INFO DAGScheduler: Submitting ShuffleMapStage 51 (MapPartitionsRDD[167] at collect at utils.scala:204), which has no missing parents
19/07/31 00:49:41 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 74.1 KB, free 911.8 MB)
19/07/31 00:49:41 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 31.6 KB, free 911.7 MB)
19/07/31 00:49:41 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:53873 (size: 31.6 KB, free: 912.2 MB)
19/07/31 00:49:41 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1006
19/07/31 00:49:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[167] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 00:49:41 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
19/07/31 00:49:41 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 84, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 00:49:41 INFO Executor: Running task 0.0 in stage 51.0 (TID 84)
19/07/31 00:49:41 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 00:49:41 INFO Executor: Finished task 0.0 in stage 51.0 (TID 84). 1687 bytes result sent to driver
19/07/31 00:49:41 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 84) in 12 ms on localhost (executor driver) (1/1)
19/07/31 00:49:41 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
19/07/31 00:49:41 INFO DAGScheduler: ShuffleMapStage 51 (collect at utils.scala:204) finished in 0.013 s
19/07/31 00:49:41 INFO DAGScheduler: looking for newly runnable stages
19/07/31 00:49:41 INFO DAGScheduler: running: Set()
19/07/31 00:49:41 INFO DAGScheduler: waiting: Set(ResultStage 52)
19/07/31 00:49:41 INFO DAGScheduler: failed: Set()
19/07/31 00:49:41 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[170] at collect at utils.scala:204), which has no missing parents
19/07/31 00:49:41 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 16.1 KB, free 911.7 MB)
19/07/31 00:49:41 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 7.8 KB, free 911.7 MB)
19/07/31 00:49:41 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 912.2 MB)
19/07/31 00:49:41 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
19/07/31 00:49:41 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 52 (MapPartitionsRDD[170] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 00:49:41 INFO TaskSchedulerImpl: Adding task set 52.0 with 4 tasks
19/07/31 00:49:41 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 85, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 00:49:41 INFO TaskSetManager: Starting task 1.0 in stage 52.0 (TID 86, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 00:49:41 INFO TaskSetManager: Starting task 2.0 in stage 52.0 (TID 87, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 00:49:41 INFO TaskSetManager: Starting task 3.0 in stage 52.0 (TID 88, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 00:49:41 INFO Executor: Running task 0.0 in stage 52.0 (TID 85)
19/07/31 00:49:41 INFO Executor: Running task 1.0 in stage 52.0 (TID 86)
19/07/31 00:49:41 INFO Executor: Running task 2.0 in stage 52.0 (TID 87)
19/07/31 00:49:41 INFO Executor: Running task 3.0 in stage 52.0 (TID 88)
19/07/31 00:49:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:49:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 00:49:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:49:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:49:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:49:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:49:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 00:49:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:49:41 INFO Executor: Finished task 0.0 in stage 52.0 (TID 85). 2299 bytes result sent to driver
19/07/31 00:49:41 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 85) in 46 ms on localhost (executor driver) (1/4)
19/07/31 00:49:41 INFO Executor: Finished task 1.0 in stage 52.0 (TID 86). 2299 bytes result sent to driver
19/07/31 00:49:41 INFO TaskSetManager: Finished task 1.0 in stage 52.0 (TID 86) in 51 ms on localhost (executor driver) (2/4)
19/07/31 00:49:41 INFO Executor: Finished task 2.0 in stage 52.0 (TID 87). 2297 bytes result sent to driver
19/07/31 00:49:41 INFO TaskSetManager: Finished task 2.0 in stage 52.0 (TID 87) in 66 ms on localhost (executor driver) (3/4)
19/07/31 00:49:41 INFO Executor: Finished task 3.0 in stage 52.0 (TID 88). 2275 bytes result sent to driver
19/07/31 00:49:41 INFO TaskSetManager: Finished task 3.0 in stage 52.0 (TID 88) in 66 ms on localhost (executor driver) (4/4)
19/07/31 00:49:41 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
19/07/31 00:49:41 INFO DAGScheduler: ResultStage 52 (collect at utils.scala:204) finished in 0.068 s
19/07/31 00:49:41 INFO DAGScheduler: Job 36 finished: collect at utils.scala:204, took 0.111560 s
19/07/31 00:50:07 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_097`) `dbplyr_098`
ORDER BY `date`) `dbplyr_099`) `dbplyr_100`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 00:50:07 INFO HiveMetaStore: 0: get_database: default
19/07/31 00:50:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 00:50:07 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_101`) `dbplyr_102`
ORDER BY `date`) `dbplyr_103`) `dbplyr_104`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 00:50:07 INFO HiveMetaStore: 0: get_database: default
19/07/31 00:50:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 00:50:07 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1848 - cust_prospect_ind.nullCount#1847) > 0)
19/07/31 00:50:07 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1853 - visit_device_type.nullCount#1852) > 0)
19/07/31 00:50:07 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#1846 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#1845))
19/07/31 00:50:07 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#1851 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#1850))
19/07/31 00:50:07 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 00:50:07 INFO DAGScheduler: Got job 37 (collect at utils.scala:204) with 1 output partitions
19/07/31 00:50:07 INFO DAGScheduler: Final stage: ResultStage 53 (collect at utils.scala:204)
19/07/31 00:50:07 INFO DAGScheduler: Parents of final stage: List()
19/07/31 00:50:07 INFO DAGScheduler: Missing parents: List()
19/07/31 00:50:07 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[175] at collect at utils.scala:204), which has no missing parents
19/07/31 00:50:07 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 71.9 KB, free 911.7 MB)
19/07/31 00:50:07 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.6 MB)
19/07/31 00:50:07 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:53873 (size: 30.4 KB, free: 912.1 MB)
19/07/31 00:50:07 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
19/07/31 00:50:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[175] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 00:50:07 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
19/07/31 00:50:07 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 89, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 00:50:07 INFO Executor: Running task 0.0 in stage 53.0 (TID 89)
19/07/31 00:50:07 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 00:50:07 INFO Executor: Finished task 0.0 in stage 53.0 (TID 89). 4695 bytes result sent to driver
19/07/31 00:50:07 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 89) in 7 ms on localhost (executor driver) (1/1)
19/07/31 00:50:07 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
19/07/31 00:50:07 INFO DAGScheduler: ResultStage 53 (collect at utils.scala:204) finished in 0.007 s
19/07/31 00:50:07 INFO DAGScheduler: Job 37 finished: collect at utils.scala:204, took 0.020633 s
19/07/31 00:50:07 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 00:50:07 INFO DAGScheduler: Registering RDD 176 (collect at utils.scala:204)
19/07/31 00:50:07 INFO DAGScheduler: Got job 38 (collect at utils.scala:204) with 4 output partitions
19/07/31 00:50:07 INFO DAGScheduler: Final stage: ResultStage 55 (collect at utils.scala:204)
19/07/31 00:50:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 54)
19/07/31 00:50:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 54)
19/07/31 00:50:07 INFO DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[176] at collect at utils.scala:204), which has no missing parents
19/07/31 00:50:07 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 74.1 KB, free 911.6 MB)
19/07/31 00:50:07 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 31.7 KB, free 911.5 MB)
19/07/31 00:50:07 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:53873 (size: 31.7 KB, free: 912.1 MB)
19/07/31 00:50:07 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
19/07/31 00:50:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[176] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 00:50:07 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
19/07/31 00:50:07 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 90, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 00:50:07 INFO Executor: Running task 0.0 in stage 54.0 (TID 90)
19/07/31 00:50:07 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 00:50:07 INFO Executor: Finished task 0.0 in stage 54.0 (TID 90). 1687 bytes result sent to driver
19/07/31 00:50:07 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 90) in 11 ms on localhost (executor driver) (1/1)
19/07/31 00:50:07 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
19/07/31 00:50:07 INFO DAGScheduler: ShuffleMapStage 54 (collect at utils.scala:204) finished in 0.013 s
19/07/31 00:50:07 INFO DAGScheduler: looking for newly runnable stages
19/07/31 00:50:07 INFO DAGScheduler: running: Set()
19/07/31 00:50:07 INFO DAGScheduler: waiting: Set(ResultStage 55)
19/07/31 00:50:07 INFO DAGScheduler: failed: Set()
19/07/31 00:50:07 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[179] at collect at utils.scala:204), which has no missing parents
19/07/31 00:50:07 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 16.1 KB, free 911.5 MB)
19/07/31 00:50:07 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 7.8 KB, free 911.5 MB)
19/07/31 00:50:07 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 912.1 MB)
19/07/31 00:50:07 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1006
19/07/31 00:50:07 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 55 (MapPartitionsRDD[179] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 00:50:07 INFO TaskSchedulerImpl: Adding task set 55.0 with 4 tasks
19/07/31 00:50:07 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 91, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 00:50:07 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 92, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 00:50:07 INFO TaskSetManager: Starting task 2.0 in stage 55.0 (TID 93, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 00:50:07 INFO TaskSetManager: Starting task 3.0 in stage 55.0 (TID 94, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 00:50:07 INFO Executor: Running task 1.0 in stage 55.0 (TID 92)
19/07/31 00:50:07 INFO Executor: Running task 2.0 in stage 55.0 (TID 93)
19/07/31 00:50:07 INFO Executor: Running task 3.0 in stage 55.0 (TID 94)
19/07/31 00:50:07 INFO Executor: Running task 0.0 in stage 55.0 (TID 91)
19/07/31 00:50:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:50:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:50:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:50:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:50:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:50:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 00:50:07 INFO Executor: Finished task 1.0 in stage 55.0 (TID 92). 2299 bytes result sent to driver
19/07/31 00:50:07 INFO Executor: Finished task 3.0 in stage 55.0 (TID 94). 2275 bytes result sent to driver
19/07/31 00:50:07 INFO Executor: Finished task 2.0 in stage 55.0 (TID 93). 2297 bytes result sent to driver
19/07/31 00:50:07 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 92) in 8 ms on localhost (executor driver) (1/4)
19/07/31 00:50:07 INFO TaskSetManager: Finished task 2.0 in stage 55.0 (TID 93) in 9 ms on localhost (executor driver) (2/4)
19/07/31 00:50:07 INFO TaskSetManager: Finished task 3.0 in stage 55.0 (TID 94) in 8 ms on localhost (executor driver) (3/4)
19/07/31 00:50:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:50:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:50:07 INFO Executor: Finished task 0.0 in stage 55.0 (TID 91). 2299 bytes result sent to driver
19/07/31 00:50:07 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 91) in 13 ms on localhost (executor driver) (4/4)
19/07/31 00:50:07 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
19/07/31 00:50:07 INFO DAGScheduler: ResultStage 55 (collect at utils.scala:204) finished in 0.013 s
19/07/31 00:50:07 INFO DAGScheduler: Job 38 finished: collect at utils.scala:204, took 0.049724 s
19/07/31 00:51:38 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_105`) `dbplyr_106`
ORDER BY `date`) `dbplyr_107`) `dbplyr_108`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 00:51:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 00:51:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 00:51:38 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_109`) `dbplyr_110`
ORDER BY `date`) `dbplyr_111`) `dbplyr_112`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 00:51:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 00:51:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 00:51:38 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1942 - cust_prospect_ind.nullCount#1941) > 0)
19/07/31 00:51:38 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1947 - visit_device_type.nullCount#1946) > 0)
19/07/31 00:51:38 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#1940 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#1939))
19/07/31 00:51:38 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#1945 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#1944))
19/07/31 00:51:38 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 00:51:38 INFO DAGScheduler: Got job 39 (collect at utils.scala:204) with 1 output partitions
19/07/31 00:51:38 INFO DAGScheduler: Final stage: ResultStage 56 (collect at utils.scala:204)
19/07/31 00:51:38 INFO DAGScheduler: Parents of final stage: List()
19/07/31 00:51:38 INFO DAGScheduler: Missing parents: List()
19/07/31 00:51:38 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[184] at collect at utils.scala:204), which has no missing parents
19/07/31 00:51:38 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 71.9 KB, free 911.4 MB)
19/07/31 00:51:38 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.4 MB)
19/07/31 00:51:38 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:53873 (size: 30.4 KB, free: 912.1 MB)
19/07/31 00:51:38 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
19/07/31 00:51:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[184] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 00:51:38 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
19/07/31 00:51:38 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 95, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 00:51:38 INFO Executor: Running task 0.0 in stage 56.0 (TID 95)
19/07/31 00:51:38 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 00:51:38 INFO Executor: Finished task 0.0 in stage 56.0 (TID 95). 4695 bytes result sent to driver
19/07/31 00:51:38 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 95) in 7 ms on localhost (executor driver) (1/1)
19/07/31 00:51:38 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
19/07/31 00:51:38 INFO DAGScheduler: ResultStage 56 (collect at utils.scala:204) finished in 0.007 s
19/07/31 00:51:38 INFO DAGScheduler: Job 39 finished: collect at utils.scala:204, took 0.019602 s
19/07/31 00:51:38 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 00:51:38 INFO DAGScheduler: Registering RDD 185 (collect at utils.scala:204)
19/07/31 00:51:38 INFO DAGScheduler: Got job 40 (collect at utils.scala:204) with 4 output partitions
19/07/31 00:51:38 INFO DAGScheduler: Final stage: ResultStage 58 (collect at utils.scala:204)
19/07/31 00:51:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 57)
19/07/31 00:51:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 57)
19/07/31 00:51:38 INFO DAGScheduler: Submitting ShuffleMapStage 57 (MapPartitionsRDD[185] at collect at utils.scala:204), which has no missing parents
19/07/31 00:51:38 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 74.1 KB, free 911.3 MB)
19/07/31 00:51:38 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 31.6 KB, free 911.3 MB)
19/07/31 00:51:38 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:53873 (size: 31.6 KB, free: 912.0 MB)
19/07/31 00:51:38 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
19/07/31 00:51:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 57 (MapPartitionsRDD[185] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 00:51:38 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
19/07/31 00:51:38 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 96, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 00:51:38 INFO Executor: Running task 0.0 in stage 57.0 (TID 96)
19/07/31 00:51:38 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 00:51:38 INFO Executor: Finished task 0.0 in stage 57.0 (TID 96). 1687 bytes result sent to driver
19/07/31 00:51:38 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 96) in 16 ms on localhost (executor driver) (1/1)
19/07/31 00:51:38 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
19/07/31 00:51:38 INFO DAGScheduler: ShuffleMapStage 57 (collect at utils.scala:204) finished in 0.016 s
19/07/31 00:51:38 INFO DAGScheduler: looking for newly runnable stages
19/07/31 00:51:38 INFO DAGScheduler: running: Set()
19/07/31 00:51:38 INFO DAGScheduler: waiting: Set(ResultStage 58)
19/07/31 00:51:38 INFO DAGScheduler: failed: Set()
19/07/31 00:51:38 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[188] at collect at utils.scala:204), which has no missing parents
19/07/31 00:51:38 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 16.1 KB, free 911.3 MB)
19/07/31 00:51:38 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 7.8 KB, free 911.3 MB)
19/07/31 00:51:38 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 912.0 MB)
19/07/31 00:51:38 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
19/07/31 00:51:38 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 58 (MapPartitionsRDD[188] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 00:51:38 INFO TaskSchedulerImpl: Adding task set 58.0 with 4 tasks
19/07/31 00:51:38 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 97, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 00:51:38 INFO TaskSetManager: Starting task 1.0 in stage 58.0 (TID 98, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 00:51:38 INFO TaskSetManager: Starting task 2.0 in stage 58.0 (TID 99, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 00:51:38 INFO TaskSetManager: Starting task 3.0 in stage 58.0 (TID 100, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 00:51:38 INFO Executor: Running task 0.0 in stage 58.0 (TID 97)
19/07/31 00:51:38 INFO Executor: Running task 1.0 in stage 58.0 (TID 98)
19/07/31 00:51:38 INFO Executor: Running task 2.0 in stage 58.0 (TID 99)
19/07/31 00:51:38 INFO Executor: Running task 3.0 in stage 58.0 (TID 100)
19/07/31 00:51:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:51:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:51:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:51:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:51:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:51:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:51:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:51:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:51:38 INFO Executor: Finished task 0.0 in stage 58.0 (TID 97). 2299 bytes result sent to driver
19/07/31 00:51:38 INFO Executor: Finished task 3.0 in stage 58.0 (TID 100). 2275 bytes result sent to driver
19/07/31 00:51:38 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 97) in 13 ms on localhost (executor driver) (1/4)
19/07/31 00:51:38 INFO Executor: Finished task 2.0 in stage 58.0 (TID 99). 2297 bytes result sent to driver
19/07/31 00:51:38 INFO TaskSetManager: Finished task 3.0 in stage 58.0 (TID 100) in 11 ms on localhost (executor driver) (2/4)
19/07/31 00:51:38 INFO TaskSetManager: Finished task 2.0 in stage 58.0 (TID 99) in 13 ms on localhost (executor driver) (3/4)
19/07/31 00:51:38 INFO Executor: Finished task 1.0 in stage 58.0 (TID 98). 2299 bytes result sent to driver
19/07/31 00:51:38 INFO TaskSetManager: Finished task 1.0 in stage 58.0 (TID 98) in 13 ms on localhost (executor driver) (4/4)
19/07/31 00:51:38 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
19/07/31 00:51:38 INFO DAGScheduler: ResultStage 58 (collect at utils.scala:204) finished in 0.015 s
19/07/31 00:51:38 INFO DAGScheduler: Job 40 finished: collect at utils.scala:204, took 0.051493 s
19/07/31 00:53:09 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_113`) `dbplyr_114`
ORDER BY `date`) `dbplyr_115`) `dbplyr_116`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 00:53:09 INFO HiveMetaStore: 0: get_database: default
19/07/31 00:53:09 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 00:53:09 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_117`) `dbplyr_118`
ORDER BY `date`) `dbplyr_119`) `dbplyr_120`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 00:53:09 INFO HiveMetaStore: 0: get_database: default
19/07/31 00:53:09 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 00:53:09 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2036 - cust_prospect_ind.nullCount#2035) > 0)
19/07/31 00:53:09 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2041 - visit_device_type.nullCount#2040) > 0)
19/07/31 00:53:09 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#2034 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#2033))
19/07/31 00:53:09 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#2039 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#2038))
19/07/31 00:53:09 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 00:53:09 INFO DAGScheduler: Got job 41 (collect at utils.scala:204) with 1 output partitions
19/07/31 00:53:09 INFO DAGScheduler: Final stage: ResultStage 59 (collect at utils.scala:204)
19/07/31 00:53:09 INFO DAGScheduler: Parents of final stage: List()
19/07/31 00:53:09 INFO DAGScheduler: Missing parents: List()
19/07/31 00:53:09 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[193] at collect at utils.scala:204), which has no missing parents
19/07/31 00:53:09 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 71.9 KB, free 911.2 MB)
19/07/31 00:53:09 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 30.3 KB, free 911.2 MB)
19/07/31 00:53:09 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:53873 (size: 30.3 KB, free: 912.0 MB)
19/07/31 00:53:09 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
19/07/31 00:53:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[193] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 00:53:09 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
19/07/31 00:53:09 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 101, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 00:53:09 INFO Executor: Running task 0.0 in stage 59.0 (TID 101)
19/07/31 00:53:09 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 00:53:09 INFO Executor: Finished task 0.0 in stage 59.0 (TID 101). 4695 bytes result sent to driver
19/07/31 00:53:09 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 101) in 7 ms on localhost (executor driver) (1/1)
19/07/31 00:53:09 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
19/07/31 00:53:09 INFO DAGScheduler: ResultStage 59 (collect at utils.scala:204) finished in 0.008 s
19/07/31 00:53:09 INFO DAGScheduler: Job 41 finished: collect at utils.scala:204, took 0.020418 s
19/07/31 00:53:09 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 00:53:09 INFO DAGScheduler: Registering RDD 194 (collect at utils.scala:204)
19/07/31 00:53:09 INFO DAGScheduler: Got job 42 (collect at utils.scala:204) with 4 output partitions
19/07/31 00:53:09 INFO DAGScheduler: Final stage: ResultStage 61 (collect at utils.scala:204)
19/07/31 00:53:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 60)
19/07/31 00:53:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 60)
19/07/31 00:53:09 INFO DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[194] at collect at utils.scala:204), which has no missing parents
19/07/31 00:53:09 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 74.1 KB, free 911.1 MB)
19/07/31 00:53:09 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 31.6 KB, free 911.1 MB)
19/07/31 00:53:09 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:53873 (size: 31.6 KB, free: 912.0 MB)
19/07/31 00:53:09 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
19/07/31 00:53:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[194] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 00:53:09 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
19/07/31 00:53:09 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 102, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 00:53:09 INFO Executor: Running task 0.0 in stage 60.0 (TID 102)
19/07/31 00:53:09 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 00:53:09 INFO Executor: Finished task 0.0 in stage 60.0 (TID 102). 1687 bytes result sent to driver
19/07/31 00:53:09 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 102) in 17 ms on localhost (executor driver) (1/1)
19/07/31 00:53:09 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
19/07/31 00:53:09 INFO DAGScheduler: ShuffleMapStage 60 (collect at utils.scala:204) finished in 0.018 s
19/07/31 00:53:09 INFO DAGScheduler: looking for newly runnable stages
19/07/31 00:53:09 INFO DAGScheduler: running: Set()
19/07/31 00:53:09 INFO DAGScheduler: waiting: Set(ResultStage 61)
19/07/31 00:53:09 INFO DAGScheduler: failed: Set()
19/07/31 00:53:09 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[197] at collect at utils.scala:204), which has no missing parents
19/07/31 00:53:09 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 16.1 KB, free 911.1 MB)
19/07/31 00:53:09 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 7.8 KB, free 911.0 MB)
19/07/31 00:53:09 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 912.0 MB)
19/07/31 00:53:09 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1006
19/07/31 00:53:09 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 61 (MapPartitionsRDD[197] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 00:53:09 INFO TaskSchedulerImpl: Adding task set 61.0 with 4 tasks
19/07/31 00:53:09 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 103, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 00:53:09 INFO TaskSetManager: Starting task 1.0 in stage 61.0 (TID 104, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 00:53:09 INFO TaskSetManager: Starting task 2.0 in stage 61.0 (TID 105, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 00:53:09 INFO TaskSetManager: Starting task 3.0 in stage 61.0 (TID 106, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 00:53:09 INFO Executor: Running task 0.0 in stage 61.0 (TID 103)
19/07/31 00:53:09 INFO Executor: Running task 1.0 in stage 61.0 (TID 104)
19/07/31 00:53:09 INFO Executor: Running task 2.0 in stage 61.0 (TID 105)
19/07/31 00:53:09 INFO Executor: Running task 3.0 in stage 61.0 (TID 106)
19/07/31 00:53:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:53:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:53:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:53:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:53:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:53:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 00:53:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:53:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 00:53:09 INFO Executor: Finished task 1.0 in stage 61.0 (TID 104). 2299 bytes result sent to driver
19/07/31 00:53:09 INFO TaskSetManager: Finished task 1.0 in stage 61.0 (TID 104) in 17 ms on localhost (executor driver) (1/4)
19/07/31 00:53:09 INFO Executor: Finished task 0.0 in stage 61.0 (TID 103). 2299 bytes result sent to driver
19/07/31 00:53:09 INFO Executor: Finished task 3.0 in stage 61.0 (TID 106). 2275 bytes result sent to driver
19/07/31 00:53:09 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 103) in 18 ms on localhost (executor driver) (2/4)
19/07/31 00:53:09 INFO TaskSetManager: Finished task 3.0 in stage 61.0 (TID 106) in 17 ms on localhost (executor driver) (3/4)
19/07/31 00:53:09 INFO Executor: Finished task 2.0 in stage 61.0 (TID 105). 2297 bytes result sent to driver
19/07/31 00:53:09 INFO TaskSetManager: Finished task 2.0 in stage 61.0 (TID 105) in 17 ms on localhost (executor driver) (4/4)
19/07/31 00:53:09 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
19/07/31 00:53:09 INFO DAGScheduler: ResultStage 61 (collect at utils.scala:204) finished in 0.020 s
19/07/31 00:53:09 INFO DAGScheduler: Job 42 finished: collect at utils.scala:204, took 0.059100 s
19/07/31 00:55:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
19/07/31 00:55:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 00:55:57 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 00:55:57 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 00:55:57 INFO DAGScheduler: Got job 43 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 00:55:57 INFO DAGScheduler: Final stage: ResultStage 62 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 00:55:57 INFO DAGScheduler: Parents of final stage: List()
19/07/31 00:55:57 INFO DAGScheduler: Missing parents: List()
19/07/31 00:55:57 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[198] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 00:55:57 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 87.5 KB, free 911.0 MB)
19/07/31 00:55:57 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 34.3 KB, free 910.9 MB)
19/07/31 00:55:57 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:53873 (size: 34.3 KB, free: 911.9 MB)
19/07/31 00:55:57 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1006
19/07/31 00:55:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[198] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 00:55:57 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
19/07/31 00:55:57 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 107, localhost, executor driver, partition 0, PROCESS_LOCAL, 5530 bytes)
19/07/31 00:55:57 INFO Executor: Running task 0.0 in stage 62.0 (TID 107)
19/07/31 00:55:57 INFO BlockManager: Found block rdd_73_0 locally
19/07/31 00:55:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 00:55:57 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 00:55:57 INFO FileOutputCommitter: Saved output of task 'attempt_20190731005557_0062_m_000000_0' to file:/Users/6jncnk4f/Desktop/anomaly/result.csv/_temporary/0/task_20190731005557_0062_m_000000
19/07/31 00:55:57 INFO SparkHadoopMapRedUtil: attempt_20190731005557_0062_m_000000_0: Committed
19/07/31 00:55:57 INFO Executor: Finished task 0.0 in stage 62.0 (TID 107). 1619 bytes result sent to driver
19/07/31 00:55:57 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 107) in 55 ms on localhost (executor driver) (1/1)
19/07/31 00:55:57 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
19/07/31 00:55:57 INFO DAGScheduler: ResultStage 62 (csv at NativeMethodAccessorImpl.java:0) finished in 0.055 s
19/07/31 00:55:57 INFO DAGScheduler: Job 43 finished: csv at NativeMethodAccessorImpl.java:0, took 0.078801 s
19/07/31 00:55:57 INFO FileFormatWriter: Job null committed.
19/07/31 00:56:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
19/07/31 00:56:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 00:56:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 00:56:17 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 00:56:17 INFO DAGScheduler: Got job 44 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 00:56:17 INFO DAGScheduler: Final stage: ResultStage 63 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 00:56:17 INFO DAGScheduler: Parents of final stage: List()
19/07/31 00:56:17 INFO DAGScheduler: Missing parents: List()
19/07/31 00:56:17 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[201] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 00:56:17 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 87.5 KB, free 910.8 MB)
19/07/31 00:56:17 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 34.3 KB, free 910.8 MB)
19/07/31 00:56:17 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:53873 (size: 34.3 KB, free: 911.9 MB)
19/07/31 00:56:17 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1006
19/07/31 00:56:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[201] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 00:56:17 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
19/07/31 00:56:17 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 108, localhost, executor driver, partition 0, PROCESS_LOCAL, 5530 bytes)
19/07/31 00:56:17 INFO Executor: Running task 0.0 in stage 63.0 (TID 108)
19/07/31 00:56:17 INFO BlockManager: Found block rdd_73_0 locally
19/07/31 00:56:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 00:56:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 00:56:17 INFO FileOutputCommitter: Saved output of task 'attempt_20190731005617_0063_m_000000_0' to file:/Users/6jncnk4f/Desktop/anomaly/result.csv/_temporary/0/task_20190731005617_0063_m_000000
19/07/31 00:56:17 INFO SparkHadoopMapRedUtil: attempt_20190731005617_0063_m_000000_0: Committed
19/07/31 00:56:17 INFO Executor: Finished task 0.0 in stage 63.0 (TID 108). 1619 bytes result sent to driver
19/07/31 00:56:17 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 108) in 75 ms on localhost (executor driver) (1/1)
19/07/31 00:56:17 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
19/07/31 00:56:17 INFO DAGScheduler: ResultStage 63 (csv at NativeMethodAccessorImpl.java:0) finished in 0.076 s
19/07/31 00:56:17 INFO DAGScheduler: Job 44 finished: csv at NativeMethodAccessorImpl.java:0, took 0.112014 s
19/07/31 00:56:17 INFO FileFormatWriter: Job null committed.
19/07/31 00:57:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
19/07/31 00:57:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 00:57:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 00:57:50 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 00:57:50 INFO DAGScheduler: Got job 45 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 00:57:50 INFO DAGScheduler: Final stage: ResultStage 64 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 00:57:50 INFO DAGScheduler: Parents of final stage: List()
19/07/31 00:57:50 INFO DAGScheduler: Missing parents: List()
19/07/31 00:57:50 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[204] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 00:57:50 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 87.5 KB, free 910.7 MB)
19/07/31 00:57:50 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 34.3 KB, free 910.7 MB)
19/07/31 00:57:50 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:53873 (size: 34.3 KB, free: 911.9 MB)
19/07/31 00:57:50 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1006
19/07/31 00:57:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[204] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 00:57:50 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
19/07/31 00:57:50 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 109, localhost, executor driver, partition 0, PROCESS_LOCAL, 5530 bytes)
19/07/31 00:57:50 INFO Executor: Running task 0.0 in stage 64.0 (TID 109)
19/07/31 00:57:50 INFO BlockManager: Found block rdd_73_0 locally
19/07/31 00:57:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 00:57:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 00:57:50 INFO FileOutputCommitter: Saved output of task 'attempt_20190731005750_0064_m_000000_0' to file:/Users/6jncnk4f/Desktop/anomaly/result.csv/_temporary/0/task_20190731005750_0064_m_000000
19/07/31 00:57:50 INFO SparkHadoopMapRedUtil: attempt_20190731005750_0064_m_000000_0: Committed
19/07/31 00:57:50 INFO Executor: Finished task 0.0 in stage 64.0 (TID 109). 1576 bytes result sent to driver
19/07/31 00:57:50 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 109) in 40 ms on localhost (executor driver) (1/1)
19/07/31 00:57:50 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
19/07/31 00:57:50 INFO DAGScheduler: ResultStage 64 (csv at NativeMethodAccessorImpl.java:0) finished in 0.040 s
19/07/31 00:57:50 INFO DAGScheduler: Job 45 finished: csv at NativeMethodAccessorImpl.java:0, took 0.071763 s
19/07/31 00:57:50 INFO FileFormatWriter: Job null committed.
19/07/31 00:58:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
19/07/31 00:58:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 00:58:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 00:58:12 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 00:58:12 INFO DAGScheduler: Got job 46 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 00:58:12 INFO DAGScheduler: Final stage: ResultStage 65 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 00:58:12 INFO DAGScheduler: Parents of final stage: List()
19/07/31 00:58:12 INFO DAGScheduler: Missing parents: List()
19/07/31 00:58:12 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[207] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 00:58:12 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 87.5 KB, free 910.6 MB)
19/07/31 00:58:12 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 34.3 KB, free 910.6 MB)
19/07/31 00:58:12 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:53873 (size: 34.3 KB, free: 911.8 MB)
19/07/31 00:58:12 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1006
19/07/31 00:58:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[207] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 00:58:12 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
19/07/31 00:58:12 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 110, localhost, executor driver, partition 0, PROCESS_LOCAL, 5530 bytes)
19/07/31 00:58:12 INFO Executor: Running task 0.0 in stage 65.0 (TID 110)
19/07/31 00:58:12 INFO BlockManager: Found block rdd_73_0 locally
19/07/31 00:58:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 00:58:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 00:58:12 INFO FileOutputCommitter: Saved output of task 'attempt_20190731005812_0065_m_000000_0' to file:/Users/6jncnk4f/Desktop/anomaly/result/_temporary/0/task_20190731005812_0065_m_000000
19/07/31 00:58:12 INFO SparkHadoopMapRedUtil: attempt_20190731005812_0065_m_000000_0: Committed
19/07/31 00:58:12 INFO Executor: Finished task 0.0 in stage 65.0 (TID 110). 1576 bytes result sent to driver
19/07/31 00:58:12 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 110) in 43 ms on localhost (executor driver) (1/1)
19/07/31 00:58:12 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
19/07/31 00:58:12 INFO DAGScheduler: ResultStage 65 (csv at NativeMethodAccessorImpl.java:0) finished in 0.043 s
19/07/31 00:58:12 INFO DAGScheduler: Job 46 finished: csv at NativeMethodAccessorImpl.java:0, took 0.075729 s
19/07/31 00:58:12 INFO FileFormatWriter: Job null committed.
19/07/31 01:00:11 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_121`) `dbplyr_122`
ORDER BY `date`) `dbplyr_123`) `dbplyr_124`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 01:00:11 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:00:11 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:00:12 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_125`) `dbplyr_126`
ORDER BY `date`) `dbplyr_127`) `dbplyr_128`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 01:00:12 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:00:12 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:00:12 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2254 - cust_prospect_ind.nullCount#2253) > 0)
19/07/31 01:00:12 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2259 - visit_device_type.nullCount#2258) > 0)
19/07/31 01:00:12 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#2252 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#2251))
19/07/31 01:00:12 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#2257 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#2256))
19/07/31 01:00:12 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:00:12 INFO DAGScheduler: Got job 47 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:00:12 INFO DAGScheduler: Final stage: ResultStage 66 (collect at utils.scala:204)
19/07/31 01:00:12 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:00:12 INFO DAGScheduler: Missing parents: List()
19/07/31 01:00:12 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[214] at collect at utils.scala:204), which has no missing parents
19/07/31 01:00:12 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 71.9 KB, free 910.5 MB)
19/07/31 01:00:12 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 30.3 KB, free 910.5 MB)
19/07/31 01:00:12 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:53873 (size: 30.3 KB, free: 911.8 MB)
19/07/31 01:00:12 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1006
19/07/31 01:00:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[214] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:00:12 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
19/07/31 01:00:12 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 111, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:00:12 INFO Executor: Running task 0.0 in stage 66.0 (TID 111)
19/07/31 01:00:12 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:00:12 INFO Executor: Finished task 0.0 in stage 66.0 (TID 111). 4695 bytes result sent to driver
19/07/31 01:00:12 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 111) in 10 ms on localhost (executor driver) (1/1)
19/07/31 01:00:12 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
19/07/31 01:00:12 INFO DAGScheduler: ResultStage 66 (collect at utils.scala:204) finished in 0.010 s
19/07/31 01:00:12 INFO DAGScheduler: Job 47 finished: collect at utils.scala:204, took 0.039154 s
19/07/31 01:00:12 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:00:12 INFO DAGScheduler: Registering RDD 215 (collect at utils.scala:204)
19/07/31 01:00:12 INFO DAGScheduler: Got job 48 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:00:12 INFO DAGScheduler: Final stage: ResultStage 68 (collect at utils.scala:204)
19/07/31 01:00:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67)
19/07/31 01:00:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 67)
19/07/31 01:00:12 INFO DAGScheduler: Submitting ShuffleMapStage 67 (MapPartitionsRDD[215] at collect at utils.scala:204), which has no missing parents
19/07/31 01:00:12 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 74.1 KB, free 910.4 MB)
19/07/31 01:00:12 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 31.6 KB, free 910.4 MB)
19/07/31 01:00:12 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:53873 (size: 31.6 KB, free: 911.8 MB)
19/07/31 01:00:12 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1006
19/07/31 01:00:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 67 (MapPartitionsRDD[215] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:00:12 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks
19/07/31 01:00:12 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 112, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:00:12 INFO Executor: Running task 0.0 in stage 67.0 (TID 112)
19/07/31 01:00:12 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:00:12 INFO Executor: Finished task 0.0 in stage 67.0 (TID 112). 1687 bytes result sent to driver
19/07/31 01:00:12 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 112) in 23 ms on localhost (executor driver) (1/1)
19/07/31 01:00:12 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
19/07/31 01:00:12 INFO DAGScheduler: ShuffleMapStage 67 (collect at utils.scala:204) finished in 0.023 s
19/07/31 01:00:12 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:00:12 INFO DAGScheduler: running: Set()
19/07/31 01:00:12 INFO DAGScheduler: waiting: Set(ResultStage 68)
19/07/31 01:00:12 INFO DAGScheduler: failed: Set()
19/07/31 01:00:12 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[218] at collect at utils.scala:204), which has no missing parents
19/07/31 01:00:12 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 16.1 KB, free 910.4 MB)
19/07/31 01:00:12 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 7.8 KB, free 910.3 MB)
19/07/31 01:00:12 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 911.8 MB)
19/07/31 01:00:12 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1006
19/07/31 01:00:12 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 68 (MapPartitionsRDD[218] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:00:12 INFO TaskSchedulerImpl: Adding task set 68.0 with 4 tasks
19/07/31 01:00:12 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 113, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:00:12 INFO TaskSetManager: Starting task 1.0 in stage 68.0 (TID 114, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:00:12 INFO TaskSetManager: Starting task 2.0 in stage 68.0 (TID 115, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:00:12 INFO TaskSetManager: Starting task 3.0 in stage 68.0 (TID 116, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:00:12 INFO Executor: Running task 0.0 in stage 68.0 (TID 113)
19/07/31 01:00:12 INFO Executor: Running task 1.0 in stage 68.0 (TID 114)
19/07/31 01:00:12 INFO Executor: Running task 2.0 in stage 68.0 (TID 115)
19/07/31 01:00:12 INFO Executor: Running task 3.0 in stage 68.0 (TID 116)
19/07/31 01:00:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:00:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:00:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:00:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:00:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:00:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:00:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:00:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:00:12 INFO Executor: Finished task 0.0 in stage 68.0 (TID 113). 2299 bytes result sent to driver
19/07/31 01:00:12 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 113) in 17 ms on localhost (executor driver) (1/4)
19/07/31 01:00:12 INFO Executor: Finished task 1.0 in stage 68.0 (TID 114). 2299 bytes result sent to driver
19/07/31 01:00:12 INFO Executor: Finished task 2.0 in stage 68.0 (TID 115). 2297 bytes result sent to driver
19/07/31 01:00:12 INFO Executor: Finished task 3.0 in stage 68.0 (TID 116). 2275 bytes result sent to driver
19/07/31 01:00:12 INFO TaskSetManager: Finished task 2.0 in stage 68.0 (TID 115) in 21 ms on localhost (executor driver) (2/4)
19/07/31 01:00:12 INFO TaskSetManager: Finished task 3.0 in stage 68.0 (TID 116) in 21 ms on localhost (executor driver) (3/4)
19/07/31 01:00:12 INFO TaskSetManager: Finished task 1.0 in stage 68.0 (TID 114) in 22 ms on localhost (executor driver) (4/4)
19/07/31 01:00:12 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
19/07/31 01:00:12 INFO DAGScheduler: ResultStage 68 (collect at utils.scala:204) finished in 0.023 s
19/07/31 01:00:12 INFO DAGScheduler: Job 48 finished: collect at utils.scala:204, took 0.102594 s
19/07/31 01:00:16 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_129`) `dbplyr_130`
ORDER BY `date`) `dbplyr_131`) `dbplyr_132`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 01:00:16 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:00:16 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:00:16 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_133`) `dbplyr_134`
ORDER BY `date`) `dbplyr_135`) `dbplyr_136`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 01:00:16 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:00:16 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:00:16 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2348 - cust_prospect_ind.nullCount#2347) > 0)
19/07/31 01:00:16 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2353 - visit_device_type.nullCount#2352) > 0)
19/07/31 01:00:16 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#2346 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#2345))
19/07/31 01:00:16 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#2351 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#2350))
19/07/31 01:00:16 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:00:16 INFO DAGScheduler: Got job 49 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:00:16 INFO DAGScheduler: Final stage: ResultStage 69 (collect at utils.scala:204)
19/07/31 01:00:16 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:00:16 INFO DAGScheduler: Missing parents: List()
19/07/31 01:00:16 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[223] at collect at utils.scala:204), which has no missing parents
19/07/31 01:00:16 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 71.9 KB, free 910.3 MB)
19/07/31 01:00:16 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.2 MB)
19/07/31 01:00:16 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:53873 (size: 30.4 KB, free: 911.7 MB)
19/07/31 01:00:16 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1006
19/07/31 01:00:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[223] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:00:16 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks
19/07/31 01:00:16 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 117, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:00:16 INFO Executor: Running task 0.0 in stage 69.0 (TID 117)
19/07/31 01:00:16 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:00:16 INFO Executor: Finished task 0.0 in stage 69.0 (TID 117). 4695 bytes result sent to driver
19/07/31 01:00:16 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 117) in 11 ms on localhost (executor driver) (1/1)
19/07/31 01:00:16 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
19/07/31 01:00:16 INFO DAGScheduler: ResultStage 69 (collect at utils.scala:204) finished in 0.011 s
19/07/31 01:00:16 INFO DAGScheduler: Job 49 finished: collect at utils.scala:204, took 0.038597 s
19/07/31 01:00:16 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:00:16 INFO DAGScheduler: Registering RDD 224 (collect at utils.scala:204)
19/07/31 01:00:16 INFO DAGScheduler: Got job 50 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:00:16 INFO DAGScheduler: Final stage: ResultStage 71 (collect at utils.scala:204)
19/07/31 01:00:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)
19/07/31 01:00:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 70)
19/07/31 01:00:16 INFO DAGScheduler: Submitting ShuffleMapStage 70 (MapPartitionsRDD[224] at collect at utils.scala:204), which has no missing parents
19/07/31 01:00:16 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 74.1 KB, free 910.2 MB)
19/07/31 01:00:16 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.1 MB)
19/07/31 01:00:16 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:53873 (size: 31.7 KB, free: 911.7 MB)
19/07/31 01:00:16 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1006
19/07/31 01:00:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[224] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:00:16 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks
19/07/31 01:00:16 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 118, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:00:16 INFO Executor: Running task 0.0 in stage 70.0 (TID 118)
19/07/31 01:00:16 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:00:16 INFO Executor: Finished task 0.0 in stage 70.0 (TID 118). 1687 bytes result sent to driver
19/07/31 01:00:16 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 118) in 10 ms on localhost (executor driver) (1/1)
19/07/31 01:00:16 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
19/07/31 01:00:16 INFO DAGScheduler: ShuffleMapStage 70 (collect at utils.scala:204) finished in 0.010 s
19/07/31 01:00:16 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:00:16 INFO DAGScheduler: running: Set()
19/07/31 01:00:16 INFO DAGScheduler: waiting: Set(ResultStage 71)
19/07/31 01:00:16 INFO DAGScheduler: failed: Set()
19/07/31 01:00:16 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[227] at collect at utils.scala:204), which has no missing parents
19/07/31 01:00:16 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 16.1 KB, free 910.1 MB)
19/07/31 01:00:16 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 7.8 KB, free 910.1 MB)
19/07/31 01:00:16 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 911.7 MB)
19/07/31 01:00:16 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1006
19/07/31 01:00:16 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 71 (MapPartitionsRDD[227] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:00:16 INFO TaskSchedulerImpl: Adding task set 71.0 with 4 tasks
19/07/31 01:00:16 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 119, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:00:16 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 120, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:00:16 INFO TaskSetManager: Starting task 2.0 in stage 71.0 (TID 121, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:00:16 INFO TaskSetManager: Starting task 3.0 in stage 71.0 (TID 122, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:00:16 INFO Executor: Running task 0.0 in stage 71.0 (TID 119)
19/07/31 01:00:16 INFO Executor: Running task 1.0 in stage 71.0 (TID 120)
19/07/31 01:00:16 INFO Executor: Running task 2.0 in stage 71.0 (TID 121)
19/07/31 01:00:16 INFO Executor: Running task 3.0 in stage 71.0 (TID 122)
19/07/31 01:00:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:00:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:00:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:00:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:00:16 INFO Executor: Finished task 1.0 in stage 71.0 (TID 120). 2299 bytes result sent to driver
19/07/31 01:00:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:00:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:00:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:00:16 INFO Executor: Finished task 2.0 in stage 71.0 (TID 121). 2297 bytes result sent to driver
19/07/31 01:00:16 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 120) in 10 ms on localhost (executor driver) (1/4)
19/07/31 01:00:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:00:16 INFO Executor: Finished task 3.0 in stage 71.0 (TID 122). 2275 bytes result sent to driver
19/07/31 01:00:16 INFO TaskSetManager: Finished task 2.0 in stage 71.0 (TID 121) in 11 ms on localhost (executor driver) (2/4)
19/07/31 01:00:16 INFO Executor: Finished task 0.0 in stage 71.0 (TID 119). 2299 bytes result sent to driver
19/07/31 01:00:16 INFO TaskSetManager: Finished task 3.0 in stage 71.0 (TID 122) in 13 ms on localhost (executor driver) (3/4)
19/07/31 01:00:16 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 119) in 15 ms on localhost (executor driver) (4/4)
19/07/31 01:00:16 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
19/07/31 01:00:16 INFO DAGScheduler: ResultStage 71 (collect at utils.scala:204) finished in 0.016 s
19/07/31 01:00:16 INFO DAGScheduler: Job 50 finished: collect at utils.scala:204, took 0.065592 s
19/07/31 01:01:21 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_137`) `dbplyr_138`
ORDER BY `date`) `dbplyr_139`) `dbplyr_140`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 01:01:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:22 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_141`) `dbplyr_142`
ORDER BY `date`) `dbplyr_143`) `dbplyr_144`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 01:01:22 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:22 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:22 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2442 - cust_prospect_ind.nullCount#2441) > 0)
19/07/31 01:01:22 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2447 - visit_device_type.nullCount#2446) > 0)
19/07/31 01:01:22 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#2440 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#2439))
19/07/31 01:01:22 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#2445 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#2444))
19/07/31 01:01:22 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:22 INFO DAGScheduler: Got job 51 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:01:22 INFO DAGScheduler: Final stage: ResultStage 72 (collect at utils.scala:204)
19/07/31 01:01:22 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:01:22 INFO DAGScheduler: Missing parents: List()
19/07/31 01:01:22 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[232] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:22 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 71.9 KB, free 910.0 MB)
19/07/31 01:01:22 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.0 MB)
19/07/31 01:01:22 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:53873 (size: 30.4 KB, free: 911.7 MB)
19/07/31 01:01:22 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[232] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:22 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks
19/07/31 01:01:22 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 123, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:01:22 INFO Executor: Running task 0.0 in stage 72.0 (TID 123)
19/07/31 01:01:22 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:22 INFO Executor: Finished task 0.0 in stage 72.0 (TID 123). 4695 bytes result sent to driver
19/07/31 01:01:22 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 123) in 10 ms on localhost (executor driver) (1/1)
19/07/31 01:01:22 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
19/07/31 01:01:22 INFO DAGScheduler: ResultStage 72 (collect at utils.scala:204) finished in 0.010 s
19/07/31 01:01:22 INFO DAGScheduler: Job 51 finished: collect at utils.scala:204, took 0.035458 s
19/07/31 01:01:22 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:22 INFO DAGScheduler: Registering RDD 233 (collect at utils.scala:204)
19/07/31 01:01:22 INFO DAGScheduler: Got job 52 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:01:22 INFO DAGScheduler: Final stage: ResultStage 74 (collect at utils.scala:204)
19/07/31 01:01:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)
19/07/31 01:01:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 73)
19/07/31 01:01:22 INFO DAGScheduler: Submitting ShuffleMapStage 73 (MapPartitionsRDD[233] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:22 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 74.1 KB, free 909.9 MB)
19/07/31 01:01:22 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 31.7 KB, free 909.9 MB)
19/07/31 01:01:22 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:53873 (size: 31.7 KB, free: 911.6 MB)
19/07/31 01:01:22 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 73 (MapPartitionsRDD[233] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:22 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks
19/07/31 01:01:22 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 124, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:01:22 INFO Executor: Running task 0.0 in stage 73.0 (TID 124)
19/07/31 01:01:22 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:22 INFO Executor: Finished task 0.0 in stage 73.0 (TID 124). 1687 bytes result sent to driver
19/07/31 01:01:22 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 124) in 18 ms on localhost (executor driver) (1/1)
19/07/31 01:01:22 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
19/07/31 01:01:22 INFO DAGScheduler: ShuffleMapStage 73 (collect at utils.scala:204) finished in 0.019 s
19/07/31 01:01:22 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:01:22 INFO DAGScheduler: running: Set()
19/07/31 01:01:22 INFO DAGScheduler: waiting: Set(ResultStage 74)
19/07/31 01:01:22 INFO DAGScheduler: failed: Set()
19/07/31 01:01:22 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[236] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:22 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 16.1 KB, free 909.9 MB)
19/07/31 01:01:22 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 7.8 KB, free 909.9 MB)
19/07/31 01:01:22 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 911.6 MB)
19/07/31 01:01:22 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 74 (MapPartitionsRDD[236] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:01:22 INFO TaskSchedulerImpl: Adding task set 74.0 with 4 tasks
19/07/31 01:01:22 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 125, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:01:22 INFO TaskSetManager: Starting task 1.0 in stage 74.0 (TID 126, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:01:22 INFO TaskSetManager: Starting task 2.0 in stage 74.0 (TID 127, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:01:22 INFO TaskSetManager: Starting task 3.0 in stage 74.0 (TID 128, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:01:22 INFO Executor: Running task 0.0 in stage 74.0 (TID 125)
19/07/31 01:01:22 INFO Executor: Running task 1.0 in stage 74.0 (TID 126)
19/07/31 01:01:22 INFO Executor: Running task 2.0 in stage 74.0 (TID 127)
19/07/31 01:01:22 INFO Executor: Running task 3.0 in stage 74.0 (TID 128)
19/07/31 01:01:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:22 INFO Executor: Finished task 1.0 in stage 74.0 (TID 126). 2299 bytes result sent to driver
19/07/31 01:01:22 INFO Executor: Finished task 2.0 in stage 74.0 (TID 127). 2297 bytes result sent to driver
19/07/31 01:01:22 INFO TaskSetManager: Finished task 2.0 in stage 74.0 (TID 127) in 18 ms on localhost (executor driver) (1/4)
19/07/31 01:01:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:22 INFO TaskSetManager: Finished task 1.0 in stage 74.0 (TID 126) in 18 ms on localhost (executor driver) (2/4)
19/07/31 01:01:22 INFO Executor: Finished task 0.0 in stage 74.0 (TID 125). 2299 bytes result sent to driver
19/07/31 01:01:22 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 125) in 20 ms on localhost (executor driver) (3/4)
19/07/31 01:01:22 INFO Executor: Finished task 3.0 in stage 74.0 (TID 128). 2275 bytes result sent to driver
19/07/31 01:01:22 INFO TaskSetManager: Finished task 3.0 in stage 74.0 (TID 128) in 22 ms on localhost (executor driver) (4/4)
19/07/31 01:01:22 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
19/07/31 01:01:22 INFO DAGScheduler: ResultStage 74 (collect at utils.scala:204) finished in 0.023 s
19/07/31 01:01:22 INFO DAGScheduler: Job 52 finished: collect at utils.scala:204, took 0.084100 s
19/07/31 01:01:23 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_145`) `dbplyr_146`
ORDER BY `date`) `dbplyr_147`) `dbplyr_148`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 01:01:23 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:23 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:23 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_149`) `dbplyr_150`
ORDER BY `date`) `dbplyr_151`) `dbplyr_152`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 01:01:23 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:23 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:23 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2536 - cust_prospect_ind.nullCount#2535) > 0)
19/07/31 01:01:23 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2541 - visit_device_type.nullCount#2540) > 0)
19/07/31 01:01:23 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#2534 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#2533))
19/07/31 01:01:23 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#2539 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#2538))
19/07/31 01:01:23 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:23 INFO DAGScheduler: Got job 53 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:01:23 INFO DAGScheduler: Final stage: ResultStage 75 (collect at utils.scala:204)
19/07/31 01:01:23 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:01:23 INFO DAGScheduler: Missing parents: List()
19/07/31 01:01:23 INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[241] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:23 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 71.9 KB, free 909.8 MB)
19/07/31 01:01:23 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 30.3 KB, free 909.8 MB)
19/07/31 01:01:23 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:53873 (size: 30.3 KB, free: 911.6 MB)
19/07/31 01:01:23 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[241] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:23 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks
19/07/31 01:01:23 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 129, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:01:23 INFO Executor: Running task 0.0 in stage 75.0 (TID 129)
19/07/31 01:01:23 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:23 INFO Executor: Finished task 0.0 in stage 75.0 (TID 129). 4695 bytes result sent to driver
19/07/31 01:01:23 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 129) in 7 ms on localhost (executor driver) (1/1)
19/07/31 01:01:23 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
19/07/31 01:01:23 INFO DAGScheduler: ResultStage 75 (collect at utils.scala:204) finished in 0.007 s
19/07/31 01:01:23 INFO DAGScheduler: Job 53 finished: collect at utils.scala:204, took 0.026233 s
19/07/31 01:01:23 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:23 INFO DAGScheduler: Registering RDD 242 (collect at utils.scala:204)
19/07/31 01:01:23 INFO DAGScheduler: Got job 54 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:01:23 INFO DAGScheduler: Final stage: ResultStage 77 (collect at utils.scala:204)
19/07/31 01:01:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 76)
19/07/31 01:01:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 76)
19/07/31 01:01:23 INFO DAGScheduler: Submitting ShuffleMapStage 76 (MapPartitionsRDD[242] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:23 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 74.1 KB, free 909.7 MB)
19/07/31 01:01:23 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 31.6 KB, free 909.7 MB)
19/07/31 01:01:23 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:53873 (size: 31.6 KB, free: 911.6 MB)
19/07/31 01:01:23 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 76 (MapPartitionsRDD[242] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:23 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks
19/07/31 01:01:23 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 130, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:01:23 INFO Executor: Running task 0.0 in stage 76.0 (TID 130)
19/07/31 01:01:23 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:23 INFO Executor: Finished task 0.0 in stage 76.0 (TID 130). 1687 bytes result sent to driver
19/07/31 01:01:23 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 130) in 14 ms on localhost (executor driver) (1/1)
19/07/31 01:01:23 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
19/07/31 01:01:23 INFO DAGScheduler: ShuffleMapStage 76 (collect at utils.scala:204) finished in 0.015 s
19/07/31 01:01:23 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:01:23 INFO DAGScheduler: running: Set()
19/07/31 01:01:23 INFO DAGScheduler: waiting: Set(ResultStage 77)
19/07/31 01:01:23 INFO DAGScheduler: failed: Set()
19/07/31 01:01:23 INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[245] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:23 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 16.1 KB, free 909.7 MB)
19/07/31 01:01:23 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 7.8 KB, free 909.7 MB)
19/07/31 01:01:23 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 911.5 MB)
19/07/31 01:01:23 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:23 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 77 (MapPartitionsRDD[245] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:01:23 INFO TaskSchedulerImpl: Adding task set 77.0 with 4 tasks
19/07/31 01:01:23 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 131, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:01:23 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 132, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:01:23 INFO TaskSetManager: Starting task 2.0 in stage 77.0 (TID 133, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:01:23 INFO TaskSetManager: Starting task 3.0 in stage 77.0 (TID 134, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:01:23 INFO Executor: Running task 0.0 in stage 77.0 (TID 131)
19/07/31 01:01:23 INFO Executor: Running task 3.0 in stage 77.0 (TID 134)
19/07/31 01:01:23 INFO Executor: Running task 2.0 in stage 77.0 (TID 133)
19/07/31 01:01:23 INFO Executor: Running task 1.0 in stage 77.0 (TID 132)
19/07/31 01:01:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:01:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:23 INFO Executor: Finished task 3.0 in stage 77.0 (TID 134). 2275 bytes result sent to driver
19/07/31 01:01:23 INFO Executor: Finished task 2.0 in stage 77.0 (TID 133). 2297 bytes result sent to driver
19/07/31 01:01:23 INFO Executor: Finished task 0.0 in stage 77.0 (TID 131). 2299 bytes result sent to driver
19/07/31 01:01:23 INFO Executor: Finished task 1.0 in stage 77.0 (TID 132). 2299 bytes result sent to driver
19/07/31 01:01:23 INFO TaskSetManager: Finished task 3.0 in stage 77.0 (TID 134) in 8 ms on localhost (executor driver) (1/4)
19/07/31 01:01:23 INFO TaskSetManager: Finished task 2.0 in stage 77.0 (TID 133) in 9 ms on localhost (executor driver) (2/4)
19/07/31 01:01:23 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 132) in 9 ms on localhost (executor driver) (3/4)
19/07/31 01:01:23 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 131) in 9 ms on localhost (executor driver) (4/4)
19/07/31 01:01:23 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
19/07/31 01:01:23 INFO DAGScheduler: ResultStage 77 (collect at utils.scala:204) finished in 0.009 s
19/07/31 01:01:23 INFO DAGScheduler: Job 54 finished: collect at utils.scala:204, took 0.060047 s
19/07/31 01:01:24 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_153`) `dbplyr_154`
ORDER BY `date`) `dbplyr_155`) `dbplyr_156`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Mobile Phone"))
19/07/31 01:01:24 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:24 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:24 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_157`) `dbplyr_158`
ORDER BY `date`) `dbplyr_159`) `dbplyr_160`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Mobile Phone"))
19/07/31 01:01:24 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:24 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:24 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2630 - cust_prospect_ind.nullCount#2629) > 0)
19/07/31 01:01:24 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2635 - visit_device_type.nullCount#2634) > 0)
19/07/31 01:01:24 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#2628 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#2627))
19/07/31 01:01:24 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#2633 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#2632))
19/07/31 01:01:24 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:24 INFO DAGScheduler: Got job 55 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:01:24 INFO DAGScheduler: Final stage: ResultStage 78 (collect at utils.scala:204)
19/07/31 01:01:24 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:01:24 INFO DAGScheduler: Missing parents: List()
19/07/31 01:01:24 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[250] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:24 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 71.9 KB, free 909.6 MB)
19/07/31 01:01:24 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 30.4 KB, free 909.6 MB)
19/07/31 01:01:24 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:53873 (size: 30.4 KB, free: 911.5 MB)
19/07/31 01:01:24 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[250] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:24 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks
19/07/31 01:01:24 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 135, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:01:24 INFO Executor: Running task 0.0 in stage 78.0 (TID 135)
19/07/31 01:01:24 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:24 INFO Executor: Finished task 0.0 in stage 78.0 (TID 135). 4646 bytes result sent to driver
19/07/31 01:01:24 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 135) in 8 ms on localhost (executor driver) (1/1)
19/07/31 01:01:24 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
19/07/31 01:01:24 INFO DAGScheduler: ResultStage 78 (collect at utils.scala:204) finished in 0.008 s
19/07/31 01:01:24 INFO DAGScheduler: Job 55 finished: collect at utils.scala:204, took 0.030060 s
19/07/31 01:01:24 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:24 INFO DAGScheduler: Registering RDD 251 (collect at utils.scala:204)
19/07/31 01:01:24 INFO DAGScheduler: Got job 56 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:01:24 INFO DAGScheduler: Final stage: ResultStage 80 (collect at utils.scala:204)
19/07/31 01:01:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 79)
19/07/31 01:01:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 79)
19/07/31 01:01:24 INFO DAGScheduler: Submitting ShuffleMapStage 79 (MapPartitionsRDD[251] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:24 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 74.1 KB, free 909.5 MB)
19/07/31 01:01:24 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 31.7 KB, free 909.5 MB)
19/07/31 01:01:24 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:53873 (size: 31.7 KB, free: 911.5 MB)
19/07/31 01:01:24 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 79 (MapPartitionsRDD[251] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:24 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks
19/07/31 01:01:24 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 136, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:01:24 INFO Executor: Running task 0.0 in stage 79.0 (TID 136)
19/07/31 01:01:24 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:24 INFO Executor: Finished task 0.0 in stage 79.0 (TID 136). 1687 bytes result sent to driver
19/07/31 01:01:24 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 136) in 18 ms on localhost (executor driver) (1/1)
19/07/31 01:01:24 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
19/07/31 01:01:24 INFO DAGScheduler: ShuffleMapStage 79 (collect at utils.scala:204) finished in 0.018 s
19/07/31 01:01:24 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:01:24 INFO DAGScheduler: running: Set()
19/07/31 01:01:24 INFO DAGScheduler: waiting: Set(ResultStage 80)
19/07/31 01:01:24 INFO DAGScheduler: failed: Set()
19/07/31 01:01:24 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[254] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:24 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 16.1 KB, free 909.4 MB)
19/07/31 01:01:24 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 7.8 KB, free 909.4 MB)
19/07/31 01:01:24 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 911.5 MB)
19/07/31 01:01:24 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:24 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 80 (MapPartitionsRDD[254] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:01:24 INFO TaskSchedulerImpl: Adding task set 80.0 with 4 tasks
19/07/31 01:01:24 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 137, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:01:24 INFO TaskSetManager: Starting task 1.0 in stage 80.0 (TID 138, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:01:24 INFO TaskSetManager: Starting task 2.0 in stage 80.0 (TID 139, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:01:24 INFO TaskSetManager: Starting task 3.0 in stage 80.0 (TID 140, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:01:24 INFO Executor: Running task 0.0 in stage 80.0 (TID 137)
19/07/31 01:01:24 INFO Executor: Running task 1.0 in stage 80.0 (TID 138)
19/07/31 01:01:24 INFO Executor: Running task 3.0 in stage 80.0 (TID 140)
19/07/31 01:01:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:24 INFO Executor: Running task 2.0 in stage 80.0 (TID 139)
19/07/31 01:01:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:01:24 INFO Executor: Finished task 1.0 in stage 80.0 (TID 138). 2300 bytes result sent to driver
19/07/31 01:01:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:24 INFO Executor: Finished task 3.0 in stage 80.0 (TID 140). 2271 bytes result sent to driver
19/07/31 01:01:24 INFO Executor: Finished task 0.0 in stage 80.0 (TID 137). 2294 bytes result sent to driver
19/07/31 01:01:24 INFO TaskSetManager: Finished task 1.0 in stage 80.0 (TID 138) in 16 ms on localhost (executor driver) (1/4)
19/07/31 01:01:24 INFO TaskSetManager: Finished task 3.0 in stage 80.0 (TID 140) in 16 ms on localhost (executor driver) (2/4)
19/07/31 01:01:24 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 137) in 18 ms on localhost (executor driver) (3/4)
19/07/31 01:01:24 INFO Executor: Finished task 2.0 in stage 80.0 (TID 139). 2300 bytes result sent to driver
19/07/31 01:01:24 INFO TaskSetManager: Finished task 2.0 in stage 80.0 (TID 139) in 19 ms on localhost (executor driver) (4/4)
19/07/31 01:01:24 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
19/07/31 01:01:24 INFO DAGScheduler: ResultStage 80 (collect at utils.scala:204) finished in 0.020 s
19/07/31 01:01:24 INFO DAGScheduler: Job 56 finished: collect at utils.scala:204, took 0.099121 s
19/07/31 01:01:25 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_161`) `dbplyr_162`
ORDER BY `date`) `dbplyr_163`) `dbplyr_164`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Mobile Phone"))
19/07/31 01:01:25 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:25 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_165`) `dbplyr_166`
ORDER BY `date`) `dbplyr_167`) `dbplyr_168`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Mobile Phone"))
19/07/31 01:01:25 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:25 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2724 - cust_prospect_ind.nullCount#2723) > 0)
19/07/31 01:01:25 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2729 - visit_device_type.nullCount#2728) > 0)
19/07/31 01:01:25 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#2722 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#2721))
19/07/31 01:01:25 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#2727 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#2726))
19/07/31 01:01:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:25 INFO DAGScheduler: Got job 57 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:01:25 INFO DAGScheduler: Final stage: ResultStage 81 (collect at utils.scala:204)
19/07/31 01:01:25 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:01:25 INFO DAGScheduler: Missing parents: List()
19/07/31 01:01:25 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[259] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:25 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 71.9 KB, free 909.4 MB)
19/07/31 01:01:25 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 30.3 KB, free 909.3 MB)
19/07/31 01:01:25 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:53873 (size: 30.3 KB, free: 911.5 MB)
19/07/31 01:01:25 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[259] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:25 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks
19/07/31 01:01:25 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 141, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:01:25 INFO Executor: Running task 0.0 in stage 81.0 (TID 141)
19/07/31 01:01:25 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:25 INFO Executor: Finished task 0.0 in stage 81.0 (TID 141). 4646 bytes result sent to driver
19/07/31 01:01:25 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 141) in 7 ms on localhost (executor driver) (1/1)
19/07/31 01:01:25 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
19/07/31 01:01:25 INFO DAGScheduler: ResultStage 81 (collect at utils.scala:204) finished in 0.007 s
19/07/31 01:01:25 INFO DAGScheduler: Job 57 finished: collect at utils.scala:204, took 0.017303 s
19/07/31 01:01:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:25 INFO DAGScheduler: Registering RDD 260 (collect at utils.scala:204)
19/07/31 01:01:25 INFO DAGScheduler: Got job 58 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:01:25 INFO DAGScheduler: Final stage: ResultStage 83 (collect at utils.scala:204)
19/07/31 01:01:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 82)
19/07/31 01:01:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 82)
19/07/31 01:01:25 INFO DAGScheduler: Submitting ShuffleMapStage 82 (MapPartitionsRDD[260] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:25 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 74.1 KB, free 909.3 MB)
19/07/31 01:01:25 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 31.6 KB, free 909.2 MB)
19/07/31 01:01:25 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:53873 (size: 31.6 KB, free: 911.4 MB)
19/07/31 01:01:25 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 82 (MapPartitionsRDD[260] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:25 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks
19/07/31 01:01:25 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 142, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:01:25 INFO Executor: Running task 0.0 in stage 82.0 (TID 142)
19/07/31 01:01:25 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:25 INFO Executor: Finished task 0.0 in stage 82.0 (TID 142). 1687 bytes result sent to driver
19/07/31 01:01:25 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 142) in 28 ms on localhost (executor driver) (1/1)
19/07/31 01:01:25 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
19/07/31 01:01:25 INFO DAGScheduler: ShuffleMapStage 82 (collect at utils.scala:204) finished in 0.028 s
19/07/31 01:01:25 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:01:25 INFO DAGScheduler: running: Set()
19/07/31 01:01:25 INFO DAGScheduler: waiting: Set(ResultStage 83)
19/07/31 01:01:25 INFO DAGScheduler: failed: Set()
19/07/31 01:01:25 INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[263] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:25 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 16.1 KB, free 909.2 MB)
19/07/31 01:01:25 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 7.8 KB, free 909.2 MB)
19/07/31 01:01:25 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 911.4 MB)
19/07/31 01:01:25 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:25 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 83 (MapPartitionsRDD[263] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:01:25 INFO TaskSchedulerImpl: Adding task set 83.0 with 4 tasks
19/07/31 01:01:25 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 143, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:01:25 INFO TaskSetManager: Starting task 1.0 in stage 83.0 (TID 144, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:01:25 INFO TaskSetManager: Starting task 2.0 in stage 83.0 (TID 145, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:01:25 INFO TaskSetManager: Starting task 3.0 in stage 83.0 (TID 146, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:01:25 INFO Executor: Running task 0.0 in stage 83.0 (TID 143)
19/07/31 01:01:25 INFO Executor: Running task 1.0 in stage 83.0 (TID 144)
19/07/31 01:01:25 INFO Executor: Running task 2.0 in stage 83.0 (TID 145)
19/07/31 01:01:25 INFO Executor: Running task 3.0 in stage 83.0 (TID 146)
19/07/31 01:01:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:01:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:01:25 INFO Executor: Finished task 3.0 in stage 83.0 (TID 146). 2275 bytes result sent to driver
19/07/31 01:01:25 INFO Executor: Finished task 2.0 in stage 83.0 (TID 145). 2290 bytes result sent to driver
19/07/31 01:01:25 INFO TaskSetManager: Finished task 3.0 in stage 83.0 (TID 146) in 17 ms on localhost (executor driver) (1/4)
19/07/31 01:01:25 INFO TaskSetManager: Finished task 2.0 in stage 83.0 (TID 145) in 17 ms on localhost (executor driver) (2/4)
19/07/31 01:01:25 INFO Executor: Finished task 0.0 in stage 83.0 (TID 143). 2294 bytes result sent to driver
19/07/31 01:01:25 INFO Executor: Finished task 1.0 in stage 83.0 (TID 144). 2271 bytes result sent to driver
19/07/31 01:01:25 INFO TaskSetManager: Finished task 1.0 in stage 83.0 (TID 144) in 21 ms on localhost (executor driver) (3/4)
19/07/31 01:01:25 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 143) in 22 ms on localhost (executor driver) (4/4)
19/07/31 01:01:25 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
19/07/31 01:01:25 INFO DAGScheduler: ResultStage 83 (collect at utils.scala:204) finished in 0.022 s
19/07/31 01:01:25 INFO DAGScheduler: Job 58 finished: collect at utils.scala:204, took 0.114767 s
19/07/31 01:01:26 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_169`) `dbplyr_170`
ORDER BY `date`) `dbplyr_171`) `dbplyr_172`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Mobile Phone"))
19/07/31 01:01:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:26 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_173`) `dbplyr_174`
ORDER BY `date`) `dbplyr_175`) `dbplyr_176`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Mobile Phone"))
19/07/31 01:01:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:26 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2818 - cust_prospect_ind.nullCount#2817) > 0)
19/07/31 01:01:26 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2823 - visit_device_type.nullCount#2822) > 0)
19/07/31 01:01:26 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#2816 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#2815))
19/07/31 01:01:26 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#2821 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#2820))
19/07/31 01:01:26 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:26 INFO DAGScheduler: Got job 59 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:01:26 INFO DAGScheduler: Final stage: ResultStage 84 (collect at utils.scala:204)
19/07/31 01:01:26 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:01:26 INFO DAGScheduler: Missing parents: List()
19/07/31 01:01:26 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[268] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:26 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 71.9 KB, free 909.1 MB)
19/07/31 01:01:26 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 30.3 KB, free 909.1 MB)
19/07/31 01:01:26 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:53873 (size: 30.3 KB, free: 911.4 MB)
19/07/31 01:01:26 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[268] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:26 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks
19/07/31 01:01:26 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 147, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:01:26 INFO Executor: Running task 0.0 in stage 84.0 (TID 147)
19/07/31 01:01:26 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:26 INFO Executor: Finished task 0.0 in stage 84.0 (TID 147). 4646 bytes result sent to driver
19/07/31 01:01:26 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 147) in 9 ms on localhost (executor driver) (1/1)
19/07/31 01:01:26 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
19/07/31 01:01:26 INFO DAGScheduler: ResultStage 84 (collect at utils.scala:204) finished in 0.009 s
19/07/31 01:01:26 INFO DAGScheduler: Job 59 finished: collect at utils.scala:204, took 0.026931 s
19/07/31 01:01:26 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:26 INFO DAGScheduler: Registering RDD 269 (collect at utils.scala:204)
19/07/31 01:01:26 INFO DAGScheduler: Got job 60 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:01:26 INFO DAGScheduler: Final stage: ResultStage 86 (collect at utils.scala:204)
19/07/31 01:01:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 85)
19/07/31 01:01:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 85)
19/07/31 01:01:26 INFO DAGScheduler: Submitting ShuffleMapStage 85 (MapPartitionsRDD[269] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:26 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 74.1 KB, free 909.0 MB)
19/07/31 01:01:26 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 31.6 KB, free 909.0 MB)
19/07/31 01:01:26 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:53873 (size: 31.6 KB, free: 911.4 MB)
19/07/31 01:01:26 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 85 (MapPartitionsRDD[269] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:26 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks
19/07/31 01:01:26 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 148, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:01:26 INFO Executor: Running task 0.0 in stage 85.0 (TID 148)
19/07/31 01:01:26 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:26 INFO Executor: Finished task 0.0 in stage 85.0 (TID 148). 1687 bytes result sent to driver
19/07/31 01:01:26 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 148) in 11 ms on localhost (executor driver) (1/1)
19/07/31 01:01:26 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
19/07/31 01:01:26 INFO DAGScheduler: ShuffleMapStage 85 (collect at utils.scala:204) finished in 0.012 s
19/07/31 01:01:26 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:01:26 INFO DAGScheduler: running: Set()
19/07/31 01:01:26 INFO DAGScheduler: waiting: Set(ResultStage 86)
19/07/31 01:01:26 INFO DAGScheduler: failed: Set()
19/07/31 01:01:26 INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[272] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:26 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 16.1 KB, free 909.0 MB)
19/07/31 01:01:26 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 7.8 KB, free 909.0 MB)
19/07/31 01:01:26 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 911.3 MB)
19/07/31 01:01:26 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 86 (MapPartitionsRDD[272] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:01:26 INFO TaskSchedulerImpl: Adding task set 86.0 with 4 tasks
19/07/31 01:01:26 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 149, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:01:26 INFO TaskSetManager: Starting task 1.0 in stage 86.0 (TID 150, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:01:26 INFO TaskSetManager: Starting task 2.0 in stage 86.0 (TID 151, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:01:26 INFO TaskSetManager: Starting task 3.0 in stage 86.0 (TID 152, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:01:26 INFO Executor: Running task 0.0 in stage 86.0 (TID 149)
19/07/31 01:01:26 INFO Executor: Running task 1.0 in stage 86.0 (TID 150)
19/07/31 01:01:26 INFO Executor: Running task 2.0 in stage 86.0 (TID 151)
19/07/31 01:01:26 INFO Executor: Running task 3.0 in stage 86.0 (TID 152)
19/07/31 01:01:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:01:26 INFO Executor: Finished task 1.0 in stage 86.0 (TID 150). 2271 bytes result sent to driver
19/07/31 01:01:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:01:26 INFO Executor: Finished task 2.0 in stage 86.0 (TID 151). 2290 bytes result sent to driver
19/07/31 01:01:26 INFO Executor: Finished task 0.0 in stage 86.0 (TID 149). 2294 bytes result sent to driver
19/07/31 01:01:26 INFO Executor: Finished task 3.0 in stage 86.0 (TID 152). 2275 bytes result sent to driver
19/07/31 01:01:26 INFO TaskSetManager: Finished task 1.0 in stage 86.0 (TID 150) in 13 ms on localhost (executor driver) (1/4)
19/07/31 01:01:26 INFO TaskSetManager: Finished task 2.0 in stage 86.0 (TID 151) in 13 ms on localhost (executor driver) (2/4)
19/07/31 01:01:26 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 149) in 13 ms on localhost (executor driver) (3/4)
19/07/31 01:01:26 INFO TaskSetManager: Finished task 3.0 in stage 86.0 (TID 152) in 13 ms on localhost (executor driver) (4/4)
19/07/31 01:01:26 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
19/07/31 01:01:26 INFO DAGScheduler: ResultStage 86 (collect at utils.scala:204) finished in 0.014 s
19/07/31 01:01:26 INFO DAGScheduler: Job 60 finished: collect at utils.scala:204, took 0.057419 s
19/07/31 01:01:27 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_177`) `dbplyr_178`
ORDER BY `date`) `dbplyr_179`) `dbplyr_180`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Desktop"))
19/07/31 01:01:27 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:27 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:27 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_181`) `dbplyr_182`
ORDER BY `date`) `dbplyr_183`) `dbplyr_184`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Desktop"))
19/07/31 01:01:27 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:27 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:27 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2912 - cust_prospect_ind.nullCount#2911) > 0)
19/07/31 01:01:27 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2917 - visit_device_type.nullCount#2916) > 0)
19/07/31 01:01:27 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#2910 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#2909))
19/07/31 01:01:27 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#2915 <= Desktop) && (Desktop <= visit_device_type.upperBound#2914))
19/07/31 01:01:27 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:27 INFO DAGScheduler: Got job 61 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:01:27 INFO DAGScheduler: Final stage: ResultStage 87 (collect at utils.scala:204)
19/07/31 01:01:27 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:01:27 INFO DAGScheduler: Missing parents: List()
19/07/31 01:01:27 INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[277] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:27 INFO ContextCleaner: Cleaned accumulator 1403
19/07/31 01:01:27 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 71.9 KB, free 908.9 MB)
19/07/31 01:01:27 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 127.0.0.1:53873 in memory (size: 31.6 KB, free: 911.4 MB)
19/07/31 01:01:27 INFO ContextCleaner: Cleaned accumulator 2158
19/07/31 01:01:27 INFO ContextCleaner: Cleaned accumulator 2074
19/07/31 01:01:27 INFO ContextCleaner: Cleaned accumulator 2233
19/07/31 01:01:27 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 911.4 MB)
19/07/31 01:01:27 INFO ContextCleaner: Cleaned accumulator 2071
19/07/31 01:01:27 INFO ContextCleaner: Cleaned shuffle 16
19/07/31 01:01:27 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:53873 in memory (size: 34.3 KB, free: 911.4 MB)
19/07/31 01:01:27 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:53873 in memory (size: 31.6 KB, free: 911.4 MB)
19/07/31 01:01:27 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 911.5 MB)
19/07/31 01:01:27 INFO ContextCleaner: Cleaned accumulator 2313
19/07/31 01:01:27 INFO ContextCleaner: Cleaned accumulator 1406
19/07/31 01:01:27 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:53873 in memory (size: 31.7 KB, free: 911.5 MB)
19/07/31 01:01:27 INFO ContextCleaner: Cleaned accumulator 1914
19/07/31 01:01:27 INFO ContextCleaner: Cleaned accumulator 1402
19/07/31 01:01:27 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:53873 in memory (size: 31.7 KB, free: 911.5 MB)
19/07/31 01:01:27 INFO ContextCleaner: Cleaned accumulator 1991
19/07/31 01:01:27 INFO ContextCleaner: Cleaned accumulator 1995
19/07/31 01:01:27 INFO ContextCleaner: Cleaned accumulator 1409
19/07/31 01:01:27 INFO ContextCleaner: Cleaned accumulator 1487
19/07/31 01:01:27 INFO ContextCleaner: Cleaned accumulator 1726
19/07/31 01:01:27 INFO ContextCleaner: Cleaned accumulator 1485
19/07/31 01:01:27 INFO ContextCleaner: Cleaned accumulator 2393
19/07/31 01:01:27 INFO ContextCleaner: Cleaned accumulator 2154
19/07/31 01:01:27 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:53873 in memory (size: 30.3 KB, free: 911.5 MB)
19/07/31 01:01:27 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:53873 in memory (size: 31.6 KB, free: 911.6 MB)
19/07/31 01:01:27 INFO ContextCleaner: Cleaned shuffle 23
19/07/31 01:01:27 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 911.6 MB)
19/07/31 01:01:28 INFO ContextCleaner: Cleaned shuffle 22
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1405
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 911.6 MB)
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:53873 in memory (size: 30.3 KB, free: 911.6 MB)
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1568
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:53873 in memory (size: 31.7 KB, free: 911.7 MB)
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:53873 in memory (size: 31.6 KB, free: 911.7 MB)
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1994
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:53873 in memory (size: 34.3 KB, free: 911.7 MB)
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1910
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2155
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1570
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:53873 in memory (size: 30.3 KB, free: 911.8 MB)
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2312
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1776
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1484
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1566
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 911.8 MB)
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2152
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1488
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:53873 in memory (size: 31.6 KB, free: 911.8 MB)
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 911.8 MB)
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1408
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2319
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1491
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1645
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1996
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2076
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1486
19/07/31 01:01:28 INFO ContextCleaner: Cleaned shuffle 24
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2235
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2236
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1569
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1565
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1992
19/07/31 01:01:28 INFO ContextCleaner: Cleaned shuffle 15
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1993
19/07/31 01:01:28 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.5 MB)
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1912
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1489
19/07/31 01:01:28 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:53873 (size: 30.4 KB, free: 911.8 MB)
19/07/31 01:01:28 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 911.8 MB)
19/07/31 01:01:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[277] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:28 INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1989
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2075
19/07/31 01:01:28 INFO ContextCleaner: Cleaned shuffle 21
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2070
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1915
19/07/31 01:01:28 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 153, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2314
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2318
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:53873 in memory (size: 30.3 KB, free: 911.9 MB)
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1567
19/07/31 01:01:28 INFO Executor: Running task 0.0 in stage 87.0 (TID 153)
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1913
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 127.0.0.1:53873 in memory (size: 30.3 KB, free: 911.9 MB)
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 911.9 MB)
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1564
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 911.9 MB)
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2315
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2238
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2150
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:53873 in memory (size: 34.3 KB, free: 912.0 MB)
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:53873 in memory (size: 31.6 KB, free: 912.0 MB)
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1483
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1407
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2317
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 912.0 MB)
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:53873 in memory (size: 31.6 KB, free: 912.1 MB)
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2153
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2231
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2077
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1490
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 912.1 MB)
19/07/31 01:01:28 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2073
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 912.1 MB)
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 912.1 MB)
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 912.1 MB)
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1801
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1911
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1572
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2316
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1571
19/07/31 01:01:28 INFO ContextCleaner: Cleaned shuffle 25
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1410
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1826
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:53873 in memory (size: 31.7 KB, free: 912.1 MB)
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2237
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1990
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2151
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1907
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2234
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1988
19/07/31 01:01:28 INFO Executor: Finished task 0.0 in stage 87.0 (TID 153). 4695 bytes result sent to driver
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:53873 in memory (size: 30.3 KB, free: 912.1 MB)
19/07/31 01:01:28 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 153) in 30 ms on localhost (executor driver) (1/1)
19/07/31 01:01:28 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1404
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2239
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2069
19/07/31 01:01:28 INFO DAGScheduler: ResultStage 87 (collect at utils.scala:204) finished in 0.030 s
19/07/31 01:01:28 INFO DAGScheduler: Job 61 finished: collect at utils.scala:204, took 0.136387 s
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 912.2 MB)
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2157
19/07/31 01:01:28 INFO ContextCleaner: Cleaned shuffle 20
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1909
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2320
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1751
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2072
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:53873 in memory (size: 34.3 KB, free: 912.2 MB)
19/07/31 01:01:28 INFO ContextCleaner: Cleaned shuffle 17
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 1908
19/07/31 01:01:28 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 912.2 MB)
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2232
19/07/31 01:01:28 INFO ContextCleaner: Cleaned accumulator 2156
19/07/31 01:01:28 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:28 INFO DAGScheduler: Registering RDD 278 (collect at utils.scala:204)
19/07/31 01:01:28 INFO DAGScheduler: Got job 62 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:01:28 INFO DAGScheduler: Final stage: ResultStage 89 (collect at utils.scala:204)
19/07/31 01:01:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 88)
19/07/31 01:01:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 88)
19/07/31 01:01:28 INFO DAGScheduler: Submitting ShuffleMapStage 88 (MapPartitionsRDD[278] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:28 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 74.1 KB, free 911.8 MB)
19/07/31 01:01:28 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 31.7 KB, free 911.7 MB)
19/07/31 01:01:28 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:53873 (size: 31.7 KB, free: 912.2 MB)
19/07/31 01:01:28 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 88 (MapPartitionsRDD[278] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:28 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks
19/07/31 01:01:28 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 154, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:01:28 INFO Executor: Running task 0.0 in stage 88.0 (TID 154)
19/07/31 01:01:28 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:28 INFO Executor: Finished task 0.0 in stage 88.0 (TID 154). 1687 bytes result sent to driver
19/07/31 01:01:28 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 154) in 19 ms on localhost (executor driver) (1/1)
19/07/31 01:01:28 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
19/07/31 01:01:28 INFO DAGScheduler: ShuffleMapStage 88 (collect at utils.scala:204) finished in 0.020 s
19/07/31 01:01:28 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:01:28 INFO DAGScheduler: running: Set()
19/07/31 01:01:28 INFO DAGScheduler: waiting: Set(ResultStage 89)
19/07/31 01:01:28 INFO DAGScheduler: failed: Set()
19/07/31 01:01:28 INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[281] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:28 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 16.1 KB, free 911.7 MB)
19/07/31 01:01:28 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 7.8 KB, free 911.7 MB)
19/07/31 01:01:28 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 912.2 MB)
19/07/31 01:01:28 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:28 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 89 (MapPartitionsRDD[281] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:01:28 INFO TaskSchedulerImpl: Adding task set 89.0 with 4 tasks
19/07/31 01:01:28 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 155, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:01:28 INFO TaskSetManager: Starting task 1.0 in stage 89.0 (TID 156, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:01:28 INFO TaskSetManager: Starting task 2.0 in stage 89.0 (TID 157, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:01:28 INFO TaskSetManager: Starting task 3.0 in stage 89.0 (TID 158, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:01:28 INFO Executor: Running task 1.0 in stage 89.0 (TID 156)
19/07/31 01:01:28 INFO Executor: Running task 0.0 in stage 89.0 (TID 155)
19/07/31 01:01:28 INFO Executor: Running task 3.0 in stage 89.0 (TID 158)
19/07/31 01:01:28 INFO Executor: Running task 2.0 in stage 89.0 (TID 157)
19/07/31 01:01:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:28 INFO Executor: Finished task 1.0 in stage 89.0 (TID 156). 2304 bytes result sent to driver
19/07/31 01:01:28 INFO TaskSetManager: Finished task 1.0 in stage 89.0 (TID 156) in 32 ms on localhost (executor driver) (1/4)
19/07/31 01:01:28 INFO Executor: Finished task 2.0 in stage 89.0 (TID 157). 2304 bytes result sent to driver
19/07/31 01:01:28 INFO Executor: Finished task 0.0 in stage 89.0 (TID 155). 2312 bytes result sent to driver
19/07/31 01:01:28 INFO TaskSetManager: Finished task 2.0 in stage 89.0 (TID 157) in 37 ms on localhost (executor driver) (2/4)
19/07/31 01:01:28 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 155) in 37 ms on localhost (executor driver) (3/4)
19/07/31 01:01:28 INFO Executor: Finished task 3.0 in stage 89.0 (TID 158). 2287 bytes result sent to driver
19/07/31 01:01:28 INFO TaskSetManager: Finished task 3.0 in stage 89.0 (TID 158) in 37 ms on localhost (executor driver) (4/4)
19/07/31 01:01:28 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
19/07/31 01:01:28 INFO DAGScheduler: ResultStage 89 (collect at utils.scala:204) finished in 0.040 s
19/07/31 01:01:28 INFO DAGScheduler: Job 62 finished: collect at utils.scala:204, took 0.091010 s
19/07/31 01:01:29 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_185`) `dbplyr_186`
ORDER BY `date`) `dbplyr_187`) `dbplyr_188`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Desktop"))
19/07/31 01:01:29 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:29 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:29 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_189`) `dbplyr_190`
ORDER BY `date`) `dbplyr_191`) `dbplyr_192`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Desktop"))
19/07/31 01:01:29 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:29 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:29 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3006 - cust_prospect_ind.nullCount#3005) > 0)
19/07/31 01:01:29 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3011 - visit_device_type.nullCount#3010) > 0)
19/07/31 01:01:29 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#3004 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#3003))
19/07/31 01:01:29 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#3009 <= Desktop) && (Desktop <= visit_device_type.upperBound#3008))
19/07/31 01:01:29 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:29 INFO DAGScheduler: Got job 63 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:01:29 INFO DAGScheduler: Final stage: ResultStage 90 (collect at utils.scala:204)
19/07/31 01:01:29 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:01:29 INFO DAGScheduler: Missing parents: List()
19/07/31 01:01:29 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[286] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:29 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 71.9 KB, free 911.7 MB)
19/07/31 01:01:29 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 30.3 KB, free 911.6 MB)
19/07/31 01:01:29 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 127.0.0.1:53873 (size: 30.3 KB, free: 912.1 MB)
19/07/31 01:01:29 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[286] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:29 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks
19/07/31 01:01:29 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 159, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:01:29 INFO Executor: Running task 0.0 in stage 90.0 (TID 159)
19/07/31 01:01:29 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:29 INFO Executor: Finished task 0.0 in stage 90.0 (TID 159). 4646 bytes result sent to driver
19/07/31 01:01:29 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 159) in 6 ms on localhost (executor driver) (1/1)
19/07/31 01:01:29 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
19/07/31 01:01:29 INFO DAGScheduler: ResultStage 90 (collect at utils.scala:204) finished in 0.006 s
19/07/31 01:01:29 INFO DAGScheduler: Job 63 finished: collect at utils.scala:204, took 0.020927 s
19/07/31 01:01:29 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:29 INFO DAGScheduler: Registering RDD 287 (collect at utils.scala:204)
19/07/31 01:01:29 INFO DAGScheduler: Got job 64 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:01:29 INFO DAGScheduler: Final stage: ResultStage 92 (collect at utils.scala:204)
19/07/31 01:01:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 91)
19/07/31 01:01:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 91)
19/07/31 01:01:29 INFO DAGScheduler: Submitting ShuffleMapStage 91 (MapPartitionsRDD[287] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:29 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 74.1 KB, free 911.6 MB)
19/07/31 01:01:29 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 31.6 KB, free 911.5 MB)
19/07/31 01:01:29 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 127.0.0.1:53873 (size: 31.6 KB, free: 912.1 MB)
19/07/31 01:01:29 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 91 (MapPartitionsRDD[287] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:29 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks
19/07/31 01:01:29 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 160, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:01:29 INFO Executor: Running task 0.0 in stage 91.0 (TID 160)
19/07/31 01:01:29 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:29 INFO Executor: Finished task 0.0 in stage 91.0 (TID 160). 1687 bytes result sent to driver
19/07/31 01:01:29 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 160) in 15 ms on localhost (executor driver) (1/1)
19/07/31 01:01:29 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
19/07/31 01:01:29 INFO DAGScheduler: ShuffleMapStage 91 (collect at utils.scala:204) finished in 0.016 s
19/07/31 01:01:29 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:01:29 INFO DAGScheduler: running: Set()
19/07/31 01:01:29 INFO DAGScheduler: waiting: Set(ResultStage 92)
19/07/31 01:01:29 INFO DAGScheduler: failed: Set()
19/07/31 01:01:29 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[290] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:29 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 16.1 KB, free 911.5 MB)
19/07/31 01:01:29 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 7.8 KB, free 911.5 MB)
19/07/31 01:01:29 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 912.1 MB)
19/07/31 01:01:29 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 92 (MapPartitionsRDD[290] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:01:29 INFO TaskSchedulerImpl: Adding task set 92.0 with 4 tasks
19/07/31 01:01:29 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 161, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:01:29 INFO TaskSetManager: Starting task 1.0 in stage 92.0 (TID 162, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:01:29 INFO TaskSetManager: Starting task 2.0 in stage 92.0 (TID 163, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:01:29 INFO TaskSetManager: Starting task 3.0 in stage 92.0 (TID 164, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:01:29 INFO Executor: Running task 1.0 in stage 92.0 (TID 162)
19/07/31 01:01:29 INFO Executor: Running task 0.0 in stage 92.0 (TID 161)
19/07/31 01:01:29 INFO Executor: Running task 2.0 in stage 92.0 (TID 163)
19/07/31 01:01:29 INFO Executor: Running task 3.0 in stage 92.0 (TID 164)
19/07/31 01:01:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:01:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/07/31 01:01:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:01:29 INFO Executor: Finished task 3.0 in stage 92.0 (TID 164). 2268 bytes result sent to driver
19/07/31 01:01:29 INFO Executor: Finished task 2.0 in stage 92.0 (TID 163). 2295 bytes result sent to driver
19/07/31 01:01:29 INFO Executor: Finished task 1.0 in stage 92.0 (TID 162). 2279 bytes result sent to driver
19/07/31 01:01:29 INFO TaskSetManager: Finished task 3.0 in stage 92.0 (TID 164) in 11 ms on localhost (executor driver) (1/4)
19/07/31 01:01:29 INFO Executor: Finished task 0.0 in stage 92.0 (TID 161). 2300 bytes result sent to driver
19/07/31 01:01:29 INFO TaskSetManager: Finished task 2.0 in stage 92.0 (TID 163) in 12 ms on localhost (executor driver) (2/4)
19/07/31 01:01:29 INFO TaskSetManager: Finished task 1.0 in stage 92.0 (TID 162) in 12 ms on localhost (executor driver) (3/4)
19/07/31 01:01:29 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 161) in 13 ms on localhost (executor driver) (4/4)
19/07/31 01:01:29 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
19/07/31 01:01:29 INFO DAGScheduler: ResultStage 92 (collect at utils.scala:204) finished in 0.013 s
19/07/31 01:01:29 INFO DAGScheduler: Job 64 finished: collect at utils.scala:204, took 0.051736 s
19/07/31 01:01:30 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_193`) `dbplyr_194`
ORDER BY `date`) `dbplyr_195`) `dbplyr_196`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Desktop"))
19/07/31 01:01:30 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:30 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:30 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_197`) `dbplyr_198`
ORDER BY `date`) `dbplyr_199`) `dbplyr_200`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Desktop"))
19/07/31 01:01:30 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:30 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:30 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3100 - cust_prospect_ind.nullCount#3099) > 0)
19/07/31 01:01:30 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3105 - visit_device_type.nullCount#3104) > 0)
19/07/31 01:01:30 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#3098 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#3097))
19/07/31 01:01:30 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#3103 <= Desktop) && (Desktop <= visit_device_type.upperBound#3102))
19/07/31 01:01:30 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:30 INFO DAGScheduler: Got job 65 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:01:30 INFO DAGScheduler: Final stage: ResultStage 93 (collect at utils.scala:204)
19/07/31 01:01:30 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:01:30 INFO DAGScheduler: Missing parents: List()
19/07/31 01:01:30 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[295] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:30 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 71.9 KB, free 911.4 MB)
19/07/31 01:01:30 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.4 MB)
19/07/31 01:01:30 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 127.0.0.1:53873 (size: 30.4 KB, free: 912.1 MB)
19/07/31 01:01:30 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[295] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:30 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks
19/07/31 01:01:30 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 165, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:01:30 INFO Executor: Running task 0.0 in stage 93.0 (TID 165)
19/07/31 01:01:30 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:30 INFO Executor: Finished task 0.0 in stage 93.0 (TID 165). 4646 bytes result sent to driver
19/07/31 01:01:30 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 165) in 8 ms on localhost (executor driver) (1/1)
19/07/31 01:01:30 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
19/07/31 01:01:30 INFO DAGScheduler: ResultStage 93 (collect at utils.scala:204) finished in 0.009 s
19/07/31 01:01:30 INFO DAGScheduler: Job 65 finished: collect at utils.scala:204, took 0.019414 s
19/07/31 01:01:30 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:30 INFO DAGScheduler: Registering RDD 296 (collect at utils.scala:204)
19/07/31 01:01:30 INFO DAGScheduler: Got job 66 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:01:30 INFO DAGScheduler: Final stage: ResultStage 95 (collect at utils.scala:204)
19/07/31 01:01:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 94)
19/07/31 01:01:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 94)
19/07/31 01:01:30 INFO DAGScheduler: Submitting ShuffleMapStage 94 (MapPartitionsRDD[296] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:30 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 74.1 KB, free 911.3 MB)
19/07/31 01:01:30 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 31.6 KB, free 911.3 MB)
19/07/31 01:01:30 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 127.0.0.1:53873 (size: 31.6 KB, free: 912.0 MB)
19/07/31 01:01:30 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 94 (MapPartitionsRDD[296] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:30 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks
19/07/31 01:01:30 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 166, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:01:30 INFO Executor: Running task 0.0 in stage 94.0 (TID 166)
19/07/31 01:01:30 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:30 INFO Executor: Finished task 0.0 in stage 94.0 (TID 166). 1687 bytes result sent to driver
19/07/31 01:01:30 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 166) in 8 ms on localhost (executor driver) (1/1)
19/07/31 01:01:30 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
19/07/31 01:01:30 INFO DAGScheduler: ShuffleMapStage 94 (collect at utils.scala:204) finished in 0.009 s
19/07/31 01:01:30 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:01:30 INFO DAGScheduler: running: Set()
19/07/31 01:01:30 INFO DAGScheduler: waiting: Set(ResultStage 95)
19/07/31 01:01:30 INFO DAGScheduler: failed: Set()
19/07/31 01:01:30 INFO DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[299] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:30 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 16.1 KB, free 911.3 MB)
19/07/31 01:01:30 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 7.8 KB, free 911.3 MB)
19/07/31 01:01:30 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 912.0 MB)
19/07/31 01:01:30 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:30 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 95 (MapPartitionsRDD[299] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:01:30 INFO TaskSchedulerImpl: Adding task set 95.0 with 4 tasks
19/07/31 01:01:30 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 167, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:01:30 INFO TaskSetManager: Starting task 1.0 in stage 95.0 (TID 168, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:01:30 INFO TaskSetManager: Starting task 2.0 in stage 95.0 (TID 169, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:01:30 INFO TaskSetManager: Starting task 3.0 in stage 95.0 (TID 170, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:01:30 INFO Executor: Running task 0.0 in stage 95.0 (TID 167)
19/07/31 01:01:30 INFO Executor: Running task 1.0 in stage 95.0 (TID 168)
19/07/31 01:01:30 INFO Executor: Running task 2.0 in stage 95.0 (TID 169)
19/07/31 01:01:30 INFO Executor: Running task 3.0 in stage 95.0 (TID 170)
19/07/31 01:01:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:30 INFO Executor: Finished task 0.0 in stage 95.0 (TID 167). 2300 bytes result sent to driver
19/07/31 01:01:30 INFO Executor: Finished task 3.0 in stage 95.0 (TID 170). 2268 bytes result sent to driver
19/07/31 01:01:30 INFO Executor: Finished task 1.0 in stage 95.0 (TID 168). 2279 bytes result sent to driver
19/07/31 01:01:30 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 167) in 10 ms on localhost (executor driver) (1/4)
19/07/31 01:01:30 INFO TaskSetManager: Finished task 3.0 in stage 95.0 (TID 170) in 9 ms on localhost (executor driver) (2/4)
19/07/31 01:01:30 INFO TaskSetManager: Finished task 1.0 in stage 95.0 (TID 168) in 10 ms on localhost (executor driver) (3/4)
19/07/31 01:01:30 INFO Executor: Finished task 2.0 in stage 95.0 (TID 169). 2295 bytes result sent to driver
19/07/31 01:01:30 INFO TaskSetManager: Finished task 2.0 in stage 95.0 (TID 169) in 11 ms on localhost (executor driver) (4/4)
19/07/31 01:01:30 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
19/07/31 01:01:30 INFO DAGScheduler: ResultStage 95 (collect at utils.scala:204) finished in 0.012 s
19/07/31 01:01:30 INFO DAGScheduler: Job 66 finished: collect at utils.scala:204, took 0.040592 s
19/07/31 01:01:31 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_201`) `dbplyr_202`
ORDER BY `date`) `dbplyr_203`) `dbplyr_204`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Desktop"))
19/07/31 01:01:31 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:31 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:31 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_205`) `dbplyr_206`
ORDER BY `date`) `dbplyr_207`) `dbplyr_208`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Desktop"))
19/07/31 01:01:31 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:31 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:31 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3194 - cust_prospect_ind.nullCount#3193) > 0)
19/07/31 01:01:31 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3199 - visit_device_type.nullCount#3198) > 0)
19/07/31 01:01:31 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#3192 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#3191))
19/07/31 01:01:31 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#3197 <= Desktop) && (Desktop <= visit_device_type.upperBound#3196))
19/07/31 01:01:31 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:31 INFO DAGScheduler: Got job 67 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:01:31 INFO DAGScheduler: Final stage: ResultStage 96 (collect at utils.scala:204)
19/07/31 01:01:31 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:01:31 INFO DAGScheduler: Missing parents: List()
19/07/31 01:01:31 INFO DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[304] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:31 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 71.9 KB, free 911.2 MB)
19/07/31 01:01:31 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.2 MB)
19/07/31 01:01:31 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 127.0.0.1:53873 (size: 30.4 KB, free: 912.0 MB)
19/07/31 01:01:31 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[304] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:31 INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks
19/07/31 01:01:31 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 171, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:01:31 INFO Executor: Running task 0.0 in stage 96.0 (TID 171)
19/07/31 01:01:31 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:31 INFO Executor: Finished task 0.0 in stage 96.0 (TID 171). 4646 bytes result sent to driver
19/07/31 01:01:31 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 171) in 6 ms on localhost (executor driver) (1/1)
19/07/31 01:01:31 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
19/07/31 01:01:31 INFO DAGScheduler: ResultStage 96 (collect at utils.scala:204) finished in 0.007 s
19/07/31 01:01:31 INFO DAGScheduler: Job 67 finished: collect at utils.scala:204, took 0.019524 s
19/07/31 01:01:31 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:31 INFO DAGScheduler: Registering RDD 305 (collect at utils.scala:204)
19/07/31 01:01:31 INFO DAGScheduler: Got job 68 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:01:31 INFO DAGScheduler: Final stage: ResultStage 98 (collect at utils.scala:204)
19/07/31 01:01:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 97)
19/07/31 01:01:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 97)
19/07/31 01:01:31 INFO DAGScheduler: Submitting ShuffleMapStage 97 (MapPartitionsRDD[305] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:31 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 74.1 KB, free 911.1 MB)
19/07/31 01:01:31 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 31.6 KB, free 911.1 MB)
19/07/31 01:01:31 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 127.0.0.1:53873 (size: 31.6 KB, free: 912.0 MB)
19/07/31 01:01:31 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 97 (MapPartitionsRDD[305] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:31 INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks
19/07/31 01:01:31 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 172, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:01:31 INFO Executor: Running task 0.0 in stage 97.0 (TID 172)
19/07/31 01:01:31 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:31 INFO Executor: Finished task 0.0 in stage 97.0 (TID 172). 1687 bytes result sent to driver
19/07/31 01:01:31 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 172) in 8 ms on localhost (executor driver) (1/1)
19/07/31 01:01:31 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
19/07/31 01:01:31 INFO DAGScheduler: ShuffleMapStage 97 (collect at utils.scala:204) finished in 0.010 s
19/07/31 01:01:31 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:01:31 INFO DAGScheduler: running: Set()
19/07/31 01:01:31 INFO DAGScheduler: waiting: Set(ResultStage 98)
19/07/31 01:01:31 INFO DAGScheduler: failed: Set()
19/07/31 01:01:31 INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[308] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:31 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 16.1 KB, free 911.1 MB)
19/07/31 01:01:31 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 7.8 KB, free 911.0 MB)
19/07/31 01:01:31 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 912.0 MB)
19/07/31 01:01:31 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:31 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 98 (MapPartitionsRDD[308] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:01:31 INFO TaskSchedulerImpl: Adding task set 98.0 with 4 tasks
19/07/31 01:01:31 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 173, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:01:31 INFO TaskSetManager: Starting task 1.0 in stage 98.0 (TID 174, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:01:31 INFO TaskSetManager: Starting task 2.0 in stage 98.0 (TID 175, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:01:31 INFO TaskSetManager: Starting task 3.0 in stage 98.0 (TID 176, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:01:31 INFO Executor: Running task 1.0 in stage 98.0 (TID 174)
19/07/31 01:01:31 INFO Executor: Running task 2.0 in stage 98.0 (TID 175)
19/07/31 01:01:31 INFO Executor: Running task 3.0 in stage 98.0 (TID 176)
19/07/31 01:01:31 INFO Executor: Running task 0.0 in stage 98.0 (TID 173)
19/07/31 01:01:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:01:31 INFO Executor: Finished task 1.0 in stage 98.0 (TID 174). 2282 bytes result sent to driver
19/07/31 01:01:31 INFO Executor: Finished task 3.0 in stage 98.0 (TID 176). 2282 bytes result sent to driver
19/07/31 01:01:31 INFO Executor: Finished task 2.0 in stage 98.0 (TID 175). 2300 bytes result sent to driver
19/07/31 01:01:31 INFO TaskSetManager: Finished task 1.0 in stage 98.0 (TID 174) in 7 ms on localhost (executor driver) (1/4)
19/07/31 01:01:31 INFO Executor: Finished task 0.0 in stage 98.0 (TID 173). 2299 bytes result sent to driver
19/07/31 01:01:31 INFO TaskSetManager: Finished task 3.0 in stage 98.0 (TID 176) in 8 ms on localhost (executor driver) (2/4)
19/07/31 01:01:31 INFO TaskSetManager: Finished task 2.0 in stage 98.0 (TID 175) in 8 ms on localhost (executor driver) (3/4)
19/07/31 01:01:31 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 173) in 9 ms on localhost (executor driver) (4/4)
19/07/31 01:01:31 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
19/07/31 01:01:31 INFO DAGScheduler: ResultStage 98 (collect at utils.scala:204) finished in 0.009 s
19/07/31 01:01:31 INFO DAGScheduler: Job 68 finished: collect at utils.scala:204, took 0.040751 s
19/07/31 01:01:32 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_209`) `dbplyr_210`
ORDER BY `date`) `dbplyr_211`) `dbplyr_212`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Tablet"))
19/07/31 01:01:32 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:32 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:32 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_213`) `dbplyr_214`
ORDER BY `date`) `dbplyr_215`) `dbplyr_216`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Tablet"))
19/07/31 01:01:32 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:32 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:32 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3288 - cust_prospect_ind.nullCount#3287) > 0)
19/07/31 01:01:32 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3293 - visit_device_type.nullCount#3292) > 0)
19/07/31 01:01:32 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#3286 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#3285))
19/07/31 01:01:32 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#3291 <= Tablet) && (Tablet <= visit_device_type.upperBound#3290))
19/07/31 01:01:32 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:32 INFO DAGScheduler: Got job 69 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:01:32 INFO DAGScheduler: Final stage: ResultStage 99 (collect at utils.scala:204)
19/07/31 01:01:32 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:01:32 INFO DAGScheduler: Missing parents: List()
19/07/31 01:01:32 INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[313] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:32 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 71.9 KB, free 911.0 MB)
19/07/31 01:01:32 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 30.3 KB, free 910.9 MB)
19/07/31 01:01:32 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 127.0.0.1:53873 (size: 30.3 KB, free: 911.9 MB)
19/07/31 01:01:32 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[313] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:32 INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks
19/07/31 01:01:32 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 177, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:01:32 INFO Executor: Running task 0.0 in stage 99.0 (TID 177)
19/07/31 01:01:32 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:32 INFO Executor: Finished task 0.0 in stage 99.0 (TID 177). 4695 bytes result sent to driver
19/07/31 01:01:32 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 177) in 6 ms on localhost (executor driver) (1/1)
19/07/31 01:01:32 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
19/07/31 01:01:32 INFO DAGScheduler: ResultStage 99 (collect at utils.scala:204) finished in 0.006 s
19/07/31 01:01:32 INFO DAGScheduler: Job 69 finished: collect at utils.scala:204, took 0.016435 s
19/07/31 01:01:32 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:32 INFO DAGScheduler: Registering RDD 314 (collect at utils.scala:204)
19/07/31 01:01:32 INFO DAGScheduler: Got job 70 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:01:32 INFO DAGScheduler: Final stage: ResultStage 101 (collect at utils.scala:204)
19/07/31 01:01:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 100)
19/07/31 01:01:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 100)
19/07/31 01:01:32 INFO DAGScheduler: Submitting ShuffleMapStage 100 (MapPartitionsRDD[314] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:32 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 74.1 KB, free 910.9 MB)
19/07/31 01:01:32 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 31.6 KB, free 910.8 MB)
19/07/31 01:01:32 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 127.0.0.1:53873 (size: 31.6 KB, free: 911.9 MB)
19/07/31 01:01:32 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 100 (MapPartitionsRDD[314] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:32 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks
19/07/31 01:01:32 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 178, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:01:32 INFO Executor: Running task 0.0 in stage 100.0 (TID 178)
19/07/31 01:01:32 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:32 INFO Executor: Finished task 0.0 in stage 100.0 (TID 178). 1687 bytes result sent to driver
19/07/31 01:01:32 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 178) in 21 ms on localhost (executor driver) (1/1)
19/07/31 01:01:32 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
19/07/31 01:01:32 INFO DAGScheduler: ShuffleMapStage 100 (collect at utils.scala:204) finished in 0.022 s
19/07/31 01:01:32 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:01:32 INFO DAGScheduler: running: Set()
19/07/31 01:01:32 INFO DAGScheduler: waiting: Set(ResultStage 101)
19/07/31 01:01:32 INFO DAGScheduler: failed: Set()
19/07/31 01:01:32 INFO DAGScheduler: Submitting ResultStage 101 (MapPartitionsRDD[317] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:32 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 16.1 KB, free 910.8 MB)
19/07/31 01:01:32 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 7.8 KB, free 910.8 MB)
19/07/31 01:01:32 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 911.9 MB)
19/07/31 01:01:32 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:32 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 101 (MapPartitionsRDD[317] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:01:32 INFO TaskSchedulerImpl: Adding task set 101.0 with 4 tasks
19/07/31 01:01:32 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 179, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:01:32 INFO TaskSetManager: Starting task 1.0 in stage 101.0 (TID 180, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:01:32 INFO TaskSetManager: Starting task 2.0 in stage 101.0 (TID 181, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:01:32 INFO TaskSetManager: Starting task 3.0 in stage 101.0 (TID 182, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:01:32 INFO Executor: Running task 3.0 in stage 101.0 (TID 182)
19/07/31 01:01:32 INFO Executor: Running task 2.0 in stage 101.0 (TID 181)
19/07/31 01:01:32 INFO Executor: Running task 1.0 in stage 101.0 (TID 180)
19/07/31 01:01:32 INFO Executor: Running task 0.0 in stage 101.0 (TID 179)
19/07/31 01:01:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:32 INFO Executor: Finished task 2.0 in stage 101.0 (TID 181). 2290 bytes result sent to driver
19/07/31 01:01:32 INFO Executor: Finished task 0.0 in stage 101.0 (TID 179). 2291 bytes result sent to driver
19/07/31 01:01:32 INFO Executor: Finished task 1.0 in stage 101.0 (TID 180). 2307 bytes result sent to driver
19/07/31 01:01:32 INFO Executor: Finished task 3.0 in stage 101.0 (TID 182). 2276 bytes result sent to driver
19/07/31 01:01:32 INFO TaskSetManager: Finished task 2.0 in stage 101.0 (TID 181) in 5 ms on localhost (executor driver) (1/4)
19/07/31 01:01:32 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 179) in 5 ms on localhost (executor driver) (2/4)
19/07/31 01:01:32 INFO TaskSetManager: Finished task 1.0 in stage 101.0 (TID 180) in 5 ms on localhost (executor driver) (3/4)
19/07/31 01:01:32 INFO TaskSetManager: Finished task 3.0 in stage 101.0 (TID 182) in 5 ms on localhost (executor driver) (4/4)
19/07/31 01:01:32 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
19/07/31 01:01:32 INFO DAGScheduler: ResultStage 101 (collect at utils.scala:204) finished in 0.005 s
19/07/31 01:01:32 INFO DAGScheduler: Job 70 finished: collect at utils.scala:204, took 0.051398 s
19/07/31 01:01:33 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_217`) `dbplyr_218`
ORDER BY `date`) `dbplyr_219`) `dbplyr_220`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Tablet"))
19/07/31 01:01:33 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:33 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:33 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_221`) `dbplyr_222`
ORDER BY `date`) `dbplyr_223`) `dbplyr_224`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Tablet"))
19/07/31 01:01:33 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:33 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:33 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3382 - cust_prospect_ind.nullCount#3381) > 0)
19/07/31 01:01:33 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3387 - visit_device_type.nullCount#3386) > 0)
19/07/31 01:01:33 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#3380 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#3379))
19/07/31 01:01:33 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#3385 <= Tablet) && (Tablet <= visit_device_type.upperBound#3384))
19/07/31 01:01:33 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:33 INFO DAGScheduler: Got job 71 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:01:33 INFO DAGScheduler: Final stage: ResultStage 102 (collect at utils.scala:204)
19/07/31 01:01:33 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:01:33 INFO DAGScheduler: Missing parents: List()
19/07/31 01:01:33 INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[322] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:33 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 71.9 KB, free 910.7 MB)
19/07/31 01:01:33 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.7 MB)
19/07/31 01:01:33 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 127.0.0.1:53873 (size: 30.4 KB, free: 911.9 MB)
19/07/31 01:01:33 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[322] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:33 INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks
19/07/31 01:01:33 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 183, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:01:33 INFO Executor: Running task 0.0 in stage 102.0 (TID 183)
19/07/31 01:01:33 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:33 INFO Executor: Finished task 0.0 in stage 102.0 (TID 183). 4695 bytes result sent to driver
19/07/31 01:01:33 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 183) in 3 ms on localhost (executor driver) (1/1)
19/07/31 01:01:33 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
19/07/31 01:01:33 INFO DAGScheduler: ResultStage 102 (collect at utils.scala:204) finished in 0.004 s
19/07/31 01:01:33 INFO DAGScheduler: Job 71 finished: collect at utils.scala:204, took 0.009438 s
19/07/31 01:01:33 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:33 INFO DAGScheduler: Registering RDD 323 (collect at utils.scala:204)
19/07/31 01:01:33 INFO DAGScheduler: Got job 72 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:01:33 INFO DAGScheduler: Final stage: ResultStage 104 (collect at utils.scala:204)
19/07/31 01:01:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 103)
19/07/31 01:01:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 103)
19/07/31 01:01:33 INFO DAGScheduler: Submitting ShuffleMapStage 103 (MapPartitionsRDD[323] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:33 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 74.1 KB, free 910.6 MB)
19/07/31 01:01:33 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.6 MB)
19/07/31 01:01:33 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 127.0.0.1:53873 (size: 31.7 KB, free: 911.8 MB)
19/07/31 01:01:33 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 103 (MapPartitionsRDD[323] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:33 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks
19/07/31 01:01:33 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 184, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:01:33 INFO Executor: Running task 0.0 in stage 103.0 (TID 184)
19/07/31 01:01:33 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:33 INFO Executor: Finished task 0.0 in stage 103.0 (TID 184). 1687 bytes result sent to driver
19/07/31 01:01:33 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 184) in 13 ms on localhost (executor driver) (1/1)
19/07/31 01:01:33 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
19/07/31 01:01:33 INFO DAGScheduler: ShuffleMapStage 103 (collect at utils.scala:204) finished in 0.014 s
19/07/31 01:01:33 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:01:33 INFO DAGScheduler: running: Set()
19/07/31 01:01:33 INFO DAGScheduler: waiting: Set(ResultStage 104)
19/07/31 01:01:33 INFO DAGScheduler: failed: Set()
19/07/31 01:01:33 INFO DAGScheduler: Submitting ResultStage 104 (MapPartitionsRDD[326] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:33 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 16.1 KB, free 910.6 MB)
19/07/31 01:01:33 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 7.8 KB, free 910.6 MB)
19/07/31 01:01:33 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 911.8 MB)
19/07/31 01:01:33 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:33 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 104 (MapPartitionsRDD[326] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:01:33 INFO TaskSchedulerImpl: Adding task set 104.0 with 4 tasks
19/07/31 01:01:33 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 185, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:01:33 INFO TaskSetManager: Starting task 1.0 in stage 104.0 (TID 186, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:01:33 INFO TaskSetManager: Starting task 2.0 in stage 104.0 (TID 187, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:01:33 INFO TaskSetManager: Starting task 3.0 in stage 104.0 (TID 188, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:01:33 INFO Executor: Running task 0.0 in stage 104.0 (TID 185)
19/07/31 01:01:33 INFO Executor: Running task 1.0 in stage 104.0 (TID 186)
19/07/31 01:01:33 INFO Executor: Running task 2.0 in stage 104.0 (TID 187)
19/07/31 01:01:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:33 INFO Executor: Running task 3.0 in stage 104.0 (TID 188)
19/07/31 01:01:33 INFO Executor: Finished task 0.0 in stage 104.0 (TID 185). 2291 bytes result sent to driver
19/07/31 01:01:33 INFO Executor: Finished task 1.0 in stage 104.0 (TID 186). 2307 bytes result sent to driver
19/07/31 01:01:33 INFO Executor: Finished task 2.0 in stage 104.0 (TID 187). 2290 bytes result sent to driver
19/07/31 01:01:33 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 185) in 5 ms on localhost (executor driver) (1/4)
19/07/31 01:01:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:33 INFO TaskSetManager: Finished task 1.0 in stage 104.0 (TID 186) in 5 ms on localhost (executor driver) (2/4)
19/07/31 01:01:33 INFO TaskSetManager: Finished task 2.0 in stage 104.0 (TID 187) in 4 ms on localhost (executor driver) (3/4)
19/07/31 01:01:33 INFO Executor: Finished task 3.0 in stage 104.0 (TID 188). 2276 bytes result sent to driver
19/07/31 01:01:33 INFO TaskSetManager: Finished task 3.0 in stage 104.0 (TID 188) in 6 ms on localhost (executor driver) (4/4)
19/07/31 01:01:33 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
19/07/31 01:01:33 INFO DAGScheduler: ResultStage 104 (collect at utils.scala:204) finished in 0.007 s
19/07/31 01:01:33 INFO DAGScheduler: Job 72 finished: collect at utils.scala:204, took 0.032503 s
19/07/31 01:01:34 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_225`) `dbplyr_226`
ORDER BY `date`) `dbplyr_227`) `dbplyr_228`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Tablet"))
19/07/31 01:01:34 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:34 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_229`) `dbplyr_230`
ORDER BY `date`) `dbplyr_231`) `dbplyr_232`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Tablet"))
19/07/31 01:01:34 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:34 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3476 - cust_prospect_ind.nullCount#3475) > 0)
19/07/31 01:01:34 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3481 - visit_device_type.nullCount#3480) > 0)
19/07/31 01:01:34 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#3474 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#3473))
19/07/31 01:01:34 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#3479 <= Tablet) && (Tablet <= visit_device_type.upperBound#3478))
19/07/31 01:01:34 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:34 INFO DAGScheduler: Got job 73 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:01:34 INFO DAGScheduler: Final stage: ResultStage 105 (collect at utils.scala:204)
19/07/31 01:01:34 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:01:34 INFO DAGScheduler: Missing parents: List()
19/07/31 01:01:34 INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[331] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:34 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 71.9 KB, free 910.5 MB)
19/07/31 01:01:35 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.5 MB)
19/07/31 01:01:35 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 127.0.0.1:53873 (size: 30.4 KB, free: 911.8 MB)
19/07/31 01:01:35 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[331] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:35 INFO TaskSchedulerImpl: Adding task set 105.0 with 1 tasks
19/07/31 01:01:35 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 189, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:01:35 INFO Executor: Running task 0.0 in stage 105.0 (TID 189)
19/07/31 01:01:35 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:35 INFO Executor: Finished task 0.0 in stage 105.0 (TID 189). 4646 bytes result sent to driver
19/07/31 01:01:35 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 189) in 5 ms on localhost (executor driver) (1/1)
19/07/31 01:01:35 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
19/07/31 01:01:35 INFO DAGScheduler: ResultStage 105 (collect at utils.scala:204) finished in 0.005 s
19/07/31 01:01:35 INFO DAGScheduler: Job 73 finished: collect at utils.scala:204, took 0.014240 s
19/07/31 01:01:35 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:35 INFO DAGScheduler: Registering RDD 332 (collect at utils.scala:204)
19/07/31 01:01:35 INFO DAGScheduler: Got job 74 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:01:35 INFO DAGScheduler: Final stage: ResultStage 107 (collect at utils.scala:204)
19/07/31 01:01:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 106)
19/07/31 01:01:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 106)
19/07/31 01:01:35 INFO DAGScheduler: Submitting ShuffleMapStage 106 (MapPartitionsRDD[332] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:35 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 74.1 KB, free 910.4 MB)
19/07/31 01:01:35 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 31.6 KB, free 910.4 MB)
19/07/31 01:01:35 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 127.0.0.1:53873 (size: 31.6 KB, free: 911.8 MB)
19/07/31 01:01:35 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 106 (MapPartitionsRDD[332] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:35 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks
19/07/31 01:01:35 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 190, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:01:35 INFO Executor: Running task 0.0 in stage 106.0 (TID 190)
19/07/31 01:01:35 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:35 INFO Executor: Finished task 0.0 in stage 106.0 (TID 190). 1687 bytes result sent to driver
19/07/31 01:01:35 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 190) in 7 ms on localhost (executor driver) (1/1)
19/07/31 01:01:35 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
19/07/31 01:01:35 INFO DAGScheduler: ShuffleMapStage 106 (collect at utils.scala:204) finished in 0.007 s
19/07/31 01:01:35 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:01:35 INFO DAGScheduler: running: Set()
19/07/31 01:01:35 INFO DAGScheduler: waiting: Set(ResultStage 107)
19/07/31 01:01:35 INFO DAGScheduler: failed: Set()
19/07/31 01:01:35 INFO DAGScheduler: Submitting ResultStage 107 (MapPartitionsRDD[335] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:35 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 16.1 KB, free 910.4 MB)
19/07/31 01:01:35 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 7.8 KB, free 910.4 MB)
19/07/31 01:01:35 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 911.8 MB)
19/07/31 01:01:35 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:35 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 107 (MapPartitionsRDD[335] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:01:35 INFO TaskSchedulerImpl: Adding task set 107.0 with 4 tasks
19/07/31 01:01:35 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 191, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:01:35 INFO TaskSetManager: Starting task 1.0 in stage 107.0 (TID 192, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:01:35 INFO TaskSetManager: Starting task 2.0 in stage 107.0 (TID 193, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:01:35 INFO TaskSetManager: Starting task 3.0 in stage 107.0 (TID 194, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:01:35 INFO Executor: Running task 0.0 in stage 107.0 (TID 191)
19/07/31 01:01:35 INFO Executor: Running task 1.0 in stage 107.0 (TID 192)
19/07/31 01:01:35 INFO Executor: Running task 2.0 in stage 107.0 (TID 193)
19/07/31 01:01:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:35 INFO Executor: Running task 3.0 in stage 107.0 (TID 194)
19/07/31 01:01:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:35 INFO Executor: Finished task 1.0 in stage 107.0 (TID 192). 2263 bytes result sent to driver
19/07/31 01:01:35 INFO Executor: Finished task 3.0 in stage 107.0 (TID 194). 2208 bytes result sent to driver
19/07/31 01:01:35 INFO Executor: Finished task 2.0 in stage 107.0 (TID 193). 2291 bytes result sent to driver
19/07/31 01:01:35 INFO TaskSetManager: Finished task 3.0 in stage 107.0 (TID 194) in 5 ms on localhost (executor driver) (1/4)
19/07/31 01:01:35 INFO TaskSetManager: Finished task 2.0 in stage 107.0 (TID 193) in 7 ms on localhost (executor driver) (2/4)
19/07/31 01:01:35 INFO TaskSetManager: Finished task 1.0 in stage 107.0 (TID 192) in 7 ms on localhost (executor driver) (3/4)
19/07/31 01:01:35 INFO Executor: Finished task 0.0 in stage 107.0 (TID 191). 2286 bytes result sent to driver
19/07/31 01:01:35 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 191) in 8 ms on localhost (executor driver) (4/4)
19/07/31 01:01:35 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
19/07/31 01:01:35 INFO DAGScheduler: ResultStage 107 (collect at utils.scala:204) finished in 0.008 s
19/07/31 01:01:35 INFO DAGScheduler: Job 74 finished: collect at utils.scala:204, took 0.027022 s
19/07/31 01:01:35 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_233`) `dbplyr_234`
ORDER BY `date`) `dbplyr_235`) `dbplyr_236`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Tablet"))
19/07/31 01:01:35 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:35 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:35 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `rate`, `date`
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_237`) `dbplyr_238`
ORDER BY `date`) `dbplyr_239`) `dbplyr_240`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Tablet"))
19/07/31 01:01:35 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:01:35 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:01:35 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3570 - cust_prospect_ind.nullCount#3569) > 0)
19/07/31 01:01:35 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3575 - visit_device_type.nullCount#3574) > 0)
19/07/31 01:01:35 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#3568 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#3567))
19/07/31 01:01:35 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#3573 <= Tablet) && (Tablet <= visit_device_type.upperBound#3572))
19/07/31 01:01:35 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:35 INFO DAGScheduler: Got job 75 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:01:35 INFO DAGScheduler: Final stage: ResultStage 108 (collect at utils.scala:204)
19/07/31 01:01:35 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:01:35 INFO DAGScheduler: Missing parents: List()
19/07/31 01:01:35 INFO DAGScheduler: Submitting ResultStage 108 (MapPartitionsRDD[340] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:35 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 71.9 KB, free 910.3 MB)
19/07/31 01:01:35 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 30.3 KB, free 910.3 MB)
19/07/31 01:01:35 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 127.0.0.1:53873 (size: 30.3 KB, free: 911.7 MB)
19/07/31 01:01:35 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 108 (MapPartitionsRDD[340] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:35 INFO TaskSchedulerImpl: Adding task set 108.0 with 1 tasks
19/07/31 01:01:35 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 195, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:01:35 INFO Executor: Running task 0.0 in stage 108.0 (TID 195)
19/07/31 01:01:35 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:35 INFO Executor: Finished task 0.0 in stage 108.0 (TID 195). 4646 bytes result sent to driver
19/07/31 01:01:35 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 195) in 6 ms on localhost (executor driver) (1/1)
19/07/31 01:01:35 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool 
19/07/31 01:01:35 INFO DAGScheduler: ResultStage 108 (collect at utils.scala:204) finished in 0.007 s
19/07/31 01:01:35 INFO DAGScheduler: Job 75 finished: collect at utils.scala:204, took 0.012000 s
19/07/31 01:01:35 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:01:35 INFO DAGScheduler: Registering RDD 341 (collect at utils.scala:204)
19/07/31 01:01:35 INFO DAGScheduler: Got job 76 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:01:35 INFO DAGScheduler: Final stage: ResultStage 110 (collect at utils.scala:204)
19/07/31 01:01:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 109)
19/07/31 01:01:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 109)
19/07/31 01:01:35 INFO DAGScheduler: Submitting ShuffleMapStage 109 (MapPartitionsRDD[341] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:35 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 74.1 KB, free 910.2 MB)
19/07/31 01:01:35 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 31.5 KB, free 910.2 MB)
19/07/31 01:01:35 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 127.0.0.1:53873 (size: 31.5 KB, free: 911.7 MB)
19/07/31 01:01:35 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 109 (MapPartitionsRDD[341] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:01:35 INFO TaskSchedulerImpl: Adding task set 109.0 with 1 tasks
19/07/31 01:01:35 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 196, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:01:35 INFO Executor: Running task 0.0 in stage 109.0 (TID 196)
19/07/31 01:01:35 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:01:35 INFO Executor: Finished task 0.0 in stage 109.0 (TID 196). 1687 bytes result sent to driver
19/07/31 01:01:35 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 196) in 7 ms on localhost (executor driver) (1/1)
19/07/31 01:01:35 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool 
19/07/31 01:01:35 INFO DAGScheduler: ShuffleMapStage 109 (collect at utils.scala:204) finished in 0.008 s
19/07/31 01:01:35 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:01:35 INFO DAGScheduler: running: Set()
19/07/31 01:01:35 INFO DAGScheduler: waiting: Set(ResultStage 110)
19/07/31 01:01:35 INFO DAGScheduler: failed: Set()
19/07/31 01:01:35 INFO DAGScheduler: Submitting ResultStage 110 (MapPartitionsRDD[344] at collect at utils.scala:204), which has no missing parents
19/07/31 01:01:35 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 16.1 KB, free 910.1 MB)
19/07/31 01:01:35 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 7.8 KB, free 910.1 MB)
19/07/31 01:01:35 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 127.0.0.1:53873 (size: 7.8 KB, free: 911.7 MB)
19/07/31 01:01:35 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1006
19/07/31 01:01:35 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 110 (MapPartitionsRDD[344] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:01:35 INFO TaskSchedulerImpl: Adding task set 110.0 with 4 tasks
19/07/31 01:01:35 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 197, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:01:35 INFO TaskSetManager: Starting task 1.0 in stage 110.0 (TID 198, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:01:35 INFO TaskSetManager: Starting task 2.0 in stage 110.0 (TID 199, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:01:35 INFO TaskSetManager: Starting task 3.0 in stage 110.0 (TID 200, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:01:35 INFO Executor: Running task 0.0 in stage 110.0 (TID 197)
19/07/31 01:01:35 INFO Executor: Running task 1.0 in stage 110.0 (TID 198)
19/07/31 01:01:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:35 INFO Executor: Running task 2.0 in stage 110.0 (TID 199)
19/07/31 01:01:35 INFO Executor: Running task 3.0 in stage 110.0 (TID 200)
19/07/31 01:01:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:01:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:35 INFO Executor: Finished task 0.0 in stage 110.0 (TID 197). 2286 bytes result sent to driver
19/07/31 01:01:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:35 INFO Executor: Finished task 2.0 in stage 110.0 (TID 199). 2288 bytes result sent to driver
19/07/31 01:01:35 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 197) in 5 ms on localhost (executor driver) (1/4)
19/07/31 01:01:35 INFO TaskSetManager: Finished task 2.0 in stage 110.0 (TID 199) in 5 ms on localhost (executor driver) (2/4)
19/07/31 01:01:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:01:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:01:35 INFO Executor: Finished task 1.0 in stage 110.0 (TID 198). 2269 bytes result sent to driver
19/07/31 01:01:35 INFO TaskSetManager: Finished task 1.0 in stage 110.0 (TID 198) in 6 ms on localhost (executor driver) (3/4)
19/07/31 01:01:35 INFO Executor: Finished task 3.0 in stage 110.0 (TID 200). 2265 bytes result sent to driver
19/07/31 01:01:35 INFO TaskSetManager: Finished task 3.0 in stage 110.0 (TID 200) in 7 ms on localhost (executor driver) (4/4)
19/07/31 01:01:35 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool 
19/07/31 01:01:35 INFO DAGScheduler: ResultStage 110 (collect at utils.scala:204) finished in 0.008 s
19/07/31 01:01:35 INFO DAGScheduler: Job 76 finished: collect at utils.scala:204, took 0.023686 s
19/07/31 01:03:27 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 01:03:27 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:03:27 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:03:27 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:03:27 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:03:27 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 01:03:27 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 01:03:27 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 01:03:27 INFO DAGScheduler: Got job 77 (collect at utils.scala:44) with 4 output partitions
19/07/31 01:03:27 INFO DAGScheduler: Final stage: ResultStage 111 (collect at utils.scala:44)
19/07/31 01:03:27 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:03:27 INFO DAGScheduler: Missing parents: List()
19/07/31 01:03:27 INFO DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[349] at map at utils.scala:41), which has no missing parents
19/07/31 01:03:27 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 6.8 KB, free 910.1 MB)
19/07/31 01:03:27 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 3.6 KB, free 910.1 MB)
19/07/31 01:03:27 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 127.0.0.1:53873 (size: 3.6 KB, free: 911.7 MB)
19/07/31 01:03:27 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1006
19/07/31 01:03:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 111 (MapPartitionsRDD[349] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:03:27 INFO TaskSchedulerImpl: Adding task set 111.0 with 4 tasks
19/07/31 01:03:27 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 201, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 01:03:27 INFO TaskSetManager: Starting task 1.0 in stage 111.0 (TID 202, localhost, executor driver, partition 1, PROCESS_LOCAL, 5035 bytes)
19/07/31 01:03:27 INFO TaskSetManager: Starting task 2.0 in stage 111.0 (TID 203, localhost, executor driver, partition 2, PROCESS_LOCAL, 5035 bytes)
19/07/31 01:03:27 INFO TaskSetManager: Starting task 3.0 in stage 111.0 (TID 204, localhost, executor driver, partition 3, PROCESS_LOCAL, 5076 bytes)
19/07/31 01:03:27 INFO Executor: Running task 0.0 in stage 111.0 (TID 201)
19/07/31 01:03:27 INFO Executor: Running task 1.0 in stage 111.0 (TID 202)
19/07/31 01:03:27 INFO Executor: Running task 3.0 in stage 111.0 (TID 204)
19/07/31 01:03:27 INFO Executor: Running task 2.0 in stage 111.0 (TID 203)
19/07/31 01:03:27 INFO Executor: Finished task 2.0 in stage 111.0 (TID 203). 998 bytes result sent to driver
19/07/31 01:03:27 INFO Executor: Finished task 3.0 in stage 111.0 (TID 204). 1005 bytes result sent to driver
19/07/31 01:03:27 INFO Executor: Finished task 0.0 in stage 111.0 (TID 201). 1007 bytes result sent to driver
19/07/31 01:03:27 INFO Executor: Finished task 1.0 in stage 111.0 (TID 202). 998 bytes result sent to driver
19/07/31 01:03:27 INFO TaskSetManager: Finished task 2.0 in stage 111.0 (TID 203) in 5 ms on localhost (executor driver) (1/4)
19/07/31 01:03:27 INFO TaskSetManager: Finished task 3.0 in stage 111.0 (TID 204) in 5 ms on localhost (executor driver) (2/4)
19/07/31 01:03:27 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 201) in 6 ms on localhost (executor driver) (3/4)
19/07/31 01:03:27 INFO TaskSetManager: Finished task 1.0 in stage 111.0 (TID 202) in 5 ms on localhost (executor driver) (4/4)
19/07/31 01:03:27 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool 
19/07/31 01:03:27 INFO DAGScheduler: ResultStage 111 (collect at utils.scala:44) finished in 0.007 s
19/07/31 01:03:27 INFO DAGScheduler: Job 77 finished: collect at utils.scala:44, took 0.015105 s
19/07/31 01:03:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 01:03:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:03:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:03:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:03:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:03:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 01:03:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 01:03:38 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 01:03:38 INFO DAGScheduler: Got job 78 (collect at utils.scala:44) with 4 output partitions
19/07/31 01:03:38 INFO DAGScheduler: Final stage: ResultStage 112 (collect at utils.scala:44)
19/07/31 01:03:38 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:03:38 INFO DAGScheduler: Missing parents: List()
19/07/31 01:03:38 INFO DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[354] at map at utils.scala:41), which has no missing parents
19/07/31 01:03:38 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 6.8 KB, free 910.1 MB)
19/07/31 01:03:38 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 3.6 KB, free 910.1 MB)
19/07/31 01:03:38 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 127.0.0.1:53873 (size: 3.6 KB, free: 911.7 MB)
19/07/31 01:03:38 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1006
19/07/31 01:03:38 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 112 (MapPartitionsRDD[354] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:03:38 INFO TaskSchedulerImpl: Adding task set 112.0 with 4 tasks
19/07/31 01:03:38 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 205, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 01:03:38 INFO TaskSetManager: Starting task 1.0 in stage 112.0 (TID 206, localhost, executor driver, partition 1, PROCESS_LOCAL, 5035 bytes)
19/07/31 01:03:38 INFO TaskSetManager: Starting task 2.0 in stage 112.0 (TID 207, localhost, executor driver, partition 2, PROCESS_LOCAL, 5035 bytes)
19/07/31 01:03:38 INFO TaskSetManager: Starting task 3.0 in stage 112.0 (TID 208, localhost, executor driver, partition 3, PROCESS_LOCAL, 5076 bytes)
19/07/31 01:03:38 INFO Executor: Running task 0.0 in stage 112.0 (TID 205)
19/07/31 01:03:38 INFO Executor: Finished task 0.0 in stage 112.0 (TID 205). 964 bytes result sent to driver
19/07/31 01:03:38 INFO Executor: Running task 1.0 in stage 112.0 (TID 206)
19/07/31 01:03:38 INFO Executor: Running task 2.0 in stage 112.0 (TID 207)
19/07/31 01:03:38 INFO Executor: Running task 3.0 in stage 112.0 (TID 208)
19/07/31 01:03:38 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 205) in 6 ms on localhost (executor driver) (1/4)
19/07/31 01:03:38 INFO Executor: Finished task 3.0 in stage 112.0 (TID 208). 962 bytes result sent to driver
19/07/31 01:03:38 INFO Executor: Finished task 2.0 in stage 112.0 (TID 207). 998 bytes result sent to driver
19/07/31 01:03:38 INFO Executor: Finished task 1.0 in stage 112.0 (TID 206). 998 bytes result sent to driver
19/07/31 01:03:38 INFO TaskSetManager: Finished task 3.0 in stage 112.0 (TID 208) in 6 ms on localhost (executor driver) (2/4)
19/07/31 01:03:38 INFO TaskSetManager: Finished task 2.0 in stage 112.0 (TID 207) in 6 ms on localhost (executor driver) (3/4)
19/07/31 01:03:38 INFO TaskSetManager: Finished task 1.0 in stage 112.0 (TID 206) in 7 ms on localhost (executor driver) (4/4)
19/07/31 01:03:38 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool 
19/07/31 01:03:38 INFO DAGScheduler: ResultStage 112 (collect at utils.scala:44) finished in 0.009 s
19/07/31 01:03:38 INFO DAGScheduler: Job 78 finished: collect at utils.scala:44, took 0.013326 s
19/07/31 01:03:38 INFO SparkSqlParser: Parsing command: DROP TABLE `test`
19/07/31 01:03:38 INFO MapPartitionsRDD: Removing RDD 73 from persistence list
19/07/31 01:03:38 INFO BlockManager: Removing RDD 73
19/07/31 01:03:38 INFO SparkSqlParser: Parsing command: test
19/07/31 01:03:38 INFO SparkSqlParser: Parsing command: CACHE TABLE `test`
19/07/31 01:03:38 INFO SparkSqlParser: Parsing command: `test`
19/07/31 01:03:38 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 01:03:38 INFO DAGScheduler: Registering RDD 362 (sql at <unknown>:0)
19/07/31 01:03:38 INFO DAGScheduler: Got job 79 (sql at <unknown>:0) with 1 output partitions
19/07/31 01:03:38 INFO DAGScheduler: Final stage: ResultStage 114 (sql at <unknown>:0)
19/07/31 01:03:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 113)
19/07/31 01:03:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 113)
19/07/31 01:03:38 INFO DAGScheduler: Submitting ShuffleMapStage 113 (MapPartitionsRDD[362] at sql at <unknown>:0), which has no missing parents
19/07/31 01:03:38 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 26.3 KB, free 910.1 MB)
19/07/31 01:03:38 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 10.4 KB, free 910.1 MB)
19/07/31 01:03:38 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 127.0.0.1:53873 (size: 10.4 KB, free: 911.7 MB)
19/07/31 01:03:38 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1006
19/07/31 01:03:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 113 (MapPartitionsRDD[362] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 01:03:38 INFO TaskSchedulerImpl: Adding task set 113.0 with 1 tasks
19/07/31 01:03:38 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 209, localhost, executor driver, partition 0, PROCESS_LOCAL, 11373 bytes)
19/07/31 01:03:38 INFO Executor: Running task 0.0 in stage 113.0 (TID 209)
19/07/31 01:03:38 INFO CodeGenerator: Code generated in 20.124739 ms
19/07/31 01:03:38 INFO CodeGenerator: Code generated in 54.710596 ms
19/07/31 01:03:38 INFO MemoryStore: Block rdd_359_0 stored as values in memory (estimated size 8.3 KB, free 910.1 MB)
19/07/31 01:03:38 INFO BlockManagerInfo: Added rdd_359_0 in memory on 127.0.0.1:53873 (size: 8.3 KB, free: 911.7 MB)
19/07/31 01:03:38 INFO Executor: Finished task 0.0 in stage 113.0 (TID 209). 2285 bytes result sent to driver
19/07/31 01:03:38 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 209) in 142 ms on localhost (executor driver) (1/1)
19/07/31 01:03:38 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool 
19/07/31 01:03:38 INFO DAGScheduler: ShuffleMapStage 113 (sql at <unknown>:0) finished in 0.143 s
19/07/31 01:03:38 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:03:38 INFO DAGScheduler: running: Set()
19/07/31 01:03:38 INFO DAGScheduler: waiting: Set(ResultStage 114)
19/07/31 01:03:38 INFO DAGScheduler: failed: Set()
19/07/31 01:03:38 INFO DAGScheduler: Submitting ResultStage 114 (MapPartitionsRDD[365] at sql at <unknown>:0), which has no missing parents
19/07/31 01:03:38 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 7.0 KB, free 910.1 MB)
19/07/31 01:03:38 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.1 MB)
19/07/31 01:03:38 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 911.7 MB)
19/07/31 01:03:38 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1006
19/07/31 01:03:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 114 (MapPartitionsRDD[365] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 01:03:38 INFO TaskSchedulerImpl: Adding task set 114.0 with 1 tasks
19/07/31 01:03:38 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 210, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:03:38 INFO Executor: Running task 0.0 in stage 114.0 (TID 210)
19/07/31 01:03:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:03:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:03:38 INFO Executor: Finished task 0.0 in stage 114.0 (TID 210). 1581 bytes result sent to driver
19/07/31 01:03:38 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 210) in 3 ms on localhost (executor driver) (1/1)
19/07/31 01:03:38 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool 
19/07/31 01:03:38 INFO DAGScheduler: ResultStage 114 (sql at <unknown>:0) finished in 0.003 s
19/07/31 01:03:38 INFO DAGScheduler: Job 79 finished: sql at <unknown>:0, took 0.155239 s
19/07/31 01:03:38 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `test`
19/07/31 01:03:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:03:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:03:38 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:03:38 INFO DAGScheduler: Registering RDD 368 (collect at utils.scala:204)
19/07/31 01:03:38 INFO DAGScheduler: Got job 80 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:03:38 INFO DAGScheduler: Final stage: ResultStage 116 (collect at utils.scala:204)
19/07/31 01:03:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 115)
19/07/31 01:03:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 115)
19/07/31 01:03:38 INFO DAGScheduler: Submitting ShuffleMapStage 115 (MapPartitionsRDD[368] at collect at utils.scala:204), which has no missing parents
19/07/31 01:03:38 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 26.3 KB, free 910.0 MB)
19/07/31 01:03:38 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 10.4 KB, free 910.0 MB)
19/07/31 01:03:38 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 127.0.0.1:53873 (size: 10.4 KB, free: 911.6 MB)
19/07/31 01:03:38 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1006
19/07/31 01:03:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 115 (MapPartitionsRDD[368] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:03:38 INFO TaskSchedulerImpl: Adding task set 115.0 with 1 tasks
19/07/31 01:03:38 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 211, localhost, executor driver, partition 0, PROCESS_LOCAL, 11373 bytes)
19/07/31 01:03:38 INFO Executor: Running task 0.0 in stage 115.0 (TID 211)
19/07/31 01:03:38 INFO BlockManager: Found block rdd_359_0 locally
19/07/31 01:03:38 INFO Executor: Finished task 0.0 in stage 115.0 (TID 211). 1690 bytes result sent to driver
19/07/31 01:03:38 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 211) in 12 ms on localhost (executor driver) (1/1)
19/07/31 01:03:38 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
19/07/31 01:03:38 INFO DAGScheduler: ShuffleMapStage 115 (collect at utils.scala:204) finished in 0.012 s
19/07/31 01:03:38 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:03:38 INFO DAGScheduler: running: Set()
19/07/31 01:03:38 INFO DAGScheduler: waiting: Set(ResultStage 116)
19/07/31 01:03:38 INFO DAGScheduler: failed: Set()
19/07/31 01:03:38 INFO DAGScheduler: Submitting ResultStage 116 (MapPartitionsRDD[371] at collect at utils.scala:204), which has no missing parents
19/07/31 01:03:38 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 7.0 KB, free 910.0 MB)
19/07/31 01:03:38 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.0 MB)
19/07/31 01:03:38 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 911.6 MB)
19/07/31 01:03:38 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1006
19/07/31 01:03:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[371] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:03:38 INFO TaskSchedulerImpl: Adding task set 116.0 with 1 tasks
19/07/31 01:03:38 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 212, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:03:38 INFO Executor: Running task 0.0 in stage 116.0 (TID 212)
19/07/31 01:03:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:03:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:03:38 INFO Executor: Finished task 0.0 in stage 116.0 (TID 212). 1581 bytes result sent to driver
19/07/31 01:03:38 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 212) in 3 ms on localhost (executor driver) (1/1)
19/07/31 01:03:38 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool 
19/07/31 01:03:38 INFO DAGScheduler: ResultStage 116 (collect at utils.scala:204) finished in 0.003 s
19/07/31 01:03:38 INFO DAGScheduler: Job 80 finished: collect at utils.scala:204, took 0.023909 s
19/07/31 01:03:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test` AS `zzz6`
WHERE (0 = 1)
19/07/31 01:03:39 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 01:03:39 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:03:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:03:39 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:03:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:03:39 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 01:03:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 01:03:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
19/07/31 01:03:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 01:03:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 01:03:43 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 01:03:43 INFO DAGScheduler: Got job 81 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 01:03:43 INFO DAGScheduler: Final stage: ResultStage 117 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 01:03:43 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:03:43 INFO DAGScheduler: Missing parents: List()
19/07/31 01:03:43 INFO DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[372] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 01:03:43 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 97.2 KB, free 909.9 MB)
19/07/31 01:03:43 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 36.6 KB, free 909.9 MB)
19/07/31 01:03:43 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 127.0.0.1:53873 (size: 36.6 KB, free: 911.6 MB)
19/07/31 01:03:43 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1006
19/07/31 01:03:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[372] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 01:03:43 INFO TaskSchedulerImpl: Adding task set 117.0 with 1 tasks
19/07/31 01:03:43 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 213, localhost, executor driver, partition 0, PROCESS_LOCAL, 11384 bytes)
19/07/31 01:03:43 INFO Executor: Running task 0.0 in stage 117.0 (TID 213)
19/07/31 01:03:43 INFO BlockManager: Found block rdd_359_0 locally
19/07/31 01:03:43 INFO CodeGenerator: Code generated in 16.754131 ms
19/07/31 01:03:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 01:03:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 01:03:43 INFO FileOutputCommitter: Saved output of task 'attempt_20190731010343_0117_m_000000_0' to file:/Users/6jncnk4f/Desktop/anomaly/result/_temporary/0/task_20190731010343_0117_m_000000
19/07/31 01:03:43 INFO SparkHadoopMapRedUtil: attempt_20190731010343_0117_m_000000_0: Committed
19/07/31 01:03:43 INFO Executor: Finished task 0.0 in stage 117.0 (TID 213). 1576 bytes result sent to driver
19/07/31 01:03:43 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 213) in 61 ms on localhost (executor driver) (1/1)
19/07/31 01:03:43 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool 
19/07/31 01:03:43 INFO DAGScheduler: ResultStage 117 (csv at NativeMethodAccessorImpl.java:0) finished in 0.061 s
19/07/31 01:03:43 INFO DAGScheduler: Job 81 finished: csv at NativeMethodAccessorImpl.java:0, took 0.081687 s
19/07/31 01:03:43 INFO FileFormatWriter: Job null committed.
19/07/31 01:03:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
19/07/31 01:03:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
19/07/31 01:03:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
19/07/31 01:03:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
19/07/31 01:03:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
19/07/31 01:03:50 INFO SparkSqlParser: Parsing command: sparklyr_tmp_615e148d28b5
19/07/31 01:03:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_615e148d28b5` AS `zzz7`
WHERE (0 = 1)
19/07/31 01:03:50 INFO SparkSqlParser: Parsing command: sparklyr_tmp_615e3f6b8d9d
19/07/31 01:03:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_615e3f6b8d9d` AS `zzz8`
WHERE (0 = 1)
19/07/31 01:03:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_615e148d28b5`
19/07/31 01:03:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_615e3f6b8d9d`
19/07/31 01:03:50 INFO SparkSqlParser: Parsing command: sparklyr_tmp_615e2e1e5ef2
19/07/31 01:03:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_615e2e1e5ef2` AS `zzz9`
WHERE (0 = 1)
19/07/31 01:03:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_615e2e1e5ef2`
19/07/31 01:03:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `sparklyr_tmp_615e2e1e5ef2`
LIMIT 1000
19/07/31 01:03:50 INFO CodeGenerator: Code generated in 8.651874 ms
19/07/31 01:03:50 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:03:50 INFO DAGScheduler: Got job 82 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:03:50 INFO DAGScheduler: Final stage: ResultStage 118 (collect at utils.scala:204)
19/07/31 01:03:50 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:03:50 INFO DAGScheduler: Missing parents: List()
19/07/31 01:03:50 INFO DAGScheduler: Submitting ResultStage 118 (MapPartitionsRDD[380] at collect at utils.scala:204), which has no missing parents
19/07/31 01:03:50 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 34.9 KB, free 909.9 MB)
19/07/31 01:03:50 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 11.9 KB, free 909.8 MB)
19/07/31 01:03:50 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 127.0.0.1:53873 (size: 11.9 KB, free: 911.6 MB)
19/07/31 01:03:50 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1006
19/07/31 01:03:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 118 (MapPartitionsRDD[380] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:03:50 INFO TaskSchedulerImpl: Adding task set 118.0 with 1 tasks
19/07/31 01:03:50 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 214, localhost, executor driver, partition 0, PROCESS_LOCAL, 11493 bytes)
19/07/31 01:03:50 INFO Executor: Running task 0.0 in stage 118.0 (TID 214)
19/07/31 01:03:50 INFO BlockManager: Found block rdd_359_0 locally
19/07/31 01:03:50 INFO Executor: Finished task 0.0 in stage 118.0 (TID 214). 5328 bytes result sent to driver
19/07/31 01:03:50 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 214) in 5 ms on localhost (executor driver) (1/1)
19/07/31 01:03:50 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool 
19/07/31 01:03:50 INFO DAGScheduler: ResultStage 118 (collect at utils.scala:204) finished in 0.005 s
19/07/31 01:03:50 INFO DAGScheduler: Job 82 finished: collect at utils.scala:204, took 0.010507 s
19/07/31 01:03:50 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:03:50 INFO DAGScheduler: Got job 83 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:03:50 INFO DAGScheduler: Final stage: ResultStage 119 (collect at utils.scala:204)
19/07/31 01:03:50 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:03:50 INFO DAGScheduler: Missing parents: List()
19/07/31 01:03:50 INFO DAGScheduler: Submitting ResultStage 119 (MapPartitionsRDD[380] at collect at utils.scala:204), which has no missing parents
19/07/31 01:03:50 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 34.9 KB, free 909.8 MB)
19/07/31 01:03:50 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 11.9 KB, free 909.8 MB)
19/07/31 01:03:50 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 127.0.0.1:53873 (size: 11.9 KB, free: 911.6 MB)
19/07/31 01:03:50 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1006
19/07/31 01:03:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 119 (MapPartitionsRDD[380] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(1))
19/07/31 01:03:50 INFO TaskSchedulerImpl: Adding task set 119.0 with 1 tasks
19/07/31 01:03:50 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 215, localhost, executor driver, partition 1, PROCESS_LOCAL, 11493 bytes)
19/07/31 01:03:50 INFO Executor: Running task 0.0 in stage 119.0 (TID 215)
19/07/31 01:03:50 INFO BlockManager: Found block rdd_359_0 locally
19/07/31 01:03:50 INFO Executor: Finished task 0.0 in stage 119.0 (TID 215). 5328 bytes result sent to driver
19/07/31 01:03:50 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 215) in 3 ms on localhost (executor driver) (1/1)
19/07/31 01:03:50 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
19/07/31 01:03:50 INFO DAGScheduler: ResultStage 119 (collect at utils.scala:204) finished in 0.004 s
19/07/31 01:03:50 INFO DAGScheduler: Job 83 finished: collect at utils.scala:204, took 0.007117 s
19/07/31 01:03:50 INFO CodeGenerator: Code generated in 10.040342 ms
19/07/31 01:05:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_241`) `dbplyr_242`
ORDER BY `date`) `dbplyr_243`) `dbplyr_244`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 01:05:24 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:24 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_245`) `dbplyr_246`
ORDER BY `date`) `dbplyr_247`) `dbplyr_248`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 01:05:24 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:24 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:25 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4455 - cust_prospect_ind.nullCount#4454) > 0)
19/07/31 01:05:25 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4460 - visit_device_type.nullCount#4459) > 0)
19/07/31 01:05:25 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#4453 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#4452))
19/07/31 01:05:25 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#4458 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#4457))
19/07/31 01:05:25 INFO CodeGenerator: Code generated in 18.461507 ms
19/07/31 01:05:25 INFO CodeGenerator: Code generated in 11.239538 ms
19/07/31 01:05:25 INFO CodeGenerator: Code generated in 5.950711 ms
19/07/31 01:05:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:25 INFO DAGScheduler: Got job 84 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:05:25 INFO DAGScheduler: Final stage: ResultStage 120 (collect at utils.scala:204)
19/07/31 01:05:25 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:05:25 INFO DAGScheduler: Missing parents: List()
19/07/31 01:05:25 INFO DAGScheduler: Submitting ResultStage 120 (MapPartitionsRDD[385] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:25 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 72.1 KB, free 909.7 MB)
19/07/31 01:05:25 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.7 MB)
19/07/31 01:05:25 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 127.0.0.1:53873 (size: 30.5 KB, free: 911.6 MB)
19/07/31 01:05:25 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 120 (MapPartitionsRDD[385] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:25 INFO TaskSchedulerImpl: Adding task set 120.0 with 1 tasks
19/07/31 01:05:25 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 216, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:05:25 INFO Executor: Running task 0.0 in stage 120.0 (TID 216)
19/07/31 01:05:25 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:25 INFO Executor: Finished task 0.0 in stage 120.0 (TID 216). 7542 bytes result sent to driver
19/07/31 01:05:25 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 216) in 9 ms on localhost (executor driver) (1/1)
19/07/31 01:05:25 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool 
19/07/31 01:05:25 INFO DAGScheduler: ResultStage 120 (collect at utils.scala:204) finished in 0.010 s
19/07/31 01:05:25 INFO DAGScheduler: Job 84 finished: collect at utils.scala:204, took 0.016712 s
19/07/31 01:05:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:25 INFO DAGScheduler: Registering RDD 386 (collect at utils.scala:204)
19/07/31 01:05:25 INFO DAGScheduler: Got job 85 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:05:25 INFO DAGScheduler: Final stage: ResultStage 122 (collect at utils.scala:204)
19/07/31 01:05:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 121)
19/07/31 01:05:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 121)
19/07/31 01:05:25 INFO DAGScheduler: Submitting ShuffleMapStage 121 (MapPartitionsRDD[386] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:25 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 74.6 KB, free 909.6 MB)
19/07/31 01:05:25 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.6 MB)
19/07/31 01:05:25 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 127.0.0.1:53873 (size: 31.8 KB, free: 911.5 MB)
19/07/31 01:05:25 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 121 (MapPartitionsRDD[386] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:25 INFO TaskSchedulerImpl: Adding task set 121.0 with 1 tasks
19/07/31 01:05:25 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 217, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:05:25 INFO Executor: Running task 0.0 in stage 121.0 (TID 217)
19/07/31 01:05:25 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:25 INFO Executor: Finished task 0.0 in stage 121.0 (TID 217). 1687 bytes result sent to driver
19/07/31 01:05:25 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 217) in 14 ms on localhost (executor driver) (1/1)
19/07/31 01:05:25 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool 
19/07/31 01:05:25 INFO DAGScheduler: ShuffleMapStage 121 (collect at utils.scala:204) finished in 0.015 s
19/07/31 01:05:25 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:05:25 INFO DAGScheduler: running: Set()
19/07/31 01:05:25 INFO DAGScheduler: waiting: Set(ResultStage 122)
19/07/31 01:05:25 INFO DAGScheduler: failed: Set()
19/07/31 01:05:25 INFO DAGScheduler: Submitting ResultStage 122 (MapPartitionsRDD[389] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:25 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 16.8 KB, free 909.6 MB)
19/07/31 01:05:25 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 8.1 KB, free 909.6 MB)
19/07/31 01:05:25 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 127.0.0.1:53873 (size: 8.1 KB, free: 911.5 MB)
19/07/31 01:05:25 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:25 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 122 (MapPartitionsRDD[389] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:05:25 INFO TaskSchedulerImpl: Adding task set 122.0 with 4 tasks
19/07/31 01:05:25 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 218, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:05:25 INFO TaskSetManager: Starting task 1.0 in stage 122.0 (TID 219, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:05:25 INFO TaskSetManager: Starting task 2.0 in stage 122.0 (TID 220, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:05:25 INFO TaskSetManager: Starting task 3.0 in stage 122.0 (TID 221, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:05:25 INFO Executor: Running task 0.0 in stage 122.0 (TID 218)
19/07/31 01:05:25 INFO Executor: Running task 1.0 in stage 122.0 (TID 219)
19/07/31 01:05:25 INFO Executor: Running task 3.0 in stage 122.0 (TID 221)
19/07/31 01:05:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
19/07/31 01:05:25 INFO Executor: Running task 2.0 in stage 122.0 (TID 220)
19/07/31 01:05:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:05:25 INFO CodeGenerator: Code generated in 10.110133 ms
19/07/31 01:05:25 INFO Executor: Finished task 0.0 in stage 122.0 (TID 218). 2365 bytes result sent to driver
19/07/31 01:05:25 INFO Executor: Finished task 2.0 in stage 122.0 (TID 220). 2364 bytes result sent to driver
19/07/31 01:05:25 INFO Executor: Finished task 1.0 in stage 122.0 (TID 219). 2368 bytes result sent to driver
19/07/31 01:05:25 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 218) in 35 ms on localhost (executor driver) (1/4)
19/07/31 01:05:25 INFO TaskSetManager: Finished task 2.0 in stage 122.0 (TID 220) in 35 ms on localhost (executor driver) (2/4)
19/07/31 01:05:25 INFO TaskSetManager: Finished task 1.0 in stage 122.0 (TID 219) in 35 ms on localhost (executor driver) (3/4)
19/07/31 01:05:25 INFO Executor: Finished task 3.0 in stage 122.0 (TID 221). 2342 bytes result sent to driver
19/07/31 01:05:25 INFO TaskSetManager: Finished task 3.0 in stage 122.0 (TID 221) in 38 ms on localhost (executor driver) (4/4)
19/07/31 01:05:25 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool 
19/07/31 01:05:25 INFO DAGScheduler: ResultStage 122 (collect at utils.scala:204) finished in 0.038 s
19/07/31 01:05:25 INFO DAGScheduler: Job 85 finished: collect at utils.scala:204, took 0.069280 s
19/07/31 01:05:25 INFO CodeGenerator: Code generated in 26.93119 ms
19/07/31 01:05:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_249`) `dbplyr_250`
ORDER BY `date`) `dbplyr_251`) `dbplyr_252`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 01:05:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_253`) `dbplyr_254`
ORDER BY `date`) `dbplyr_255`) `dbplyr_256`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 01:05:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:26 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4553 - cust_prospect_ind.nullCount#4552) > 0)
19/07/31 01:05:26 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4558 - visit_device_type.nullCount#4557) > 0)
19/07/31 01:05:26 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#4551 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#4550))
19/07/31 01:05:26 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#4556 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#4555))
19/07/31 01:05:26 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:26 INFO DAGScheduler: Got job 86 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:05:26 INFO DAGScheduler: Final stage: ResultStage 123 (collect at utils.scala:204)
19/07/31 01:05:26 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:05:26 INFO DAGScheduler: Missing parents: List()
19/07/31 01:05:26 INFO DAGScheduler: Submitting ResultStage 123 (MapPartitionsRDD[394] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:26 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 72.1 KB, free 909.5 MB)
19/07/31 01:05:26 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 30.4 KB, free 909.5 MB)
19/07/31 01:05:26 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 127.0.0.1:53873 (size: 30.4 KB, free: 911.5 MB)
19/07/31 01:05:26 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 123 (MapPartitionsRDD[394] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:26 INFO TaskSchedulerImpl: Adding task set 123.0 with 1 tasks
19/07/31 01:05:26 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 222, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:05:26 INFO Executor: Running task 0.0 in stage 123.0 (TID 222)
19/07/31 01:05:26 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:26 INFO Executor: Finished task 0.0 in stage 123.0 (TID 222). 7542 bytes result sent to driver
19/07/31 01:05:26 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 222) in 4 ms on localhost (executor driver) (1/1)
19/07/31 01:05:26 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool 
19/07/31 01:05:26 INFO DAGScheduler: ResultStage 123 (collect at utils.scala:204) finished in 0.005 s
19/07/31 01:05:26 INFO DAGScheduler: Job 86 finished: collect at utils.scala:204, took 0.008747 s
19/07/31 01:05:26 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:26 INFO DAGScheduler: Registering RDD 395 (collect at utils.scala:204)
19/07/31 01:05:26 INFO DAGScheduler: Got job 87 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:05:26 INFO DAGScheduler: Final stage: ResultStage 125 (collect at utils.scala:204)
19/07/31 01:05:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 124)
19/07/31 01:05:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 124)
19/07/31 01:05:26 INFO DAGScheduler: Submitting ShuffleMapStage 124 (MapPartitionsRDD[395] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:26 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 74.6 KB, free 909.4 MB)
19/07/31 01:05:26 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 31.7 KB, free 909.4 MB)
19/07/31 01:05:26 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 127.0.0.1:53873 (size: 31.7 KB, free: 911.5 MB)
19/07/31 01:05:26 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 124 (MapPartitionsRDD[395] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:26 INFO TaskSchedulerImpl: Adding task set 124.0 with 1 tasks
19/07/31 01:05:26 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 223, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:05:26 INFO Executor: Running task 0.0 in stage 124.0 (TID 223)
19/07/31 01:05:26 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:26 INFO Executor: Finished task 0.0 in stage 124.0 (TID 223). 1687 bytes result sent to driver
19/07/31 01:05:26 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 223) in 11 ms on localhost (executor driver) (1/1)
19/07/31 01:05:26 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool 
19/07/31 01:05:26 INFO DAGScheduler: ShuffleMapStage 124 (collect at utils.scala:204) finished in 0.012 s
19/07/31 01:05:26 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:05:26 INFO DAGScheduler: running: Set()
19/07/31 01:05:26 INFO DAGScheduler: waiting: Set(ResultStage 125)
19/07/31 01:05:26 INFO DAGScheduler: failed: Set()
19/07/31 01:05:26 INFO DAGScheduler: Submitting ResultStage 125 (MapPartitionsRDD[398] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:26 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 16.8 KB, free 909.3 MB)
19/07/31 01:05:26 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 8.1 KB, free 909.3 MB)
19/07/31 01:05:26 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 127.0.0.1:53873 (size: 8.1 KB, free: 911.4 MB)
19/07/31 01:05:26 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 125 (MapPartitionsRDD[398] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:05:26 INFO TaskSchedulerImpl: Adding task set 125.0 with 4 tasks
19/07/31 01:05:26 INFO TaskSetManager: Starting task 0.0 in stage 125.0 (TID 224, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:05:26 INFO TaskSetManager: Starting task 1.0 in stage 125.0 (TID 225, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:05:26 INFO TaskSetManager: Starting task 2.0 in stage 125.0 (TID 226, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:05:26 INFO TaskSetManager: Starting task 3.0 in stage 125.0 (TID 227, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:05:26 INFO Executor: Running task 3.0 in stage 125.0 (TID 227)
19/07/31 01:05:26 INFO Executor: Running task 1.0 in stage 125.0 (TID 225)
19/07/31 01:05:26 INFO Executor: Running task 0.0 in stage 125.0 (TID 224)
19/07/31 01:05:26 INFO Executor: Running task 2.0 in stage 125.0 (TID 226)
19/07/31 01:05:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:05:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:26 INFO Executor: Finished task 2.0 in stage 125.0 (TID 226). 2364 bytes result sent to driver
19/07/31 01:05:26 INFO Executor: Finished task 3.0 in stage 125.0 (TID 227). 2342 bytes result sent to driver
19/07/31 01:05:26 INFO Executor: Finished task 0.0 in stage 125.0 (TID 224). 2365 bytes result sent to driver
19/07/31 01:05:26 INFO TaskSetManager: Finished task 2.0 in stage 125.0 (TID 226) in 6 ms on localhost (executor driver) (1/4)
19/07/31 01:05:26 INFO TaskSetManager: Finished task 3.0 in stage 125.0 (TID 227) in 6 ms on localhost (executor driver) (2/4)
19/07/31 01:05:26 INFO Executor: Finished task 1.0 in stage 125.0 (TID 225). 2368 bytes result sent to driver
19/07/31 01:05:26 INFO TaskSetManager: Finished task 0.0 in stage 125.0 (TID 224) in 7 ms on localhost (executor driver) (3/4)
19/07/31 01:05:26 INFO TaskSetManager: Finished task 1.0 in stage 125.0 (TID 225) in 8 ms on localhost (executor driver) (4/4)
19/07/31 01:05:26 INFO TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool 
19/07/31 01:05:26 INFO DAGScheduler: ResultStage 125 (collect at utils.scala:204) finished in 0.008 s
19/07/31 01:05:26 INFO DAGScheduler: Job 87 finished: collect at utils.scala:204, took 0.035316 s
19/07/31 01:05:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_257`) `dbplyr_258`
ORDER BY `date`) `dbplyr_259`) `dbplyr_260`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Mobile Phone"))
19/07/31 01:05:27 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:27 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_261`) `dbplyr_262`
ORDER BY `date`) `dbplyr_263`) `dbplyr_264`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Mobile Phone"))
19/07/31 01:05:27 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:27 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:27 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4651 - cust_prospect_ind.nullCount#4650) > 0)
19/07/31 01:05:27 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4656 - visit_device_type.nullCount#4655) > 0)
19/07/31 01:05:27 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#4649 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#4648))
19/07/31 01:05:27 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#4654 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#4653))
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3105
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 127.0.0.1:53873 in memory (size: 31.6 KB, free: 911.5 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2799
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3165
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 911.5 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3095
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 127.0.0.1:53873 in memory (size: 30.5 KB, free: 911.5 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned shuffle 26
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3160
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3155
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2560
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2960
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2641
19/07/31 01:05:27 INFO ContextCleaner: Cleaned shuffle 29
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 127.0.0.1:53873 in memory (size: 30.3 KB, free: 911.5 MB)
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 911.5 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3376
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2482
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2480
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2963
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 127.0.0.1:53873 in memory (size: 31.6 KB, free: 911.6 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3453
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 127.0.0.1:53873 in memory (size: 3.7 KB, free: 911.6 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3101
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3096
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2887
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2802
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2555
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 127.0.0.1:53873 in memory (size: 31.7 KB, free: 911.6 MB)
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 127.0.0.1:53873 in memory (size: 3.6 KB, free: 911.6 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2886
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3299
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2639
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3102
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2966
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 911.6 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2474
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3242
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3293
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2882
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2967
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2642
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3104
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 911.7 MB)
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 127.0.0.1:53873 in memory (size: 3.7 KB, free: 911.7 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2562
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 127.0.0.1:53873 in memory (size: 10.4 KB, free: 911.7 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned shuffle 36
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 127.0.0.1:53873 in memory (size: 30.3 KB, free: 911.7 MB)
19/07/31 01:05:27 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3241
19/07/31 01:05:27 INFO ContextCleaner: Cleaned shuffle 30
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3159
19/07/31 01:05:27 INFO DAGScheduler: Got job 88 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:05:27 INFO DAGScheduler: Final stage: ResultStage 126 (collect at utils.scala:204)
19/07/31 01:05:27 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:05:27 INFO DAGScheduler: Missing parents: List()
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 127.0.0.1:53873 in memory (size: 10.4 KB, free: 911.7 MB)
19/07/31 01:05:27 INFO DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[403] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2717
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 127.0.0.1:53873 in memory (size: 31.8 KB, free: 911.7 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3097
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 911.7 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3215
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3380
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3103
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2725
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2881
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2719
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 127.0.0.1:53873 in memory (size: 31.7 KB, free: 911.8 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2805
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3296
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 127.0.0.1:53873 in memory (size: 11.9 KB, free: 911.8 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3379
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2640
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2638
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2563
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2637
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2478
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2558
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3161
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 127.0.0.1:53873 in memory (size: 31.6 KB, free: 911.8 MB)
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 127.0.0.1:53873 in memory (size: 8.1 KB, free: 911.8 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3374
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2724
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2800
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3372
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3166
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3291
19/07/31 01:05:27 INFO ContextCleaner: Cleaned shuffle 27
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3156
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 911.8 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3066
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2879
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 127.0.0.1:53873 in memory (size: 31.6 KB, free: 911.9 MB)
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 127.0.0.1:53873 in memory (size: 8.1 KB, free: 911.9 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2720
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3094
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2801
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 911.9 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2961
19/07/31 01:05:27 INFO ContextCleaner: Cleaned shuffle 32
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 127.0.0.1:53873 in memory (size: 31.5 KB, free: 911.9 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned shuffle 28
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2804
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2968
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2880
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2479
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3162
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3098
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2884
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3157
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2556
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2723
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3373
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 911.9 MB)
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 912.0 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2721
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3294
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2962
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2476
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2798
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3100
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2481
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3292
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 912.0 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2718
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2722
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2644
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3297
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2965
19/07/31 01:05:27 INFO ContextCleaner: Cleaned shuffle 35
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3378
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 127.0.0.1:53873 in memory (size: 31.6 KB, free: 912.0 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3099
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3295
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3298
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 912.0 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2477
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2885
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 127.0.0.1:53873 in memory (size: 36.6 KB, free: 912.1 MB)
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 912.1 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2883
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2643
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2803
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 127.0.0.1:53873 in memory (size: 7.8 KB, free: 912.1 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3154
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2636
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3158
19/07/31 01:05:27 INFO ContextCleaner: Cleaned shuffle 31
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3377
19/07/31 01:05:27 INFO ContextCleaner: Cleaned shuffle 33
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3163
19/07/31 01:05:27 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 72.1 KB, free 911.5 MB)
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 127.0.0.1:53873 in memory (size: 11.9 KB, free: 912.1 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3164
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2561
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 127.0.0.1:53873 in memory (size: 30.3 KB, free: 912.2 MB)
19/07/31 01:05:27 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 30.5 KB, free 911.6 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2964
19/07/31 01:05:27 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 127.0.0.1:53873 (size: 30.5 KB, free: 912.1 MB)
19/07/31 01:05:27 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 912.2 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2475
19/07/31 01:05:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 126 (MapPartitionsRDD[403] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:27 INFO TaskSchedulerImpl: Adding task set 126.0 with 1 tasks
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 127.0.0.1:53873 in memory (size: 3.6 KB, free: 912.2 MB)
19/07/31 01:05:27 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 228, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned shuffle 37
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3375
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2559
19/07/31 01:05:27 INFO Executor: Running task 0.0 in stage 126.0 (TID 228)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned shuffle 34
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2557
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3041
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3240
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 2806
19/07/31 01:05:27 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 127.0.0.1:53873 in memory (size: 31.7 KB, free: 912.2 MB)
19/07/31 01:05:27 INFO ContextCleaner: Cleaned accumulator 3093
19/07/31 01:05:27 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:27 INFO Executor: Finished task 0.0 in stage 126.0 (TID 228). 6979 bytes result sent to driver
19/07/31 01:05:27 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 228) in 5 ms on localhost (executor driver) (1/1)
19/07/31 01:05:27 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool 
19/07/31 01:05:27 INFO DAGScheduler: ResultStage 126 (collect at utils.scala:204) finished in 0.006 s
19/07/31 01:05:27 INFO DAGScheduler: Job 88 finished: collect at utils.scala:204, took 0.026107 s
19/07/31 01:05:27 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:27 INFO DAGScheduler: Registering RDD 404 (collect at utils.scala:204)
19/07/31 01:05:27 INFO DAGScheduler: Got job 89 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:05:27 INFO DAGScheduler: Final stage: ResultStage 128 (collect at utils.scala:204)
19/07/31 01:05:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 127)
19/07/31 01:05:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 127)
19/07/31 01:05:27 INFO DAGScheduler: Submitting ShuffleMapStage 127 (MapPartitionsRDD[404] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:27 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 74.5 KB, free 911.8 MB)
19/07/31 01:05:27 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.7 MB)
19/07/31 01:05:27 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 127.0.0.1:53873 (size: 31.8 KB, free: 912.2 MB)
19/07/31 01:05:27 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 127 (MapPartitionsRDD[404] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:27 INFO TaskSchedulerImpl: Adding task set 127.0 with 1 tasks
19/07/31 01:05:27 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 229, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:05:27 INFO Executor: Running task 0.0 in stage 127.0 (TID 229)
19/07/31 01:05:27 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:27 INFO Executor: Finished task 0.0 in stage 127.0 (TID 229). 1687 bytes result sent to driver
19/07/31 01:05:27 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 229) in 9 ms on localhost (executor driver) (1/1)
19/07/31 01:05:27 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool 
19/07/31 01:05:27 INFO DAGScheduler: ShuffleMapStage 127 (collect at utils.scala:204) finished in 0.009 s
19/07/31 01:05:27 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:05:27 INFO DAGScheduler: running: Set()
19/07/31 01:05:27 INFO DAGScheduler: waiting: Set(ResultStage 128)
19/07/31 01:05:27 INFO DAGScheduler: failed: Set()
19/07/31 01:05:27 INFO DAGScheduler: Submitting ResultStage 128 (MapPartitionsRDD[407] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:27 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 16.8 KB, free 911.7 MB)
19/07/31 01:05:27 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 8.1 KB, free 911.7 MB)
19/07/31 01:05:27 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 127.0.0.1:53873 (size: 8.1 KB, free: 912.2 MB)
19/07/31 01:05:27 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 128 (MapPartitionsRDD[407] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:05:27 INFO TaskSchedulerImpl: Adding task set 128.0 with 4 tasks
19/07/31 01:05:27 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 230, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:05:27 INFO TaskSetManager: Starting task 1.0 in stage 128.0 (TID 231, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:05:27 INFO TaskSetManager: Starting task 2.0 in stage 128.0 (TID 232, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:05:27 INFO TaskSetManager: Starting task 3.0 in stage 128.0 (TID 233, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:05:27 INFO Executor: Running task 3.0 in stage 128.0 (TID 233)
19/07/31 01:05:27 INFO Executor: Running task 2.0 in stage 128.0 (TID 232)
19/07/31 01:05:27 INFO Executor: Running task 1.0 in stage 128.0 (TID 231)
19/07/31 01:05:27 INFO Executor: Running task 0.0 in stage 128.0 (TID 230)
19/07/31 01:05:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:27 INFO Executor: Finished task 3.0 in stage 128.0 (TID 233). 2341 bytes result sent to driver
19/07/31 01:05:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:27 INFO Executor: Finished task 1.0 in stage 128.0 (TID 231). 2353 bytes result sent to driver
19/07/31 01:05:27 INFO TaskSetManager: Finished task 3.0 in stage 128.0 (TID 233) in 7 ms on localhost (executor driver) (1/4)
19/07/31 01:05:27 INFO Executor: Finished task 0.0 in stage 128.0 (TID 230). 2348 bytes result sent to driver
19/07/31 01:05:27 INFO TaskSetManager: Finished task 1.0 in stage 128.0 (TID 231) in 8 ms on localhost (executor driver) (2/4)
19/07/31 01:05:27 INFO Executor: Finished task 2.0 in stage 128.0 (TID 232). 2357 bytes result sent to driver
19/07/31 01:05:27 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 230) in 8 ms on localhost (executor driver) (3/4)
19/07/31 01:05:27 INFO TaskSetManager: Finished task 2.0 in stage 128.0 (TID 232) in 8 ms on localhost (executor driver) (4/4)
19/07/31 01:05:27 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool 
19/07/31 01:05:27 INFO DAGScheduler: ResultStage 128 (collect at utils.scala:204) finished in 0.008 s
19/07/31 01:05:27 INFO DAGScheduler: Job 89 finished: collect at utils.scala:204, took 0.027117 s
19/07/31 01:05:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_265`) `dbplyr_266`
ORDER BY `date`) `dbplyr_267`) `dbplyr_268`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Mobile Phone"))
19/07/31 01:05:28 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:28 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_269`) `dbplyr_270`
ORDER BY `date`) `dbplyr_271`) `dbplyr_272`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Mobile Phone"))
19/07/31 01:05:28 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:28 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:28 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4749 - cust_prospect_ind.nullCount#4748) > 0)
19/07/31 01:05:28 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4754 - visit_device_type.nullCount#4753) > 0)
19/07/31 01:05:28 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#4747 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#4746))
19/07/31 01:05:28 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#4752 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#4751))
19/07/31 01:05:28 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:28 INFO DAGScheduler: Got job 90 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:05:28 INFO DAGScheduler: Final stage: ResultStage 129 (collect at utils.scala:204)
19/07/31 01:05:28 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:05:28 INFO DAGScheduler: Missing parents: List()
19/07/31 01:05:28 INFO DAGScheduler: Submitting ResultStage 129 (MapPartitionsRDD[412] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:28 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 72.1 KB, free 911.6 MB)
19/07/31 01:05:28 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 30.5 KB, free 911.6 MB)
19/07/31 01:05:28 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 127.0.0.1:53873 (size: 30.5 KB, free: 912.1 MB)
19/07/31 01:05:28 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 129 (MapPartitionsRDD[412] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:28 INFO TaskSchedulerImpl: Adding task set 129.0 with 1 tasks
19/07/31 01:05:28 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 234, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:05:28 INFO Executor: Running task 0.0 in stage 129.0 (TID 234)
19/07/31 01:05:28 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:28 INFO Executor: Finished task 0.0 in stage 129.0 (TID 234). 6979 bytes result sent to driver
19/07/31 01:05:28 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 234) in 3 ms on localhost (executor driver) (1/1)
19/07/31 01:05:28 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool 
19/07/31 01:05:28 INFO DAGScheduler: ResultStage 129 (collect at utils.scala:204) finished in 0.004 s
19/07/31 01:05:28 INFO DAGScheduler: Job 90 finished: collect at utils.scala:204, took 0.007671 s
19/07/31 01:05:28 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:28 INFO DAGScheduler: Registering RDD 413 (collect at utils.scala:204)
19/07/31 01:05:28 INFO DAGScheduler: Got job 91 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:05:28 INFO DAGScheduler: Final stage: ResultStage 131 (collect at utils.scala:204)
19/07/31 01:05:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 130)
19/07/31 01:05:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 130)
19/07/31 01:05:28 INFO DAGScheduler: Submitting ShuffleMapStage 130 (MapPartitionsRDD[413] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:28 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 74.5 KB, free 911.5 MB)
19/07/31 01:05:28 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.5 MB)
19/07/31 01:05:28 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 127.0.0.1:53873 (size: 31.8 KB, free: 912.1 MB)
19/07/31 01:05:28 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 130 (MapPartitionsRDD[413] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:28 INFO TaskSchedulerImpl: Adding task set 130.0 with 1 tasks
19/07/31 01:05:28 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 235, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:05:28 INFO Executor: Running task 0.0 in stage 130.0 (TID 235)
19/07/31 01:05:28 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:28 INFO Executor: Finished task 0.0 in stage 130.0 (TID 235). 1687 bytes result sent to driver
19/07/31 01:05:28 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 235) in 7 ms on localhost (executor driver) (1/1)
19/07/31 01:05:28 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool 
19/07/31 01:05:28 INFO DAGScheduler: ShuffleMapStage 130 (collect at utils.scala:204) finished in 0.007 s
19/07/31 01:05:28 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:05:28 INFO DAGScheduler: running: Set()
19/07/31 01:05:28 INFO DAGScheduler: waiting: Set(ResultStage 131)
19/07/31 01:05:28 INFO DAGScheduler: failed: Set()
19/07/31 01:05:28 INFO DAGScheduler: Submitting ResultStage 131 (MapPartitionsRDD[416] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:28 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 16.8 KB, free 911.5 MB)
19/07/31 01:05:28 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 8.1 KB, free 911.5 MB)
19/07/31 01:05:28 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 127.0.0.1:53873 (size: 8.1 KB, free: 912.1 MB)
19/07/31 01:05:28 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:28 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 131 (MapPartitionsRDD[416] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:05:28 INFO TaskSchedulerImpl: Adding task set 131.0 with 4 tasks
19/07/31 01:05:28 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 236, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:05:28 INFO TaskSetManager: Starting task 1.0 in stage 131.0 (TID 237, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:05:28 INFO TaskSetManager: Starting task 2.0 in stage 131.0 (TID 238, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:05:28 INFO TaskSetManager: Starting task 3.0 in stage 131.0 (TID 239, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:05:28 INFO Executor: Running task 0.0 in stage 131.0 (TID 236)
19/07/31 01:05:28 INFO Executor: Running task 2.0 in stage 131.0 (TID 238)
19/07/31 01:05:28 INFO Executor: Running task 3.0 in stage 131.0 (TID 239)
19/07/31 01:05:28 INFO Executor: Running task 1.0 in stage 131.0 (TID 237)
19/07/31 01:05:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:05:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:05:28 INFO Executor: Finished task 1.0 in stage 131.0 (TID 237). 2329 bytes result sent to driver
19/07/31 01:05:28 INFO Executor: Finished task 2.0 in stage 131.0 (TID 238). 2350 bytes result sent to driver
19/07/31 01:05:28 INFO Executor: Finished task 3.0 in stage 131.0 (TID 239). 2333 bytes result sent to driver
19/07/31 01:05:28 INFO Executor: Finished task 0.0 in stage 131.0 (TID 236). 2348 bytes result sent to driver
19/07/31 01:05:28 INFO TaskSetManager: Finished task 1.0 in stage 131.0 (TID 237) in 4 ms on localhost (executor driver) (1/4)
19/07/31 01:05:28 INFO TaskSetManager: Finished task 3.0 in stage 131.0 (TID 239) in 4 ms on localhost (executor driver) (2/4)
19/07/31 01:05:28 INFO TaskSetManager: Finished task 2.0 in stage 131.0 (TID 238) in 4 ms on localhost (executor driver) (3/4)
19/07/31 01:05:28 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 236) in 4 ms on localhost (executor driver) (4/4)
19/07/31 01:05:28 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool 
19/07/31 01:05:28 INFO DAGScheduler: ResultStage 131 (collect at utils.scala:204) finished in 0.006 s
19/07/31 01:05:28 INFO DAGScheduler: Job 91 finished: collect at utils.scala:204, took 0.020024 s
19/07/31 01:05:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_273`) `dbplyr_274`
ORDER BY `date`) `dbplyr_275`) `dbplyr_276`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Desktop"))
19/07/31 01:05:29 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:29 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_277`) `dbplyr_278`
ORDER BY `date`) `dbplyr_279`) `dbplyr_280`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Desktop"))
19/07/31 01:05:29 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:29 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:29 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4847 - cust_prospect_ind.nullCount#4846) > 0)
19/07/31 01:05:29 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4852 - visit_device_type.nullCount#4851) > 0)
19/07/31 01:05:29 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#4845 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#4844))
19/07/31 01:05:29 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#4850 <= Desktop) && (Desktop <= visit_device_type.upperBound#4849))
19/07/31 01:05:29 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:29 INFO DAGScheduler: Got job 92 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:05:29 INFO DAGScheduler: Final stage: ResultStage 132 (collect at utils.scala:204)
19/07/31 01:05:29 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:05:29 INFO DAGScheduler: Missing parents: List()
19/07/31 01:05:29 INFO DAGScheduler: Submitting ResultStage 132 (MapPartitionsRDD[421] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:29 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 72.1 KB, free 911.4 MB)
19/07/31 01:05:29 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.4 MB)
19/07/31 01:05:29 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 127.0.0.1:53873 (size: 30.4 KB, free: 912.1 MB)
19/07/31 01:05:29 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 132 (MapPartitionsRDD[421] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:29 INFO TaskSchedulerImpl: Adding task set 132.0 with 1 tasks
19/07/31 01:05:29 INFO TaskSetManager: Starting task 0.0 in stage 132.0 (TID 240, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:05:29 INFO Executor: Running task 0.0 in stage 132.0 (TID 240)
19/07/31 01:05:29 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:29 INFO Executor: Finished task 0.0 in stage 132.0 (TID 240). 7068 bytes result sent to driver
19/07/31 01:05:29 INFO TaskSetManager: Finished task 0.0 in stage 132.0 (TID 240) in 4 ms on localhost (executor driver) (1/1)
19/07/31 01:05:29 INFO TaskSchedulerImpl: Removed TaskSet 132.0, whose tasks have all completed, from pool 
19/07/31 01:05:29 INFO DAGScheduler: ResultStage 132 (collect at utils.scala:204) finished in 0.005 s
19/07/31 01:05:29 INFO DAGScheduler: Job 92 finished: collect at utils.scala:204, took 0.013378 s
19/07/31 01:05:29 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:29 INFO DAGScheduler: Registering RDD 422 (collect at utils.scala:204)
19/07/31 01:05:29 INFO DAGScheduler: Got job 93 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:05:29 INFO DAGScheduler: Final stage: ResultStage 134 (collect at utils.scala:204)
19/07/31 01:05:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 133)
19/07/31 01:05:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 133)
19/07/31 01:05:29 INFO DAGScheduler: Submitting ShuffleMapStage 133 (MapPartitionsRDD[422] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:29 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 74.5 KB, free 911.3 MB)
19/07/31 01:05:29 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.3 MB)
19/07/31 01:05:29 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 127.0.0.1:53873 (size: 31.8 KB, free: 912.0 MB)
19/07/31 01:05:29 INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 133 (MapPartitionsRDD[422] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:29 INFO TaskSchedulerImpl: Adding task set 133.0 with 1 tasks
19/07/31 01:05:29 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 241, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:05:29 INFO Executor: Running task 0.0 in stage 133.0 (TID 241)
19/07/31 01:05:29 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:29 INFO Executor: Finished task 0.0 in stage 133.0 (TID 241). 1687 bytes result sent to driver
19/07/31 01:05:29 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 241) in 7 ms on localhost (executor driver) (1/1)
19/07/31 01:05:29 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool 
19/07/31 01:05:29 INFO DAGScheduler: ShuffleMapStage 133 (collect at utils.scala:204) finished in 0.007 s
19/07/31 01:05:29 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:05:29 INFO DAGScheduler: running: Set()
19/07/31 01:05:29 INFO DAGScheduler: waiting: Set(ResultStage 134)
19/07/31 01:05:29 INFO DAGScheduler: failed: Set()
19/07/31 01:05:29 INFO DAGScheduler: Submitting ResultStage 134 (MapPartitionsRDD[425] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:29 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 16.8 KB, free 911.3 MB)
19/07/31 01:05:29 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 8.1 KB, free 911.3 MB)
19/07/31 01:05:29 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 127.0.0.1:53873 (size: 8.1 KB, free: 912.0 MB)
19/07/31 01:05:29 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 134 (MapPartitionsRDD[425] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:05:29 INFO TaskSchedulerImpl: Adding task set 134.0 with 4 tasks
19/07/31 01:05:29 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 242, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:05:29 INFO TaskSetManager: Starting task 1.0 in stage 134.0 (TID 243, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:05:29 INFO TaskSetManager: Starting task 2.0 in stage 134.0 (TID 244, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:05:29 INFO TaskSetManager: Starting task 3.0 in stage 134.0 (TID 245, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:05:29 INFO Executor: Running task 0.0 in stage 134.0 (TID 242)
19/07/31 01:05:29 INFO Executor: Running task 3.0 in stage 134.0 (TID 245)
19/07/31 01:05:29 INFO Executor: Running task 2.0 in stage 134.0 (TID 244)
19/07/31 01:05:29 INFO Executor: Running task 1.0 in stage 134.0 (TID 243)
19/07/31 01:05:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:29 INFO Executor: Finished task 2.0 in stage 134.0 (TID 244). 2366 bytes result sent to driver
19/07/31 01:05:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/07/31 01:05:29 INFO Executor: Finished task 0.0 in stage 134.0 (TID 242). 2373 bytes result sent to driver
19/07/31 01:05:29 INFO Executor: Finished task 1.0 in stage 134.0 (TID 243). 2369 bytes result sent to driver
19/07/31 01:05:29 INFO TaskSetManager: Finished task 2.0 in stage 134.0 (TID 244) in 4 ms on localhost (executor driver) (1/4)
19/07/31 01:05:29 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 242) in 5 ms on localhost (executor driver) (2/4)
19/07/31 01:05:29 INFO TaskSetManager: Finished task 1.0 in stage 134.0 (TID 243) in 4 ms on localhost (executor driver) (3/4)
19/07/31 01:05:29 INFO Executor: Finished task 3.0 in stage 134.0 (TID 245). 2348 bytes result sent to driver
19/07/31 01:05:29 INFO TaskSetManager: Finished task 3.0 in stage 134.0 (TID 245) in 5 ms on localhost (executor driver) (4/4)
19/07/31 01:05:29 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool 
19/07/31 01:05:29 INFO DAGScheduler: ResultStage 134 (collect at utils.scala:204) finished in 0.006 s
19/07/31 01:05:29 INFO DAGScheduler: Job 93 finished: collect at utils.scala:204, took 0.022299 s
19/07/31 01:05:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_281`) `dbplyr_282`
ORDER BY `date`) `dbplyr_283`) `dbplyr_284`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Desktop"))
19/07/31 01:05:30 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:30 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_285`) `dbplyr_286`
ORDER BY `date`) `dbplyr_287`) `dbplyr_288`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Desktop"))
19/07/31 01:05:30 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:30 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:30 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4945 - cust_prospect_ind.nullCount#4944) > 0)
19/07/31 01:05:30 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4950 - visit_device_type.nullCount#4949) > 0)
19/07/31 01:05:30 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#4943 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#4942))
19/07/31 01:05:30 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#4948 <= Desktop) && (Desktop <= visit_device_type.upperBound#4947))
19/07/31 01:05:30 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:30 INFO DAGScheduler: Got job 94 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:05:30 INFO DAGScheduler: Final stage: ResultStage 135 (collect at utils.scala:204)
19/07/31 01:05:30 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:05:30 INFO DAGScheduler: Missing parents: List()
19/07/31 01:05:30 INFO DAGScheduler: Submitting ResultStage 135 (MapPartitionsRDD[430] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:30 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 72.1 KB, free 911.2 MB)
19/07/31 01:05:30 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 30.5 KB, free 911.2 MB)
19/07/31 01:05:30 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 127.0.0.1:53873 (size: 30.5 KB, free: 912.0 MB)
19/07/31 01:05:30 INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 135 (MapPartitionsRDD[430] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:30 INFO TaskSchedulerImpl: Adding task set 135.0 with 1 tasks
19/07/31 01:05:30 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 246, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:05:30 INFO Executor: Running task 0.0 in stage 135.0 (TID 246)
19/07/31 01:05:30 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:30 INFO Executor: Finished task 0.0 in stage 135.0 (TID 246). 7068 bytes result sent to driver
19/07/31 01:05:30 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 246) in 4 ms on localhost (executor driver) (1/1)
19/07/31 01:05:30 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool 
19/07/31 01:05:30 INFO DAGScheduler: ResultStage 135 (collect at utils.scala:204) finished in 0.005 s
19/07/31 01:05:30 INFO DAGScheduler: Job 94 finished: collect at utils.scala:204, took 0.015438 s
19/07/31 01:05:30 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:30 INFO DAGScheduler: Registering RDD 431 (collect at utils.scala:204)
19/07/31 01:05:30 INFO DAGScheduler: Got job 95 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:05:30 INFO DAGScheduler: Final stage: ResultStage 137 (collect at utils.scala:204)
19/07/31 01:05:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 136)
19/07/31 01:05:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 136)
19/07/31 01:05:30 INFO DAGScheduler: Submitting ShuffleMapStage 136 (MapPartitionsRDD[431] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:30 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 74.5 KB, free 911.1 MB)
19/07/31 01:05:30 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.1 MB)
19/07/31 01:05:30 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 127.0.0.1:53873 (size: 31.8 KB, free: 912.0 MB)
19/07/31 01:05:30 INFO SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 136 (MapPartitionsRDD[431] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:30 INFO TaskSchedulerImpl: Adding task set 136.0 with 1 tasks
19/07/31 01:05:30 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 247, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:05:30 INFO Executor: Running task 0.0 in stage 136.0 (TID 247)
19/07/31 01:05:30 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:30 INFO Executor: Finished task 0.0 in stage 136.0 (TID 247). 1687 bytes result sent to driver
19/07/31 01:05:30 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 247) in 13 ms on localhost (executor driver) (1/1)
19/07/31 01:05:30 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool 
19/07/31 01:05:30 INFO DAGScheduler: ShuffleMapStage 136 (collect at utils.scala:204) finished in 0.013 s
19/07/31 01:05:30 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:05:30 INFO DAGScheduler: running: Set()
19/07/31 01:05:30 INFO DAGScheduler: waiting: Set(ResultStage 137)
19/07/31 01:05:30 INFO DAGScheduler: failed: Set()
19/07/31 01:05:30 INFO DAGScheduler: Submitting ResultStage 137 (MapPartitionsRDD[434] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:30 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 16.8 KB, free 911.0 MB)
19/07/31 01:05:30 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 8.1 KB, free 911.0 MB)
19/07/31 01:05:30 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 127.0.0.1:53873 (size: 8.1 KB, free: 911.9 MB)
19/07/31 01:05:30 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:30 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 137 (MapPartitionsRDD[434] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:05:30 INFO TaskSchedulerImpl: Adding task set 137.0 with 4 tasks
19/07/31 01:05:30 INFO TaskSetManager: Starting task 0.0 in stage 137.0 (TID 248, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:05:30 INFO TaskSetManager: Starting task 1.0 in stage 137.0 (TID 249, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:05:30 INFO TaskSetManager: Starting task 2.0 in stage 137.0 (TID 250, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:05:30 INFO TaskSetManager: Starting task 3.0 in stage 137.0 (TID 251, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:05:30 INFO Executor: Running task 0.0 in stage 137.0 (TID 248)
19/07/31 01:05:30 INFO Executor: Running task 1.0 in stage 137.0 (TID 249)
19/07/31 01:05:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:30 INFO Executor: Running task 2.0 in stage 137.0 (TID 250)
19/07/31 01:05:30 INFO Executor: Running task 3.0 in stage 137.0 (TID 251)
19/07/31 01:05:30 INFO Executor: Finished task 0.0 in stage 137.0 (TID 248). 2373 bytes result sent to driver
19/07/31 01:05:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:30 INFO Executor: Finished task 1.0 in stage 137.0 (TID 249). 2369 bytes result sent to driver
19/07/31 01:05:30 INFO Executor: Finished task 3.0 in stage 137.0 (TID 251). 2305 bytes result sent to driver
19/07/31 01:05:30 INFO TaskSetManager: Finished task 0.0 in stage 137.0 (TID 248) in 9 ms on localhost (executor driver) (1/4)
19/07/31 01:05:30 INFO TaskSetManager: Finished task 1.0 in stage 137.0 (TID 249) in 10 ms on localhost (executor driver) (2/4)
19/07/31 01:05:30 INFO TaskSetManager: Finished task 3.0 in stage 137.0 (TID 251) in 10 ms on localhost (executor driver) (3/4)
19/07/31 01:05:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:05:30 INFO Executor: Finished task 2.0 in stage 137.0 (TID 250). 2366 bytes result sent to driver
19/07/31 01:05:30 INFO TaskSetManager: Finished task 2.0 in stage 137.0 (TID 250) in 14 ms on localhost (executor driver) (4/4)
19/07/31 01:05:30 INFO TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool 
19/07/31 01:05:30 INFO DAGScheduler: ResultStage 137 (collect at utils.scala:204) finished in 0.016 s
19/07/31 01:05:30 INFO DAGScheduler: Job 95 finished: collect at utils.scala:204, took 0.038080 s
19/07/31 01:05:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_289`) `dbplyr_290`
ORDER BY `date`) `dbplyr_291`) `dbplyr_292`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Desktop"))
19/07/31 01:05:31 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:31 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_293`) `dbplyr_294`
ORDER BY `date`) `dbplyr_295`) `dbplyr_296`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Desktop"))
19/07/31 01:05:31 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:31 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:31 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#5043 - cust_prospect_ind.nullCount#5042) > 0)
19/07/31 01:05:31 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#5048 - visit_device_type.nullCount#5047) > 0)
19/07/31 01:05:31 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#5041 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#5040))
19/07/31 01:05:31 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#5046 <= Desktop) && (Desktop <= visit_device_type.upperBound#5045))
19/07/31 01:05:31 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:31 INFO DAGScheduler: Got job 96 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:05:31 INFO DAGScheduler: Final stage: ResultStage 138 (collect at utils.scala:204)
19/07/31 01:05:31 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:05:31 INFO DAGScheduler: Missing parents: List()
19/07/31 01:05:31 INFO DAGScheduler: Submitting ResultStage 138 (MapPartitionsRDD[439] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:31 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 72.1 KB, free 911.0 MB)
19/07/31 01:05:31 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.9 MB)
19/07/31 01:05:31 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 127.0.0.1:53873 (size: 30.4 KB, free: 911.9 MB)
19/07/31 01:05:31 INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 138 (MapPartitionsRDD[439] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:31 INFO TaskSchedulerImpl: Adding task set 138.0 with 1 tasks
19/07/31 01:05:31 INFO TaskSetManager: Starting task 0.0 in stage 138.0 (TID 252, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:05:31 INFO Executor: Running task 0.0 in stage 138.0 (TID 252)
19/07/31 01:05:31 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:31 INFO Executor: Finished task 0.0 in stage 138.0 (TID 252). 6512 bytes result sent to driver
19/07/31 01:05:31 INFO TaskSetManager: Finished task 0.0 in stage 138.0 (TID 252) in 9 ms on localhost (executor driver) (1/1)
19/07/31 01:05:31 INFO TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool 
19/07/31 01:05:31 INFO DAGScheduler: ResultStage 138 (collect at utils.scala:204) finished in 0.009 s
19/07/31 01:05:31 INFO DAGScheduler: Job 96 finished: collect at utils.scala:204, took 0.015780 s
19/07/31 01:05:31 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:31 INFO DAGScheduler: Registering RDD 440 (collect at utils.scala:204)
19/07/31 01:05:31 INFO DAGScheduler: Got job 97 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:05:31 INFO DAGScheduler: Final stage: ResultStage 140 (collect at utils.scala:204)
19/07/31 01:05:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 139)
19/07/31 01:05:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 139)
19/07/31 01:05:31 INFO DAGScheduler: Submitting ShuffleMapStage 139 (MapPartitionsRDD[440] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:31 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 74.5 KB, free 910.9 MB)
19/07/31 01:05:31 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.8 MB)
19/07/31 01:05:31 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 127.0.0.1:53873 (size: 31.7 KB, free: 911.9 MB)
19/07/31 01:05:31 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 139 (MapPartitionsRDD[440] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:31 INFO TaskSchedulerImpl: Adding task set 139.0 with 1 tasks
19/07/31 01:05:31 INFO TaskSetManager: Starting task 0.0 in stage 139.0 (TID 253, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:05:31 INFO Executor: Running task 0.0 in stage 139.0 (TID 253)
19/07/31 01:05:31 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:31 INFO Executor: Finished task 0.0 in stage 139.0 (TID 253). 1687 bytes result sent to driver
19/07/31 01:05:31 INFO TaskSetManager: Finished task 0.0 in stage 139.0 (TID 253) in 15 ms on localhost (executor driver) (1/1)
19/07/31 01:05:31 INFO TaskSchedulerImpl: Removed TaskSet 139.0, whose tasks have all completed, from pool 
19/07/31 01:05:31 INFO DAGScheduler: ShuffleMapStage 139 (collect at utils.scala:204) finished in 0.015 s
19/07/31 01:05:31 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:05:31 INFO DAGScheduler: running: Set()
19/07/31 01:05:31 INFO DAGScheduler: waiting: Set(ResultStage 140)
19/07/31 01:05:31 INFO DAGScheduler: failed: Set()
19/07/31 01:05:31 INFO DAGScheduler: Submitting ResultStage 140 (MapPartitionsRDD[443] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:31 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 16.8 KB, free 910.8 MB)
19/07/31 01:05:31 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 8.1 KB, free 910.8 MB)
19/07/31 01:05:31 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 127.0.0.1:53873 (size: 8.1 KB, free: 911.9 MB)
19/07/31 01:05:31 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:31 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 140 (MapPartitionsRDD[443] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:05:31 INFO TaskSchedulerImpl: Adding task set 140.0 with 4 tasks
19/07/31 01:05:31 INFO TaskSetManager: Starting task 0.0 in stage 140.0 (TID 254, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:05:31 INFO TaskSetManager: Starting task 1.0 in stage 140.0 (TID 255, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:05:31 INFO TaskSetManager: Starting task 2.0 in stage 140.0 (TID 256, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:05:31 INFO TaskSetManager: Starting task 3.0 in stage 140.0 (TID 257, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:05:31 INFO Executor: Running task 0.0 in stage 140.0 (TID 254)
19/07/31 01:05:31 INFO Executor: Running task 1.0 in stage 140.0 (TID 255)
19/07/31 01:05:31 INFO Executor: Running task 3.0 in stage 140.0 (TID 257)
19/07/31 01:05:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:31 INFO Executor: Running task 2.0 in stage 140.0 (TID 256)
19/07/31 01:05:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:31 INFO Executor: Finished task 0.0 in stage 140.0 (TID 254). 2349 bytes result sent to driver
19/07/31 01:05:31 INFO Executor: Finished task 1.0 in stage 140.0 (TID 255). 2334 bytes result sent to driver
19/07/31 01:05:31 INFO TaskSetManager: Finished task 0.0 in stage 140.0 (TID 254) in 10 ms on localhost (executor driver) (1/4)
19/07/31 01:05:31 INFO TaskSetManager: Finished task 1.0 in stage 140.0 (TID 255) in 10 ms on localhost (executor driver) (2/4)
19/07/31 01:05:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:31 INFO Executor: Finished task 3.0 in stage 140.0 (TID 257). 2334 bytes result sent to driver
19/07/31 01:05:31 INFO TaskSetManager: Finished task 3.0 in stage 140.0 (TID 257) in 10 ms on localhost (executor driver) (3/4)
19/07/31 01:05:31 INFO Executor: Finished task 2.0 in stage 140.0 (TID 256). 2352 bytes result sent to driver
19/07/31 01:05:31 INFO TaskSetManager: Finished task 2.0 in stage 140.0 (TID 256) in 13 ms on localhost (executor driver) (4/4)
19/07/31 01:05:31 INFO TaskSchedulerImpl: Removed TaskSet 140.0, whose tasks have all completed, from pool 
19/07/31 01:05:31 INFO DAGScheduler: ResultStage 140 (collect at utils.scala:204) finished in 0.013 s
19/07/31 01:05:31 INFO DAGScheduler: Job 97 finished: collect at utils.scala:204, took 0.038543 s
19/07/31 01:05:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_297`) `dbplyr_298`
ORDER BY `date`) `dbplyr_299`) `dbplyr_300`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Desktop"))
19/07/31 01:05:33 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:33 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_301`) `dbplyr_302`
ORDER BY `date`) `dbplyr_303`) `dbplyr_304`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Desktop"))
19/07/31 01:05:33 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:33 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:33 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#5141 - cust_prospect_ind.nullCount#5140) > 0)
19/07/31 01:05:33 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#5146 - visit_device_type.nullCount#5145) > 0)
19/07/31 01:05:33 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#5139 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#5138))
19/07/31 01:05:33 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#5144 <= Desktop) && (Desktop <= visit_device_type.upperBound#5143))
19/07/31 01:05:33 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:33 INFO DAGScheduler: Got job 98 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:05:33 INFO DAGScheduler: Final stage: ResultStage 141 (collect at utils.scala:204)
19/07/31 01:05:33 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:05:33 INFO DAGScheduler: Missing parents: List()
19/07/31 01:05:33 INFO DAGScheduler: Submitting ResultStage 141 (MapPartitionsRDD[448] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:33 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 72.1 KB, free 910.7 MB)
19/07/31 01:05:33 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.7 MB)
19/07/31 01:05:33 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 127.0.0.1:53873 (size: 30.4 KB, free: 911.8 MB)
19/07/31 01:05:33 INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 141 (MapPartitionsRDD[448] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:33 INFO TaskSchedulerImpl: Adding task set 141.0 with 1 tasks
19/07/31 01:05:33 INFO TaskSetManager: Starting task 0.0 in stage 141.0 (TID 258, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:05:33 INFO Executor: Running task 0.0 in stage 141.0 (TID 258)
19/07/31 01:05:33 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:33 INFO Executor: Finished task 0.0 in stage 141.0 (TID 258). 6512 bytes result sent to driver
19/07/31 01:05:33 INFO TaskSetManager: Finished task 0.0 in stage 141.0 (TID 258) in 12 ms on localhost (executor driver) (1/1)
19/07/31 01:05:33 INFO TaskSchedulerImpl: Removed TaskSet 141.0, whose tasks have all completed, from pool 
19/07/31 01:05:33 INFO DAGScheduler: ResultStage 141 (collect at utils.scala:204) finished in 0.013 s
19/07/31 01:05:33 INFO DAGScheduler: Job 98 finished: collect at utils.scala:204, took 0.026841 s
19/07/31 01:05:33 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:33 INFO DAGScheduler: Registering RDD 449 (collect at utils.scala:204)
19/07/31 01:05:33 INFO DAGScheduler: Got job 99 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:05:33 INFO DAGScheduler: Final stage: ResultStage 143 (collect at utils.scala:204)
19/07/31 01:05:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 142)
19/07/31 01:05:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 142)
19/07/31 01:05:33 INFO DAGScheduler: Submitting ShuffleMapStage 142 (MapPartitionsRDD[449] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:33 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 74.5 KB, free 910.6 MB)
19/07/31 01:05:33 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.6 MB)
19/07/31 01:05:33 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 127.0.0.1:53873 (size: 31.7 KB, free: 911.8 MB)
19/07/31 01:05:33 INFO SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 142 (MapPartitionsRDD[449] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:33 INFO TaskSchedulerImpl: Adding task set 142.0 with 1 tasks
19/07/31 01:05:33 INFO TaskSetManager: Starting task 0.0 in stage 142.0 (TID 259, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:05:33 INFO Executor: Running task 0.0 in stage 142.0 (TID 259)
19/07/31 01:05:33 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:33 INFO Executor: Finished task 0.0 in stage 142.0 (TID 259). 1687 bytes result sent to driver
19/07/31 01:05:33 INFO TaskSetManager: Finished task 0.0 in stage 142.0 (TID 259) in 17 ms on localhost (executor driver) (1/1)
19/07/31 01:05:33 INFO TaskSchedulerImpl: Removed TaskSet 142.0, whose tasks have all completed, from pool 
19/07/31 01:05:33 INFO DAGScheduler: ShuffleMapStage 142 (collect at utils.scala:204) finished in 0.018 s
19/07/31 01:05:33 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:05:33 INFO DAGScheduler: running: Set()
19/07/31 01:05:33 INFO DAGScheduler: waiting: Set(ResultStage 143)
19/07/31 01:05:33 INFO DAGScheduler: failed: Set()
19/07/31 01:05:33 INFO DAGScheduler: Submitting ResultStage 143 (MapPartitionsRDD[452] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:33 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 16.8 KB, free 910.6 MB)
19/07/31 01:05:33 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 8.1 KB, free 910.6 MB)
19/07/31 01:05:33 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 127.0.0.1:53873 (size: 8.1 KB, free: 911.8 MB)
19/07/31 01:05:33 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:33 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 143 (MapPartitionsRDD[452] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:05:33 INFO TaskSchedulerImpl: Adding task set 143.0 with 4 tasks
19/07/31 01:05:33 INFO TaskSetManager: Starting task 0.0 in stage 143.0 (TID 260, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:05:33 INFO TaskSetManager: Starting task 1.0 in stage 143.0 (TID 261, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:05:33 INFO TaskSetManager: Starting task 2.0 in stage 143.0 (TID 262, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:05:33 INFO TaskSetManager: Starting task 3.0 in stage 143.0 (TID 263, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:05:33 INFO Executor: Running task 0.0 in stage 143.0 (TID 260)
19/07/31 01:05:33 INFO Executor: Running task 1.0 in stage 143.0 (TID 261)
19/07/31 01:05:33 INFO Executor: Running task 2.0 in stage 143.0 (TID 262)
19/07/31 01:05:33 INFO Executor: Running task 3.0 in stage 143.0 (TID 263)
19/07/31 01:05:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:05:33 INFO Executor: Finished task 0.0 in stage 143.0 (TID 260). 2353 bytes result sent to driver
19/07/31 01:05:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:33 INFO Executor: Finished task 3.0 in stage 143.0 (TID 263). 2350 bytes result sent to driver
19/07/31 01:05:33 INFO TaskSetManager: Finished task 0.0 in stage 143.0 (TID 260) in 17 ms on localhost (executor driver) (1/4)
19/07/31 01:05:33 INFO TaskSetManager: Finished task 3.0 in stage 143.0 (TID 263) in 16 ms on localhost (executor driver) (2/4)
19/07/31 01:05:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:33 INFO Executor: Finished task 2.0 in stage 143.0 (TID 262). 2354 bytes result sent to driver
19/07/31 01:05:33 INFO TaskSetManager: Finished task 2.0 in stage 143.0 (TID 262) in 21 ms on localhost (executor driver) (3/4)
19/07/31 01:05:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:33 INFO Executor: Finished task 1.0 in stage 143.0 (TID 261). 2338 bytes result sent to driver
19/07/31 01:05:33 INFO TaskSetManager: Finished task 1.0 in stage 143.0 (TID 261) in 24 ms on localhost (executor driver) (4/4)
19/07/31 01:05:33 INFO TaskSchedulerImpl: Removed TaskSet 143.0, whose tasks have all completed, from pool 
19/07/31 01:05:33 INFO DAGScheduler: ResultStage 143 (collect at utils.scala:204) finished in 0.025 s
19/07/31 01:05:33 INFO DAGScheduler: Job 99 finished: collect at utils.scala:204, took 0.062399 s
19/07/31 01:05:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_305`) `dbplyr_306`
ORDER BY `date`) `dbplyr_307`) `dbplyr_308`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Tablet"))
19/07/31 01:05:34 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_309`) `dbplyr_310`
ORDER BY `date`) `dbplyr_311`) `dbplyr_312`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Tablet"))
19/07/31 01:05:34 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:34 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#5239 - cust_prospect_ind.nullCount#5238) > 0)
19/07/31 01:05:34 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#5244 - visit_device_type.nullCount#5243) > 0)
19/07/31 01:05:34 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#5237 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#5236))
19/07/31 01:05:34 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#5242 <= Tablet) && (Tablet <= visit_device_type.upperBound#5241))
19/07/31 01:05:34 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:34 INFO DAGScheduler: Got job 100 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:05:34 INFO DAGScheduler: Final stage: ResultStage 144 (collect at utils.scala:204)
19/07/31 01:05:34 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:05:34 INFO DAGScheduler: Missing parents: List()
19/07/31 01:05:34 INFO DAGScheduler: Submitting ResultStage 144 (MapPartitionsRDD[457] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:34 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 72.1 KB, free 910.5 MB)
19/07/31 01:05:34 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.5 MB)
19/07/31 01:05:34 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 127.0.0.1:53873 (size: 30.5 KB, free: 911.8 MB)
19/07/31 01:05:34 INFO SparkContext: Created broadcast 147 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 144 (MapPartitionsRDD[457] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:34 INFO TaskSchedulerImpl: Adding task set 144.0 with 1 tasks
19/07/31 01:05:34 INFO TaskSetManager: Starting task 0.0 in stage 144.0 (TID 264, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:05:34 INFO Executor: Running task 0.0 in stage 144.0 (TID 264)
19/07/31 01:05:34 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:34 INFO Executor: Finished task 0.0 in stage 144.0 (TID 264). 7068 bytes result sent to driver
19/07/31 01:05:34 INFO TaskSetManager: Finished task 0.0 in stage 144.0 (TID 264) in 9 ms on localhost (executor driver) (1/1)
19/07/31 01:05:34 INFO TaskSchedulerImpl: Removed TaskSet 144.0, whose tasks have all completed, from pool 
19/07/31 01:05:34 INFO DAGScheduler: ResultStage 144 (collect at utils.scala:204) finished in 0.009 s
19/07/31 01:05:34 INFO DAGScheduler: Job 100 finished: collect at utils.scala:204, took 0.018113 s
19/07/31 01:05:34 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:34 INFO DAGScheduler: Registering RDD 458 (collect at utils.scala:204)
19/07/31 01:05:34 INFO DAGScheduler: Got job 101 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:05:34 INFO DAGScheduler: Final stage: ResultStage 146 (collect at utils.scala:204)
19/07/31 01:05:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 145)
19/07/31 01:05:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 145)
19/07/31 01:05:34 INFO DAGScheduler: Submitting ShuffleMapStage 145 (MapPartitionsRDD[458] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:34 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 74.5 KB, free 910.4 MB)
19/07/31 01:05:34 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.4 MB)
19/07/31 01:05:34 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 127.0.0.1:53873 (size: 31.8 KB, free: 911.7 MB)
19/07/31 01:05:34 INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 145 (MapPartitionsRDD[458] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:34 INFO TaskSchedulerImpl: Adding task set 145.0 with 1 tasks
19/07/31 01:05:34 INFO TaskSetManager: Starting task 0.0 in stage 145.0 (TID 265, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:05:34 INFO Executor: Running task 0.0 in stage 145.0 (TID 265)
19/07/31 01:05:34 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:34 INFO Executor: Finished task 0.0 in stage 145.0 (TID 265). 1687 bytes result sent to driver
19/07/31 01:05:34 INFO TaskSetManager: Finished task 0.0 in stage 145.0 (TID 265) in 8 ms on localhost (executor driver) (1/1)
19/07/31 01:05:34 INFO TaskSchedulerImpl: Removed TaskSet 145.0, whose tasks have all completed, from pool 
19/07/31 01:05:34 INFO DAGScheduler: ShuffleMapStage 145 (collect at utils.scala:204) finished in 0.008 s
19/07/31 01:05:34 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:05:34 INFO DAGScheduler: running: Set()
19/07/31 01:05:34 INFO DAGScheduler: waiting: Set(ResultStage 146)
19/07/31 01:05:34 INFO DAGScheduler: failed: Set()
19/07/31 01:05:34 INFO DAGScheduler: Submitting ResultStage 146 (MapPartitionsRDD[461] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:34 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 16.8 KB, free 910.4 MB)
19/07/31 01:05:34 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 8.1 KB, free 910.3 MB)
19/07/31 01:05:34 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 127.0.0.1:53873 (size: 8.1 KB, free: 911.7 MB)
19/07/31 01:05:34 INFO SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:34 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 146 (MapPartitionsRDD[461] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:05:34 INFO TaskSchedulerImpl: Adding task set 146.0 with 4 tasks
19/07/31 01:05:34 INFO TaskSetManager: Starting task 0.0 in stage 146.0 (TID 266, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:05:34 INFO TaskSetManager: Starting task 1.0 in stage 146.0 (TID 267, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:05:34 INFO TaskSetManager: Starting task 2.0 in stage 146.0 (TID 268, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:05:34 INFO TaskSetManager: Starting task 3.0 in stage 146.0 (TID 269, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:05:34 INFO Executor: Running task 0.0 in stage 146.0 (TID 266)
19/07/31 01:05:34 INFO Executor: Running task 1.0 in stage 146.0 (TID 267)
19/07/31 01:05:34 INFO Executor: Running task 2.0 in stage 146.0 (TID 268)
19/07/31 01:05:34 INFO Executor: Running task 3.0 in stage 146.0 (TID 269)
19/07/31 01:05:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:05:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:34 INFO Executor: Finished task 1.0 in stage 146.0 (TID 267). 2361 bytes result sent to driver
19/07/31 01:05:34 INFO Executor: Finished task 0.0 in stage 146.0 (TID 266). 2354 bytes result sent to driver
19/07/31 01:05:34 INFO Executor: Finished task 3.0 in stage 146.0 (TID 269). 2332 bytes result sent to driver
19/07/31 01:05:34 INFO TaskSetManager: Finished task 0.0 in stage 146.0 (TID 266) in 8 ms on localhost (executor driver) (1/4)
19/07/31 01:05:34 INFO TaskSetManager: Finished task 1.0 in stage 146.0 (TID 267) in 8 ms on localhost (executor driver) (2/4)
19/07/31 01:05:34 INFO TaskSetManager: Finished task 3.0 in stage 146.0 (TID 269) in 8 ms on localhost (executor driver) (3/4)
19/07/31 01:05:34 INFO Executor: Finished task 2.0 in stage 146.0 (TID 268). 2355 bytes result sent to driver
19/07/31 01:05:34 INFO TaskSetManager: Finished task 2.0 in stage 146.0 (TID 268) in 9 ms on localhost (executor driver) (4/4)
19/07/31 01:05:34 INFO TaskSchedulerImpl: Removed TaskSet 146.0, whose tasks have all completed, from pool 
19/07/31 01:05:34 INFO DAGScheduler: ResultStage 146 (collect at utils.scala:204) finished in 0.009 s
19/07/31 01:05:34 INFO DAGScheduler: Job 101 finished: collect at utils.scala:204, took 0.035030 s
19/07/31 01:05:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_313`) `dbplyr_314`
ORDER BY `date`) `dbplyr_315`) `dbplyr_316`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Tablet"))
19/07/31 01:05:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_317`) `dbplyr_318`
ORDER BY `date`) `dbplyr_319`) `dbplyr_320`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Tablet"))
19/07/31 01:05:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:36 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#5337 - cust_prospect_ind.nullCount#5336) > 0)
19/07/31 01:05:36 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#5342 - visit_device_type.nullCount#5341) > 0)
19/07/31 01:05:36 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#5335 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#5334))
19/07/31 01:05:36 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#5340 <= Tablet) && (Tablet <= visit_device_type.upperBound#5339))
19/07/31 01:05:36 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:36 INFO DAGScheduler: Got job 102 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:05:36 INFO DAGScheduler: Final stage: ResultStage 147 (collect at utils.scala:204)
19/07/31 01:05:36 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:05:36 INFO DAGScheduler: Missing parents: List()
19/07/31 01:05:36 INFO DAGScheduler: Submitting ResultStage 147 (MapPartitionsRDD[466] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:36 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 72.1 KB, free 910.3 MB)
19/07/31 01:05:36 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.2 MB)
19/07/31 01:05:36 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 127.0.0.1:53873 (size: 30.4 KB, free: 911.7 MB)
19/07/31 01:05:36 INFO SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 147 (MapPartitionsRDD[466] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:36 INFO TaskSchedulerImpl: Adding task set 147.0 with 1 tasks
19/07/31 01:05:36 INFO TaskSetManager: Starting task 0.0 in stage 147.0 (TID 270, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:05:36 INFO Executor: Running task 0.0 in stage 147.0 (TID 270)
19/07/31 01:05:36 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:36 INFO Executor: Finished task 0.0 in stage 147.0 (TID 270). 7068 bytes result sent to driver
19/07/31 01:05:36 INFO TaskSetManager: Finished task 0.0 in stage 147.0 (TID 270) in 9 ms on localhost (executor driver) (1/1)
19/07/31 01:05:36 INFO TaskSchedulerImpl: Removed TaskSet 147.0, whose tasks have all completed, from pool 
19/07/31 01:05:36 INFO DAGScheduler: ResultStage 147 (collect at utils.scala:204) finished in 0.009 s
19/07/31 01:05:36 INFO DAGScheduler: Job 102 finished: collect at utils.scala:204, took 0.020338 s
19/07/31 01:05:36 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:36 INFO DAGScheduler: Registering RDD 467 (collect at utils.scala:204)
19/07/31 01:05:36 INFO DAGScheduler: Got job 103 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:05:36 INFO DAGScheduler: Final stage: ResultStage 149 (collect at utils.scala:204)
19/07/31 01:05:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 148)
19/07/31 01:05:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 148)
19/07/31 01:05:36 INFO DAGScheduler: Submitting ShuffleMapStage 148 (MapPartitionsRDD[467] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:36 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 74.5 KB, free 910.2 MB)
19/07/31 01:05:36 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.1 MB)
19/07/31 01:05:36 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 127.0.0.1:53873 (size: 31.7 KB, free: 911.7 MB)
19/07/31 01:05:36 INFO SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 148 (MapPartitionsRDD[467] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:36 INFO TaskSchedulerImpl: Adding task set 148.0 with 1 tasks
19/07/31 01:05:36 INFO TaskSetManager: Starting task 0.0 in stage 148.0 (TID 271, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:05:36 INFO Executor: Running task 0.0 in stage 148.0 (TID 271)
19/07/31 01:05:36 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:36 INFO Executor: Finished task 0.0 in stage 148.0 (TID 271). 1687 bytes result sent to driver
19/07/31 01:05:36 INFO TaskSetManager: Finished task 0.0 in stage 148.0 (TID 271) in 12 ms on localhost (executor driver) (1/1)
19/07/31 01:05:36 INFO TaskSchedulerImpl: Removed TaskSet 148.0, whose tasks have all completed, from pool 
19/07/31 01:05:36 INFO DAGScheduler: ShuffleMapStage 148 (collect at utils.scala:204) finished in 0.013 s
19/07/31 01:05:36 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:05:36 INFO DAGScheduler: running: Set()
19/07/31 01:05:36 INFO DAGScheduler: waiting: Set(ResultStage 149)
19/07/31 01:05:36 INFO DAGScheduler: failed: Set()
19/07/31 01:05:36 INFO DAGScheduler: Submitting ResultStage 149 (MapPartitionsRDD[470] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:36 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 16.8 KB, free 910.1 MB)
19/07/31 01:05:36 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 8.1 KB, free 910.1 MB)
19/07/31 01:05:36 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 127.0.0.1:53873 (size: 8.1 KB, free: 911.7 MB)
19/07/31 01:05:36 INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:36 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 149 (MapPartitionsRDD[470] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:05:36 INFO TaskSchedulerImpl: Adding task set 149.0 with 4 tasks
19/07/31 01:05:36 INFO TaskSetManager: Starting task 0.0 in stage 149.0 (TID 272, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:05:36 INFO TaskSetManager: Starting task 1.0 in stage 149.0 (TID 273, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:05:36 INFO TaskSetManager: Starting task 2.0 in stage 149.0 (TID 274, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:05:36 INFO TaskSetManager: Starting task 3.0 in stage 149.0 (TID 275, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:05:36 INFO Executor: Running task 0.0 in stage 149.0 (TID 272)
19/07/31 01:05:36 INFO Executor: Running task 1.0 in stage 149.0 (TID 273)
19/07/31 01:05:36 INFO Executor: Running task 3.0 in stage 149.0 (TID 275)
19/07/31 01:05:36 INFO Executor: Running task 2.0 in stage 149.0 (TID 274)
19/07/31 01:05:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:05:36 INFO Executor: Finished task 1.0 in stage 149.0 (TID 273). 2361 bytes result sent to driver
19/07/31 01:05:36 INFO Executor: Finished task 3.0 in stage 149.0 (TID 275). 2332 bytes result sent to driver
19/07/31 01:05:36 INFO TaskSetManager: Finished task 1.0 in stage 149.0 (TID 273) in 6 ms on localhost (executor driver) (1/4)
19/07/31 01:05:36 INFO TaskSetManager: Finished task 3.0 in stage 149.0 (TID 275) in 6 ms on localhost (executor driver) (2/4)
19/07/31 01:05:36 INFO Executor: Finished task 2.0 in stage 149.0 (TID 274). 2355 bytes result sent to driver
19/07/31 01:05:36 INFO TaskSetManager: Finished task 2.0 in stage 149.0 (TID 274) in 7 ms on localhost (executor driver) (3/4)
19/07/31 01:05:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:36 INFO Executor: Finished task 0.0 in stage 149.0 (TID 272). 2354 bytes result sent to driver
19/07/31 01:05:36 INFO TaskSetManager: Finished task 0.0 in stage 149.0 (TID 272) in 12 ms on localhost (executor driver) (4/4)
19/07/31 01:05:36 INFO TaskSchedulerImpl: Removed TaskSet 149.0, whose tasks have all completed, from pool 
19/07/31 01:05:36 INFO DAGScheduler: ResultStage 149 (collect at utils.scala:204) finished in 0.012 s
19/07/31 01:05:36 INFO DAGScheduler: Job 103 finished: collect at utils.scala:204, took 0.041659 s
19/07/31 01:05:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_321`) `dbplyr_322`
ORDER BY `date`) `dbplyr_323`) `dbplyr_324`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Tablet"))
19/07/31 01:05:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_325`) `dbplyr_326`
ORDER BY `date`) `dbplyr_327`) `dbplyr_328`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Tablet"))
19/07/31 01:05:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:37 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#5435 - cust_prospect_ind.nullCount#5434) > 0)
19/07/31 01:05:37 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#5440 - visit_device_type.nullCount#5439) > 0)
19/07/31 01:05:37 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#5433 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#5432))
19/07/31 01:05:37 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#5438 <= Tablet) && (Tablet <= visit_device_type.upperBound#5437))
19/07/31 01:05:37 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:37 INFO DAGScheduler: Got job 104 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:05:37 INFO DAGScheduler: Final stage: ResultStage 150 (collect at utils.scala:204)
19/07/31 01:05:37 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:05:37 INFO DAGScheduler: Missing parents: List()
19/07/31 01:05:37 INFO DAGScheduler: Submitting ResultStage 150 (MapPartitionsRDD[475] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:37 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 72.1 KB, free 910.0 MB)
19/07/31 01:05:37 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.0 MB)
19/07/31 01:05:37 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 127.0.0.1:53873 (size: 30.5 KB, free: 911.6 MB)
19/07/31 01:05:37 INFO SparkContext: Created broadcast 153 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 150 (MapPartitionsRDD[475] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:37 INFO TaskSchedulerImpl: Adding task set 150.0 with 1 tasks
19/07/31 01:05:37 INFO TaskSetManager: Starting task 0.0 in stage 150.0 (TID 276, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:05:37 INFO Executor: Running task 0.0 in stage 150.0 (TID 276)
19/07/31 01:05:37 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:37 INFO Executor: Finished task 0.0 in stage 150.0 (TID 276). 6512 bytes result sent to driver
19/07/31 01:05:37 INFO TaskSetManager: Finished task 0.0 in stage 150.0 (TID 276) in 6 ms on localhost (executor driver) (1/1)
19/07/31 01:05:37 INFO TaskSchedulerImpl: Removed TaskSet 150.0, whose tasks have all completed, from pool 
19/07/31 01:05:37 INFO DAGScheduler: ResultStage 150 (collect at utils.scala:204) finished in 0.006 s
19/07/31 01:05:37 INFO DAGScheduler: Job 104 finished: collect at utils.scala:204, took 0.015071 s
19/07/31 01:05:37 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:37 INFO DAGScheduler: Registering RDD 476 (collect at utils.scala:204)
19/07/31 01:05:37 INFO DAGScheduler: Got job 105 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:05:37 INFO DAGScheduler: Final stage: ResultStage 152 (collect at utils.scala:204)
19/07/31 01:05:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 151)
19/07/31 01:05:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 151)
19/07/31 01:05:37 INFO DAGScheduler: Submitting ShuffleMapStage 151 (MapPartitionsRDD[476] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:37 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 74.5 KB, free 909.9 MB)
19/07/31 01:05:37 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.9 MB)
19/07/31 01:05:37 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 127.0.0.1:53873 (size: 31.8 KB, free: 911.6 MB)
19/07/31 01:05:37 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 151 (MapPartitionsRDD[476] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:37 INFO TaskSchedulerImpl: Adding task set 151.0 with 1 tasks
19/07/31 01:05:37 INFO TaskSetManager: Starting task 0.0 in stage 151.0 (TID 277, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:05:37 INFO Executor: Running task 0.0 in stage 151.0 (TID 277)
19/07/31 01:05:37 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:37 INFO Executor: Finished task 0.0 in stage 151.0 (TID 277). 1687 bytes result sent to driver
19/07/31 01:05:37 INFO TaskSetManager: Finished task 0.0 in stage 151.0 (TID 277) in 9 ms on localhost (executor driver) (1/1)
19/07/31 01:05:37 INFO TaskSchedulerImpl: Removed TaskSet 151.0, whose tasks have all completed, from pool 
19/07/31 01:05:37 INFO DAGScheduler: ShuffleMapStage 151 (collect at utils.scala:204) finished in 0.009 s
19/07/31 01:05:37 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:05:37 INFO DAGScheduler: running: Set()
19/07/31 01:05:37 INFO DAGScheduler: waiting: Set(ResultStage 152)
19/07/31 01:05:37 INFO DAGScheduler: failed: Set()
19/07/31 01:05:37 INFO DAGScheduler: Submitting ResultStage 152 (MapPartitionsRDD[479] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:37 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 16.8 KB, free 909.9 MB)
19/07/31 01:05:37 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 8.1 KB, free 909.9 MB)
19/07/31 01:05:37 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 127.0.0.1:53873 (size: 8.1 KB, free: 911.6 MB)
19/07/31 01:05:37 INFO SparkContext: Created broadcast 155 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:37 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 152 (MapPartitionsRDD[479] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:05:37 INFO TaskSchedulerImpl: Adding task set 152.0 with 4 tasks
19/07/31 01:05:37 INFO TaskSetManager: Starting task 0.0 in stage 152.0 (TID 278, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:05:37 INFO TaskSetManager: Starting task 1.0 in stage 152.0 (TID 279, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:05:37 INFO TaskSetManager: Starting task 2.0 in stage 152.0 (TID 280, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:05:37 INFO TaskSetManager: Starting task 3.0 in stage 152.0 (TID 281, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:05:37 INFO Executor: Running task 0.0 in stage 152.0 (TID 278)
19/07/31 01:05:37 INFO Executor: Running task 2.0 in stage 152.0 (TID 280)
19/07/31 01:05:37 INFO Executor: Running task 1.0 in stage 152.0 (TID 279)
19/07/31 01:05:37 INFO Executor: Running task 3.0 in stage 152.0 (TID 281)
19/07/31 01:05:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:05:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:37 INFO Executor: Finished task 0.0 in stage 152.0 (TID 278). 2347 bytes result sent to driver
19/07/31 01:05:37 INFO Executor: Finished task 1.0 in stage 152.0 (TID 279). 2313 bytes result sent to driver
19/07/31 01:05:37 INFO Executor: Finished task 2.0 in stage 152.0 (TID 280). 2338 bytes result sent to driver
19/07/31 01:05:37 INFO Executor: Finished task 3.0 in stage 152.0 (TID 281). 2311 bytes result sent to driver
19/07/31 01:05:37 INFO TaskSetManager: Finished task 0.0 in stage 152.0 (TID 278) in 10 ms on localhost (executor driver) (1/4)
19/07/31 01:05:37 INFO TaskSetManager: Finished task 1.0 in stage 152.0 (TID 279) in 9 ms on localhost (executor driver) (2/4)
19/07/31 01:05:37 INFO TaskSetManager: Finished task 2.0 in stage 152.0 (TID 280) in 9 ms on localhost (executor driver) (3/4)
19/07/31 01:05:37 INFO TaskSetManager: Finished task 3.0 in stage 152.0 (TID 281) in 9 ms on localhost (executor driver) (4/4)
19/07/31 01:05:37 INFO TaskSchedulerImpl: Removed TaskSet 152.0, whose tasks have all completed, from pool 
19/07/31 01:05:37 INFO DAGScheduler: ResultStage 152 (collect at utils.scala:204) finished in 0.011 s
19/07/31 01:05:37 INFO DAGScheduler: Job 105 finished: collect at utils.scala:204, took 0.036257 s
19/07/31 01:05:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_329`) `dbplyr_330`
ORDER BY `date`) `dbplyr_331`) `dbplyr_332`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Tablet"))
19/07/31 01:05:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_333`) `dbplyr_334`
ORDER BY `date`) `dbplyr_335`) `dbplyr_336`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Tablet"))
19/07/31 01:05:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:38 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#5533 - cust_prospect_ind.nullCount#5532) > 0)
19/07/31 01:05:38 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#5538 - visit_device_type.nullCount#5537) > 0)
19/07/31 01:05:38 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#5531 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#5530))
19/07/31 01:05:38 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#5536 <= Tablet) && (Tablet <= visit_device_type.upperBound#5535))
19/07/31 01:05:38 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:38 INFO DAGScheduler: Got job 106 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:05:38 INFO DAGScheduler: Final stage: ResultStage 153 (collect at utils.scala:204)
19/07/31 01:05:38 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:05:38 INFO DAGScheduler: Missing parents: List()
19/07/31 01:05:38 INFO DAGScheduler: Submitting ResultStage 153 (MapPartitionsRDD[484] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:38 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 72.1 KB, free 909.8 MB)
19/07/31 01:05:38 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.8 MB)
19/07/31 01:05:38 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 127.0.0.1:53873 (size: 30.5 KB, free: 911.6 MB)
19/07/31 01:05:38 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 153 (MapPartitionsRDD[484] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:38 INFO TaskSchedulerImpl: Adding task set 153.0 with 1 tasks
19/07/31 01:05:38 INFO TaskSetManager: Starting task 0.0 in stage 153.0 (TID 282, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:05:38 INFO Executor: Running task 0.0 in stage 153.0 (TID 282)
19/07/31 01:05:38 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:38 INFO Executor: Finished task 0.0 in stage 153.0 (TID 282). 6512 bytes result sent to driver
19/07/31 01:05:38 INFO TaskSetManager: Finished task 0.0 in stage 153.0 (TID 282) in 4 ms on localhost (executor driver) (1/1)
19/07/31 01:05:38 INFO TaskSchedulerImpl: Removed TaskSet 153.0, whose tasks have all completed, from pool 
19/07/31 01:05:38 INFO DAGScheduler: ResultStage 153 (collect at utils.scala:204) finished in 0.005 s
19/07/31 01:05:38 INFO DAGScheduler: Job 106 finished: collect at utils.scala:204, took 0.014620 s
19/07/31 01:05:38 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:38 INFO DAGScheduler: Registering RDD 485 (collect at utils.scala:204)
19/07/31 01:05:38 INFO DAGScheduler: Got job 107 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:05:38 INFO DAGScheduler: Final stage: ResultStage 155 (collect at utils.scala:204)
19/07/31 01:05:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 154)
19/07/31 01:05:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 154)
19/07/31 01:05:38 INFO DAGScheduler: Submitting ShuffleMapStage 154 (MapPartitionsRDD[485] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:38 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 74.5 KB, free 909.7 MB)
19/07/31 01:05:38 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.7 MB)
19/07/31 01:05:38 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 127.0.0.1:53873 (size: 31.8 KB, free: 911.5 MB)
19/07/31 01:05:38 INFO SparkContext: Created broadcast 157 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 154 (MapPartitionsRDD[485] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:38 INFO TaskSchedulerImpl: Adding task set 154.0 with 1 tasks
19/07/31 01:05:38 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 283, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:05:38 INFO Executor: Running task 0.0 in stage 154.0 (TID 283)
19/07/31 01:05:38 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:38 INFO Executor: Finished task 0.0 in stage 154.0 (TID 283). 1687 bytes result sent to driver
19/07/31 01:05:38 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 283) in 8 ms on localhost (executor driver) (1/1)
19/07/31 01:05:38 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool 
19/07/31 01:05:38 INFO DAGScheduler: ShuffleMapStage 154 (collect at utils.scala:204) finished in 0.009 s
19/07/31 01:05:38 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:05:38 INFO DAGScheduler: running: Set()
19/07/31 01:05:38 INFO DAGScheduler: waiting: Set(ResultStage 155)
19/07/31 01:05:38 INFO DAGScheduler: failed: Set()
19/07/31 01:05:38 INFO DAGScheduler: Submitting ResultStage 155 (MapPartitionsRDD[488] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:38 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 16.8 KB, free 909.7 MB)
19/07/31 01:05:38 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 8.1 KB, free 909.7 MB)
19/07/31 01:05:38 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 127.0.0.1:53873 (size: 8.1 KB, free: 911.5 MB)
19/07/31 01:05:38 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:38 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 155 (MapPartitionsRDD[488] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:05:38 INFO TaskSchedulerImpl: Adding task set 155.0 with 4 tasks
19/07/31 01:05:38 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 284, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:05:38 INFO TaskSetManager: Starting task 1.0 in stage 155.0 (TID 285, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:05:38 INFO TaskSetManager: Starting task 2.0 in stage 155.0 (TID 286, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:05:38 INFO TaskSetManager: Starting task 3.0 in stage 155.0 (TID 287, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:05:38 INFO Executor: Running task 3.0 in stage 155.0 (TID 287)
19/07/31 01:05:38 INFO Executor: Running task 1.0 in stage 155.0 (TID 285)
19/07/31 01:05:38 INFO Executor: Running task 0.0 in stage 155.0 (TID 284)
19/07/31 01:05:38 INFO Executor: Running task 2.0 in stage 155.0 (TID 286)
19/07/31 01:05:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:38 INFO Executor: Finished task 0.0 in stage 155.0 (TID 284). 2347 bytes result sent to driver
19/07/31 01:05:38 INFO Executor: Finished task 1.0 in stage 155.0 (TID 285). 2313 bytes result sent to driver
19/07/31 01:05:38 INFO Executor: Finished task 2.0 in stage 155.0 (TID 286). 2338 bytes result sent to driver
19/07/31 01:05:38 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 284) in 6 ms on localhost (executor driver) (1/4)
19/07/31 01:05:38 INFO TaskSetManager: Finished task 1.0 in stage 155.0 (TID 285) in 5 ms on localhost (executor driver) (2/4)
19/07/31 01:05:38 INFO Executor: Finished task 3.0 in stage 155.0 (TID 287). 2311 bytes result sent to driver
19/07/31 01:05:38 INFO TaskSetManager: Finished task 2.0 in stage 155.0 (TID 286) in 5 ms on localhost (executor driver) (3/4)
19/07/31 01:05:38 INFO TaskSetManager: Finished task 3.0 in stage 155.0 (TID 287) in 6 ms on localhost (executor driver) (4/4)
19/07/31 01:05:38 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool 
19/07/31 01:05:38 INFO DAGScheduler: ResultStage 155 (collect at utils.scala:204) finished in 0.007 s
19/07/31 01:05:38 INFO DAGScheduler: Job 107 finished: collect at utils.scala:204, took 0.028992 s
19/07/31 01:05:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_337`) `dbplyr_338`
ORDER BY `date`) `dbplyr_339`) `dbplyr_340`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Tablet"))
19/07/31 01:05:39 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_341`) `dbplyr_342`
ORDER BY `date`) `dbplyr_343`) `dbplyr_344`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Tablet"))
19/07/31 01:05:39 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:39 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#5631 - cust_prospect_ind.nullCount#5630) > 0)
19/07/31 01:05:39 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#5636 - visit_device_type.nullCount#5635) > 0)
19/07/31 01:05:39 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#5629 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#5628))
19/07/31 01:05:39 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#5634 <= Tablet) && (Tablet <= visit_device_type.upperBound#5633))
19/07/31 01:05:39 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:39 INFO DAGScheduler: Got job 108 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:05:39 INFO DAGScheduler: Final stage: ResultStage 156 (collect at utils.scala:204)
19/07/31 01:05:39 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:05:39 INFO DAGScheduler: Missing parents: List()
19/07/31 01:05:39 INFO DAGScheduler: Submitting ResultStage 156 (MapPartitionsRDD[493] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:39 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 72.1 KB, free 909.6 MB)
19/07/31 01:05:39 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 30.4 KB, free 909.6 MB)
19/07/31 01:05:39 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on 127.0.0.1:53873 (size: 30.4 KB, free: 911.5 MB)
19/07/31 01:05:39 INFO SparkContext: Created broadcast 159 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 156 (MapPartitionsRDD[493] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:39 INFO TaskSchedulerImpl: Adding task set 156.0 with 1 tasks
19/07/31 01:05:39 INFO TaskSetManager: Starting task 0.0 in stage 156.0 (TID 288, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:05:39 INFO Executor: Running task 0.0 in stage 156.0 (TID 288)
19/07/31 01:05:39 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:39 INFO Executor: Finished task 0.0 in stage 156.0 (TID 288). 6512 bytes result sent to driver
19/07/31 01:05:39 INFO TaskSetManager: Finished task 0.0 in stage 156.0 (TID 288) in 5 ms on localhost (executor driver) (1/1)
19/07/31 01:05:39 INFO TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool 
19/07/31 01:05:39 INFO DAGScheduler: ResultStage 156 (collect at utils.scala:204) finished in 0.005 s
19/07/31 01:05:39 INFO DAGScheduler: Job 108 finished: collect at utils.scala:204, took 0.013454 s
19/07/31 01:05:39 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:39 INFO DAGScheduler: Registering RDD 494 (collect at utils.scala:204)
19/07/31 01:05:39 INFO DAGScheduler: Got job 109 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:05:39 INFO DAGScheduler: Final stage: ResultStage 158 (collect at utils.scala:204)
19/07/31 01:05:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 157)
19/07/31 01:05:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 157)
19/07/31 01:05:39 INFO DAGScheduler: Submitting ShuffleMapStage 157 (MapPartitionsRDD[494] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:39 INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 74.5 KB, free 909.5 MB)
19/07/31 01:05:39 INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 31.7 KB, free 909.5 MB)
19/07/31 01:05:39 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on 127.0.0.1:53873 (size: 31.7 KB, free: 911.5 MB)
19/07/31 01:05:39 INFO SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 157 (MapPartitionsRDD[494] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:39 INFO TaskSchedulerImpl: Adding task set 157.0 with 1 tasks
19/07/31 01:05:39 INFO TaskSetManager: Starting task 0.0 in stage 157.0 (TID 289, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:05:39 INFO Executor: Running task 0.0 in stage 157.0 (TID 289)
19/07/31 01:05:39 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:05:39 INFO Executor: Finished task 0.0 in stage 157.0 (TID 289). 1687 bytes result sent to driver
19/07/31 01:05:39 INFO TaskSetManager: Finished task 0.0 in stage 157.0 (TID 289) in 8 ms on localhost (executor driver) (1/1)
19/07/31 01:05:39 INFO TaskSchedulerImpl: Removed TaskSet 157.0, whose tasks have all completed, from pool 
19/07/31 01:05:39 INFO DAGScheduler: ShuffleMapStage 157 (collect at utils.scala:204) finished in 0.009 s
19/07/31 01:05:39 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:05:39 INFO DAGScheduler: running: Set()
19/07/31 01:05:39 INFO DAGScheduler: waiting: Set(ResultStage 158)
19/07/31 01:05:39 INFO DAGScheduler: failed: Set()
19/07/31 01:05:39 INFO DAGScheduler: Submitting ResultStage 158 (MapPartitionsRDD[497] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:39 INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 16.8 KB, free 909.4 MB)
19/07/31 01:05:39 INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 8.1 KB, free 909.4 MB)
19/07/31 01:05:39 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on 127.0.0.1:53873 (size: 8.1 KB, free: 911.5 MB)
19/07/31 01:05:39 INFO SparkContext: Created broadcast 161 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:39 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 158 (MapPartitionsRDD[497] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:05:39 INFO TaskSchedulerImpl: Adding task set 158.0 with 4 tasks
19/07/31 01:05:39 INFO TaskSetManager: Starting task 0.0 in stage 158.0 (TID 290, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:05:39 INFO TaskSetManager: Starting task 1.0 in stage 158.0 (TID 291, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:05:39 INFO TaskSetManager: Starting task 2.0 in stage 158.0 (TID 292, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:05:39 INFO TaskSetManager: Starting task 3.0 in stage 158.0 (TID 293, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:05:39 INFO Executor: Running task 0.0 in stage 158.0 (TID 290)
19/07/31 01:05:39 INFO Executor: Running task 1.0 in stage 158.0 (TID 291)
19/07/31 01:05:39 INFO Executor: Running task 2.0 in stage 158.0 (TID 292)
19/07/31 01:05:39 INFO Executor: Running task 3.0 in stage 158.0 (TID 293)
19/07/31 01:05:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:39 INFO Executor: Finished task 1.0 in stage 158.0 (TID 291). 2326 bytes result sent to driver
19/07/31 01:05:39 INFO Executor: Finished task 0.0 in stage 158.0 (TID 290). 2341 bytes result sent to driver
19/07/31 01:05:39 INFO Executor: Finished task 2.0 in stage 158.0 (TID 292). 2345 bytes result sent to driver
19/07/31 01:05:39 INFO TaskSetManager: Finished task 1.0 in stage 158.0 (TID 291) in 7 ms on localhost (executor driver) (1/4)
19/07/31 01:05:39 INFO Executor: Finished task 3.0 in stage 158.0 (TID 293). 2318 bytes result sent to driver
19/07/31 01:05:39 INFO TaskSetManager: Finished task 0.0 in stage 158.0 (TID 290) in 7 ms on localhost (executor driver) (2/4)
19/07/31 01:05:39 INFO TaskSetManager: Finished task 2.0 in stage 158.0 (TID 292) in 7 ms on localhost (executor driver) (3/4)
19/07/31 01:05:39 INFO TaskSetManager: Finished task 3.0 in stage 158.0 (TID 293) in 7 ms on localhost (executor driver) (4/4)
19/07/31 01:05:39 INFO TaskSchedulerImpl: Removed TaskSet 158.0, whose tasks have all completed, from pool 
19/07/31 01:05:39 INFO DAGScheduler: ResultStage 158 (collect at utils.scala:204) finished in 0.008 s
19/07/31 01:05:39 INFO DAGScheduler: Job 109 finished: collect at utils.scala:204, took 0.032757 s
19/07/31 01:05:56 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 01:05:56 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:56 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:56 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:56 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:56 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 01:05:56 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 01:05:56 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 01:05:56 INFO DAGScheduler: Got job 110 (collect at utils.scala:44) with 4 output partitions
19/07/31 01:05:56 INFO DAGScheduler: Final stage: ResultStage 159 (collect at utils.scala:44)
19/07/31 01:05:56 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:05:56 INFO DAGScheduler: Missing parents: List()
19/07/31 01:05:56 INFO DAGScheduler: Submitting ResultStage 159 (MapPartitionsRDD[502] at map at utils.scala:41), which has no missing parents
19/07/31 01:05:56 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 7.1 KB, free 909.4 MB)
19/07/31 01:05:56 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 3.7 KB, free 909.4 MB)
19/07/31 01:05:56 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 911.5 MB)
19/07/31 01:05:56 INFO SparkContext: Created broadcast 162 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:56 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 159 (MapPartitionsRDD[502] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:05:56 INFO TaskSchedulerImpl: Adding task set 159.0 with 4 tasks
19/07/31 01:05:56 INFO TaskSetManager: Starting task 0.0 in stage 159.0 (TID 294, localhost, executor driver, partition 0, PROCESS_LOCAL, 5108 bytes)
19/07/31 01:05:56 INFO TaskSetManager: Starting task 1.0 in stage 159.0 (TID 295, localhost, executor driver, partition 1, PROCESS_LOCAL, 5100 bytes)
19/07/31 01:05:56 INFO TaskSetManager: Starting task 2.0 in stage 159.0 (TID 296, localhost, executor driver, partition 2, PROCESS_LOCAL, 5100 bytes)
19/07/31 01:05:56 INFO TaskSetManager: Starting task 3.0 in stage 159.0 (TID 297, localhost, executor driver, partition 3, PROCESS_LOCAL, 5076 bytes)
19/07/31 01:05:56 INFO Executor: Running task 0.0 in stage 159.0 (TID 294)
19/07/31 01:05:56 INFO Executor: Running task 3.0 in stage 159.0 (TID 297)
19/07/31 01:05:56 INFO Executor: Running task 1.0 in stage 159.0 (TID 295)
19/07/31 01:05:56 INFO Executor: Running task 2.0 in stage 159.0 (TID 296)
19/07/31 01:05:56 INFO Executor: Finished task 2.0 in stage 159.0 (TID 296). 1026 bytes result sent to driver
19/07/31 01:05:56 INFO Executor: Finished task 3.0 in stage 159.0 (TID 297). 1005 bytes result sent to driver
19/07/31 01:05:56 INFO TaskSetManager: Finished task 2.0 in stage 159.0 (TID 296) in 8 ms on localhost (executor driver) (1/4)
19/07/31 01:05:56 INFO TaskSetManager: Finished task 3.0 in stage 159.0 (TID 297) in 8 ms on localhost (executor driver) (2/4)
19/07/31 01:05:56 INFO Executor: Finished task 0.0 in stage 159.0 (TID 294). 1035 bytes result sent to driver
19/07/31 01:05:56 INFO TaskSetManager: Finished task 0.0 in stage 159.0 (TID 294) in 12 ms on localhost (executor driver) (3/4)
19/07/31 01:05:56 INFO Executor: Finished task 1.0 in stage 159.0 (TID 295). 1026 bytes result sent to driver
19/07/31 01:05:56 INFO TaskSetManager: Finished task 1.0 in stage 159.0 (TID 295) in 12 ms on localhost (executor driver) (4/4)
19/07/31 01:05:56 INFO TaskSchedulerImpl: Removed TaskSet 159.0, whose tasks have all completed, from pool 
19/07/31 01:05:56 INFO DAGScheduler: ResultStage 159 (collect at utils.scala:44) finished in 0.013 s
19/07/31 01:05:56 INFO DAGScheduler: Job 110 finished: collect at utils.scala:44, took 0.019130 s
19/07/31 01:05:56 INFO SparkSqlParser: Parsing command: DROP TABLE `test`
19/07/31 01:05:56 INFO MapPartitionsRDD: Removing RDD 359 from persistence list
19/07/31 01:05:56 INFO BlockManager: Removing RDD 359
19/07/31 01:05:56 INFO SparkSqlParser: Parsing command: test
19/07/31 01:05:56 INFO SparkSqlParser: Parsing command: CACHE TABLE `test`
19/07/31 01:05:56 INFO SparkSqlParser: Parsing command: `test`
19/07/31 01:05:56 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 01:05:56 INFO DAGScheduler: Registering RDD 510 (sql at <unknown>:0)
19/07/31 01:05:56 INFO DAGScheduler: Got job 111 (sql at <unknown>:0) with 1 output partitions
19/07/31 01:05:56 INFO DAGScheduler: Final stage: ResultStage 161 (sql at <unknown>:0)
19/07/31 01:05:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 160)
19/07/31 01:05:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 160)
19/07/31 01:05:56 INFO DAGScheduler: Submitting ShuffleMapStage 160 (MapPartitionsRDD[510] at sql at <unknown>:0), which has no missing parents
19/07/31 01:05:56 INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 28.1 KB, free 909.4 MB)
19/07/31 01:05:56 INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 10.9 KB, free 909.4 MB)
19/07/31 01:05:56 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on 127.0.0.1:53873 (size: 10.9 KB, free: 911.5 MB)
19/07/31 01:05:56 INFO SparkContext: Created broadcast 163 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 160 (MapPartitionsRDD[510] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:56 INFO TaskSchedulerImpl: Adding task set 160.0 with 1 tasks
19/07/31 01:05:56 INFO TaskSetManager: Starting task 0.0 in stage 160.0 (TID 298, localhost, executor driver, partition 0, PROCESS_LOCAL, 14183 bytes)
19/07/31 01:05:56 INFO Executor: Running task 0.0 in stage 160.0 (TID 298)
19/07/31 01:05:56 INFO CodeGenerator: Code generated in 8.1505 ms
19/07/31 01:05:56 INFO CodeGenerator: Code generated in 43.858219 ms
19/07/31 01:05:56 INFO MemoryStore: Block rdd_507_0 stored as values in memory (estimated size 8.8 KB, free 909.4 MB)
19/07/31 01:05:56 INFO BlockManagerInfo: Added rdd_507_0 in memory on 127.0.0.1:53873 (size: 8.8 KB, free: 911.5 MB)
19/07/31 01:05:56 INFO Executor: Finished task 0.0 in stage 160.0 (TID 298). 2285 bytes result sent to driver
19/07/31 01:05:56 INFO TaskSetManager: Finished task 0.0 in stage 160.0 (TID 298) in 77 ms on localhost (executor driver) (1/1)
19/07/31 01:05:56 INFO TaskSchedulerImpl: Removed TaskSet 160.0, whose tasks have all completed, from pool 
19/07/31 01:05:56 INFO DAGScheduler: ShuffleMapStage 160 (sql at <unknown>:0) finished in 0.079 s
19/07/31 01:05:56 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:05:56 INFO DAGScheduler: running: Set()
19/07/31 01:05:56 INFO DAGScheduler: waiting: Set(ResultStage 161)
19/07/31 01:05:56 INFO DAGScheduler: failed: Set()
19/07/31 01:05:56 INFO DAGScheduler: Submitting ResultStage 161 (MapPartitionsRDD[513] at sql at <unknown>:0), which has no missing parents
19/07/31 01:05:56 INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 7.0 KB, free 909.4 MB)
19/07/31 01:05:56 INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 3.7 KB, free 909.4 MB)
19/07/31 01:05:56 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 911.4 MB)
19/07/31 01:05:56 INFO SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 161 (MapPartitionsRDD[513] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:56 INFO TaskSchedulerImpl: Adding task set 161.0 with 1 tasks
19/07/31 01:05:56 INFO TaskSetManager: Starting task 0.0 in stage 161.0 (TID 299, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:05:56 INFO Executor: Running task 0.0 in stage 161.0 (TID 299)
19/07/31 01:05:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:56 INFO Executor: Finished task 0.0 in stage 161.0 (TID 299). 1538 bytes result sent to driver
19/07/31 01:05:56 INFO TaskSetManager: Finished task 0.0 in stage 161.0 (TID 299) in 3 ms on localhost (executor driver) (1/1)
19/07/31 01:05:56 INFO TaskSchedulerImpl: Removed TaskSet 161.0, whose tasks have all completed, from pool 
19/07/31 01:05:56 INFO DAGScheduler: ResultStage 161 (sql at <unknown>:0) finished in 0.003 s
19/07/31 01:05:56 INFO DAGScheduler: Job 111 finished: sql at <unknown>:0, took 0.090311 s
19/07/31 01:05:56 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `test`
19/07/31 01:05:56 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:56 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:56 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:05:56 INFO DAGScheduler: Registering RDD 516 (collect at utils.scala:204)
19/07/31 01:05:56 INFO DAGScheduler: Got job 112 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:05:56 INFO DAGScheduler: Final stage: ResultStage 163 (collect at utils.scala:204)
19/07/31 01:05:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 162)
19/07/31 01:05:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 162)
19/07/31 01:05:56 INFO DAGScheduler: Submitting ShuffleMapStage 162 (MapPartitionsRDD[516] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:56 INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 28.1 KB, free 909.3 MB)
19/07/31 01:05:56 INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 10.9 KB, free 909.3 MB)
19/07/31 01:05:56 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on 127.0.0.1:53873 (size: 10.9 KB, free: 911.4 MB)
19/07/31 01:05:56 INFO SparkContext: Created broadcast 165 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 162 (MapPartitionsRDD[516] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:56 INFO TaskSchedulerImpl: Adding task set 162.0 with 1 tasks
19/07/31 01:05:56 INFO TaskSetManager: Starting task 0.0 in stage 162.0 (TID 300, localhost, executor driver, partition 0, PROCESS_LOCAL, 14183 bytes)
19/07/31 01:05:56 INFO Executor: Running task 0.0 in stage 162.0 (TID 300)
19/07/31 01:05:56 INFO BlockManager: Found block rdd_507_0 locally
19/07/31 01:05:56 INFO Executor: Finished task 0.0 in stage 162.0 (TID 300). 1690 bytes result sent to driver
19/07/31 01:05:56 INFO TaskSetManager: Finished task 0.0 in stage 162.0 (TID 300) in 6 ms on localhost (executor driver) (1/1)
19/07/31 01:05:56 INFO TaskSchedulerImpl: Removed TaskSet 162.0, whose tasks have all completed, from pool 
19/07/31 01:05:56 INFO DAGScheduler: ShuffleMapStage 162 (collect at utils.scala:204) finished in 0.006 s
19/07/31 01:05:56 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:05:56 INFO DAGScheduler: running: Set()
19/07/31 01:05:56 INFO DAGScheduler: waiting: Set(ResultStage 163)
19/07/31 01:05:56 INFO DAGScheduler: failed: Set()
19/07/31 01:05:56 INFO DAGScheduler: Submitting ResultStage 163 (MapPartitionsRDD[519] at collect at utils.scala:204), which has no missing parents
19/07/31 01:05:56 INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 7.0 KB, free 909.3 MB)
19/07/31 01:05:56 INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 3.8 KB, free 909.3 MB)
19/07/31 01:05:56 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on 127.0.0.1:53873 (size: 3.8 KB, free: 911.4 MB)
19/07/31 01:05:56 INFO SparkContext: Created broadcast 166 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 163 (MapPartitionsRDD[519] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:56 INFO TaskSchedulerImpl: Adding task set 163.0 with 1 tasks
19/07/31 01:05:56 INFO TaskSetManager: Starting task 0.0 in stage 163.0 (TID 301, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:05:56 INFO Executor: Running task 0.0 in stage 163.0 (TID 301)
19/07/31 01:05:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:05:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:05:56 INFO Executor: Finished task 0.0 in stage 163.0 (TID 301). 1581 bytes result sent to driver
19/07/31 01:05:56 INFO TaskSetManager: Finished task 0.0 in stage 163.0 (TID 301) in 6 ms on localhost (executor driver) (1/1)
19/07/31 01:05:56 INFO TaskSchedulerImpl: Removed TaskSet 163.0, whose tasks have all completed, from pool 
19/07/31 01:05:56 INFO DAGScheduler: ResultStage 163 (collect at utils.scala:204) finished in 0.006 s
19/07/31 01:05:56 INFO DAGScheduler: Job 112 finished: collect at utils.scala:204, took 0.022839 s
19/07/31 01:05:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test` AS `zzz10`
WHERE (0 = 1)
19/07/31 01:05:56 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 01:05:56 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:56 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:56 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:05:56 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:05:56 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 01:05:56 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 01:05:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
19/07/31 01:05:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 01:05:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 01:05:59 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 01:05:59 INFO DAGScheduler: Got job 113 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 01:05:59 INFO DAGScheduler: Final stage: ResultStage 164 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 01:05:59 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:05:59 INFO DAGScheduler: Missing parents: List()
19/07/31 01:05:59 INFO DAGScheduler: Submitting ResultStage 164 (MapPartitionsRDD[520] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 01:05:59 INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 99.1 KB, free 909.2 MB)
19/07/31 01:05:59 INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 37.3 KB, free 909.2 MB)
19/07/31 01:05:59 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on 127.0.0.1:53873 (size: 37.3 KB, free: 911.4 MB)
19/07/31 01:05:59 INFO SparkContext: Created broadcast 167 from broadcast at DAGScheduler.scala:1006
19/07/31 01:05:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 164 (MapPartitionsRDD[520] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 01:05:59 INFO TaskSchedulerImpl: Adding task set 164.0 with 1 tasks
19/07/31 01:05:59 INFO TaskSetManager: Starting task 0.0 in stage 164.0 (TID 302, localhost, executor driver, partition 0, PROCESS_LOCAL, 14194 bytes)
19/07/31 01:05:59 INFO Executor: Running task 0.0 in stage 164.0 (TID 302)
19/07/31 01:05:59 INFO BlockManager: Found block rdd_507_0 locally
19/07/31 01:05:59 INFO CodeGenerator: Code generated in 9.613034 ms
19/07/31 01:05:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 01:05:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 01:05:59 INFO FileOutputCommitter: Saved output of task 'attempt_20190731010559_0164_m_000000_0' to file:/Users/6jncnk4f/Desktop/anomaly/result/_temporary/0/task_20190731010559_0164_m_000000
19/07/31 01:05:59 INFO SparkHadoopMapRedUtil: attempt_20190731010559_0164_m_000000_0: Committed
19/07/31 01:05:59 INFO Executor: Finished task 0.0 in stage 164.0 (TID 302). 1576 bytes result sent to driver
19/07/31 01:05:59 INFO TaskSetManager: Finished task 0.0 in stage 164.0 (TID 302) in 120 ms on localhost (executor driver) (1/1)
19/07/31 01:05:59 INFO TaskSchedulerImpl: Removed TaskSet 164.0, whose tasks have all completed, from pool 
19/07/31 01:05:59 INFO DAGScheduler: ResultStage 164 (csv at NativeMethodAccessorImpl.java:0) finished in 0.120 s
19/07/31 01:05:59 INFO DAGScheduler: Job 113 finished: csv at NativeMethodAccessorImpl.java:0, took 0.135189 s
19/07/31 01:05:59 INFO FileFormatWriter: Job null committed.
19/07/31 01:08:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_345`) `dbplyr_346`
ORDER BY `date`) `dbplyr_347`) `dbplyr_348`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 01:08:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:08:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:08:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_349`) `dbplyr_350`
ORDER BY `date`) `dbplyr_351`) `dbplyr_352`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 01:08:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:08:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:08:41 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#6249 - cust_prospect_ind.nullCount#6248) > 0)
19/07/31 01:08:41 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#6254 - visit_device_type.nullCount#6253) > 0)
19/07/31 01:08:41 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#6247 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#6246))
19/07/31 01:08:41 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#6252 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#6251))
19/07/31 01:08:41 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:08:41 INFO DAGScheduler: Got job 114 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:08:41 INFO DAGScheduler: Final stage: ResultStage 165 (collect at utils.scala:204)
19/07/31 01:08:41 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:08:41 INFO DAGScheduler: Missing parents: List()
19/07/31 01:08:41 INFO DAGScheduler: Submitting ResultStage 165 (MapPartitionsRDD[527] at collect at utils.scala:204), which has no missing parents
19/07/31 01:08:41 INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 72.1 KB, free 909.1 MB)
19/07/31 01:08:41 INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.1 MB)
19/07/31 01:08:41 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on 127.0.0.1:53873 (size: 30.5 KB, free: 911.4 MB)
19/07/31 01:08:41 INFO SparkContext: Created broadcast 168 from broadcast at DAGScheduler.scala:1006
19/07/31 01:08:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 165 (MapPartitionsRDD[527] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:08:41 INFO TaskSchedulerImpl: Adding task set 165.0 with 1 tasks
19/07/31 01:08:41 INFO TaskSetManager: Starting task 0.0 in stage 165.0 (TID 303, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:08:41 INFO Executor: Running task 0.0 in stage 165.0 (TID 303)
19/07/31 01:08:41 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:08:41 INFO Executor: Finished task 0.0 in stage 165.0 (TID 303). 7585 bytes result sent to driver
19/07/31 01:08:41 INFO TaskSetManager: Finished task 0.0 in stage 165.0 (TID 303) in 6 ms on localhost (executor driver) (1/1)
19/07/31 01:08:41 INFO TaskSchedulerImpl: Removed TaskSet 165.0, whose tasks have all completed, from pool 
19/07/31 01:08:41 INFO DAGScheduler: ResultStage 165 (collect at utils.scala:204) finished in 0.007 s
19/07/31 01:08:41 INFO DAGScheduler: Job 114 finished: collect at utils.scala:204, took 0.019480 s
19/07/31 01:08:41 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:08:41 INFO DAGScheduler: Registering RDD 528 (collect at utils.scala:204)
19/07/31 01:08:41 INFO DAGScheduler: Got job 115 (collect at utils.scala:204) with 4 output partitions
19/07/31 01:08:41 INFO DAGScheduler: Final stage: ResultStage 167 (collect at utils.scala:204)
19/07/31 01:08:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 166)
19/07/31 01:08:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 166)
19/07/31 01:08:41 INFO DAGScheduler: Submitting ShuffleMapStage 166 (MapPartitionsRDD[528] at collect at utils.scala:204), which has no missing parents
19/07/31 01:08:41 INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 74.6 KB, free 909.0 MB)
19/07/31 01:08:41 INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.0 MB)
19/07/31 01:08:41 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on 127.0.0.1:53873 (size: 31.8 KB, free: 911.3 MB)
19/07/31 01:08:41 INFO SparkContext: Created broadcast 169 from broadcast at DAGScheduler.scala:1006
19/07/31 01:08:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 166 (MapPartitionsRDD[528] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:08:41 INFO TaskSchedulerImpl: Adding task set 166.0 with 1 tasks
19/07/31 01:08:41 INFO TaskSetManager: Starting task 0.0 in stage 166.0 (TID 304, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:08:41 INFO Executor: Running task 0.0 in stage 166.0 (TID 304)
19/07/31 01:08:41 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4378
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3778
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3860
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3939
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3701
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4379
19/07/31 01:08:41 INFO ContextCleaner: Cleaned shuffle 47
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3541
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4263
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3785
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_166_piece0 on 127.0.0.1:53873 in memory (size: 3.8 KB, free: 911.3 MB)
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_145_piece0 on 127.0.0.1:53873 in memory (size: 31.7 KB, free: 911.4 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3944
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4266
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 127.0.0.1:53873 in memory (size: 8.1 KB, free: 911.4 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3946
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4344
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3866
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_146_piece0 on 127.0.0.1:53873 in memory (size: 8.1 KB, free: 911.4 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3859
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4270
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4189
19/07/31 01:08:41 INFO ContextCleaner: Cleaned shuffle 41
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4438
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3698
19/07/31 01:08:41 INFO ContextCleaner: Cleaned shuffle 43
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3945
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3702
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3861
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4026
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3862
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4184
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_148_piece0 on 127.0.0.1:53873 in memory (size: 31.8 KB, free: 911.4 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3534
19/07/31 01:08:41 INFO Executor: Finished task 0.0 in stage 166.0 (TID 304). 1730 bytes result sent to driver
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_159_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 911.4 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4269
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3941
19/07/31 01:08:41 INFO TaskSetManager: Finished task 0.0 in stage 166.0 (TID 304) in 24 ms on localhost (executor driver) (1/1)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3539
19/07/31 01:08:41 INFO TaskSchedulerImpl: Removed TaskSet 166.0, whose tasks have all completed, from pool 
19/07/31 01:08:41 INFO DAGScheduler: ShuffleMapStage 166 (collect at utils.scala:204) finished in 0.024 s
19/07/31 01:08:41 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:08:41 INFO DAGScheduler: running: Set()
19/07/31 01:08:41 INFO DAGScheduler: waiting: Set(ResultStage 167)
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_150_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 911.5 MB)
19/07/31 01:08:41 INFO DAGScheduler: failed: Set()
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3781
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4186
19/07/31 01:08:41 INFO DAGScheduler: Submitting ResultStage 167 (MapPartitionsRDD[531] at collect at utils.scala:204), which has no missing parents
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 127.0.0.1:53873 in memory (size: 31.8 KB, free: 911.5 MB)
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 127.0.0.1:53873 in memory (size: 30.5 KB, free: 911.5 MB)
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 127.0.0.1:53873 in memory (size: 31.8 KB, free: 911.6 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4518
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_168_piece0 on 127.0.0.1:53873 in memory (size: 30.5 KB, free: 911.6 MB)
19/07/31 01:08:41 INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 16.8 KB, free 909.8 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3536
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 127.0.0.1:53873 in memory (size: 30.5 KB, free: 911.6 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3537
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4380
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3947
19/07/31 01:08:41 INFO ContextCleaner: Cleaned shuffle 49
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3940
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3777
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3780
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4101
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4372
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4437
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4434
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4439
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4104
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 127.0.0.1:53873 in memory (size: 31.7 KB, free: 911.7 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned shuffle 38
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4025
19/07/31 01:08:41 INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 8.1 KB, free 910.1 MB)
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 127.0.0.1:53873 in memory (size: 8.1 KB, free: 911.7 MB)
19/07/31 01:08:41 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on 127.0.0.1:53873 (size: 8.1 KB, free: 911.7 MB)
19/07/31 01:08:41 INFO SparkContext: Created broadcast 170 from broadcast at DAGScheduler.scala:1006
19/07/31 01:08:41 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 167 (MapPartitionsRDD[531] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:08:41 INFO TaskSchedulerImpl: Adding task set 167.0 with 4 tasks
19/07/31 01:08:41 INFO TaskSetManager: Starting task 0.0 in stage 167.0 (TID 305, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:08:41 INFO TaskSetManager: Starting task 1.0 in stage 167.0 (TID 306, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 01:08:41 INFO TaskSetManager: Starting task 2.0 in stage 167.0 (TID 307, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 01:08:41 INFO TaskSetManager: Starting task 3.0 in stage 167.0 (TID 308, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_158_piece0 on 127.0.0.1:53873 in memory (size: 8.1 KB, free: 911.7 MB)
19/07/31 01:08:41 INFO Executor: Running task 0.0 in stage 167.0 (TID 305)
19/07/31 01:08:41 INFO Executor: Running task 1.0 in stage 167.0 (TID 306)
19/07/31 01:08:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:08:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:08:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:08:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:08:41 INFO Executor: Finished task 1.0 in stage 167.0 (TID 306). 2368 bytes result sent to driver
19/07/31 01:08:41 INFO Executor: Running task 2.0 in stage 167.0 (TID 307)
19/07/31 01:08:41 INFO Executor: Finished task 0.0 in stage 167.0 (TID 305). 2365 bytes result sent to driver
19/07/31 01:08:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:08:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:08:41 INFO Executor: Finished task 2.0 in stage 167.0 (TID 307). 2364 bytes result sent to driver
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_144_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 911.7 MB)
19/07/31 01:08:41 INFO Executor: Running task 3.0 in stage 167.0 (TID 308)
19/07/31 01:08:41 INFO TaskSetManager: Finished task 1.0 in stage 167.0 (TID 306) in 13 ms on localhost (executor driver) (1/4)
19/07/31 01:08:41 INFO TaskSetManager: Finished task 2.0 in stage 167.0 (TID 307) in 13 ms on localhost (executor driver) (2/4)
19/07/31 01:08:41 INFO TaskSetManager: Finished task 0.0 in stage 167.0 (TID 305) in 13 ms on localhost (executor driver) (3/4)
19/07/31 01:08:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:08:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:08:41 INFO Executor: Finished task 3.0 in stage 167.0 (TID 308). 2342 bytes result sent to driver
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_139_piece0 on 127.0.0.1:53873 in memory (size: 31.8 KB, free: 911.7 MB)
19/07/31 01:08:41 INFO TaskSetManager: Finished task 3.0 in stage 167.0 (TID 308) in 17 ms on localhost (executor driver) (4/4)
19/07/31 01:08:41 INFO TaskSchedulerImpl: Removed TaskSet 167.0, whose tasks have all completed, from pool 
19/07/31 01:08:41 INFO DAGScheduler: ResultStage 167 (collect at utils.scala:204) finished in 0.017 s
19/07/31 01:08:41 INFO DAGScheduler: Job 115 finished: collect at utils.scala:204, took 0.071315 s
19/07/31 01:08:41 INFO ContextCleaner: Cleaned shuffle 48
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_152_piece0 on 127.0.0.1:53873 in memory (size: 8.1 KB, free: 911.7 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4107
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3615
19/07/31 01:08:41 INFO ContextCleaner: Cleaned shuffle 39
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_157_piece0 on 127.0.0.1:53873 in memory (size: 31.8 KB, free: 911.8 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4024
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4376
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4271
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4106
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3704
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4022
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3697
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4436
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4105
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4383
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 127.0.0.1:53873 in memory (size: 31.8 KB, free: 911.8 MB)
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_151_piece0 on 127.0.0.1:53873 in memory (size: 31.7 KB, free: 911.8 MB)
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_155_piece0 on 127.0.0.1:53873 in memory (size: 8.1 KB, free: 911.8 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4185
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4441
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3619
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4190
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4442
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3779
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 911.9 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4381
19/07/31 01:08:41 INFO ContextCleaner: Cleaned shuffle 42
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4443
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4188
19/07/31 01:08:41 INFO ContextCleaner: Cleaned shuffle 50
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3618
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3696
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4377
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_156_piece0 on 127.0.0.1:53873 in memory (size: 30.5 KB, free: 911.9 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3858
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 127.0.0.1:53873 in memory (size: 8.1 KB, free: 911.9 MB)
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 127.0.0.1:53873 in memory (size: 8.1 KB, free: 911.9 MB)
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_165_piece0 on 127.0.0.1:53873 in memory (size: 10.9 KB, free: 911.9 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4444
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3622
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4432
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4268
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4187
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4433
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3784
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4183
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4021
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4103
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4371
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3621
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4020
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4265
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3783
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3535
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_161_piece0 on 127.0.0.1:53873 in memory (size: 8.1 KB, free: 911.9 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3700
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_153_piece0 on 127.0.0.1:53873 in memory (size: 30.5 KB, free: 912.0 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4373
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4028
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4023
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_160_piece0 on 127.0.0.1:53873 in memory (size: 31.7 KB, free: 912.0 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3540
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3699
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4382
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3623
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_167_piece0 on 127.0.0.1:53873 in memory (size: 37.3 KB, free: 912.0 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4440
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_162_piece0 on 127.0.0.1:53873 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3782
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3620
19/07/31 01:08:41 INFO ContextCleaner: Cleaned shuffle 46
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4435
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_163_piece0 on 127.0.0.1:53873 in memory (size: 10.9 KB, free: 912.0 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned shuffle 45
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3864
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 127.0.0.1:53873 in memory (size: 30.4 KB, free: 912.1 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3863
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3943
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4375
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4108
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4267
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4182
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_147_piece0 on 127.0.0.1:53873 in memory (size: 30.5 KB, free: 912.1 MB)
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 127.0.0.1:53873 in memory (size: 30.5 KB, free: 912.1 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4493
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3865
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 127.0.0.1:53873 in memory (size: 8.1 KB, free: 912.1 MB)
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 127.0.0.1:53873 in memory (size: 31.8 KB, free: 912.2 MB)
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_164_piece0 on 127.0.0.1:53873 in memory (size: 3.7 KB, free: 912.2 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4109
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3538
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4374
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4264
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3617
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3703
19/07/31 01:08:41 INFO ContextCleaner: Cleaned shuffle 40
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3942
19/07/31 01:08:41 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 127.0.0.1:53873 in memory (size: 8.1 KB, free: 912.2 MB)
19/07/31 01:08:41 INFO ContextCleaner: Cleaned shuffle 44
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4102
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3542
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 4027
19/07/31 01:08:41 INFO ContextCleaner: Cleaned accumulator 3616
19/07/31 01:10:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
19/07/31 01:10:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
LIMIT 1000
19/07/31 01:10:21 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:10:21 INFO DAGScheduler: Got job 116 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:10:21 INFO DAGScheduler: Final stage: ResultStage 168 (collect at utils.scala:204)
19/07/31 01:10:21 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:10:21 INFO DAGScheduler: Missing parents: List()
19/07/31 01:10:21 INFO DAGScheduler: Submitting ResultStage 168 (MapPartitionsRDD[533] at collect at utils.scala:204), which has no missing parents
19/07/31 01:10:21 INFO MemoryStore: Block broadcast_171 stored as values in memory (estimated size 23.8 KB, free 911.8 MB)
19/07/31 01:10:21 INFO MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 8.9 KB, free 911.8 MB)
19/07/31 01:10:21 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on 127.0.0.1:53873 (size: 8.9 KB, free: 912.2 MB)
19/07/31 01:10:21 INFO SparkContext: Created broadcast 171 from broadcast at DAGScheduler.scala:1006
19/07/31 01:10:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 168 (MapPartitionsRDD[533] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:10:21 INFO TaskSchedulerImpl: Adding task set 168.0 with 1 tasks
19/07/31 01:10:21 INFO TaskSetManager: Starting task 0.0 in stage 168.0 (TID 309, localhost, executor driver, partition 0, PROCESS_LOCAL, 14194 bytes)
19/07/31 01:10:21 INFO Executor: Running task 0.0 in stage 168.0 (TID 309)
19/07/31 01:10:21 INFO BlockManager: Found block rdd_507_0 locally
19/07/31 01:10:21 INFO Executor: Finished task 0.0 in stage 168.0 (TID 309). 5432 bytes result sent to driver
19/07/31 01:10:21 INFO TaskSetManager: Finished task 0.0 in stage 168.0 (TID 309) in 5 ms on localhost (executor driver) (1/1)
19/07/31 01:10:21 INFO TaskSchedulerImpl: Removed TaskSet 168.0, whose tasks have all completed, from pool 
19/07/31 01:10:21 INFO DAGScheduler: ResultStage 168 (collect at utils.scala:204) finished in 0.007 s
19/07/31 01:10:21 INFO DAGScheduler: Job 116 finished: collect at utils.scala:204, took 0.014992 s
19/07/31 01:10:21 INFO CodeGenerator: Code generated in 29.963517 ms
19/07/31 01:13:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
19/07/31 01:13:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 01:13:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 01:13:11 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 01:13:11 INFO DAGScheduler: Got job 117 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 01:13:11 INFO DAGScheduler: Final stage: ResultStage 169 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 01:13:11 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:13:11 INFO DAGScheduler: Missing parents: List()
19/07/31 01:13:11 INFO DAGScheduler: Submitting ResultStage 169 (MapPartitionsRDD[534] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 01:13:11 INFO MemoryStore: Block broadcast_172 stored as values in memory (estimated size 99.1 KB, free 911.7 MB)
19/07/31 01:13:11 INFO MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 37.2 KB, free 911.7 MB)
19/07/31 01:13:11 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on 127.0.0.1:53873 (size: 37.2 KB, free: 912.1 MB)
19/07/31 01:13:11 INFO SparkContext: Created broadcast 172 from broadcast at DAGScheduler.scala:1006
19/07/31 01:13:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 169 (MapPartitionsRDD[534] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 01:13:11 INFO TaskSchedulerImpl: Adding task set 169.0 with 1 tasks
19/07/31 01:13:11 INFO TaskSetManager: Starting task 0.0 in stage 169.0 (TID 310, localhost, executor driver, partition 0, PROCESS_LOCAL, 14194 bytes)
19/07/31 01:13:11 INFO Executor: Running task 0.0 in stage 169.0 (TID 310)
19/07/31 01:13:11 INFO BlockManager: Found block rdd_507_0 locally
19/07/31 01:13:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 01:13:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 01:13:11 INFO FileOutputCommitter: Saved output of task 'attempt_20190731011311_0169_m_000000_0' to file:/Users/6jncnk4f/Desktop/anomaly/result/_temporary/0/task_20190731011311_0169_m_000000
19/07/31 01:13:11 INFO SparkHadoopMapRedUtil: attempt_20190731011311_0169_m_000000_0: Committed
19/07/31 01:13:11 INFO Executor: Finished task 0.0 in stage 169.0 (TID 310). 1576 bytes result sent to driver
19/07/31 01:13:11 INFO TaskSetManager: Finished task 0.0 in stage 169.0 (TID 310) in 137 ms on localhost (executor driver) (1/1)
19/07/31 01:13:11 INFO TaskSchedulerImpl: Removed TaskSet 169.0, whose tasks have all completed, from pool 
19/07/31 01:13:11 INFO DAGScheduler: ResultStage 169 (csv at NativeMethodAccessorImpl.java:0) finished in 0.138 s
19/07/31 01:13:11 INFO DAGScheduler: Job 117 finished: csv at NativeMethodAccessorImpl.java:0, took 0.177520 s
19/07/31 01:13:11 INFO FileFormatWriter: Job null committed.
19/07/31 01:13:15 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 01:13:15 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:13:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:13:15 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:13:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:13:15 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 01:13:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 01:13:15 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 01:13:15 INFO DAGScheduler: Got job 118 (collect at utils.scala:44) with 4 output partitions
19/07/31 01:13:15 INFO DAGScheduler: Final stage: ResultStage 170 (collect at utils.scala:44)
19/07/31 01:13:15 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:13:15 INFO DAGScheduler: Missing parents: List()
19/07/31 01:13:15 INFO DAGScheduler: Submitting ResultStage 170 (MapPartitionsRDD[541] at map at utils.scala:41), which has no missing parents
19/07/31 01:13:15 INFO MemoryStore: Block broadcast_173 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
19/07/31 01:13:15 INFO MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.6 MB)
19/07/31 01:13:15 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 912.1 MB)
19/07/31 01:13:15 INFO SparkContext: Created broadcast 173 from broadcast at DAGScheduler.scala:1006
19/07/31 01:13:15 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 170 (MapPartitionsRDD[541] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:13:15 INFO TaskSchedulerImpl: Adding task set 170.0 with 4 tasks
19/07/31 01:13:15 INFO TaskSetManager: Starting task 0.0 in stage 170.0 (TID 311, localhost, executor driver, partition 0, PROCESS_LOCAL, 5108 bytes)
19/07/31 01:13:15 INFO TaskSetManager: Starting task 1.0 in stage 170.0 (TID 312, localhost, executor driver, partition 1, PROCESS_LOCAL, 5100 bytes)
19/07/31 01:13:15 INFO TaskSetManager: Starting task 2.0 in stage 170.0 (TID 313, localhost, executor driver, partition 2, PROCESS_LOCAL, 5100 bytes)
19/07/31 01:13:15 INFO TaskSetManager: Starting task 3.0 in stage 170.0 (TID 314, localhost, executor driver, partition 3, PROCESS_LOCAL, 5076 bytes)
19/07/31 01:13:15 INFO Executor: Running task 0.0 in stage 170.0 (TID 311)
19/07/31 01:13:15 INFO Executor: Running task 1.0 in stage 170.0 (TID 312)
19/07/31 01:13:15 INFO Executor: Running task 3.0 in stage 170.0 (TID 314)
19/07/31 01:13:15 INFO Executor: Running task 2.0 in stage 170.0 (TID 313)
19/07/31 01:13:15 INFO Executor: Finished task 1.0 in stage 170.0 (TID 312). 983 bytes result sent to driver
19/07/31 01:13:15 INFO Executor: Finished task 2.0 in stage 170.0 (TID 313). 983 bytes result sent to driver
19/07/31 01:13:15 INFO Executor: Finished task 0.0 in stage 170.0 (TID 311). 1035 bytes result sent to driver
19/07/31 01:13:15 INFO Executor: Finished task 3.0 in stage 170.0 (TID 314). 962 bytes result sent to driver
19/07/31 01:13:15 INFO TaskSetManager: Finished task 2.0 in stage 170.0 (TID 313) in 4 ms on localhost (executor driver) (1/4)
19/07/31 01:13:15 INFO TaskSetManager: Finished task 0.0 in stage 170.0 (TID 311) in 4 ms on localhost (executor driver) (2/4)
19/07/31 01:13:15 INFO TaskSetManager: Finished task 1.0 in stage 170.0 (TID 312) in 4 ms on localhost (executor driver) (3/4)
19/07/31 01:13:15 INFO TaskSetManager: Finished task 3.0 in stage 170.0 (TID 314) in 4 ms on localhost (executor driver) (4/4)
19/07/31 01:13:15 INFO TaskSchedulerImpl: Removed TaskSet 170.0, whose tasks have all completed, from pool 
19/07/31 01:13:15 INFO DAGScheduler: ResultStage 170 (collect at utils.scala:44) finished in 0.005 s
19/07/31 01:13:15 INFO DAGScheduler: Job 118 finished: collect at utils.scala:44, took 0.014028 s
19/07/31 01:13:15 INFO SparkSqlParser: Parsing command: DROP TABLE `test`
19/07/31 01:13:15 INFO MapPartitionsRDD: Removing RDD 507 from persistence list
19/07/31 01:13:15 INFO BlockManager: Removing RDD 507
19/07/31 01:13:15 INFO SparkSqlParser: Parsing command: test
19/07/31 01:13:15 INFO SparkSqlParser: Parsing command: CACHE TABLE `test`
19/07/31 01:13:15 INFO SparkSqlParser: Parsing command: `test`
19/07/31 01:13:15 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 01:13:15 INFO DAGScheduler: Registering RDD 549 (sql at <unknown>:0)
19/07/31 01:13:15 INFO DAGScheduler: Got job 119 (sql at <unknown>:0) with 1 output partitions
19/07/31 01:13:15 INFO DAGScheduler: Final stage: ResultStage 172 (sql at <unknown>:0)
19/07/31 01:13:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 171)
19/07/31 01:13:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 171)
19/07/31 01:13:15 INFO DAGScheduler: Submitting ShuffleMapStage 171 (MapPartitionsRDD[549] at sql at <unknown>:0), which has no missing parents
19/07/31 01:13:15 INFO MemoryStore: Block broadcast_174 stored as values in memory (estimated size 28.2 KB, free 911.6 MB)
19/07/31 01:13:15 INFO MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 10.9 KB, free 911.6 MB)
19/07/31 01:13:15 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on 127.0.0.1:53873 (size: 10.9 KB, free: 912.1 MB)
19/07/31 01:13:15 INFO SparkContext: Created broadcast 174 from broadcast at DAGScheduler.scala:1006
19/07/31 01:13:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 171 (MapPartitionsRDD[549] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 01:13:15 INFO TaskSchedulerImpl: Adding task set 171.0 with 1 tasks
19/07/31 01:13:15 INFO TaskSetManager: Starting task 0.0 in stage 171.0 (TID 315, localhost, executor driver, partition 0, PROCESS_LOCAL, 14768 bytes)
19/07/31 01:13:15 INFO Executor: Running task 0.0 in stage 171.0 (TID 315)
19/07/31 01:13:15 INFO CodeGenerator: Code generated in 15.84291 ms
19/07/31 01:13:15 INFO CodeGenerator: Code generated in 65.29393 ms
19/07/31 01:13:15 INFO MemoryStore: Block rdd_546_0 stored as values in memory (estimated size 9.0 KB, free 911.6 MB)
19/07/31 01:13:15 INFO BlockManagerInfo: Added rdd_546_0 in memory on 127.0.0.1:53873 (size: 9.0 KB, free: 912.1 MB)
19/07/31 01:13:15 INFO Executor: Finished task 0.0 in stage 171.0 (TID 315). 2285 bytes result sent to driver
19/07/31 01:13:15 INFO TaskSetManager: Finished task 0.0 in stage 171.0 (TID 315) in 128 ms on localhost (executor driver) (1/1)
19/07/31 01:13:15 INFO TaskSchedulerImpl: Removed TaskSet 171.0, whose tasks have all completed, from pool 
19/07/31 01:13:15 INFO DAGScheduler: ShuffleMapStage 171 (sql at <unknown>:0) finished in 0.128 s
19/07/31 01:13:15 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:13:15 INFO DAGScheduler: running: Set()
19/07/31 01:13:15 INFO DAGScheduler: waiting: Set(ResultStage 172)
19/07/31 01:13:15 INFO DAGScheduler: failed: Set()
19/07/31 01:13:15 INFO DAGScheduler: Submitting ResultStage 172 (MapPartitionsRDD[552] at sql at <unknown>:0), which has no missing parents
19/07/31 01:13:15 INFO MemoryStore: Block broadcast_175 stored as values in memory (estimated size 7.0 KB, free 911.6 MB)
19/07/31 01:13:15 INFO MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.6 MB)
19/07/31 01:13:15 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 912.1 MB)
19/07/31 01:13:15 INFO SparkContext: Created broadcast 175 from broadcast at DAGScheduler.scala:1006
19/07/31 01:13:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 172 (MapPartitionsRDD[552] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 01:13:15 INFO TaskSchedulerImpl: Adding task set 172.0 with 1 tasks
19/07/31 01:13:15 INFO TaskSetManager: Starting task 0.0 in stage 172.0 (TID 316, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:13:15 INFO Executor: Running task 0.0 in stage 172.0 (TID 316)
19/07/31 01:13:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:13:15 INFO Executor: Finished task 0.0 in stage 172.0 (TID 316). 1538 bytes result sent to driver
19/07/31 01:13:15 INFO TaskSetManager: Finished task 0.0 in stage 172.0 (TID 316) in 3 ms on localhost (executor driver) (1/1)
19/07/31 01:13:15 INFO TaskSchedulerImpl: Removed TaskSet 172.0, whose tasks have all completed, from pool 
19/07/31 01:13:15 INFO DAGScheduler: ResultStage 172 (sql at <unknown>:0) finished in 0.003 s
19/07/31 01:13:15 INFO DAGScheduler: Job 119 finished: sql at <unknown>:0, took 0.149325 s
19/07/31 01:13:15 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `test`
19/07/31 01:13:15 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:13:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:13:15 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:13:15 INFO DAGScheduler: Registering RDD 555 (collect at utils.scala:204)
19/07/31 01:13:15 INFO DAGScheduler: Got job 120 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:13:15 INFO DAGScheduler: Final stage: ResultStage 174 (collect at utils.scala:204)
19/07/31 01:13:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 173)
19/07/31 01:13:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 173)
19/07/31 01:13:15 INFO DAGScheduler: Submitting ShuffleMapStage 173 (MapPartitionsRDD[555] at collect at utils.scala:204), which has no missing parents
19/07/31 01:13:15 INFO MemoryStore: Block broadcast_176 stored as values in memory (estimated size 28.2 KB, free 911.6 MB)
19/07/31 01:13:15 INFO MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 10.9 KB, free 911.6 MB)
19/07/31 01:13:15 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on 127.0.0.1:53873 (size: 10.9 KB, free: 912.1 MB)
19/07/31 01:13:15 INFO SparkContext: Created broadcast 176 from broadcast at DAGScheduler.scala:1006
19/07/31 01:13:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 173 (MapPartitionsRDD[555] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:13:15 INFO TaskSchedulerImpl: Adding task set 173.0 with 1 tasks
19/07/31 01:13:15 INFO TaskSetManager: Starting task 0.0 in stage 173.0 (TID 317, localhost, executor driver, partition 0, PROCESS_LOCAL, 14768 bytes)
19/07/31 01:13:15 INFO Executor: Running task 0.0 in stage 173.0 (TID 317)
19/07/31 01:13:15 INFO BlockManager: Found block rdd_546_0 locally
19/07/31 01:13:15 INFO Executor: Finished task 0.0 in stage 173.0 (TID 317). 1690 bytes result sent to driver
19/07/31 01:13:15 INFO TaskSetManager: Finished task 0.0 in stage 173.0 (TID 317) in 6 ms on localhost (executor driver) (1/1)
19/07/31 01:13:15 INFO TaskSchedulerImpl: Removed TaskSet 173.0, whose tasks have all completed, from pool 
19/07/31 01:13:15 INFO DAGScheduler: ShuffleMapStage 173 (collect at utils.scala:204) finished in 0.006 s
19/07/31 01:13:15 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:13:15 INFO DAGScheduler: running: Set()
19/07/31 01:13:15 INFO DAGScheduler: waiting: Set(ResultStage 174)
19/07/31 01:13:15 INFO DAGScheduler: failed: Set()
19/07/31 01:13:15 INFO DAGScheduler: Submitting ResultStage 174 (MapPartitionsRDD[558] at collect at utils.scala:204), which has no missing parents
19/07/31 01:13:15 INFO MemoryStore: Block broadcast_177 stored as values in memory (estimated size 7.0 KB, free 911.5 MB)
19/07/31 01:13:15 INFO MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.5 MB)
19/07/31 01:13:15 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 912.1 MB)
19/07/31 01:13:15 INFO SparkContext: Created broadcast 177 from broadcast at DAGScheduler.scala:1006
19/07/31 01:13:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 174 (MapPartitionsRDD[558] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:13:15 INFO TaskSchedulerImpl: Adding task set 174.0 with 1 tasks
19/07/31 01:13:15 INFO TaskSetManager: Starting task 0.0 in stage 174.0 (TID 318, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:13:15 INFO Executor: Running task 0.0 in stage 174.0 (TID 318)
19/07/31 01:13:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:13:15 INFO Executor: Finished task 0.0 in stage 174.0 (TID 318). 1581 bytes result sent to driver
19/07/31 01:13:15 INFO TaskSetManager: Finished task 0.0 in stage 174.0 (TID 318) in 3 ms on localhost (executor driver) (1/1)
19/07/31 01:13:15 INFO TaskSchedulerImpl: Removed TaskSet 174.0, whose tasks have all completed, from pool 
19/07/31 01:13:15 INFO DAGScheduler: ResultStage 174 (collect at utils.scala:204) finished in 0.004 s
19/07/31 01:13:15 INFO DAGScheduler: Job 120 finished: collect at utils.scala:204, took 0.026141 s
19/07/31 01:13:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test` AS `zzz11`
WHERE (0 = 1)
19/07/31 01:13:15 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 01:13:15 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:13:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:13:15 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:13:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:13:15 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 01:13:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 01:13:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
19/07/31 01:13:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
LIMIT 1000
19/07/31 01:13:16 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:13:16 INFO DAGScheduler: Got job 121 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:13:16 INFO DAGScheduler: Final stage: ResultStage 175 (collect at utils.scala:204)
19/07/31 01:13:16 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:13:16 INFO DAGScheduler: Missing parents: List()
19/07/31 01:13:16 INFO DAGScheduler: Submitting ResultStage 175 (MapPartitionsRDD[560] at collect at utils.scala:204), which has no missing parents
19/07/31 01:13:16 INFO MemoryStore: Block broadcast_178 stored as values in memory (estimated size 23.9 KB, free 911.5 MB)
19/07/31 01:13:16 INFO MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 8.9 KB, free 911.5 MB)
19/07/31 01:13:16 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on 127.0.0.1:53873 (size: 8.9 KB, free: 912.1 MB)
19/07/31 01:13:16 INFO SparkContext: Created broadcast 178 from broadcast at DAGScheduler.scala:1006
19/07/31 01:13:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 175 (MapPartitionsRDD[560] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:13:16 INFO TaskSchedulerImpl: Adding task set 175.0 with 1 tasks
19/07/31 01:13:16 INFO TaskSetManager: Starting task 0.0 in stage 175.0 (TID 319, localhost, executor driver, partition 0, PROCESS_LOCAL, 14779 bytes)
19/07/31 01:13:16 INFO Executor: Running task 0.0 in stage 175.0 (TID 319)
19/07/31 01:13:16 INFO BlockManager: Found block rdd_546_0 locally
19/07/31 01:13:16 INFO CodeGenerator: Code generated in 22.709933 ms
19/07/31 01:13:16 INFO Executor: Finished task 0.0 in stage 175.0 (TID 319). 5410 bytes result sent to driver
19/07/31 01:13:16 INFO TaskSetManager: Finished task 0.0 in stage 175.0 (TID 319) in 31 ms on localhost (executor driver) (1/1)
19/07/31 01:13:16 INFO TaskSchedulerImpl: Removed TaskSet 175.0, whose tasks have all completed, from pool 
19/07/31 01:13:16 INFO DAGScheduler: ResultStage 175 (collect at utils.scala:204) finished in 0.031 s
19/07/31 01:13:16 INFO DAGScheduler: Job 121 finished: collect at utils.scala:204, took 0.039552 s
19/07/31 01:13:16 INFO CodeGenerator: Code generated in 14.770403 ms
19/07/31 01:13:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `test`
19/07/31 01:13:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 01:13:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 01:13:19 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 01:13:19 INFO DAGScheduler: Got job 122 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 01:13:19 INFO DAGScheduler: Final stage: ResultStage 176 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 01:13:19 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:13:19 INFO DAGScheduler: Missing parents: List()
19/07/31 01:13:19 INFO DAGScheduler: Submitting ResultStage 176 (MapPartitionsRDD[561] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 01:13:19 INFO MemoryStore: Block broadcast_179 stored as values in memory (estimated size 99.2 KB, free 911.4 MB)
19/07/31 01:13:19 INFO MemoryStore: Block broadcast_179_piece0 stored as bytes in memory (estimated size 37.2 KB, free 911.4 MB)
19/07/31 01:13:19 INFO BlockManagerInfo: Added broadcast_179_piece0 in memory on 127.0.0.1:53873 (size: 37.2 KB, free: 912.1 MB)
19/07/31 01:13:19 INFO SparkContext: Created broadcast 179 from broadcast at DAGScheduler.scala:1006
19/07/31 01:13:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 176 (MapPartitionsRDD[561] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 01:13:19 INFO TaskSchedulerImpl: Adding task set 176.0 with 1 tasks
19/07/31 01:13:19 INFO TaskSetManager: Starting task 0.0 in stage 176.0 (TID 320, localhost, executor driver, partition 0, PROCESS_LOCAL, 14779 bytes)
19/07/31 01:13:19 INFO Executor: Running task 0.0 in stage 176.0 (TID 320)
19/07/31 01:13:19 INFO BlockManager: Found block rdd_546_0 locally
19/07/31 01:13:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 01:13:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 01:13:19 INFO FileOutputCommitter: Saved output of task 'attempt_20190731011319_0176_m_000000_0' to file:/Users/6jncnk4f/Desktop/anomaly/result/_temporary/0/task_20190731011319_0176_m_000000
19/07/31 01:13:19 INFO SparkHadoopMapRedUtil: attempt_20190731011319_0176_m_000000_0: Committed
19/07/31 01:13:19 INFO Executor: Finished task 0.0 in stage 176.0 (TID 320). 1576 bytes result sent to driver
19/07/31 01:13:19 INFO TaskSetManager: Finished task 0.0 in stage 176.0 (TID 320) in 33 ms on localhost (executor driver) (1/1)
19/07/31 01:13:19 INFO TaskSchedulerImpl: Removed TaskSet 176.0, whose tasks have all completed, from pool 
19/07/31 01:13:19 INFO DAGScheduler: ResultStage 176 (csv at NativeMethodAccessorImpl.java:0) finished in 0.033 s
19/07/31 01:13:19 INFO DAGScheduler: Job 122 finished: csv at NativeMethodAccessorImpl.java:0, took 0.058817 s
19/07/31 01:13:19 INFO FileFormatWriter: Job null committed.
19/07/31 01:17:58 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 01:17:58 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:17:58 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:17:58 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:17:58 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:17:58 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 01:17:58 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 01:17:58 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 01:17:58 INFO DAGScheduler: Got job 123 (collect at utils.scala:44) with 4 output partitions
19/07/31 01:17:58 INFO DAGScheduler: Final stage: ResultStage 177 (collect at utils.scala:44)
19/07/31 01:17:58 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:17:58 INFO DAGScheduler: Missing parents: List()
19/07/31 01:17:58 INFO DAGScheduler: Submitting ResultStage 177 (MapPartitionsRDD[568] at map at utils.scala:41), which has no missing parents
19/07/31 01:17:58 INFO MemoryStore: Block broadcast_180 stored as values in memory (estimated size 7.1 KB, free 911.4 MB)
19/07/31 01:17:58 INFO MemoryStore: Block broadcast_180_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.4 MB)
19/07/31 01:17:58 INFO BlockManagerInfo: Added broadcast_180_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 912.1 MB)
19/07/31 01:17:58 INFO SparkContext: Created broadcast 180 from broadcast at DAGScheduler.scala:1006
19/07/31 01:17:58 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 177 (MapPartitionsRDD[568] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:17:58 INFO TaskSchedulerImpl: Adding task set 177.0 with 4 tasks
19/07/31 01:17:58 INFO TaskSetManager: Starting task 0.0 in stage 177.0 (TID 321, localhost, executor driver, partition 0, PROCESS_LOCAL, 5108 bytes)
19/07/31 01:17:58 INFO TaskSetManager: Starting task 1.0 in stage 177.0 (TID 322, localhost, executor driver, partition 1, PROCESS_LOCAL, 5100 bytes)
19/07/31 01:17:58 INFO TaskSetManager: Starting task 2.0 in stage 177.0 (TID 323, localhost, executor driver, partition 2, PROCESS_LOCAL, 5100 bytes)
19/07/31 01:17:58 INFO TaskSetManager: Starting task 3.0 in stage 177.0 (TID 324, localhost, executor driver, partition 3, PROCESS_LOCAL, 5076 bytes)
19/07/31 01:17:58 INFO Executor: Running task 0.0 in stage 177.0 (TID 321)
19/07/31 01:17:58 INFO Executor: Running task 1.0 in stage 177.0 (TID 322)
19/07/31 01:17:58 INFO Executor: Running task 3.0 in stage 177.0 (TID 324)
19/07/31 01:17:58 INFO Executor: Running task 2.0 in stage 177.0 (TID 323)
19/07/31 01:17:58 INFO Executor: Finished task 2.0 in stage 177.0 (TID 323). 1026 bytes result sent to driver
19/07/31 01:17:58 INFO Executor: Finished task 0.0 in stage 177.0 (TID 321). 1035 bytes result sent to driver
19/07/31 01:17:58 INFO Executor: Finished task 1.0 in stage 177.0 (TID 322). 1026 bytes result sent to driver
19/07/31 01:17:58 INFO Executor: Finished task 3.0 in stage 177.0 (TID 324). 1005 bytes result sent to driver
19/07/31 01:17:58 INFO TaskSetManager: Finished task 2.0 in stage 177.0 (TID 323) in 6 ms on localhost (executor driver) (1/4)
19/07/31 01:17:58 INFO TaskSetManager: Finished task 1.0 in stage 177.0 (TID 322) in 7 ms on localhost (executor driver) (2/4)
19/07/31 01:17:58 INFO TaskSetManager: Finished task 0.0 in stage 177.0 (TID 321) in 7 ms on localhost (executor driver) (3/4)
19/07/31 01:17:58 INFO TaskSetManager: Finished task 3.0 in stage 177.0 (TID 324) in 7 ms on localhost (executor driver) (4/4)
19/07/31 01:17:58 INFO TaskSchedulerImpl: Removed TaskSet 177.0, whose tasks have all completed, from pool 
19/07/31 01:17:58 INFO DAGScheduler: ResultStage 177 (collect at utils.scala:44) finished in 0.007 s
19/07/31 01:17:58 INFO DAGScheduler: Job 123 finished: collect at utils.scala:44, took 0.019423 s
19/07/31 01:17:58 INFO SparkSqlParser: Parsing command: result
19/07/31 01:17:58 INFO SparkSqlParser: Parsing command: CACHE TABLE `result`
19/07/31 01:17:58 INFO SparkSqlParser: Parsing command: `result`
19/07/31 01:17:58 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 01:17:58 INFO DAGScheduler: Registering RDD 576 (sql at <unknown>:0)
19/07/31 01:17:58 INFO DAGScheduler: Got job 124 (sql at <unknown>:0) with 1 output partitions
19/07/31 01:17:58 INFO DAGScheduler: Final stage: ResultStage 179 (sql at <unknown>:0)
19/07/31 01:17:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 178)
19/07/31 01:17:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 178)
19/07/31 01:17:58 INFO DAGScheduler: Submitting ShuffleMapStage 178 (MapPartitionsRDD[576] at sql at <unknown>:0), which has no missing parents
19/07/31 01:17:58 INFO MemoryStore: Block broadcast_181 stored as values in memory (estimated size 28.2 KB, free 911.3 MB)
19/07/31 01:17:58 INFO MemoryStore: Block broadcast_181_piece0 stored as bytes in memory (estimated size 10.9 KB, free 911.3 MB)
19/07/31 01:17:58 INFO BlockManagerInfo: Added broadcast_181_piece0 in memory on 127.0.0.1:53873 (size: 10.9 KB, free: 912.0 MB)
19/07/31 01:17:58 INFO SparkContext: Created broadcast 181 from broadcast at DAGScheduler.scala:1006
19/07/31 01:17:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 178 (MapPartitionsRDD[576] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 01:17:58 INFO TaskSchedulerImpl: Adding task set 178.0 with 1 tasks
19/07/31 01:17:58 INFO TaskSetManager: Starting task 0.0 in stage 178.0 (TID 325, localhost, executor driver, partition 0, PROCESS_LOCAL, 46876 bytes)
19/07/31 01:17:58 INFO Executor: Running task 0.0 in stage 178.0 (TID 325)
19/07/31 01:17:58 INFO MemoryStore: Block rdd_573_0 stored as values in memory (estimated size 28.5 KB, free 911.3 MB)
19/07/31 01:17:58 INFO BlockManagerInfo: Added rdd_573_0 in memory on 127.0.0.1:53873 (size: 28.5 KB, free: 912.0 MB)
19/07/31 01:17:58 INFO Executor: Finished task 0.0 in stage 178.0 (TID 325). 2328 bytes result sent to driver
19/07/31 01:17:58 INFO TaskSetManager: Finished task 0.0 in stage 178.0 (TID 325) in 56 ms on localhost (executor driver) (1/1)
19/07/31 01:17:58 INFO TaskSchedulerImpl: Removed TaskSet 178.0, whose tasks have all completed, from pool 
19/07/31 01:17:58 INFO DAGScheduler: ShuffleMapStage 178 (sql at <unknown>:0) finished in 0.057 s
19/07/31 01:17:58 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:17:58 INFO DAGScheduler: running: Set()
19/07/31 01:17:58 INFO DAGScheduler: waiting: Set(ResultStage 179)
19/07/31 01:17:58 INFO DAGScheduler: failed: Set()
19/07/31 01:17:58 INFO DAGScheduler: Submitting ResultStage 179 (MapPartitionsRDD[579] at sql at <unknown>:0), which has no missing parents
19/07/31 01:17:58 INFO MemoryStore: Block broadcast_182 stored as values in memory (estimated size 7.0 KB, free 911.3 MB)
19/07/31 01:17:58 INFO MemoryStore: Block broadcast_182_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.3 MB)
19/07/31 01:17:58 INFO BlockManagerInfo: Added broadcast_182_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 912.0 MB)
19/07/31 01:17:58 INFO SparkContext: Created broadcast 182 from broadcast at DAGScheduler.scala:1006
19/07/31 01:17:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 179 (MapPartitionsRDD[579] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 01:17:58 INFO TaskSchedulerImpl: Adding task set 179.0 with 1 tasks
19/07/31 01:17:58 INFO TaskSetManager: Starting task 0.0 in stage 179.0 (TID 326, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:17:58 INFO Executor: Running task 0.0 in stage 179.0 (TID 326)
19/07/31 01:17:58 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:17:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:17:58 INFO Executor: Finished task 0.0 in stage 179.0 (TID 326). 1538 bytes result sent to driver
19/07/31 01:17:58 INFO TaskSetManager: Finished task 0.0 in stage 179.0 (TID 326) in 4 ms on localhost (executor driver) (1/1)
19/07/31 01:17:58 INFO TaskSchedulerImpl: Removed TaskSet 179.0, whose tasks have all completed, from pool 
19/07/31 01:17:58 INFO DAGScheduler: ResultStage 179 (sql at <unknown>:0) finished in 0.005 s
19/07/31 01:17:58 INFO DAGScheduler: Job 124 finished: sql at <unknown>:0, took 0.080119 s
19/07/31 01:17:58 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `result`
19/07/31 01:17:58 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:17:58 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:17:58 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:17:58 INFO DAGScheduler: Registering RDD 582 (collect at utils.scala:204)
19/07/31 01:17:58 INFO DAGScheduler: Got job 125 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:17:58 INFO DAGScheduler: Final stage: ResultStage 181 (collect at utils.scala:204)
19/07/31 01:17:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 180)
19/07/31 01:17:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 180)
19/07/31 01:17:58 INFO DAGScheduler: Submitting ShuffleMapStage 180 (MapPartitionsRDD[582] at collect at utils.scala:204), which has no missing parents
19/07/31 01:17:58 INFO MemoryStore: Block broadcast_183 stored as values in memory (estimated size 28.2 KB, free 911.3 MB)
19/07/31 01:17:58 INFO MemoryStore: Block broadcast_183_piece0 stored as bytes in memory (estimated size 10.9 KB, free 911.3 MB)
19/07/31 01:17:58 INFO BlockManagerInfo: Added broadcast_183_piece0 in memory on 127.0.0.1:53873 (size: 10.9 KB, free: 912.0 MB)
19/07/31 01:17:58 INFO SparkContext: Created broadcast 183 from broadcast at DAGScheduler.scala:1006
19/07/31 01:17:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 180 (MapPartitionsRDD[582] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:17:58 INFO TaskSchedulerImpl: Adding task set 180.0 with 1 tasks
19/07/31 01:17:58 INFO TaskSetManager: Starting task 0.0 in stage 180.0 (TID 327, localhost, executor driver, partition 0, PROCESS_LOCAL, 46876 bytes)
19/07/31 01:17:58 INFO Executor: Running task 0.0 in stage 180.0 (TID 327)
19/07/31 01:17:58 INFO BlockManager: Found block rdd_573_0 locally
19/07/31 01:17:58 INFO Executor: Finished task 0.0 in stage 180.0 (TID 327). 1690 bytes result sent to driver
19/07/31 01:17:58 INFO TaskSetManager: Finished task 0.0 in stage 180.0 (TID 327) in 6 ms on localhost (executor driver) (1/1)
19/07/31 01:17:58 INFO TaskSchedulerImpl: Removed TaskSet 180.0, whose tasks have all completed, from pool 
19/07/31 01:17:58 INFO DAGScheduler: ShuffleMapStage 180 (collect at utils.scala:204) finished in 0.007 s
19/07/31 01:17:58 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:17:58 INFO DAGScheduler: running: Set()
19/07/31 01:17:58 INFO DAGScheduler: waiting: Set(ResultStage 181)
19/07/31 01:17:58 INFO DAGScheduler: failed: Set()
19/07/31 01:17:58 INFO DAGScheduler: Submitting ResultStage 181 (MapPartitionsRDD[585] at collect at utils.scala:204), which has no missing parents
19/07/31 01:17:58 INFO MemoryStore: Block broadcast_184 stored as values in memory (estimated size 7.0 KB, free 911.2 MB)
19/07/31 01:17:58 INFO MemoryStore: Block broadcast_184_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.2 MB)
19/07/31 01:17:58 INFO BlockManagerInfo: Added broadcast_184_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 912.0 MB)
19/07/31 01:17:58 INFO SparkContext: Created broadcast 184 from broadcast at DAGScheduler.scala:1006
19/07/31 01:17:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 181 (MapPartitionsRDD[585] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:17:58 INFO TaskSchedulerImpl: Adding task set 181.0 with 1 tasks
19/07/31 01:17:58 INFO TaskSetManager: Starting task 0.0 in stage 181.0 (TID 328, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:17:58 INFO Executor: Running task 0.0 in stage 181.0 (TID 328)
19/07/31 01:17:58 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:17:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:17:58 INFO Executor: Finished task 0.0 in stage 181.0 (TID 328). 1538 bytes result sent to driver
19/07/31 01:17:58 INFO TaskSetManager: Finished task 0.0 in stage 181.0 (TID 328) in 3 ms on localhost (executor driver) (1/1)
19/07/31 01:17:58 INFO TaskSchedulerImpl: Removed TaskSet 181.0, whose tasks have all completed, from pool 
19/07/31 01:17:58 INFO DAGScheduler: ResultStage 181 (collect at utils.scala:204) finished in 0.003 s
19/07/31 01:17:58 INFO DAGScheduler: Job 125 finished: collect at utils.scala:204, took 0.032641 s
19/07/31 01:17:58 INFO SparkSqlParser: Parsing command: SELECT *
FROM `result` AS `zzz12`
WHERE (0 = 1)
19/07/31 01:17:58 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 01:17:58 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:17:58 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:17:59 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:17:59 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:17:59 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 01:17:59 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 01:18:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `result`
19/07/31 01:18:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 01:18:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 01:18:09 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 01:18:09 INFO DAGScheduler: Got job 126 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 01:18:09 INFO DAGScheduler: Final stage: ResultStage 182 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 01:18:09 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:18:09 INFO DAGScheduler: Missing parents: List()
19/07/31 01:18:09 INFO DAGScheduler: Submitting ResultStage 182 (MapPartitionsRDD[586] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 01:18:09 INFO MemoryStore: Block broadcast_185 stored as values in memory (estimated size 99.2 KB, free 911.1 MB)
19/07/31 01:18:09 INFO MemoryStore: Block broadcast_185_piece0 stored as bytes in memory (estimated size 37.2 KB, free 911.1 MB)
19/07/31 01:18:09 INFO BlockManagerInfo: Added broadcast_185_piece0 in memory on 127.0.0.1:53873 (size: 37.2 KB, free: 912.0 MB)
19/07/31 01:18:09 INFO SparkContext: Created broadcast 185 from broadcast at DAGScheduler.scala:1006
19/07/31 01:18:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 182 (MapPartitionsRDD[586] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 01:18:09 INFO TaskSchedulerImpl: Adding task set 182.0 with 1 tasks
19/07/31 01:18:09 INFO TaskSetManager: Starting task 0.0 in stage 182.0 (TID 329, localhost, executor driver, partition 0, PROCESS_LOCAL, 46887 bytes)
19/07/31 01:18:09 INFO Executor: Running task 0.0 in stage 182.0 (TID 329)
19/07/31 01:18:09 INFO BlockManager: Found block rdd_573_0 locally
19/07/31 01:18:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 01:18:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 01:18:09 INFO FileOutputCommitter: Saved output of task 'attempt_20190731011809_0182_m_000000_0' to file:/Users/6jncnk4f/Desktop/anomaly/result/_temporary/0/task_20190731011809_0182_m_000000
19/07/31 01:18:09 INFO SparkHadoopMapRedUtil: attempt_20190731011809_0182_m_000000_0: Committed
19/07/31 01:18:09 INFO Executor: Finished task 0.0 in stage 182.0 (TID 329). 1576 bytes result sent to driver
19/07/31 01:18:09 INFO TaskSetManager: Finished task 0.0 in stage 182.0 (TID 329) in 81 ms on localhost (executor driver) (1/1)
19/07/31 01:18:09 INFO TaskSchedulerImpl: Removed TaskSet 182.0, whose tasks have all completed, from pool 
19/07/31 01:18:09 INFO DAGScheduler: ResultStage 182 (csv at NativeMethodAccessorImpl.java:0) finished in 0.081 s
19/07/31 01:18:09 INFO DAGScheduler: Job 126 finished: csv at NativeMethodAccessorImpl.java:0, took 0.100395 s
19/07/31 01:18:09 INFO FileFormatWriter: Job null committed.
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4521
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1648
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1834
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1646
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1242
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1831
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 3455
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 586
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 3091
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4519
19/07/31 01:19:03 INFO ContextCleaner: Cleaned shuffle 19
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4798
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4686
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4883
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4848
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4678
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4746
19/07/31 01:19:03 INFO BlockManagerInfo: Removed broadcast_176_piece0 on 127.0.0.1:53873 in memory (size: 10.9 KB, free: 912.0 MB)
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4885
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4747
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4739
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4744
19/07/31 01:19:03 INFO BlockManagerInfo: Removed broadcast_180_piece0 on 127.0.0.1:53873 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4741
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4875
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4938
19/07/31 01:19:03 INFO ContextCleaner: Cleaned shuffle 54
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4742
19/07/31 01:19:03 INFO BlockManagerInfo: Removed broadcast_177_piece0 on 127.0.0.1:53873 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4943
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4680
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4879
19/07/31 01:19:03 INFO BlockManagerInfo: Removed broadcast_178_piece0 on 127.0.0.1:53873 in memory (size: 8.9 KB, free: 912.0 MB)
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4738
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4679
19/07/31 01:19:03 INFO BlockManagerInfo: Removed broadcast_185_piece0 on 127.0.0.1:53873 in memory (size: 37.2 KB, free: 912.0 MB)
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4941
19/07/31 01:19:03 INFO BlockManagerInfo: Removed broadcast_182_piece0 on 127.0.0.1:53873 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4877
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4677
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4681
19/07/31 01:19:03 INFO BlockManagerInfo: Removed broadcast_171_piece0 on 127.0.0.1:53873 in memory (size: 8.9 KB, free: 912.0 MB)
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4740
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4685
19/07/31 01:19:03 INFO BlockManagerInfo: Removed broadcast_172_piece0 on 127.0.0.1:53873 in memory (size: 37.2 KB, free: 912.1 MB)
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4876
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4682
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4743
19/07/31 01:19:03 INFO BlockManagerInfo: Removed broadcast_179_piece0 on 127.0.0.1:53873 in memory (size: 37.2 KB, free: 912.1 MB)
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4886
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4687
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4649
19/07/31 01:19:03 INFO BlockManagerInfo: Removed broadcast_183_piece0 on 127.0.0.1:53873 in memory (size: 10.9 KB, free: 912.1 MB)
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4880
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4683
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4684
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4884
19/07/31 01:19:03 INFO BlockManagerInfo: Removed broadcast_184_piece0 on 127.0.0.1:53873 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4745
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4748
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4823
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4688
19/07/31 01:19:03 INFO BlockManagerInfo: Removed broadcast_181_piece0 on 127.0.0.1:53873 in memory (size: 10.9 KB, free: 912.1 MB)
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4936
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4937
19/07/31 01:19:03 INFO BlockManagerInfo: Removed broadcast_175_piece0 on 127.0.0.1:53873 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4947
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4948
19/07/31 01:19:03 INFO ContextCleaner: Cleaned shuffle 55
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4676
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4940
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4942
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4624
19/07/31 01:19:03 INFO ContextCleaner: Cleaned shuffle 53
19/07/31 01:19:03 INFO BlockManagerInfo: Removed broadcast_170_piece0 on 127.0.0.1:53873 in memory (size: 8.1 KB, free: 912.1 MB)
19/07/31 01:19:03 INFO ContextCleaner: Cleaned shuffle 52
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4882
19/07/31 01:19:03 INFO BlockManagerInfo: Removed broadcast_173_piece0 on 127.0.0.1:53873 in memory (size: 3.7 KB, free: 912.2 MB)
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4878
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4939
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4997
19/07/31 01:19:03 INFO BlockManagerInfo: Removed broadcast_174_piece0 on 127.0.0.1:53873 in memory (size: 10.9 KB, free: 912.2 MB)
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4945
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4749
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4881
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4737
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4887
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4946
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4944
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1323
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1243
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1327
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 3458
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1651
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 2395
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1329
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1828
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1325
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1652
19/07/31 01:19:03 INFO ContextCleaner: Cleaned shuffle 18
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 3092
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1827
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 2400
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 2399
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 2397
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 2396
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1328
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1244
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1241
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1833
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1248
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 2398
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4522
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1245
19/07/31 01:19:03 INFO ContextCleaner: Cleaned shuffle 13
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 3456
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 3457
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 3460
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1829
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1649
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4524
19/07/31 01:19:03 INFO BlockManager: Removing RDD 359
19/07/31 01:19:03 INFO ContextCleaner: Cleaned RDD 359
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 585
19/07/31 01:19:03 INFO BlockManagerInfo: Removed broadcast_169_piece0 on 127.0.0.1:53873 in memory (size: 31.8 KB, free: 912.2 MB)
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4523
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 3459
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1246
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 2394
19/07/31 01:19:03 INFO ContextCleaner: Cleaned shuffle 14
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 3461
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4520
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 2401
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1326
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1830
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1650
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1647
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4525
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 3454
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1832
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1653
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1247
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1324
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 1322
19/07/31 01:19:03 INFO ContextCleaner: Cleaned accumulator 4526
19/07/31 01:19:03 INFO ContextCleaner: Cleaned shuffle 51
19/07/31 01:19:03 INFO BlockManager: Removing RDD 73
19/07/31 01:19:03 INFO ContextCleaner: Cleaned RDD 73
19/07/31 01:43:03 INFO SparkContext: Running Spark version 2.2.0
19/07/31 01:43:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/07/31 01:43:04 INFO SparkContext: Submitted application: sparklyr
19/07/31 01:43:04 INFO SecurityManager: Changing view acls to: 6jncnk4f
19/07/31 01:43:04 INFO SecurityManager: Changing modify acls to: 6jncnk4f
19/07/31 01:43:04 INFO SecurityManager: Changing view acls groups to: 
19/07/31 01:43:04 INFO SecurityManager: Changing modify acls groups to: 
19/07/31 01:43:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(6jncnk4f); groups with view permissions: Set(); users  with modify permissions: Set(6jncnk4f); groups with modify permissions: Set()
19/07/31 01:43:04 INFO Utils: Successfully started service 'sparkDriver' on port 57857.
19/07/31 01:43:04 INFO SparkEnv: Registering MapOutputTracker
19/07/31 01:43:04 INFO SparkEnv: Registering BlockManagerMaster
19/07/31 01:43:04 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/07/31 01:43:04 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/07/31 01:43:04 INFO DiskBlockManager: Created local directory at /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/blockmgr-8e454c44-9f46-4aa3-9f98-40ffb6723f19
19/07/31 01:43:04 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/07/31 01:43:04 INFO SparkEnv: Registering OutputCommitCoordinator
19/07/31 01:43:04 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/07/31 01:43:04 INFO Utils: Successfully started service 'SparkUI' on port 4041.
19/07/31 01:43:04 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
19/07/31 01:43:04 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:57857/jars/sparklyr-2.0-2.11.jar with timestamp 1564551784658
19/07/31 01:43:04 INFO Executor: Starting executor ID driver on host localhost
19/07/31 01:43:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57861.
19/07/31 01:43:04 INFO NettyBlockTransferService: Server created on 127.0.0.1:57861
19/07/31 01:43:04 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/07/31 01:43:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 57861, None)
19/07/31 01:43:04 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:57861 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 57861, None)
19/07/31 01:43:04 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 57861, None)
19/07/31 01:43:04 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 57861, None)
19/07/31 01:43:04 INFO SharedState: loading hive config file: file:/Users/6jncnk4f/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/07/31 01:43:04 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse').
19/07/31 01:43:04 INFO SharedState: Warehouse path is 'file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse'.
19/07/31 01:43:05 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/07/31 01:43:06 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/07/31 01:43:06 INFO ObjectStore: ObjectStore, initialize called
19/07/31 01:43:06 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/07/31 01:43:06 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/07/31 01:43:07 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/07/31 01:43:08 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 01:43:08 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 01:43:08 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 01:43:08 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 01:43:09 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/07/31 01:43:09 INFO ObjectStore: Initialized ObjectStore
19/07/31 01:43:09 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/07/31 01:43:09 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/07/31 01:43:09 INFO HiveMetaStore: Added admin role in metastore
19/07/31 01:43:09 INFO HiveMetaStore: Added public role in metastore
19/07/31 01:43:09 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/07/31 01:43:09 INFO HiveMetaStore: 0: get_all_databases
19/07/31 01:43:09 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_all_databases	
19/07/31 01:43:09 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/07/31 01:43:09 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/07/31 01:43:09 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 01:43:09 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/975ab39a-aa50-43f5-a525-12c809294dde_resources
19/07/31 01:43:09 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/975ab39a-aa50-43f5-a525-12c809294dde
19/07/31 01:43:09 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/975ab39a-aa50-43f5-a525-12c809294dde
19/07/31 01:43:09 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/975ab39a-aa50-43f5-a525-12c809294dde/_tmp_space.db
19/07/31 01:43:09 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 01:43:09 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:43:09 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:43:09 INFO HiveMetaStore: 0: get_database: global_temp
19/07/31 01:43:09 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/07/31 01:43:09 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/07/31 01:43:09 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/ad75cca9-1614-4ef5-96bd-964ec4347146_resources
19/07/31 01:43:10 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/ad75cca9-1614-4ef5-96bd-964ec4347146
19/07/31 01:43:10 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/ad75cca9-1614-4ef5-96bd-964ec4347146
19/07/31 01:43:10 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/ad75cca9-1614-4ef5-96bd-964ec4347146/_tmp_space.db
19/07/31 01:43:10 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 01:43:10 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/07/31 01:43:10 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 01:43:11 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:43:11 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:43:11 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:43:11 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:43:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 01:43:11 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 01:43:12 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 01:43:12 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/07/31 01:43:12 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/07/31 01:43:12 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:43:12 INFO DAGScheduler: Missing parents: List()
19/07/31 01:43:12 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/07/31 01:43:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/07/31 01:43:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/07/31 01:43:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:57861 (size: 3.4 KB, free: 912.3 MB)
19/07/31 01:43:12 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/07/31 01:43:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 01:43:12 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/07/31 01:43:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/07/31 01:43:12 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/07/31 01:43:12 INFO Executor: Fetching spark://127.0.0.1:57857/jars/sparklyr-2.0-2.11.jar with timestamp 1564551784658
19/07/31 01:43:12 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:57857 after 12 ms (0 ms spent in bootstraps)
19/07/31 01:43:12 INFO Utils: Fetching spark://127.0.0.1:57857/jars/sparklyr-2.0-2.11.jar to /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-6d54ad23-6bb5-4afc-a595-766c035136d6/userFiles-8a7f7ded-8f79-4590-982e-0b13916f2060/fetchFileTemp7143269392580398471.tmp
19/07/31 01:43:12 INFO Executor: Adding file:/private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-6d54ad23-6bb5-4afc-a595-766c035136d6/userFiles-8a7f7ded-8f79-4590-982e-0b13916f2060/sparklyr-2.0-2.11.jar to class loader
19/07/31 01:43:12 INFO CodeGenerator: Code generated in 247.580708 ms
19/07/31 01:43:12 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
19/07/31 01:43:12 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 609 ms on localhost (executor driver) (1/1)
19/07/31 01:43:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/07/31 01:43:12 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.629 s
19/07/31 01:43:12 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0.753955 s
19/07/31 01:43:13 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 01:43:13 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#10)) > 0)
19/07/31 01:43:13 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 01:43:13 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 01:43:13 INFO CodeGenerator: Code generated in 13.737983 ms
19/07/31 01:43:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 281.2 KB, free 912.0 MB)
19/07/31 01:43:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.8 KB, free 912.0 MB)
19/07/31 01:43:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:57861 (size: 23.8 KB, free: 912.3 MB)
19/07/31 01:43:13 INFO SparkContext: Created broadcast 1 from csv at NativeMethodAccessorImpl.java:0
19/07/31 01:43:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 01:43:13 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 01:43:13 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 01:43:13 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 01:43:13 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:43:13 INFO DAGScheduler: Missing parents: List()
19/07/31 01:43:13 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 01:43:13 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 912.0 MB)
19/07/31 01:43:13 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 912.0 MB)
19/07/31 01:43:13 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:57861 (size: 4.3 KB, free: 912.3 MB)
19/07/31 01:43:13 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/07/31 01:43:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 01:43:13 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/07/31 01:43:13 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:43:13 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/07/31 01:43:13 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 01:43:13 INFO CodeGenerator: Code generated in 10.392658 ms
19/07/31 01:43:13 INFO ContextCleaner: Cleaned accumulator 0
19/07/31 01:43:13 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:57861 in memory (size: 3.4 KB, free: 912.3 MB)
19/07/31 01:43:13 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1480 bytes result sent to driver
19/07/31 01:43:13 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 159 ms on localhost (executor driver) (1/1)
19/07/31 01:43:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/07/31 01:43:13 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0.160 s
19/07/31 01:43:13 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0.171124 s
19/07/31 01:43:13 INFO CodeGenerator: Code generated in 5.337008 ms
19/07/31 01:43:13 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 01:43:13 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 01:43:13 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 01:43:13 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 01:43:13 INFO CodeGenerator: Code generated in 5.264732 ms
19/07/31 01:43:13 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 281.2 KB, free 911.7 MB)
19/07/31 01:43:13 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.7 MB)
19/07/31 01:43:13 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:57861 (size: 23.8 KB, free: 912.2 MB)
19/07/31 01:43:13 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:0
19/07/31 01:43:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 01:43:13 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 01:43:13 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 01:43:13 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 01:43:13 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:43:13 INFO DAGScheduler: Missing parents: List()
19/07/31 01:43:13 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 01:43:13 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.8 KB, free 911.7 MB)
19/07/31 01:43:13 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.7 MB)
19/07/31 01:43:13 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:57861 (size: 8.6 KB, free: 912.2 MB)
19/07/31 01:43:13 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/07/31 01:43:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 01:43:13 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/07/31 01:43:13 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:43:13 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/07/31 01:43:13 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 01:43:13 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1627 bytes result sent to driver
19/07/31 01:43:13 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 70 ms on localhost (executor driver) (1/1)
19/07/31 01:43:13 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/07/31 01:43:13 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.070 s
19/07/31 01:43:13 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.078004 s
19/07/31 01:43:13 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 01:43:13 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:43:13 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:43:13 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:43:13 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:43:13 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 01:43:13 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 01:43:13 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 01:43:13 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 01:43:13 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 01:43:13 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 01:43:13 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 01:43:13 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 01:43:13 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 01:43:13 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 282.3 KB, free 911.4 MB)
19/07/31 01:43:13 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.4 MB)
19/07/31 01:43:13 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:57861 (size: 24.0 KB, free: 912.2 MB)
19/07/31 01:43:13 INFO SparkContext: Created broadcast 5 from sql at NativeMethodAccessorImpl.java:0
19/07/31 01:43:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 01:43:14 INFO CodeGenerator: Code generated in 8.028961 ms
19/07/31 01:43:14 INFO CodeGenerator: Code generated in 7.127889 ms
19/07/31 01:43:14 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 01:43:14 INFO DAGScheduler: Registering RDD 18 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 01:43:14 INFO DAGScheduler: Got job 3 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 01:43:14 INFO DAGScheduler: Final stage: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 01:43:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/07/31 01:43:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/07/31 01:43:14 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 01:43:14 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 26.3 KB, free 911.3 MB)
19/07/31 01:43:14 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.8 KB, free 911.3 MB)
19/07/31 01:43:14 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:57861 (size: 11.8 KB, free: 912.2 MB)
19/07/31 01:43:14 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/07/31 01:43:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 01:43:14 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/07/31 01:43:14 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:43:14 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/07/31 01:43:14 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 01:43:14 INFO CodeGenerator: Code generated in 13.90745 ms
19/07/31 01:43:14 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 48.9 KB, free 911.3 MB)
19/07/31 01:43:14 INFO BlockManagerInfo: Added rdd_15_0 in memory on 127.0.0.1:57861 (size: 48.9 KB, free: 912.2 MB)
19/07/31 01:43:14 INFO CodeGenerator: Code generated in 3.645123 ms
19/07/31 01:43:14 INFO CodeGenerator: Code generated in 16.745486 ms
19/07/31 01:43:14 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2504 bytes result sent to driver
19/07/31 01:43:14 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 326 ms on localhost (executor driver) (1/1)
19/07/31 01:43:14 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/07/31 01:43:14 INFO DAGScheduler: ShuffleMapStage 3 (sql at NativeMethodAccessorImpl.java:0) finished in 0.327 s
19/07/31 01:43:14 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:43:14 INFO DAGScheduler: running: Set()
19/07/31 01:43:14 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/07/31 01:43:14 INFO DAGScheduler: failed: Set()
19/07/31 01:43:14 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 01:43:14 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 911.3 MB)
19/07/31 01:43:14 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.3 MB)
19/07/31 01:43:14 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:57861 (size: 3.7 KB, free: 912.2 MB)
19/07/31 01:43:14 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/07/31 01:43:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 01:43:14 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/07/31 01:43:14 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:43:14 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/07/31 01:43:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:43:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
19/07/31 01:43:14 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1581 bytes result sent to driver
19/07/31 01:43:14 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 47 ms on localhost (executor driver) (1/1)
19/07/31 01:43:14 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/07/31 01:43:14 INFO DAGScheduler: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0) finished in 0.049 s
19/07/31 01:43:14 INFO DAGScheduler: Job 3 finished: sql at NativeMethodAccessorImpl.java:0, took 0.490642 s
19/07/31 01:43:14 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 01:43:14 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:43:14 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:43:14 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:43:14 INFO DAGScheduler: Registering RDD 24 (collect at utils.scala:204)
19/07/31 01:43:14 INFO DAGScheduler: Got job 4 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:43:14 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
19/07/31 01:43:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/07/31 01:43:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/07/31 01:43:14 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204), which has no missing parents
19/07/31 01:43:14 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 26.3 KB, free 911.2 MB)
19/07/31 01:43:14 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.9 KB, free 911.2 MB)
19/07/31 01:43:14 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:57861 (size: 11.9 KB, free: 912.1 MB)
19/07/31 01:43:14 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/07/31 01:43:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:43:14 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/07/31 01:43:14 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:43:14 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/07/31 01:43:14 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 01:43:14 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1780 bytes result sent to driver
19/07/31 01:43:14 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 10 ms on localhost (executor driver) (1/1)
19/07/31 01:43:14 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/07/31 01:43:14 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:204) finished in 0.010 s
19/07/31 01:43:14 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:43:14 INFO DAGScheduler: running: Set()
19/07/31 01:43:14 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/07/31 01:43:14 INFO DAGScheduler: failed: Set()
19/07/31 01:43:14 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204), which has no missing parents
19/07/31 01:43:14 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 911.2 MB)
19/07/31 01:43:14 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.2 MB)
19/07/31 01:43:14 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:57861 (size: 3.7 KB, free: 912.1 MB)
19/07/31 01:43:14 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/07/31 01:43:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:43:14 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/07/31 01:43:14 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:43:14 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/07/31 01:43:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:43:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:43:14 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1581 bytes result sent to driver
19/07/31 01:43:14 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 5 ms on localhost (executor driver) (1/1)
19/07/31 01:43:14 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/07/31 01:43:14 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.005 s
19/07/31 01:43:14 INFO DAGScheduler: Job 4 finished: collect at utils.scala:204, took 0.032227 s
19/07/31 01:43:14 INFO CodeGenerator: Code generated in 8.940084 ms
19/07/31 01:43:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz1`
WHERE (0 = 1)
19/07/31 01:43:15 INFO SparkContext: Invoking stop() from shutdown hook
19/07/31 01:43:15 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
19/07/31 01:43:15 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/07/31 01:43:15 INFO MemoryStore: MemoryStore cleared
19/07/31 01:43:15 INFO BlockManager: BlockManager stopped
19/07/31 01:43:15 INFO BlockManagerMaster: BlockManagerMaster stopped
19/07/31 01:43:15 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/07/31 01:43:15 INFO SparkContext: Successfully stopped SparkContext
19/07/31 01:43:15 INFO ShutdownHookManager: Shutdown hook called
19/07/31 01:43:15 INFO ShutdownHookManager: Deleting directory /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-6d54ad23-6bb5-4afc-a595-766c035136d6
19/07/31 01:59:37 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 01:59:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:59:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:59:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:59:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:59:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 01:59:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 01:59:37 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 01:59:37 INFO DAGScheduler: Got job 127 (collect at utils.scala:44) with 4 output partitions
19/07/31 01:59:37 INFO DAGScheduler: Final stage: ResultStage 183 (collect at utils.scala:44)
19/07/31 01:59:37 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:59:37 INFO DAGScheduler: Missing parents: List()
19/07/31 01:59:37 INFO DAGScheduler: Submitting ResultStage 183 (MapPartitionsRDD[593] at map at utils.scala:41), which has no missing parents
19/07/31 01:59:37 INFO MemoryStore: Block broadcast_186 stored as values in memory (estimated size 7.2 KB, free 911.9 MB)
19/07/31 01:59:37 INFO MemoryStore: Block broadcast_186_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.9 MB)
19/07/31 01:59:37 INFO BlockManagerInfo: Added broadcast_186_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 912.2 MB)
19/07/31 01:59:37 INFO SparkContext: Created broadcast 186 from broadcast at DAGScheduler.scala:1006
19/07/31 01:59:37 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 183 (MapPartitionsRDD[593] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 01:59:37 INFO TaskSchedulerImpl: Adding task set 183.0 with 4 tasks
19/07/31 01:59:37 INFO TaskSetManager: Starting task 0.0 in stage 183.0 (TID 330, localhost, executor driver, partition 0, PROCESS_LOCAL, 5084 bytes)
19/07/31 01:59:37 INFO TaskSetManager: Starting task 1.0 in stage 183.0 (TID 331, localhost, executor driver, partition 1, PROCESS_LOCAL, 5100 bytes)
19/07/31 01:59:37 INFO TaskSetManager: Starting task 2.0 in stage 183.0 (TID 332, localhost, executor driver, partition 2, PROCESS_LOCAL, 5100 bytes)
19/07/31 01:59:37 INFO TaskSetManager: Starting task 3.0 in stage 183.0 (TID 333, localhost, executor driver, partition 3, PROCESS_LOCAL, 5141 bytes)
19/07/31 01:59:37 INFO Executor: Running task 1.0 in stage 183.0 (TID 331)
19/07/31 01:59:37 INFO Executor: Running task 0.0 in stage 183.0 (TID 330)
19/07/31 01:59:37 INFO Executor: Running task 2.0 in stage 183.0 (TID 332)
19/07/31 01:59:37 INFO Executor: Running task 3.0 in stage 183.0 (TID 333)
19/07/31 01:59:37 INFO Executor: Finished task 0.0 in stage 183.0 (TID 330). 1016 bytes result sent to driver
19/07/31 01:59:37 INFO Executor: Finished task 3.0 in stage 183.0 (TID 333). 1033 bytes result sent to driver
19/07/31 01:59:37 INFO Executor: Finished task 2.0 in stage 183.0 (TID 332). 1026 bytes result sent to driver
19/07/31 01:59:37 INFO Executor: Finished task 1.0 in stage 183.0 (TID 331). 1026 bytes result sent to driver
19/07/31 01:59:37 INFO TaskSetManager: Finished task 0.0 in stage 183.0 (TID 330) in 32 ms on localhost (executor driver) (1/4)
19/07/31 01:59:37 INFO TaskSetManager: Finished task 2.0 in stage 183.0 (TID 332) in 20 ms on localhost (executor driver) (2/4)
19/07/31 01:59:37 INFO TaskSetManager: Finished task 3.0 in stage 183.0 (TID 333) in 20 ms on localhost (executor driver) (3/4)
19/07/31 01:59:37 INFO TaskSetManager: Finished task 1.0 in stage 183.0 (TID 331) in 22 ms on localhost (executor driver) (4/4)
19/07/31 01:59:37 INFO TaskSchedulerImpl: Removed TaskSet 183.0, whose tasks have all completed, from pool 
19/07/31 01:59:37 INFO DAGScheduler: ResultStage 183 (collect at utils.scala:44) finished in 0.034 s
19/07/31 01:59:37 INFO DAGScheduler: Job 127 finished: collect at utils.scala:44, took 0.081919 s
19/07/31 01:59:37 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 01:59:37 INFO MapPartitionsRDD: Removing RDD 15 from persistence list
19/07/31 01:59:37 INFO BlockManager: Removing RDD 15
19/07/31 01:59:38 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 01:59:38 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#7667)) > 0)
19/07/31 01:59:38 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 01:59:38 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 01:59:38 INFO MemoryStore: Block broadcast_187 stored as values in memory (estimated size 281.2 KB, free 911.7 MB)
19/07/31 01:59:38 INFO MemoryStore: Block broadcast_187_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.7 MB)
19/07/31 01:59:38 INFO BlockManagerInfo: Added broadcast_187_piece0 in memory on 127.0.0.1:53873 (size: 23.8 KB, free: 912.2 MB)
19/07/31 01:59:38 INFO SparkContext: Created broadcast 187 from csv at NativeMethodAccessorImpl.java:0
19/07/31 01:59:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 01:59:38 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 01:59:38 INFO DAGScheduler: Got job 128 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 01:59:38 INFO DAGScheduler: Final stage: ResultStage 184 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 01:59:38 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:59:38 INFO DAGScheduler: Missing parents: List()
19/07/31 01:59:38 INFO DAGScheduler: Submitting ResultStage 184 (MapPartitionsRDD[596] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 01:59:38 INFO MemoryStore: Block broadcast_188 stored as values in memory (estimated size 8.2 KB, free 911.6 MB)
19/07/31 01:59:38 INFO MemoryStore: Block broadcast_188_piece0 stored as bytes in memory (estimated size 4.3 KB, free 911.6 MB)
19/07/31 01:59:38 INFO BlockManagerInfo: Added broadcast_188_piece0 in memory on 127.0.0.1:53873 (size: 4.3 KB, free: 912.2 MB)
19/07/31 01:59:38 INFO SparkContext: Created broadcast 188 from broadcast at DAGScheduler.scala:1006
19/07/31 01:59:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 184 (MapPartitionsRDD[596] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 01:59:38 INFO TaskSchedulerImpl: Adding task set 184.0 with 1 tasks
19/07/31 01:59:38 INFO TaskSetManager: Starting task 0.0 in stage 184.0 (TID 334, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:59:38 INFO Executor: Running task 0.0 in stage 184.0 (TID 334)
19/07/31 01:59:38 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 01:59:38 INFO Executor: Finished task 0.0 in stage 184.0 (TID 334). 1394 bytes result sent to driver
19/07/31 01:59:38 INFO TaskSetManager: Finished task 0.0 in stage 184.0 (TID 334) in 22 ms on localhost (executor driver) (1/1)
19/07/31 01:59:38 INFO TaskSchedulerImpl: Removed TaskSet 184.0, whose tasks have all completed, from pool 
19/07/31 01:59:38 INFO DAGScheduler: ResultStage 184 (csv at NativeMethodAccessorImpl.java:0) finished in 0.024 s
19/07/31 01:59:38 INFO DAGScheduler: Job 128 finished: csv at NativeMethodAccessorImpl.java:0, took 0.059884 s
19/07/31 01:59:38 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 01:59:38 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 01:59:38 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 01:59:38 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 01:59:38 INFO MemoryStore: Block broadcast_189 stored as values in memory (estimated size 281.2 KB, free 911.4 MB)
19/07/31 01:59:38 INFO MemoryStore: Block broadcast_189_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.3 MB)
19/07/31 01:59:38 INFO BlockManagerInfo: Added broadcast_189_piece0 in memory on 127.0.0.1:53873 (size: 23.8 KB, free: 912.2 MB)
19/07/31 01:59:38 INFO SparkContext: Created broadcast 189 from csv at NativeMethodAccessorImpl.java:0
19/07/31 01:59:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 01:59:38 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 01:59:38 INFO DAGScheduler: Got job 129 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 01:59:38 INFO DAGScheduler: Final stage: ResultStage 185 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 01:59:38 INFO DAGScheduler: Parents of final stage: List()
19/07/31 01:59:38 INFO DAGScheduler: Missing parents: List()
19/07/31 01:59:38 INFO DAGScheduler: Submitting ResultStage 185 (MapPartitionsRDD[601] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 01:59:38 INFO MemoryStore: Block broadcast_190 stored as values in memory (estimated size 14.8 KB, free 911.3 MB)
19/07/31 01:59:38 INFO MemoryStore: Block broadcast_190_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.3 MB)
19/07/31 01:59:38 INFO BlockManagerInfo: Added broadcast_190_piece0 in memory on 127.0.0.1:53873 (size: 8.6 KB, free: 912.2 MB)
19/07/31 01:59:38 INFO SparkContext: Created broadcast 190 from broadcast at DAGScheduler.scala:1006
19/07/31 01:59:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 185 (MapPartitionsRDD[601] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 01:59:38 INFO TaskSchedulerImpl: Adding task set 185.0 with 1 tasks
19/07/31 01:59:38 INFO TaskSetManager: Starting task 0.0 in stage 185.0 (TID 335, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 01:59:38 INFO Executor: Running task 0.0 in stage 185.0 (TID 335)
19/07/31 01:59:38 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 01:59:38 INFO Executor: Finished task 0.0 in stage 185.0 (TID 335). 1627 bytes result sent to driver
19/07/31 01:59:38 INFO TaskSetManager: Finished task 0.0 in stage 185.0 (TID 335) in 46 ms on localhost (executor driver) (1/1)
19/07/31 01:59:38 INFO TaskSchedulerImpl: Removed TaskSet 185.0, whose tasks have all completed, from pool 
19/07/31 01:59:38 INFO DAGScheduler: ResultStage 185 (csv at NativeMethodAccessorImpl.java:0) finished in 0.046 s
19/07/31 01:59:38 INFO DAGScheduler: Job 129 finished: csv at NativeMethodAccessorImpl.java:0, took 0.064121 s
19/07/31 01:59:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 01:59:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:59:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:59:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:59:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:59:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 01:59:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 01:59:38 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 01:59:38 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 01:59:38 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 01:59:38 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 01:59:38 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 01:59:38 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 01:59:38 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 01:59:38 INFO MemoryStore: Block broadcast_191 stored as values in memory (estimated size 282.3 KB, free 911.0 MB)
19/07/31 01:59:38 INFO MemoryStore: Block broadcast_191_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.0 MB)
19/07/31 01:59:38 INFO BlockManagerInfo: Added broadcast_191_piece0 in memory on 127.0.0.1:53873 (size: 24.0 KB, free: 912.2 MB)
19/07/31 01:59:38 INFO SparkContext: Created broadcast 191 from sql at NativeMethodAccessorImpl.java:0
19/07/31 01:59:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 01:59:38 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 01:59:38 INFO DAGScheduler: Registering RDD 607 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 01:59:38 INFO DAGScheduler: Got job 130 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 01:59:38 INFO DAGScheduler: Final stage: ResultStage 187 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 01:59:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 186)
19/07/31 01:59:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 186)
19/07/31 01:59:38 INFO DAGScheduler: Submitting ShuffleMapStage 186 (MapPartitionsRDD[607] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 01:59:38 INFO MemoryStore: Block broadcast_192 stored as values in memory (estimated size 26.3 KB, free 911.0 MB)
19/07/31 01:59:38 INFO MemoryStore: Block broadcast_192_piece0 stored as bytes in memory (estimated size 11.8 KB, free 911.0 MB)
19/07/31 01:59:38 INFO BlockManagerInfo: Added broadcast_192_piece0 in memory on 127.0.0.1:53873 (size: 11.8 KB, free: 912.1 MB)
19/07/31 01:59:38 INFO SparkContext: Created broadcast 192 from broadcast at DAGScheduler.scala:1006
19/07/31 01:59:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 186 (MapPartitionsRDD[607] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 01:59:38 INFO TaskSchedulerImpl: Adding task set 186.0 with 1 tasks
19/07/31 01:59:38 INFO TaskSetManager: Starting task 0.0 in stage 186.0 (TID 336, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:59:38 INFO Executor: Running task 0.0 in stage 186.0 (TID 336)
19/07/31 01:59:38 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 01:59:38 INFO MemoryStore: Block rdd_604_0 stored as values in memory (estimated size 48.9 KB, free 910.9 MB)
19/07/31 01:59:38 INFO BlockManagerInfo: Added rdd_604_0 in memory on 127.0.0.1:53873 (size: 48.9 KB, free: 912.1 MB)
19/07/31 01:59:38 INFO Executor: Finished task 0.0 in stage 186.0 (TID 336). 2461 bytes result sent to driver
19/07/31 01:59:38 INFO TaskSetManager: Finished task 0.0 in stage 186.0 (TID 336) in 103 ms on localhost (executor driver) (1/1)
19/07/31 01:59:38 INFO TaskSchedulerImpl: Removed TaskSet 186.0, whose tasks have all completed, from pool 
19/07/31 01:59:38 INFO DAGScheduler: ShuffleMapStage 186 (sql at NativeMethodAccessorImpl.java:0) finished in 0.105 s
19/07/31 01:59:38 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:59:38 INFO DAGScheduler: running: Set()
19/07/31 01:59:38 INFO DAGScheduler: waiting: Set(ResultStage 187)
19/07/31 01:59:38 INFO DAGScheduler: failed: Set()
19/07/31 01:59:38 INFO DAGScheduler: Submitting ResultStage 187 (MapPartitionsRDD[610] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 01:59:38 INFO MemoryStore: Block broadcast_193 stored as values in memory (estimated size 7.0 KB, free 910.9 MB)
19/07/31 01:59:38 INFO MemoryStore: Block broadcast_193_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.9 MB)
19/07/31 01:59:38 INFO BlockManagerInfo: Added broadcast_193_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 912.1 MB)
19/07/31 01:59:38 INFO SparkContext: Created broadcast 193 from broadcast at DAGScheduler.scala:1006
19/07/31 01:59:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 187 (MapPartitionsRDD[610] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 01:59:38 INFO TaskSchedulerImpl: Adding task set 187.0 with 1 tasks
19/07/31 01:59:38 INFO TaskSetManager: Starting task 0.0 in stage 187.0 (TID 337, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:59:38 INFO Executor: Running task 0.0 in stage 187.0 (TID 337)
19/07/31 01:59:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:59:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 01:59:39 INFO Executor: Finished task 0.0 in stage 187.0 (TID 337). 1538 bytes result sent to driver
19/07/31 01:59:39 INFO TaskSetManager: Finished task 0.0 in stage 187.0 (TID 337) in 10 ms on localhost (executor driver) (1/1)
19/07/31 01:59:39 INFO TaskSchedulerImpl: Removed TaskSet 187.0, whose tasks have all completed, from pool 
19/07/31 01:59:39 INFO DAGScheduler: ResultStage 187 (sql at NativeMethodAccessorImpl.java:0) finished in 0.010 s
19/07/31 01:59:39 INFO DAGScheduler: Job 130 finished: sql at NativeMethodAccessorImpl.java:0, took 0.171279 s
19/07/31 01:59:39 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 01:59:39 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:59:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:59:39 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 01:59:39 INFO DAGScheduler: Registering RDD 613 (collect at utils.scala:204)
19/07/31 01:59:39 INFO DAGScheduler: Got job 131 (collect at utils.scala:204) with 1 output partitions
19/07/31 01:59:39 INFO DAGScheduler: Final stage: ResultStage 189 (collect at utils.scala:204)
19/07/31 01:59:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 188)
19/07/31 01:59:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 188)
19/07/31 01:59:39 INFO DAGScheduler: Submitting ShuffleMapStage 188 (MapPartitionsRDD[613] at collect at utils.scala:204), which has no missing parents
19/07/31 01:59:39 INFO MemoryStore: Block broadcast_194 stored as values in memory (estimated size 26.3 KB, free 910.9 MB)
19/07/31 01:59:39 INFO MemoryStore: Block broadcast_194_piece0 stored as bytes in memory (estimated size 11.9 KB, free 910.9 MB)
19/07/31 01:59:39 INFO BlockManagerInfo: Added broadcast_194_piece0 in memory on 127.0.0.1:53873 (size: 11.9 KB, free: 912.1 MB)
19/07/31 01:59:39 INFO SparkContext: Created broadcast 194 from broadcast at DAGScheduler.scala:1006
19/07/31 01:59:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 188 (MapPartitionsRDD[613] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:59:39 INFO TaskSchedulerImpl: Adding task set 188.0 with 1 tasks
19/07/31 01:59:39 INFO TaskSetManager: Starting task 0.0 in stage 188.0 (TID 338, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 01:59:39 INFO Executor: Running task 0.0 in stage 188.0 (TID 338)
19/07/31 01:59:39 INFO BlockManager: Found block rdd_604_0 locally
19/07/31 01:59:39 INFO Executor: Finished task 0.0 in stage 188.0 (TID 338). 1780 bytes result sent to driver
19/07/31 01:59:39 INFO TaskSetManager: Finished task 0.0 in stage 188.0 (TID 338) in 7 ms on localhost (executor driver) (1/1)
19/07/31 01:59:39 INFO TaskSchedulerImpl: Removed TaskSet 188.0, whose tasks have all completed, from pool 
19/07/31 01:59:39 INFO DAGScheduler: ShuffleMapStage 188 (collect at utils.scala:204) finished in 0.008 s
19/07/31 01:59:39 INFO DAGScheduler: looking for newly runnable stages
19/07/31 01:59:39 INFO DAGScheduler: running: Set()
19/07/31 01:59:39 INFO DAGScheduler: waiting: Set(ResultStage 189)
19/07/31 01:59:39 INFO DAGScheduler: failed: Set()
19/07/31 01:59:39 INFO DAGScheduler: Submitting ResultStage 189 (MapPartitionsRDD[616] at collect at utils.scala:204), which has no missing parents
19/07/31 01:59:39 INFO MemoryStore: Block broadcast_195 stored as values in memory (estimated size 7.0 KB, free 910.9 MB)
19/07/31 01:59:39 INFO MemoryStore: Block broadcast_195_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.9 MB)
19/07/31 01:59:39 INFO BlockManagerInfo: Added broadcast_195_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 912.1 MB)
19/07/31 01:59:39 INFO SparkContext: Created broadcast 195 from broadcast at DAGScheduler.scala:1006
19/07/31 01:59:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 189 (MapPartitionsRDD[616] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 01:59:39 INFO TaskSchedulerImpl: Adding task set 189.0 with 1 tasks
19/07/31 01:59:39 INFO TaskSetManager: Starting task 0.0 in stage 189.0 (TID 339, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 01:59:39 INFO Executor: Running task 0.0 in stage 189.0 (TID 339)
19/07/31 01:59:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 01:59:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 01:59:39 INFO Executor: Finished task 0.0 in stage 189.0 (TID 339). 1581 bytes result sent to driver
19/07/31 01:59:39 INFO TaskSetManager: Finished task 0.0 in stage 189.0 (TID 339) in 6 ms on localhost (executor driver) (1/1)
19/07/31 01:59:39 INFO TaskSchedulerImpl: Removed TaskSet 189.0, whose tasks have all completed, from pool 
19/07/31 01:59:39 INFO DAGScheduler: ResultStage 189 (collect at utils.scala:204) finished in 0.006 s
19/07/31 01:59:39 INFO DAGScheduler: Job 131 finished: collect at utils.scala:204, took 0.053177 s
19/07/31 01:59:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz13`
WHERE (0 = 1)
19/07/31 01:59:39 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 01:59:39 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:59:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:59:39 INFO HiveMetaStore: 0: get_database: default
19/07/31 01:59:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 01:59:39 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 01:59:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 02:00:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 02:00:20 INFO HiveMetaStore: 0: get_database: default
19/07/31 02:00:20 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 02:00:20 INFO HiveMetaStore: 0: get_database: default
19/07/31 02:00:20 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 02:00:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 02:00:20 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 02:00:21 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 02:00:21 INFO DAGScheduler: Got job 132 (collect at utils.scala:44) with 4 output partitions
19/07/31 02:00:21 INFO DAGScheduler: Final stage: ResultStage 190 (collect at utils.scala:44)
19/07/31 02:00:21 INFO DAGScheduler: Parents of final stage: List()
19/07/31 02:00:21 INFO DAGScheduler: Missing parents: List()
19/07/31 02:00:21 INFO DAGScheduler: Submitting ResultStage 190 (MapPartitionsRDD[621] at map at utils.scala:41), which has no missing parents
19/07/31 02:00:21 INFO MemoryStore: Block broadcast_196 stored as values in memory (estimated size 7.2 KB, free 910.9 MB)
19/07/31 02:00:21 INFO MemoryStore: Block broadcast_196_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.9 MB)
19/07/31 02:00:21 INFO BlockManagerInfo: Added broadcast_196_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 912.1 MB)
19/07/31 02:00:21 INFO SparkContext: Created broadcast 196 from broadcast at DAGScheduler.scala:1006
19/07/31 02:00:21 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 190 (MapPartitionsRDD[621] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 02:00:21 INFO TaskSchedulerImpl: Adding task set 190.0 with 4 tasks
19/07/31 02:00:21 INFO TaskSetManager: Starting task 0.0 in stage 190.0 (TID 340, localhost, executor driver, partition 0, PROCESS_LOCAL, 5084 bytes)
19/07/31 02:00:21 INFO TaskSetManager: Starting task 1.0 in stage 190.0 (TID 341, localhost, executor driver, partition 1, PROCESS_LOCAL, 5100 bytes)
19/07/31 02:00:21 INFO TaskSetManager: Starting task 2.0 in stage 190.0 (TID 342, localhost, executor driver, partition 2, PROCESS_LOCAL, 5100 bytes)
19/07/31 02:00:21 INFO TaskSetManager: Starting task 3.0 in stage 190.0 (TID 343, localhost, executor driver, partition 3, PROCESS_LOCAL, 5141 bytes)
19/07/31 02:00:21 INFO Executor: Running task 0.0 in stage 190.0 (TID 340)
19/07/31 02:00:21 INFO Executor: Running task 2.0 in stage 190.0 (TID 342)
19/07/31 02:00:21 INFO Executor: Running task 3.0 in stage 190.0 (TID 343)
19/07/31 02:00:21 INFO Executor: Running task 1.0 in stage 190.0 (TID 341)
19/07/31 02:00:21 INFO Executor: Finished task 3.0 in stage 190.0 (TID 343). 990 bytes result sent to driver
19/07/31 02:00:21 INFO Executor: Finished task 2.0 in stage 190.0 (TID 342). 983 bytes result sent to driver
19/07/31 02:00:21 INFO Executor: Finished task 0.0 in stage 190.0 (TID 340). 973 bytes result sent to driver
19/07/31 02:00:21 INFO TaskSetManager: Finished task 3.0 in stage 190.0 (TID 343) in 3 ms on localhost (executor driver) (1/4)
19/07/31 02:00:21 INFO TaskSetManager: Finished task 2.0 in stage 190.0 (TID 342) in 4 ms on localhost (executor driver) (2/4)
19/07/31 02:00:21 INFO TaskSetManager: Finished task 0.0 in stage 190.0 (TID 340) in 5 ms on localhost (executor driver) (3/4)
19/07/31 02:00:21 INFO Executor: Finished task 1.0 in stage 190.0 (TID 341). 1026 bytes result sent to driver
19/07/31 02:00:21 INFO TaskSetManager: Finished task 1.0 in stage 190.0 (TID 341) in 5 ms on localhost (executor driver) (4/4)
19/07/31 02:00:21 INFO TaskSchedulerImpl: Removed TaskSet 190.0, whose tasks have all completed, from pool 
19/07/31 02:00:21 INFO DAGScheduler: ResultStage 190 (collect at utils.scala:44) finished in 0.007 s
19/07/31 02:00:21 INFO DAGScheduler: Job 132 finished: collect at utils.scala:44, took 0.020823 s
19/07/31 02:00:21 INFO SparkSqlParser: Parsing command: SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 02:00:21 INFO SparkSqlParser: Parsing command: SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 02:00:21 INFO CodeGenerator: Code generated in 16.954817 ms
19/07/31 02:00:21 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 02:00:21 INFO DAGScheduler: Got job 133 (collect at utils.scala:204) with 1 output partitions
19/07/31 02:00:21 INFO DAGScheduler: Final stage: ResultStage 191 (collect at utils.scala:204)
19/07/31 02:00:21 INFO DAGScheduler: Parents of final stage: List()
19/07/31 02:00:21 INFO DAGScheduler: Missing parents: List()
19/07/31 02:00:21 INFO DAGScheduler: Submitting ResultStage 191 (MapPartitionsRDD[624] at collect at utils.scala:204), which has no missing parents
19/07/31 02:00:21 INFO MemoryStore: Block broadcast_197 stored as values in memory (estimated size 25.8 KB, free 910.8 MB)
19/07/31 02:00:21 INFO MemoryStore: Block broadcast_197_piece0 stored as bytes in memory (estimated size 11.3 KB, free 910.8 MB)
19/07/31 02:00:21 INFO BlockManagerInfo: Added broadcast_197_piece0 in memory on 127.0.0.1:53873 (size: 11.3 KB, free: 912.1 MB)
19/07/31 02:00:21 INFO SparkContext: Created broadcast 197 from broadcast at DAGScheduler.scala:1006
19/07/31 02:00:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 191 (MapPartitionsRDD[624] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 02:00:21 INFO TaskSchedulerImpl: Adding task set 191.0 with 1 tasks
19/07/31 02:00:21 INFO TaskSetManager: Starting task 0.0 in stage 191.0 (TID 344, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 02:00:21 INFO Executor: Running task 0.0 in stage 191.0 (TID 344)
19/07/31 02:00:21 INFO BlockManager: Found block rdd_604_0 locally
19/07/31 02:00:21 INFO CodeGenerator: Code generated in 12.627712 ms
19/07/31 02:00:21 INFO Executor: Finished task 0.0 in stage 191.0 (TID 344). 37152 bytes result sent to driver
19/07/31 02:00:21 INFO TaskSetManager: Finished task 0.0 in stage 191.0 (TID 344) in 23 ms on localhost (executor driver) (1/1)
19/07/31 02:00:21 INFO TaskSchedulerImpl: Removed TaskSet 191.0, whose tasks have all completed, from pool 
19/07/31 02:00:21 INFO DAGScheduler: ResultStage 191 (collect at utils.scala:204) finished in 0.024 s
19/07/31 02:00:21 INFO DAGScheduler: Job 133 finished: collect at utils.scala:204, took 0.040097 s
19/07/31 02:00:21 INFO CodeGenerator: Code generated in 10.433946 ms
19/07/31 02:00:21 INFO SparkSqlParser: Parsing command: df
19/07/31 02:00:21 INFO SparkSqlParser: Parsing command: CACHE TABLE `df`
19/07/31 02:00:21 INFO SparkSqlParser: Parsing command: `df`
19/07/31 02:00:21 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 02:00:21 INFO DAGScheduler: Registering RDD 632 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 02:00:21 INFO DAGScheduler: Got job 134 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 02:00:21 INFO DAGScheduler: Final stage: ResultStage 193 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 02:00:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 192)
19/07/31 02:00:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 192)
19/07/31 02:00:21 INFO DAGScheduler: Submitting ShuffleMapStage 192 (MapPartitionsRDD[632] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 02:00:21 INFO MemoryStore: Block broadcast_198 stored as values in memory (estimated size 18.2 KB, free 910.8 MB)
19/07/31 02:00:21 INFO MemoryStore: Block broadcast_198_piece0 stored as bytes in memory (estimated size 8.5 KB, free 910.8 MB)
19/07/31 02:00:21 INFO BlockManagerInfo: Added broadcast_198_piece0 in memory on 127.0.0.1:53873 (size: 8.5 KB, free: 912.1 MB)
19/07/31 02:00:21 INFO SparkContext: Created broadcast 198 from broadcast at DAGScheduler.scala:1006
19/07/31 02:00:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 192 (MapPartitionsRDD[632] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 02:00:21 INFO TaskSchedulerImpl: Adding task set 192.0 with 1 tasks
19/07/31 02:00:21 INFO TaskSetManager: Starting task 0.0 in stage 192.0 (TID 345, localhost, executor driver, partition 0, PROCESS_LOCAL, 54567 bytes)
19/07/31 02:00:21 INFO Executor: Running task 0.0 in stage 192.0 (TID 345)
19/07/31 02:00:21 INFO CodeGenerator: Code generated in 19.937896 ms
19/07/31 02:00:21 INFO CodeGenerator: Code generated in 62.14887 ms
19/07/31 02:00:21 INFO MemoryStore: Block rdd_629_0 stored as values in memory (estimated size 16.1 KB, free 910.8 MB)
19/07/31 02:00:21 INFO BlockManagerInfo: Added rdd_629_0 in memory on 127.0.0.1:53873 (size: 16.1 KB, free: 912.0 MB)
19/07/31 02:00:21 INFO Executor: Finished task 0.0 in stage 192.0 (TID 345). 2285 bytes result sent to driver
19/07/31 02:00:21 INFO TaskSetManager: Finished task 0.0 in stage 192.0 (TID 345) in 153 ms on localhost (executor driver) (1/1)
19/07/31 02:00:21 INFO TaskSchedulerImpl: Removed TaskSet 192.0, whose tasks have all completed, from pool 
19/07/31 02:00:21 INFO DAGScheduler: ShuffleMapStage 192 (sql at NativeMethodAccessorImpl.java:0) finished in 0.154 s
19/07/31 02:00:21 INFO DAGScheduler: looking for newly runnable stages
19/07/31 02:00:21 INFO DAGScheduler: running: Set()
19/07/31 02:00:21 INFO DAGScheduler: waiting: Set(ResultStage 193)
19/07/31 02:00:21 INFO DAGScheduler: failed: Set()
19/07/31 02:00:21 INFO DAGScheduler: Submitting ResultStage 193 (MapPartitionsRDD[635] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 02:00:21 INFO MemoryStore: Block broadcast_199 stored as values in memory (estimated size 7.0 KB, free 910.8 MB)
19/07/31 02:00:21 INFO MemoryStore: Block broadcast_199_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.8 MB)
19/07/31 02:00:21 INFO BlockManagerInfo: Added broadcast_199_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 912.0 MB)
19/07/31 02:00:21 INFO SparkContext: Created broadcast 199 from broadcast at DAGScheduler.scala:1006
19/07/31 02:00:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 193 (MapPartitionsRDD[635] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 02:00:21 INFO TaskSchedulerImpl: Adding task set 193.0 with 1 tasks
19/07/31 02:00:21 INFO TaskSetManager: Starting task 0.0 in stage 193.0 (TID 346, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 02:00:21 INFO Executor: Running task 0.0 in stage 193.0 (TID 346)
19/07/31 02:00:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 02:00:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 02:00:21 INFO Executor: Finished task 0.0 in stage 193.0 (TID 346). 1581 bytes result sent to driver
19/07/31 02:00:21 INFO TaskSetManager: Finished task 0.0 in stage 193.0 (TID 346) in 4 ms on localhost (executor driver) (1/1)
19/07/31 02:00:21 INFO TaskSchedulerImpl: Removed TaskSet 193.0, whose tasks have all completed, from pool 
19/07/31 02:00:21 INFO DAGScheduler: ResultStage 193 (sql at NativeMethodAccessorImpl.java:0) finished in 0.005 s
19/07/31 02:00:21 INFO DAGScheduler: Job 134 finished: sql at NativeMethodAccessorImpl.java:0, took 0.192299 s
19/07/31 02:00:21 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `df`
19/07/31 02:00:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 02:00:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 02:00:21 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 02:00:21 INFO DAGScheduler: Registering RDD 638 (collect at utils.scala:204)
19/07/31 02:00:21 INFO DAGScheduler: Got job 135 (collect at utils.scala:204) with 1 output partitions
19/07/31 02:00:21 INFO DAGScheduler: Final stage: ResultStage 195 (collect at utils.scala:204)
19/07/31 02:00:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 194)
19/07/31 02:00:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 194)
19/07/31 02:00:21 INFO DAGScheduler: Submitting ShuffleMapStage 194 (MapPartitionsRDD[638] at collect at utils.scala:204), which has no missing parents
19/07/31 02:00:21 INFO MemoryStore: Block broadcast_200 stored as values in memory (estimated size 18.2 KB, free 910.8 MB)
19/07/31 02:00:21 INFO MemoryStore: Block broadcast_200_piece0 stored as bytes in memory (estimated size 8.5 KB, free 910.8 MB)
19/07/31 02:00:21 INFO BlockManagerInfo: Added broadcast_200_piece0 in memory on 127.0.0.1:53873 (size: 8.5 KB, free: 912.0 MB)
19/07/31 02:00:21 INFO SparkContext: Created broadcast 200 from broadcast at DAGScheduler.scala:1006
19/07/31 02:00:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 194 (MapPartitionsRDD[638] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 02:00:21 INFO TaskSchedulerImpl: Adding task set 194.0 with 1 tasks
19/07/31 02:00:21 INFO TaskSetManager: Starting task 0.0 in stage 194.0 (TID 347, localhost, executor driver, partition 0, PROCESS_LOCAL, 54567 bytes)
19/07/31 02:00:21 INFO Executor: Running task 0.0 in stage 194.0 (TID 347)
19/07/31 02:00:21 INFO BlockManager: Found block rdd_629_0 locally
19/07/31 02:00:21 INFO Executor: Finished task 0.0 in stage 194.0 (TID 347). 1690 bytes result sent to driver
19/07/31 02:00:21 INFO TaskSetManager: Finished task 0.0 in stage 194.0 (TID 347) in 16 ms on localhost (executor driver) (1/1)
19/07/31 02:00:21 INFO TaskSchedulerImpl: Removed TaskSet 194.0, whose tasks have all completed, from pool 
19/07/31 02:00:21 INFO DAGScheduler: ShuffleMapStage 194 (collect at utils.scala:204) finished in 0.016 s
19/07/31 02:00:21 INFO DAGScheduler: looking for newly runnable stages
19/07/31 02:00:21 INFO DAGScheduler: running: Set()
19/07/31 02:00:21 INFO DAGScheduler: waiting: Set(ResultStage 195)
19/07/31 02:00:21 INFO DAGScheduler: failed: Set()
19/07/31 02:00:21 INFO DAGScheduler: Submitting ResultStage 195 (MapPartitionsRDD[641] at collect at utils.scala:204), which has no missing parents
19/07/31 02:00:21 INFO MemoryStore: Block broadcast_201 stored as values in memory (estimated size 7.0 KB, free 910.7 MB)
19/07/31 02:00:21 INFO MemoryStore: Block broadcast_201_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.7 MB)
19/07/31 02:00:21 INFO BlockManagerInfo: Added broadcast_201_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 912.0 MB)
19/07/31 02:00:21 INFO SparkContext: Created broadcast 201 from broadcast at DAGScheduler.scala:1006
19/07/31 02:00:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 195 (MapPartitionsRDD[641] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 02:00:21 INFO TaskSchedulerImpl: Adding task set 195.0 with 1 tasks
19/07/31 02:00:21 INFO TaskSetManager: Starting task 0.0 in stage 195.0 (TID 348, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 02:00:21 INFO Executor: Running task 0.0 in stage 195.0 (TID 348)
19/07/31 02:00:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 02:00:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 02:00:21 INFO Executor: Finished task 0.0 in stage 195.0 (TID 348). 1538 bytes result sent to driver
19/07/31 02:00:21 INFO TaskSetManager: Finished task 0.0 in stage 195.0 (TID 348) in 3 ms on localhost (executor driver) (1/1)
19/07/31 02:00:21 INFO TaskSchedulerImpl: Removed TaskSet 195.0, whose tasks have all completed, from pool 
19/07/31 02:00:21 INFO DAGScheduler: ResultStage 195 (collect at utils.scala:204) finished in 0.003 s
19/07/31 02:00:21 INFO DAGScheduler: Job 135 finished: collect at utils.scala:204, took 0.049369 s
19/07/31 02:00:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df` AS `zzz14`
WHERE (0 = 1)
19/07/31 02:00:21 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 02:00:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 02:00:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 02:00:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 02:00:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 02:00:21 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 02:00:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 02:01:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 02:01:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 02:01:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 02:01:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 02:01:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 02:01:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 02:01:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 02:01:36 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 02:01:36 INFO DAGScheduler: Got job 136 (collect at utils.scala:44) with 4 output partitions
19/07/31 02:01:36 INFO DAGScheduler: Final stage: ResultStage 196 (collect at utils.scala:44)
19/07/31 02:01:36 INFO DAGScheduler: Parents of final stage: List()
19/07/31 02:01:36 INFO DAGScheduler: Missing parents: List()
19/07/31 02:01:36 INFO DAGScheduler: Submitting ResultStage 196 (MapPartitionsRDD[646] at map at utils.scala:41), which has no missing parents
19/07/31 02:01:36 INFO MemoryStore: Block broadcast_202 stored as values in memory (estimated size 7.3 KB, free 910.7 MB)
19/07/31 02:01:36 INFO MemoryStore: Block broadcast_202_piece0 stored as bytes in memory (estimated size 3.8 KB, free 910.7 MB)
19/07/31 02:01:36 INFO BlockManagerInfo: Added broadcast_202_piece0 in memory on 127.0.0.1:53873 (size: 3.8 KB, free: 912.0 MB)
19/07/31 02:01:36 INFO SparkContext: Created broadcast 202 from broadcast at DAGScheduler.scala:1006
19/07/31 02:01:36 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 196 (MapPartitionsRDD[646] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 02:01:36 INFO TaskSchedulerImpl: Adding task set 196.0 with 4 tasks
19/07/31 02:01:36 INFO TaskSetManager: Starting task 0.0 in stage 196.0 (TID 349, localhost, executor driver, partition 0, PROCESS_LOCAL, 5084 bytes)
19/07/31 02:01:36 INFO TaskSetManager: Starting task 1.0 in stage 196.0 (TID 350, localhost, executor driver, partition 1, PROCESS_LOCAL, 5141 bytes)
19/07/31 02:01:36 INFO TaskSetManager: Starting task 2.0 in stage 196.0 (TID 351, localhost, executor driver, partition 2, PROCESS_LOCAL, 5100 bytes)
19/07/31 02:01:36 INFO TaskSetManager: Starting task 3.0 in stage 196.0 (TID 352, localhost, executor driver, partition 3, PROCESS_LOCAL, 5141 bytes)
19/07/31 02:01:36 INFO Executor: Running task 0.0 in stage 196.0 (TID 349)
19/07/31 02:01:36 INFO Executor: Running task 1.0 in stage 196.0 (TID 350)
19/07/31 02:01:36 INFO Executor: Running task 2.0 in stage 196.0 (TID 351)
19/07/31 02:01:36 INFO Executor: Running task 3.0 in stage 196.0 (TID 352)
19/07/31 02:01:36 INFO Executor: Finished task 2.0 in stage 196.0 (TID 351). 1026 bytes result sent to driver
19/07/31 02:01:36 INFO Executor: Finished task 1.0 in stage 196.0 (TID 350). 992 bytes result sent to driver
19/07/31 02:01:36 INFO Executor: Finished task 0.0 in stage 196.0 (TID 349). 1012 bytes result sent to driver
19/07/31 02:01:36 INFO Executor: Finished task 3.0 in stage 196.0 (TID 352). 1033 bytes result sent to driver
19/07/31 02:01:36 INFO TaskSetManager: Finished task 0.0 in stage 196.0 (TID 349) in 16 ms on localhost (executor driver) (1/4)
19/07/31 02:01:36 INFO TaskSetManager: Finished task 1.0 in stage 196.0 (TID 350) in 17 ms on localhost (executor driver) (2/4)
19/07/31 02:01:36 INFO TaskSetManager: Finished task 2.0 in stage 196.0 (TID 351) in 17 ms on localhost (executor driver) (3/4)
19/07/31 02:01:36 INFO TaskSetManager: Finished task 3.0 in stage 196.0 (TID 352) in 17 ms on localhost (executor driver) (4/4)
19/07/31 02:01:36 INFO TaskSchedulerImpl: Removed TaskSet 196.0, whose tasks have all completed, from pool 
19/07/31 02:01:36 INFO DAGScheduler: ResultStage 196 (collect at utils.scala:44) finished in 0.018 s
19/07/31 02:01:36 INFO DAGScheduler: Job 136 finished: collect at utils.scala:44, took 0.039751 s
19/07/31 02:01:36 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 02:01:36 INFO MapPartitionsRDD: Removing RDD 604 from persistence list
19/07/31 02:01:36 INFO BlockManager: Removing RDD 604
19/07/31 02:01:36 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 02:01:36 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#8284)) > 0)
19/07/31 02:01:36 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 02:01:36 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 02:01:36 INFO MemoryStore: Block broadcast_203 stored as values in memory (estimated size 281.2 KB, free 910.5 MB)
19/07/31 02:01:36 INFO MemoryStore: Block broadcast_203_piece0 stored as bytes in memory (estimated size 23.8 KB, free 910.5 MB)
19/07/31 02:01:36 INFO BlockManagerInfo: Added broadcast_203_piece0 in memory on 127.0.0.1:53873 (size: 23.8 KB, free: 912.0 MB)
19/07/31 02:01:36 INFO SparkContext: Created broadcast 203 from csv at NativeMethodAccessorImpl.java:0
19/07/31 02:01:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 02:01:36 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 02:01:36 INFO DAGScheduler: Got job 137 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 02:01:36 INFO DAGScheduler: Final stage: ResultStage 197 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 02:01:36 INFO DAGScheduler: Parents of final stage: List()
19/07/31 02:01:36 INFO DAGScheduler: Missing parents: List()
19/07/31 02:01:36 INFO DAGScheduler: Submitting ResultStage 197 (MapPartitionsRDD[649] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 02:01:36 INFO MemoryStore: Block broadcast_204 stored as values in memory (estimated size 8.2 KB, free 910.5 MB)
19/07/31 02:01:36 INFO MemoryStore: Block broadcast_204_piece0 stored as bytes in memory (estimated size 4.3 KB, free 910.5 MB)
19/07/31 02:01:36 INFO BlockManagerInfo: Added broadcast_204_piece0 in memory on 127.0.0.1:53873 (size: 4.3 KB, free: 912.0 MB)
19/07/31 02:01:36 INFO SparkContext: Created broadcast 204 from broadcast at DAGScheduler.scala:1006
19/07/31 02:01:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 197 (MapPartitionsRDD[649] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 02:01:36 INFO TaskSchedulerImpl: Adding task set 197.0 with 1 tasks
19/07/31 02:01:36 INFO TaskSetManager: Starting task 0.0 in stage 197.0 (TID 353, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 02:01:36 INFO Executor: Running task 0.0 in stage 197.0 (TID 353)
19/07/31 02:01:36 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 02:01:36 INFO Executor: Finished task 0.0 in stage 197.0 (TID 353). 1394 bytes result sent to driver
19/07/31 02:01:36 INFO TaskSetManager: Finished task 0.0 in stage 197.0 (TID 353) in 6 ms on localhost (executor driver) (1/1)
19/07/31 02:01:36 INFO TaskSchedulerImpl: Removed TaskSet 197.0, whose tasks have all completed, from pool 
19/07/31 02:01:36 INFO DAGScheduler: ResultStage 197 (csv at NativeMethodAccessorImpl.java:0) finished in 0.007 s
19/07/31 02:01:36 INFO DAGScheduler: Job 137 finished: csv at NativeMethodAccessorImpl.java:0, took 0.034082 s
19/07/31 02:01:36 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 02:01:36 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 02:01:36 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 02:01:36 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 02:01:36 INFO MemoryStore: Block broadcast_205 stored as values in memory (estimated size 281.2 KB, free 910.2 MB)
19/07/31 02:01:36 INFO MemoryStore: Block broadcast_205_piece0 stored as bytes in memory (estimated size 23.8 KB, free 910.2 MB)
19/07/31 02:01:36 INFO BlockManagerInfo: Added broadcast_205_piece0 in memory on 127.0.0.1:53873 (size: 23.8 KB, free: 912.0 MB)
19/07/31 02:01:36 INFO SparkContext: Created broadcast 205 from csv at NativeMethodAccessorImpl.java:0
19/07/31 02:01:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 02:01:36 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 02:01:36 INFO DAGScheduler: Got job 138 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 02:01:36 INFO DAGScheduler: Final stage: ResultStage 198 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 02:01:36 INFO DAGScheduler: Parents of final stage: List()
19/07/31 02:01:36 INFO DAGScheduler: Missing parents: List()
19/07/31 02:01:36 INFO DAGScheduler: Submitting ResultStage 198 (MapPartitionsRDD[654] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 02:01:36 INFO MemoryStore: Block broadcast_206 stored as values in memory (estimated size 14.8 KB, free 910.2 MB)
19/07/31 02:01:36 INFO MemoryStore: Block broadcast_206_piece0 stored as bytes in memory (estimated size 8.6 KB, free 910.2 MB)
19/07/31 02:01:36 INFO BlockManagerInfo: Added broadcast_206_piece0 in memory on 127.0.0.1:53873 (size: 8.6 KB, free: 912.0 MB)
19/07/31 02:01:36 INFO SparkContext: Created broadcast 206 from broadcast at DAGScheduler.scala:1006
19/07/31 02:01:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 198 (MapPartitionsRDD[654] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 02:01:36 INFO TaskSchedulerImpl: Adding task set 198.0 with 1 tasks
19/07/31 02:01:36 INFO TaskSetManager: Starting task 0.0 in stage 198.0 (TID 354, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 02:01:36 INFO Executor: Running task 0.0 in stage 198.0 (TID 354)
19/07/31 02:01:36 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 02:01:36 INFO Executor: Finished task 0.0 in stage 198.0 (TID 354). 1584 bytes result sent to driver
19/07/31 02:01:36 INFO TaskSetManager: Finished task 0.0 in stage 198.0 (TID 354) in 42 ms on localhost (executor driver) (1/1)
19/07/31 02:01:36 INFO TaskSchedulerImpl: Removed TaskSet 198.0, whose tasks have all completed, from pool 
19/07/31 02:01:36 INFO DAGScheduler: ResultStage 198 (csv at NativeMethodAccessorImpl.java:0) finished in 0.042 s
19/07/31 02:01:36 INFO DAGScheduler: Job 138 finished: csv at NativeMethodAccessorImpl.java:0, took 0.056167 s
19/07/31 02:01:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 02:01:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 02:01:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 02:01:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 02:01:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 02:01:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 02:01:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 02:01:36 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 02:01:36 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 02:01:36 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 02:01:36 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 02:01:36 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 02:01:36 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 02:01:36 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 02:01:36 INFO MemoryStore: Block broadcast_207 stored as values in memory (estimated size 282.3 KB, free 909.9 MB)
19/07/31 02:01:37 INFO MemoryStore: Block broadcast_207_piece0 stored as bytes in memory (estimated size 24.0 KB, free 909.9 MB)
19/07/31 02:01:37 INFO BlockManagerInfo: Added broadcast_207_piece0 in memory on 127.0.0.1:53873 (size: 24.0 KB, free: 912.0 MB)
19/07/31 02:01:37 INFO SparkContext: Created broadcast 207 from sql at <unknown>:0
19/07/31 02:01:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 02:01:37 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 02:01:37 INFO DAGScheduler: Registering RDD 660 (sql at <unknown>:0)
19/07/31 02:01:37 INFO DAGScheduler: Got job 139 (sql at <unknown>:0) with 1 output partitions
19/07/31 02:01:37 INFO DAGScheduler: Final stage: ResultStage 200 (sql at <unknown>:0)
19/07/31 02:01:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 199)
19/07/31 02:01:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 199)
19/07/31 02:01:37 INFO DAGScheduler: Submitting ShuffleMapStage 199 (MapPartitionsRDD[660] at sql at <unknown>:0), which has no missing parents
19/07/31 02:01:37 INFO MemoryStore: Block broadcast_208 stored as values in memory (estimated size 26.3 KB, free 909.8 MB)
19/07/31 02:01:37 INFO MemoryStore: Block broadcast_208_piece0 stored as bytes in memory (estimated size 11.9 KB, free 909.8 MB)
19/07/31 02:01:37 INFO BlockManagerInfo: Added broadcast_208_piece0 in memory on 127.0.0.1:53873 (size: 11.9 KB, free: 912.0 MB)
19/07/31 02:01:37 INFO SparkContext: Created broadcast 208 from broadcast at DAGScheduler.scala:1006
19/07/31 02:01:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 199 (MapPartitionsRDD[660] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 02:01:37 INFO TaskSchedulerImpl: Adding task set 199.0 with 1 tasks
19/07/31 02:01:37 INFO TaskSetManager: Starting task 0.0 in stage 199.0 (TID 355, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 02:01:37 INFO Executor: Running task 0.0 in stage 199.0 (TID 355)
19/07/31 02:01:37 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 02:01:37 INFO MemoryStore: Block rdd_657_0 stored as values in memory (estimated size 48.9 KB, free 909.8 MB)
19/07/31 02:01:37 INFO BlockManagerInfo: Added rdd_657_0 in memory on 127.0.0.1:53873 (size: 48.9 KB, free: 911.9 MB)
19/07/31 02:01:37 INFO Executor: Finished task 0.0 in stage 199.0 (TID 355). 2461 bytes result sent to driver
19/07/31 02:01:37 INFO TaskSetManager: Finished task 0.0 in stage 199.0 (TID 355) in 73 ms on localhost (executor driver) (1/1)
19/07/31 02:01:37 INFO TaskSchedulerImpl: Removed TaskSet 199.0, whose tasks have all completed, from pool 
19/07/31 02:01:37 INFO DAGScheduler: ShuffleMapStage 199 (sql at <unknown>:0) finished in 0.074 s
19/07/31 02:01:37 INFO DAGScheduler: looking for newly runnable stages
19/07/31 02:01:37 INFO DAGScheduler: running: Set()
19/07/31 02:01:37 INFO DAGScheduler: waiting: Set(ResultStage 200)
19/07/31 02:01:37 INFO DAGScheduler: failed: Set()
19/07/31 02:01:37 INFO DAGScheduler: Submitting ResultStage 200 (MapPartitionsRDD[663] at sql at <unknown>:0), which has no missing parents
19/07/31 02:01:37 INFO MemoryStore: Block broadcast_209 stored as values in memory (estimated size 7.0 KB, free 909.8 MB)
19/07/31 02:01:37 INFO MemoryStore: Block broadcast_209_piece0 stored as bytes in memory (estimated size 3.7 KB, free 909.8 MB)
19/07/31 02:01:37 INFO BlockManagerInfo: Added broadcast_209_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 911.9 MB)
19/07/31 02:01:37 INFO SparkContext: Created broadcast 209 from broadcast at DAGScheduler.scala:1006
19/07/31 02:01:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 200 (MapPartitionsRDD[663] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 02:01:37 INFO TaskSchedulerImpl: Adding task set 200.0 with 1 tasks
19/07/31 02:01:37 INFO TaskSetManager: Starting task 0.0 in stage 200.0 (TID 356, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 02:01:37 INFO Executor: Running task 0.0 in stage 200.0 (TID 356)
19/07/31 02:01:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 02:01:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 02:01:37 INFO Executor: Finished task 0.0 in stage 200.0 (TID 356). 1581 bytes result sent to driver
19/07/31 02:01:37 INFO TaskSetManager: Finished task 0.0 in stage 200.0 (TID 356) in 24 ms on localhost (executor driver) (1/1)
19/07/31 02:01:37 INFO TaskSchedulerImpl: Removed TaskSet 200.0, whose tasks have all completed, from pool 
19/07/31 02:01:37 INFO DAGScheduler: ResultStage 200 (sql at <unknown>:0) finished in 0.024 s
19/07/31 02:01:37 INFO DAGScheduler: Job 139 finished: sql at <unknown>:0, took 0.144412 s
19/07/31 02:01:37 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 02:01:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 02:01:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 02:01:37 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 02:01:37 INFO DAGScheduler: Registering RDD 666 (collect at utils.scala:204)
19/07/31 02:01:37 INFO DAGScheduler: Got job 140 (collect at utils.scala:204) with 1 output partitions
19/07/31 02:01:37 INFO DAGScheduler: Final stage: ResultStage 202 (collect at utils.scala:204)
19/07/31 02:01:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 201)
19/07/31 02:01:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 201)
19/07/31 02:01:37 INFO DAGScheduler: Submitting ShuffleMapStage 201 (MapPartitionsRDD[666] at collect at utils.scala:204), which has no missing parents
19/07/31 02:01:37 INFO MemoryStore: Block broadcast_210 stored as values in memory (estimated size 26.3 KB, free 909.7 MB)
19/07/31 02:01:37 INFO MemoryStore: Block broadcast_210_piece0 stored as bytes in memory (estimated size 11.9 KB, free 909.7 MB)
19/07/31 02:01:37 INFO BlockManagerInfo: Added broadcast_210_piece0 in memory on 127.0.0.1:53873 (size: 11.9 KB, free: 911.9 MB)
19/07/31 02:01:37 INFO SparkContext: Created broadcast 210 from broadcast at DAGScheduler.scala:1006
19/07/31 02:01:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 201 (MapPartitionsRDD[666] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 02:01:37 INFO TaskSchedulerImpl: Adding task set 201.0 with 1 tasks
19/07/31 02:01:37 INFO TaskSetManager: Starting task 0.0 in stage 201.0 (TID 357, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 02:01:37 INFO Executor: Running task 0.0 in stage 201.0 (TID 357)
19/07/31 02:01:37 INFO BlockManager: Found block rdd_657_0 locally
19/07/31 02:01:37 INFO Executor: Finished task 0.0 in stage 201.0 (TID 357). 1780 bytes result sent to driver
19/07/31 02:01:37 INFO TaskSetManager: Finished task 0.0 in stage 201.0 (TID 357) in 11 ms on localhost (executor driver) (1/1)
19/07/31 02:01:37 INFO TaskSchedulerImpl: Removed TaskSet 201.0, whose tasks have all completed, from pool 
19/07/31 02:01:37 INFO DAGScheduler: ShuffleMapStage 201 (collect at utils.scala:204) finished in 0.011 s
19/07/31 02:01:37 INFO DAGScheduler: looking for newly runnable stages
19/07/31 02:01:37 INFO DAGScheduler: running: Set()
19/07/31 02:01:37 INFO DAGScheduler: waiting: Set(ResultStage 202)
19/07/31 02:01:37 INFO DAGScheduler: failed: Set()
19/07/31 02:01:37 INFO DAGScheduler: Submitting ResultStage 202 (MapPartitionsRDD[669] at collect at utils.scala:204), which has no missing parents
19/07/31 02:01:37 INFO MemoryStore: Block broadcast_211 stored as values in memory (estimated size 7.0 KB, free 909.7 MB)
19/07/31 02:01:37 INFO MemoryStore: Block broadcast_211_piece0 stored as bytes in memory (estimated size 3.7 KB, free 909.7 MB)
19/07/31 02:01:37 INFO BlockManagerInfo: Added broadcast_211_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 911.9 MB)
19/07/31 02:01:37 INFO SparkContext: Created broadcast 211 from broadcast at DAGScheduler.scala:1006
19/07/31 02:01:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 202 (MapPartitionsRDD[669] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 02:01:37 INFO TaskSchedulerImpl: Adding task set 202.0 with 1 tasks
19/07/31 02:01:37 INFO TaskSetManager: Starting task 0.0 in stage 202.0 (TID 358, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 02:01:37 INFO Executor: Running task 0.0 in stage 202.0 (TID 358)
19/07/31 02:01:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 02:01:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 02:01:37 INFO Executor: Finished task 0.0 in stage 202.0 (TID 358). 1581 bytes result sent to driver
19/07/31 02:01:37 INFO TaskSetManager: Finished task 0.0 in stage 202.0 (TID 358) in 8 ms on localhost (executor driver) (1/1)
19/07/31 02:01:37 INFO TaskSchedulerImpl: Removed TaskSet 202.0, whose tasks have all completed, from pool 
19/07/31 02:01:37 INFO DAGScheduler: ResultStage 202 (collect at utils.scala:204) finished in 0.009 s
19/07/31 02:01:37 INFO DAGScheduler: Job 140 finished: collect at utils.scala:204, took 0.060618 s
19/07/31 02:01:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz15`
WHERE (0 = 1)
19/07/31 02:01:37 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 02:01:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 02:01:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 02:01:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 02:01:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 02:01:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 02:01:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 4370
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5047
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5510
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5348
19/07/31 02:19:03 INFO BlockManager: Removing RDD 604
19/07/31 02:19:03 INFO ContextCleaner: Cleaned RDD 604
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5466
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5296
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5506
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_200_piece0 on 127.0.0.1:53873 in memory (size: 8.5 KB, free: 911.9 MB)
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5435
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5351
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_202_piece0 on 127.0.0.1:53873 in memory (size: 3.8 KB, free: 911.9 MB)
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5120
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5437
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5464
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5507
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5511
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5297
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5081
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5438
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5350
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5118
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5185
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5078
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5560
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5173
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5052
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5111
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_187_piece0 on 127.0.0.1:53873 in memory (size: 23.8 KB, free: 911.9 MB)
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5359
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5182
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5122
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5292
19/07/31 02:19:03 INFO ContextCleaner: Cleaned shuffle 58
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_190_piece0 on 127.0.0.1:53873 in memory (size: 8.6 KB, free: 911.9 MB)
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5287
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5354
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5500
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_196_piece0 on 127.0.0.1:53873 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5124
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5077
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5113
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_193_piece0 on 127.0.0.1:53873 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5509
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5434
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5288
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5293
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5115
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5180
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_189_piece0 on 127.0.0.1:53873 in memory (size: 23.8 KB, free: 912.0 MB)
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5357
19/07/31 02:19:03 INFO ContextCleaner: Cleaned shuffle 60
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5079
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_198_piece0 on 127.0.0.1:53873 in memory (size: 8.5 KB, free: 912.0 MB)
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5501
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5356
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5049
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5505
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5106
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_206_piece0 on 127.0.0.1:53873 in memory (size: 8.6 KB, free: 912.0 MB)
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5080
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_205_piece0 on 127.0.0.1:53873 in memory (size: 23.8 KB, free: 912.0 MB)
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5499
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_195_piece0 on 127.0.0.1:53873 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5114
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5050
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_199_piece0 on 127.0.0.1:53873 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5508
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5295
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5121
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5465
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5178
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5112
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5175
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5467
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_191_piece0 on 127.0.0.1:53873 in memory (size: 24.0 KB, free: 912.0 MB)
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_201_piece0 on 127.0.0.1:53873 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_209_piece0 on 127.0.0.1:53873 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5123
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5260
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5360
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5181
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_197_piece0 on 127.0.0.1:53873 in memory (size: 11.3 KB, free: 912.1 MB)
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5436
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5048
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5179
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5409
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_203_piece0 on 127.0.0.1:53873 in memory (size: 23.8 KB, free: 912.1 MB)
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5022
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_188_piece0 on 127.0.0.1:53873 in memory (size: 4.3 KB, free: 912.1 MB)
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5355
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5298
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5110
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_210_piece0 on 127.0.0.1:53873 in memory (size: 11.9 KB, free: 912.1 MB)
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5051
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5291
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5107
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5259
19/07/31 02:19:03 INFO ContextCleaner: Cleaned shuffle 57
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5439
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5503
19/07/31 02:19:03 INFO ContextCleaner: Cleaned shuffle 56
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5117
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5502
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5174
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5290
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5352
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5358
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5183
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5294
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5116
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_204_piece0 on 127.0.0.1:53873 in memory (size: 4.3 KB, free: 912.1 MB)
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_194_piece0 on 127.0.0.1:53873 in memory (size: 11.9 KB, free: 912.1 MB)
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_211_piece0 on 127.0.0.1:53873 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5109
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5119
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_208_piece0 on 127.0.0.1:53873 in memory (size: 11.9 KB, free: 912.1 MB)
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5108
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5349
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5353
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5177
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5504
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_192_piece0 on 127.0.0.1:53873 in memory (size: 11.8 KB, free: 912.1 MB)
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5184
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_186_piece0 on 127.0.0.1:53873 in memory (size: 3.7 KB, free: 912.2 MB)
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5176
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5234
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5468
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5299
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 5289
19/07/31 02:19:03 INFO ContextCleaner: Cleaned shuffle 59
19/07/31 02:19:03 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:53873 in memory (size: 24.0 KB, free: 912.2 MB)
19/07/31 02:19:03 INFO BlockManager: Removing RDD 507
19/07/31 02:19:03 INFO ContextCleaner: Cleaned RDD 507
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 4369
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 4599
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 112
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 109
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 113
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 111
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 108
19/07/31 02:19:03 INFO BlockManager: Removing RDD 15
19/07/31 02:19:03 INFO ContextCleaner: Cleaned RDD 15
19/07/31 02:19:03 INFO ContextCleaner: Cleaned accumulator 110
19/07/31 10:00:02 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:00:02 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:00:02 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:00:02 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:00:02 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:00:02 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:00:02 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:00:02 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 10:00:02 INFO DAGScheduler: Got job 141 (collect at utils.scala:44) with 4 output partitions
19/07/31 10:00:02 INFO DAGScheduler: Final stage: ResultStage 203 (collect at utils.scala:44)
19/07/31 10:00:02 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:00:02 INFO DAGScheduler: Missing parents: List()
19/07/31 10:00:02 INFO DAGScheduler: Submitting ResultStage 203 (MapPartitionsRDD[674] at map at utils.scala:41), which has no missing parents
19/07/31 10:00:02 INFO MemoryStore: Block broadcast_212 stored as values in memory (estimated size 7.3 KB, free 911.9 MB)
19/07/31 10:00:02 INFO MemoryStore: Block broadcast_212_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.9 MB)
19/07/31 10:00:02 INFO BlockManagerInfo: Added broadcast_212_piece0 in memory on 127.0.0.1:53873 (size: 3.8 KB, free: 912.2 MB)
19/07/31 10:00:02 INFO SparkContext: Created broadcast 212 from broadcast at DAGScheduler.scala:1006
19/07/31 10:00:02 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 203 (MapPartitionsRDD[674] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 10:00:02 INFO TaskSchedulerImpl: Adding task set 203.0 with 4 tasks
19/07/31 10:00:02 INFO TaskSetManager: Starting task 0.0 in stage 203.0 (TID 359, localhost, executor driver, partition 0, PROCESS_LOCAL, 5084 bytes)
19/07/31 10:00:02 INFO TaskSetManager: Starting task 1.0 in stage 203.0 (TID 360, localhost, executor driver, partition 1, PROCESS_LOCAL, 5141 bytes)
19/07/31 10:00:02 INFO TaskSetManager: Starting task 2.0 in stage 203.0 (TID 361, localhost, executor driver, partition 2, PROCESS_LOCAL, 5100 bytes)
19/07/31 10:00:02 INFO TaskSetManager: Starting task 3.0 in stage 203.0 (TID 362, localhost, executor driver, partition 3, PROCESS_LOCAL, 5141 bytes)
19/07/31 10:00:02 INFO Executor: Running task 1.0 in stage 203.0 (TID 360)
19/07/31 10:00:02 INFO Executor: Running task 0.0 in stage 203.0 (TID 359)
19/07/31 10:00:02 INFO Executor: Running task 2.0 in stage 203.0 (TID 361)
19/07/31 10:00:02 INFO Executor: Finished task 0.0 in stage 203.0 (TID 359). 1012 bytes result sent to driver
19/07/31 10:00:02 INFO Executor: Running task 3.0 in stage 203.0 (TID 362)
19/07/31 10:00:02 INFO Executor: Finished task 2.0 in stage 203.0 (TID 361). 983 bytes result sent to driver
19/07/31 10:00:02 INFO Executor: Finished task 1.0 in stage 203.0 (TID 360). 1035 bytes result sent to driver
19/07/31 10:00:02 INFO Executor: Finished task 3.0 in stage 203.0 (TID 362). 990 bytes result sent to driver
19/07/31 10:00:02 INFO TaskSetManager: Finished task 0.0 in stage 203.0 (TID 359) in 23 ms on localhost (executor driver) (1/4)
19/07/31 10:00:02 INFO TaskSetManager: Finished task 2.0 in stage 203.0 (TID 361) in 14 ms on localhost (executor driver) (2/4)
19/07/31 10:00:02 INFO TaskSetManager: Finished task 1.0 in stage 203.0 (TID 360) in 14 ms on localhost (executor driver) (3/4)
19/07/31 10:00:02 INFO TaskSetManager: Finished task 3.0 in stage 203.0 (TID 362) in 15 ms on localhost (executor driver) (4/4)
19/07/31 10:00:02 INFO TaskSchedulerImpl: Removed TaskSet 203.0, whose tasks have all completed, from pool 
19/07/31 10:00:02 INFO DAGScheduler: ResultStage 203 (collect at utils.scala:44) finished in 0.024 s
19/07/31 10:00:02 INFO DAGScheduler: Job 141 finished: collect at utils.scala:44, took 0.062605 s
19/07/31 10:00:02 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 10:00:03 INFO MapPartitionsRDD: Removing RDD 657 from persistence list
19/07/31 10:00:03 INFO BlockManager: Removing RDD 657
19/07/31 10:00:03 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:00:03 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#8663)) > 0)
19/07/31 10:00:03 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 10:00:03 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:00:03 INFO MemoryStore: Block broadcast_213 stored as values in memory (estimated size 281.2 KB, free 911.7 MB)
19/07/31 10:00:03 INFO MemoryStore: Block broadcast_213_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.6 MB)
19/07/31 10:00:03 INFO BlockManagerInfo: Added broadcast_213_piece0 in memory on 127.0.0.1:53873 (size: 23.8 KB, free: 912.2 MB)
19/07/31 10:00:03 INFO SparkContext: Created broadcast 213 from csv at NativeMethodAccessorImpl.java:0
19/07/31 10:00:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:00:03 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 10:00:03 INFO DAGScheduler: Got job 142 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 10:00:03 INFO DAGScheduler: Final stage: ResultStage 204 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 10:00:03 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:00:03 INFO DAGScheduler: Missing parents: List()
19/07/31 10:00:03 INFO DAGScheduler: Submitting ResultStage 204 (MapPartitionsRDD[677] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:00:03 INFO MemoryStore: Block broadcast_214 stored as values in memory (estimated size 8.2 KB, free 911.6 MB)
19/07/31 10:00:03 INFO MemoryStore: Block broadcast_214_piece0 stored as bytes in memory (estimated size 4.3 KB, free 911.6 MB)
19/07/31 10:00:03 INFO BlockManagerInfo: Added broadcast_214_piece0 in memory on 127.0.0.1:53873 (size: 4.3 KB, free: 912.2 MB)
19/07/31 10:00:03 INFO SparkContext: Created broadcast 214 from broadcast at DAGScheduler.scala:1006
19/07/31 10:00:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 204 (MapPartitionsRDD[677] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:00:03 INFO TaskSchedulerImpl: Adding task set 204.0 with 1 tasks
19/07/31 10:00:03 INFO TaskSetManager: Starting task 0.0 in stage 204.0 (TID 363, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:00:03 INFO Executor: Running task 0.0 in stage 204.0 (TID 363)
19/07/31 10:00:03 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:00:03 INFO Executor: Finished task 0.0 in stage 204.0 (TID 363). 1394 bytes result sent to driver
19/07/31 10:00:03 INFO TaskSetManager: Finished task 0.0 in stage 204.0 (TID 363) in 20 ms on localhost (executor driver) (1/1)
19/07/31 10:00:03 INFO TaskSchedulerImpl: Removed TaskSet 204.0, whose tasks have all completed, from pool 
19/07/31 10:00:03 INFO DAGScheduler: ResultStage 204 (csv at NativeMethodAccessorImpl.java:0) finished in 0.022 s
19/07/31 10:00:03 INFO DAGScheduler: Job 142 finished: csv at NativeMethodAccessorImpl.java:0, took 0.056153 s
19/07/31 10:00:03 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:00:03 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 10:00:03 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 10:00:03 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:00:03 INFO MemoryStore: Block broadcast_215 stored as values in memory (estimated size 281.2 KB, free 911.4 MB)
19/07/31 10:00:03 INFO MemoryStore: Block broadcast_215_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.3 MB)
19/07/31 10:00:03 INFO BlockManagerInfo: Added broadcast_215_piece0 in memory on 127.0.0.1:53873 (size: 23.8 KB, free: 912.2 MB)
19/07/31 10:00:03 INFO SparkContext: Created broadcast 215 from csv at NativeMethodAccessorImpl.java:0
19/07/31 10:00:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:00:03 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 10:00:03 INFO DAGScheduler: Got job 143 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 10:00:03 INFO DAGScheduler: Final stage: ResultStage 205 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 10:00:03 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:00:03 INFO DAGScheduler: Missing parents: List()
19/07/31 10:00:03 INFO DAGScheduler: Submitting ResultStage 205 (MapPartitionsRDD[682] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:00:03 INFO MemoryStore: Block broadcast_216 stored as values in memory (estimated size 14.8 KB, free 911.3 MB)
19/07/31 10:00:03 INFO MemoryStore: Block broadcast_216_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.3 MB)
19/07/31 10:00:03 INFO BlockManagerInfo: Added broadcast_216_piece0 in memory on 127.0.0.1:53873 (size: 8.6 KB, free: 912.2 MB)
19/07/31 10:00:03 INFO SparkContext: Created broadcast 216 from broadcast at DAGScheduler.scala:1006
19/07/31 10:00:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 205 (MapPartitionsRDD[682] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:00:03 INFO TaskSchedulerImpl: Adding task set 205.0 with 1 tasks
19/07/31 10:00:03 INFO TaskSetManager: Starting task 0.0 in stage 205.0 (TID 364, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:00:03 INFO Executor: Running task 0.0 in stage 205.0 (TID 364)
19/07/31 10:00:03 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:00:03 INFO Executor: Finished task 0.0 in stage 205.0 (TID 364). 1627 bytes result sent to driver
19/07/31 10:00:03 INFO TaskSetManager: Finished task 0.0 in stage 205.0 (TID 364) in 23 ms on localhost (executor driver) (1/1)
19/07/31 10:00:03 INFO TaskSchedulerImpl: Removed TaskSet 205.0, whose tasks have all completed, from pool 
19/07/31 10:00:03 INFO DAGScheduler: ResultStage 205 (csv at NativeMethodAccessorImpl.java:0) finished in 0.023 s
19/07/31 10:00:03 INFO DAGScheduler: Job 143 finished: csv at NativeMethodAccessorImpl.java:0, took 0.032571 s
19/07/31 10:00:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:00:03 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:00:03 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:00:03 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:00:03 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:00:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:00:03 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:00:03 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 10:00:03 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 10:00:03 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 10:00:03 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:00:03 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 10:00:03 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 10:00:03 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:00:03 INFO MemoryStore: Block broadcast_217 stored as values in memory (estimated size 282.3 KB, free 911.0 MB)
19/07/31 10:00:03 INFO MemoryStore: Block broadcast_217_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.0 MB)
19/07/31 10:00:03 INFO BlockManagerInfo: Added broadcast_217_piece0 in memory on 127.0.0.1:53873 (size: 24.0 KB, free: 912.1 MB)
19/07/31 10:00:03 INFO SparkContext: Created broadcast 217 from sql at NativeMethodAccessorImpl.java:0
19/07/31 10:00:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:00:03 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 10:00:03 INFO DAGScheduler: Registering RDD 688 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 10:00:03 INFO DAGScheduler: Got job 144 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 10:00:03 INFO DAGScheduler: Final stage: ResultStage 207 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 10:00:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 206)
19/07/31 10:00:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 206)
19/07/31 10:00:03 INFO DAGScheduler: Submitting ShuffleMapStage 206 (MapPartitionsRDD[688] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:00:03 INFO MemoryStore: Block broadcast_218 stored as values in memory (estimated size 26.3 KB, free 911.0 MB)
19/07/31 10:00:03 INFO MemoryStore: Block broadcast_218_piece0 stored as bytes in memory (estimated size 11.8 KB, free 911.0 MB)
19/07/31 10:00:03 INFO BlockManagerInfo: Added broadcast_218_piece0 in memory on 127.0.0.1:53873 (size: 11.8 KB, free: 912.1 MB)
19/07/31 10:00:03 INFO SparkContext: Created broadcast 218 from broadcast at DAGScheduler.scala:1006
19/07/31 10:00:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 206 (MapPartitionsRDD[688] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:00:03 INFO TaskSchedulerImpl: Adding task set 206.0 with 1 tasks
19/07/31 10:00:03 INFO TaskSetManager: Starting task 0.0 in stage 206.0 (TID 365, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 10:00:03 INFO Executor: Running task 0.0 in stage 206.0 (TID 365)
19/07/31 10:00:03 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:00:03 INFO MemoryStore: Block rdd_685_0 stored as values in memory (estimated size 48.9 KB, free 910.9 MB)
19/07/31 10:00:03 INFO BlockManagerInfo: Added rdd_685_0 in memory on 127.0.0.1:53873 (size: 48.9 KB, free: 912.1 MB)
19/07/31 10:00:03 INFO Executor: Finished task 0.0 in stage 206.0 (TID 365). 2461 bytes result sent to driver
19/07/31 10:00:03 INFO TaskSetManager: Finished task 0.0 in stage 206.0 (TID 365) in 66 ms on localhost (executor driver) (1/1)
19/07/31 10:00:03 INFO TaskSchedulerImpl: Removed TaskSet 206.0, whose tasks have all completed, from pool 
19/07/31 10:00:03 INFO DAGScheduler: ShuffleMapStage 206 (sql at NativeMethodAccessorImpl.java:0) finished in 0.068 s
19/07/31 10:00:03 INFO DAGScheduler: looking for newly runnable stages
19/07/31 10:00:03 INFO DAGScheduler: running: Set()
19/07/31 10:00:03 INFO DAGScheduler: waiting: Set(ResultStage 207)
19/07/31 10:00:03 INFO DAGScheduler: failed: Set()
19/07/31 10:00:03 INFO DAGScheduler: Submitting ResultStage 207 (MapPartitionsRDD[691] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:00:03 INFO MemoryStore: Block broadcast_219 stored as values in memory (estimated size 7.0 KB, free 910.9 MB)
19/07/31 10:00:03 INFO MemoryStore: Block broadcast_219_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.9 MB)
19/07/31 10:00:03 INFO BlockManagerInfo: Added broadcast_219_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 912.1 MB)
19/07/31 10:00:03 INFO SparkContext: Created broadcast 219 from broadcast at DAGScheduler.scala:1006
19/07/31 10:00:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 207 (MapPartitionsRDD[691] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:00:03 INFO TaskSchedulerImpl: Adding task set 207.0 with 1 tasks
19/07/31 10:00:03 INFO TaskSetManager: Starting task 0.0 in stage 207.0 (TID 366, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 10:00:03 INFO Executor: Running task 0.0 in stage 207.0 (TID 366)
19/07/31 10:00:03 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 10:00:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 10:00:03 INFO Executor: Finished task 0.0 in stage 207.0 (TID 366). 1581 bytes result sent to driver
19/07/31 10:00:03 INFO TaskSetManager: Finished task 0.0 in stage 207.0 (TID 366) in 8 ms on localhost (executor driver) (1/1)
19/07/31 10:00:03 INFO TaskSchedulerImpl: Removed TaskSet 207.0, whose tasks have all completed, from pool 
19/07/31 10:00:03 INFO DAGScheduler: ResultStage 207 (sql at NativeMethodAccessorImpl.java:0) finished in 0.008 s
19/07/31 10:00:03 INFO DAGScheduler: Job 144 finished: sql at NativeMethodAccessorImpl.java:0, took 0.101315 s
19/07/31 10:00:03 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 10:00:03 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:00:03 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:00:03 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 10:00:03 INFO DAGScheduler: Registering RDD 694 (collect at utils.scala:204)
19/07/31 10:00:03 INFO DAGScheduler: Got job 145 (collect at utils.scala:204) with 1 output partitions
19/07/31 10:00:03 INFO DAGScheduler: Final stage: ResultStage 209 (collect at utils.scala:204)
19/07/31 10:00:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 208)
19/07/31 10:00:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 208)
19/07/31 10:00:03 INFO DAGScheduler: Submitting ShuffleMapStage 208 (MapPartitionsRDD[694] at collect at utils.scala:204), which has no missing parents
19/07/31 10:00:03 INFO MemoryStore: Block broadcast_220 stored as values in memory (estimated size 26.3 KB, free 910.9 MB)
19/07/31 10:00:03 INFO MemoryStore: Block broadcast_220_piece0 stored as bytes in memory (estimated size 11.9 KB, free 910.9 MB)
19/07/31 10:00:03 INFO BlockManagerInfo: Added broadcast_220_piece0 in memory on 127.0.0.1:53873 (size: 11.9 KB, free: 912.1 MB)
19/07/31 10:00:03 INFO SparkContext: Created broadcast 220 from broadcast at DAGScheduler.scala:1006
19/07/31 10:00:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 208 (MapPartitionsRDD[694] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:00:03 INFO TaskSchedulerImpl: Adding task set 208.0 with 1 tasks
19/07/31 10:00:03 INFO TaskSetManager: Starting task 0.0 in stage 208.0 (TID 367, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 10:00:03 INFO Executor: Running task 0.0 in stage 208.0 (TID 367)
19/07/31 10:00:03 INFO BlockManager: Found block rdd_685_0 locally
19/07/31 10:00:03 INFO Executor: Finished task 0.0 in stage 208.0 (TID 367). 1780 bytes result sent to driver
19/07/31 10:00:03 INFO TaskSetManager: Finished task 0.0 in stage 208.0 (TID 367) in 6 ms on localhost (executor driver) (1/1)
19/07/31 10:00:03 INFO TaskSchedulerImpl: Removed TaskSet 208.0, whose tasks have all completed, from pool 
19/07/31 10:00:03 INFO DAGScheduler: ShuffleMapStage 208 (collect at utils.scala:204) finished in 0.006 s
19/07/31 10:00:03 INFO DAGScheduler: looking for newly runnable stages
19/07/31 10:00:03 INFO DAGScheduler: running: Set()
19/07/31 10:00:03 INFO DAGScheduler: waiting: Set(ResultStage 209)
19/07/31 10:00:03 INFO DAGScheduler: failed: Set()
19/07/31 10:00:03 INFO DAGScheduler: Submitting ResultStage 209 (MapPartitionsRDD[697] at collect at utils.scala:204), which has no missing parents
19/07/31 10:00:03 INFO MemoryStore: Block broadcast_221 stored as values in memory (estimated size 7.0 KB, free 910.9 MB)
19/07/31 10:00:03 INFO MemoryStore: Block broadcast_221_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.9 MB)
19/07/31 10:00:03 INFO BlockManagerInfo: Added broadcast_221_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 912.1 MB)
19/07/31 10:00:03 INFO SparkContext: Created broadcast 221 from broadcast at DAGScheduler.scala:1006
19/07/31 10:00:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 209 (MapPartitionsRDD[697] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:00:03 INFO TaskSchedulerImpl: Adding task set 209.0 with 1 tasks
19/07/31 10:00:03 INFO TaskSetManager: Starting task 0.0 in stage 209.0 (TID 368, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 10:00:03 INFO Executor: Running task 0.0 in stage 209.0 (TID 368)
19/07/31 10:00:03 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 10:00:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 10:00:03 INFO Executor: Finished task 0.0 in stage 209.0 (TID 368). 1538 bytes result sent to driver
19/07/31 10:00:03 INFO TaskSetManager: Finished task 0.0 in stage 209.0 (TID 368) in 4 ms on localhost (executor driver) (1/1)
19/07/31 10:00:03 INFO TaskSchedulerImpl: Removed TaskSet 209.0, whose tasks have all completed, from pool 
19/07/31 10:00:03 INFO DAGScheduler: ResultStage 209 (collect at utils.scala:204) finished in 0.004 s
19/07/31 10:00:03 INFO DAGScheduler: Job 145 finished: collect at utils.scala:204, took 0.042074 s
19/07/31 10:00:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz16`
WHERE (0 = 1)
19/07/31 10:00:04 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:00:04 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:00:04 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:00:04 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:00:04 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:00:04 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:00:04 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:00:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:00:19 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:00:19 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:00:19 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:00:19 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:00:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:00:19 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:00:19 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 10:00:19 INFO DAGScheduler: Got job 146 (collect at utils.scala:44) with 4 output partitions
19/07/31 10:00:19 INFO DAGScheduler: Final stage: ResultStage 210 (collect at utils.scala:44)
19/07/31 10:00:19 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:00:19 INFO DAGScheduler: Missing parents: List()
19/07/31 10:00:19 INFO DAGScheduler: Submitting ResultStage 210 (MapPartitionsRDD[702] at map at utils.scala:41), which has no missing parents
19/07/31 10:00:19 INFO MemoryStore: Block broadcast_222 stored as values in memory (estimated size 7.3 KB, free 910.9 MB)
19/07/31 10:00:19 INFO MemoryStore: Block broadcast_222_piece0 stored as bytes in memory (estimated size 3.8 KB, free 910.9 MB)
19/07/31 10:00:19 INFO BlockManagerInfo: Added broadcast_222_piece0 in memory on 127.0.0.1:53873 (size: 3.8 KB, free: 912.1 MB)
19/07/31 10:00:19 INFO SparkContext: Created broadcast 222 from broadcast at DAGScheduler.scala:1006
19/07/31 10:00:19 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 210 (MapPartitionsRDD[702] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 10:00:19 INFO TaskSchedulerImpl: Adding task set 210.0 with 4 tasks
19/07/31 10:00:19 INFO TaskSetManager: Starting task 0.0 in stage 210.0 (TID 369, localhost, executor driver, partition 0, PROCESS_LOCAL, 5084 bytes)
19/07/31 10:00:19 INFO TaskSetManager: Starting task 1.0 in stage 210.0 (TID 370, localhost, executor driver, partition 1, PROCESS_LOCAL, 5141 bytes)
19/07/31 10:00:19 INFO TaskSetManager: Starting task 2.0 in stage 210.0 (TID 371, localhost, executor driver, partition 2, PROCESS_LOCAL, 5100 bytes)
19/07/31 10:00:19 INFO TaskSetManager: Starting task 3.0 in stage 210.0 (TID 372, localhost, executor driver, partition 3, PROCESS_LOCAL, 5141 bytes)
19/07/31 10:00:19 INFO Executor: Running task 1.0 in stage 210.0 (TID 370)
19/07/31 10:00:19 INFO Executor: Running task 0.0 in stage 210.0 (TID 369)
19/07/31 10:00:19 INFO Executor: Running task 2.0 in stage 210.0 (TID 371)
19/07/31 10:00:19 INFO Executor: Running task 3.0 in stage 210.0 (TID 372)
19/07/31 10:00:19 INFO Executor: Finished task 0.0 in stage 210.0 (TID 369). 1055 bytes result sent to driver
19/07/31 10:00:19 INFO Executor: Finished task 1.0 in stage 210.0 (TID 370). 1035 bytes result sent to driver
19/07/31 10:00:19 INFO TaskSetManager: Finished task 0.0 in stage 210.0 (TID 369) in 11 ms on localhost (executor driver) (1/4)
19/07/31 10:00:19 INFO Executor: Finished task 3.0 in stage 210.0 (TID 372). 1033 bytes result sent to driver
19/07/31 10:00:19 INFO TaskSetManager: Finished task 1.0 in stage 210.0 (TID 370) in 10 ms on localhost (executor driver) (2/4)
19/07/31 10:00:19 INFO TaskSetManager: Finished task 3.0 in stage 210.0 (TID 372) in 10 ms on localhost (executor driver) (3/4)
19/07/31 10:00:19 INFO Executor: Finished task 2.0 in stage 210.0 (TID 371). 1026 bytes result sent to driver
19/07/31 10:00:19 INFO TaskSetManager: Finished task 2.0 in stage 210.0 (TID 371) in 11 ms on localhost (executor driver) (4/4)
19/07/31 10:00:19 INFO TaskSchedulerImpl: Removed TaskSet 210.0, whose tasks have all completed, from pool 
19/07/31 10:00:19 INFO DAGScheduler: ResultStage 210 (collect at utils.scala:44) finished in 0.013 s
19/07/31 10:00:19 INFO DAGScheduler: Job 146 finished: collect at utils.scala:44, took 0.026025 s
19/07/31 10:00:19 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 10:00:19 INFO MapPartitionsRDD: Removing RDD 685 from persistence list
19/07/31 10:00:19 INFO BlockManager: Removing RDD 685
19/07/31 10:00:19 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:00:19 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#9042)) > 0)
19/07/31 10:00:19 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 10:00:19 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:00:19 INFO MemoryStore: Block broadcast_223 stored as values in memory (estimated size 281.2 KB, free 910.6 MB)
19/07/31 10:00:19 INFO MemoryStore: Block broadcast_223_piece0 stored as bytes in memory (estimated size 23.8 KB, free 910.6 MB)
19/07/31 10:00:19 INFO BlockManagerInfo: Added broadcast_223_piece0 in memory on 127.0.0.1:53873 (size: 23.8 KB, free: 912.1 MB)
19/07/31 10:00:19 INFO SparkContext: Created broadcast 223 from csv at NativeMethodAccessorImpl.java:0
19/07/31 10:00:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:00:19 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 10:00:19 INFO DAGScheduler: Got job 147 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 10:00:19 INFO DAGScheduler: Final stage: ResultStage 211 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 10:00:19 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:00:19 INFO DAGScheduler: Missing parents: List()
19/07/31 10:00:19 INFO DAGScheduler: Submitting ResultStage 211 (MapPartitionsRDD[705] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:00:19 INFO MemoryStore: Block broadcast_224 stored as values in memory (estimated size 8.2 KB, free 910.6 MB)
19/07/31 10:00:19 INFO MemoryStore: Block broadcast_224_piece0 stored as bytes in memory (estimated size 4.3 KB, free 910.6 MB)
19/07/31 10:00:19 INFO BlockManagerInfo: Added broadcast_224_piece0 in memory on 127.0.0.1:53873 (size: 4.3 KB, free: 912.1 MB)
19/07/31 10:00:19 INFO SparkContext: Created broadcast 224 from broadcast at DAGScheduler.scala:1006
19/07/31 10:00:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 211 (MapPartitionsRDD[705] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:00:19 INFO TaskSchedulerImpl: Adding task set 211.0 with 1 tasks
19/07/31 10:00:19 INFO TaskSetManager: Starting task 0.0 in stage 211.0 (TID 373, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:00:19 INFO Executor: Running task 0.0 in stage 211.0 (TID 373)
19/07/31 10:00:19 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:00:19 INFO Executor: Finished task 0.0 in stage 211.0 (TID 373). 1394 bytes result sent to driver
19/07/31 10:00:19 INFO TaskSetManager: Finished task 0.0 in stage 211.0 (TID 373) in 8 ms on localhost (executor driver) (1/1)
19/07/31 10:00:19 INFO TaskSchedulerImpl: Removed TaskSet 211.0, whose tasks have all completed, from pool 
19/07/31 10:00:19 INFO DAGScheduler: ResultStage 211 (csv at NativeMethodAccessorImpl.java:0) finished in 0.008 s
19/07/31 10:00:19 INFO DAGScheduler: Job 147 finished: csv at NativeMethodAccessorImpl.java:0, took 0.021703 s
19/07/31 10:00:19 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:00:19 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 10:00:19 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 10:00:19 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:00:19 INFO MemoryStore: Block broadcast_225 stored as values in memory (estimated size 281.2 KB, free 910.3 MB)
19/07/31 10:00:19 INFO MemoryStore: Block broadcast_225_piece0 stored as bytes in memory (estimated size 23.8 KB, free 910.3 MB)
19/07/31 10:00:19 INFO BlockManagerInfo: Added broadcast_225_piece0 in memory on 127.0.0.1:53873 (size: 23.8 KB, free: 912.1 MB)
19/07/31 10:00:19 INFO SparkContext: Created broadcast 225 from csv at NativeMethodAccessorImpl.java:0
19/07/31 10:00:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:00:19 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 10:00:19 INFO DAGScheduler: Got job 148 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 10:00:19 INFO DAGScheduler: Final stage: ResultStage 212 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 10:00:19 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:00:19 INFO DAGScheduler: Missing parents: List()
19/07/31 10:00:19 INFO DAGScheduler: Submitting ResultStage 212 (MapPartitionsRDD[710] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:00:19 INFO MemoryStore: Block broadcast_226 stored as values in memory (estimated size 14.8 KB, free 910.3 MB)
19/07/31 10:00:19 INFO MemoryStore: Block broadcast_226_piece0 stored as bytes in memory (estimated size 8.6 KB, free 910.3 MB)
19/07/31 10:00:19 INFO BlockManagerInfo: Added broadcast_226_piece0 in memory on 127.0.0.1:53873 (size: 8.6 KB, free: 912.0 MB)
19/07/31 10:00:19 INFO SparkContext: Created broadcast 226 from broadcast at DAGScheduler.scala:1006
19/07/31 10:00:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 212 (MapPartitionsRDD[710] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:00:19 INFO TaskSchedulerImpl: Adding task set 212.0 with 1 tasks
19/07/31 10:00:19 INFO TaskSetManager: Starting task 0.0 in stage 212.0 (TID 374, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:00:19 INFO Executor: Running task 0.0 in stage 212.0 (TID 374)
19/07/31 10:00:19 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:00:19 INFO Executor: Finished task 0.0 in stage 212.0 (TID 374). 1584 bytes result sent to driver
19/07/31 10:00:19 INFO TaskSetManager: Finished task 0.0 in stage 212.0 (TID 374) in 22 ms on localhost (executor driver) (1/1)
19/07/31 10:00:19 INFO TaskSchedulerImpl: Removed TaskSet 212.0, whose tasks have all completed, from pool 
19/07/31 10:00:19 INFO DAGScheduler: ResultStage 212 (csv at NativeMethodAccessorImpl.java:0) finished in 0.022 s
19/07/31 10:00:19 INFO DAGScheduler: Job 148 finished: csv at NativeMethodAccessorImpl.java:0, took 0.034298 s
19/07/31 10:00:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:00:19 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:00:19 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:00:19 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:00:19 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:00:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:00:19 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:00:19 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 10:00:19 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 10:00:19 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 10:00:19 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:00:19 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 10:00:19 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 10:00:19 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:00:19 INFO MemoryStore: Block broadcast_227 stored as values in memory (estimated size 282.3 KB, free 910.0 MB)
19/07/31 10:00:19 INFO MemoryStore: Block broadcast_227_piece0 stored as bytes in memory (estimated size 24.0 KB, free 910.0 MB)
19/07/31 10:00:19 INFO BlockManagerInfo: Added broadcast_227_piece0 in memory on 127.0.0.1:53873 (size: 24.0 KB, free: 912.0 MB)
19/07/31 10:00:19 INFO SparkContext: Created broadcast 227 from sql at NativeMethodAccessorImpl.java:0
19/07/31 10:00:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:00:19 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 10:00:19 INFO DAGScheduler: Registering RDD 716 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 10:00:19 INFO DAGScheduler: Got job 149 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 10:00:19 INFO DAGScheduler: Final stage: ResultStage 214 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 10:00:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 213)
19/07/31 10:00:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 213)
19/07/31 10:00:19 INFO DAGScheduler: Submitting ShuffleMapStage 213 (MapPartitionsRDD[716] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:00:19 INFO MemoryStore: Block broadcast_228 stored as values in memory (estimated size 26.3 KB, free 909.9 MB)
19/07/31 10:00:19 INFO MemoryStore: Block broadcast_228_piece0 stored as bytes in memory (estimated size 11.9 KB, free 909.9 MB)
19/07/31 10:00:19 INFO BlockManagerInfo: Added broadcast_228_piece0 in memory on 127.0.0.1:53873 (size: 11.9 KB, free: 912.0 MB)
19/07/31 10:00:19 INFO SparkContext: Created broadcast 228 from broadcast at DAGScheduler.scala:1006
19/07/31 10:00:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 213 (MapPartitionsRDD[716] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:00:19 INFO TaskSchedulerImpl: Adding task set 213.0 with 1 tasks
19/07/31 10:00:19 INFO TaskSetManager: Starting task 0.0 in stage 213.0 (TID 375, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 10:00:19 INFO Executor: Running task 0.0 in stage 213.0 (TID 375)
19/07/31 10:00:19 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:00:19 INFO MemoryStore: Block rdd_713_0 stored as values in memory (estimated size 48.9 KB, free 909.9 MB)
19/07/31 10:00:19 INFO BlockManagerInfo: Added rdd_713_0 in memory on 127.0.0.1:53873 (size: 48.9 KB, free: 912.0 MB)
19/07/31 10:00:19 INFO Executor: Finished task 0.0 in stage 213.0 (TID 375). 2461 bytes result sent to driver
19/07/31 10:00:19 INFO TaskSetManager: Finished task 0.0 in stage 213.0 (TID 375) in 47 ms on localhost (executor driver) (1/1)
19/07/31 10:00:19 INFO TaskSchedulerImpl: Removed TaskSet 213.0, whose tasks have all completed, from pool 
19/07/31 10:00:19 INFO DAGScheduler: ShuffleMapStage 213 (sql at NativeMethodAccessorImpl.java:0) finished in 0.048 s
19/07/31 10:00:19 INFO DAGScheduler: looking for newly runnable stages
19/07/31 10:00:19 INFO DAGScheduler: running: Set()
19/07/31 10:00:19 INFO DAGScheduler: waiting: Set(ResultStage 214)
19/07/31 10:00:19 INFO DAGScheduler: failed: Set()
19/07/31 10:00:19 INFO DAGScheduler: Submitting ResultStage 214 (MapPartitionsRDD[719] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:00:19 INFO MemoryStore: Block broadcast_229 stored as values in memory (estimated size 7.0 KB, free 909.9 MB)
19/07/31 10:00:19 INFO MemoryStore: Block broadcast_229_piece0 stored as bytes in memory (estimated size 3.7 KB, free 909.9 MB)
19/07/31 10:00:19 INFO BlockManagerInfo: Added broadcast_229_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 912.0 MB)
19/07/31 10:00:19 INFO SparkContext: Created broadcast 229 from broadcast at DAGScheduler.scala:1006
19/07/31 10:00:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 214 (MapPartitionsRDD[719] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:00:19 INFO TaskSchedulerImpl: Adding task set 214.0 with 1 tasks
19/07/31 10:00:19 INFO TaskSetManager: Starting task 0.0 in stage 214.0 (TID 376, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 10:00:19 INFO Executor: Running task 0.0 in stage 214.0 (TID 376)
19/07/31 10:00:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 10:00:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 10:00:19 INFO Executor: Finished task 0.0 in stage 214.0 (TID 376). 1581 bytes result sent to driver
19/07/31 10:00:19 INFO TaskSetManager: Finished task 0.0 in stage 214.0 (TID 376) in 5 ms on localhost (executor driver) (1/1)
19/07/31 10:00:19 INFO TaskSchedulerImpl: Removed TaskSet 214.0, whose tasks have all completed, from pool 
19/07/31 10:00:19 INFO DAGScheduler: ResultStage 214 (sql at NativeMethodAccessorImpl.java:0) finished in 0.005 s
19/07/31 10:00:19 INFO DAGScheduler: Job 149 finished: sql at NativeMethodAccessorImpl.java:0, took 0.076442 s
19/07/31 10:00:19 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 10:00:19 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:00:19 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:00:19 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 10:00:19 INFO DAGScheduler: Registering RDD 722 (collect at utils.scala:204)
19/07/31 10:00:19 INFO DAGScheduler: Got job 150 (collect at utils.scala:204) with 1 output partitions
19/07/31 10:00:19 INFO DAGScheduler: Final stage: ResultStage 216 (collect at utils.scala:204)
19/07/31 10:00:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 215)
19/07/31 10:00:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 215)
19/07/31 10:00:19 INFO DAGScheduler: Submitting ShuffleMapStage 215 (MapPartitionsRDD[722] at collect at utils.scala:204), which has no missing parents
19/07/31 10:00:19 INFO MemoryStore: Block broadcast_230 stored as values in memory (estimated size 26.3 KB, free 909.9 MB)
19/07/31 10:00:19 INFO MemoryStore: Block broadcast_230_piece0 stored as bytes in memory (estimated size 11.8 KB, free 909.8 MB)
19/07/31 10:00:19 INFO BlockManagerInfo: Added broadcast_230_piece0 in memory on 127.0.0.1:53873 (size: 11.8 KB, free: 911.9 MB)
19/07/31 10:00:19 INFO SparkContext: Created broadcast 230 from broadcast at DAGScheduler.scala:1006
19/07/31 10:00:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 215 (MapPartitionsRDD[722] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:00:19 INFO TaskSchedulerImpl: Adding task set 215.0 with 1 tasks
19/07/31 10:00:19 INFO TaskSetManager: Starting task 0.0 in stage 215.0 (TID 377, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 10:00:19 INFO Executor: Running task 0.0 in stage 215.0 (TID 377)
19/07/31 10:00:19 INFO BlockManager: Found block rdd_713_0 locally
19/07/31 10:00:19 INFO Executor: Finished task 0.0 in stage 215.0 (TID 377). 1780 bytes result sent to driver
19/07/31 10:00:19 INFO TaskSetManager: Finished task 0.0 in stage 215.0 (TID 377) in 14 ms on localhost (executor driver) (1/1)
19/07/31 10:00:19 INFO TaskSchedulerImpl: Removed TaskSet 215.0, whose tasks have all completed, from pool 
19/07/31 10:00:19 INFO DAGScheduler: ShuffleMapStage 215 (collect at utils.scala:204) finished in 0.015 s
19/07/31 10:00:19 INFO DAGScheduler: looking for newly runnable stages
19/07/31 10:00:19 INFO DAGScheduler: running: Set()
19/07/31 10:00:19 INFO DAGScheduler: waiting: Set(ResultStage 216)
19/07/31 10:00:19 INFO DAGScheduler: failed: Set()
19/07/31 10:00:19 INFO DAGScheduler: Submitting ResultStage 216 (MapPartitionsRDD[725] at collect at utils.scala:204), which has no missing parents
19/07/31 10:00:19 INFO MemoryStore: Block broadcast_231 stored as values in memory (estimated size 7.0 KB, free 909.8 MB)
19/07/31 10:00:19 INFO MemoryStore: Block broadcast_231_piece0 stored as bytes in memory (estimated size 3.7 KB, free 909.8 MB)
19/07/31 10:00:19 INFO BlockManagerInfo: Added broadcast_231_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 911.9 MB)
19/07/31 10:00:19 INFO SparkContext: Created broadcast 231 from broadcast at DAGScheduler.scala:1006
19/07/31 10:00:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 216 (MapPartitionsRDD[725] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:00:19 INFO TaskSchedulerImpl: Adding task set 216.0 with 1 tasks
19/07/31 10:00:19 INFO TaskSetManager: Starting task 0.0 in stage 216.0 (TID 378, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 10:00:19 INFO Executor: Running task 0.0 in stage 216.0 (TID 378)
19/07/31 10:00:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 10:00:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 10:00:19 INFO Executor: Finished task 0.0 in stage 216.0 (TID 378). 1581 bytes result sent to driver
19/07/31 10:00:19 INFO TaskSetManager: Finished task 0.0 in stage 216.0 (TID 378) in 4 ms on localhost (executor driver) (1/1)
19/07/31 10:00:19 INFO TaskSchedulerImpl: Removed TaskSet 216.0, whose tasks have all completed, from pool 
19/07/31 10:00:19 INFO DAGScheduler: ResultStage 216 (collect at utils.scala:204) finished in 0.004 s
19/07/31 10:00:19 INFO DAGScheduler: Job 150 finished: collect at utils.scala:204, took 0.048446 s
19/07/31 10:00:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz17`
WHERE (0 = 1)
19/07/31 10:00:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:00:20 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:00:20 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:00:20 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:00:20 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:00:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:00:20 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5565
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5568
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5566
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5495
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5572
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5567
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5710
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5777
19/07/31 10:08:55 INFO BlockManagerInfo: Removed broadcast_218_piece0 on 127.0.0.1:53873 in memory (size: 11.8 KB, free: 912.0 MB)
19/07/31 10:08:55 INFO BlockManager: Removing RDD 685
19/07/31 10:08:55 INFO ContextCleaner: Cleaned RDD 685
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5706
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5715
19/07/31 10:08:55 INFO BlockManagerInfo: Removed broadcast_228_piece0 on 127.0.0.1:53873 in memory (size: 11.9 KB, free: 912.0 MB)
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5707
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5719
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5782
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5711
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5650
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5781
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5779
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5647
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5676
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5930
19/07/31 10:08:55 INFO BlockManagerInfo: Removed broadcast_217_piece0 on 127.0.0.1:53873 in memory (size: 24.0 KB, free: 912.0 MB)
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5648
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5928
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5712
19/07/31 10:08:55 INFO BlockManagerInfo: Removed broadcast_221_piece0 on 127.0.0.1:53873 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5984
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5713
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5889
19/07/31 10:08:55 INFO BlockManagerInfo: Removed broadcast_224_piece0 on 127.0.0.1:53873 in memory (size: 4.3 KB, free: 912.0 MB)
19/07/31 10:08:55 INFO BlockManagerInfo: Removed broadcast_222_piece0 on 127.0.0.1:53873 in memory (size: 3.8 KB, free: 912.0 MB)
19/07/31 10:08:55 INFO ContextCleaner: Cleaned shuffle 63
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5649
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5859
19/07/31 10:08:55 INFO BlockManagerInfo: Removed broadcast_215_piece0 on 127.0.0.1:53873 in memory (size: 23.8 KB, free: 912.0 MB)
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5774
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5935
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5833
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5714
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5773
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5888
19/07/31 10:08:55 INFO BlockManagerInfo: Removed broadcast_212_piece0 on 127.0.0.1:53873 in memory (size: 3.8 KB, free: 912.0 MB)
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5932
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5621
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5933
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5772
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5709
19/07/31 10:08:55 INFO ContextCleaner: Cleaned shuffle 62
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5924
19/07/31 10:08:55 INFO BlockManagerInfo: Removed broadcast_229_piece0 on 127.0.0.1:53873 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5784
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5927
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5890
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5651
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5721
19/07/31 10:08:55 INFO BlockManagerInfo: Removed broadcast_214_piece0 on 127.0.0.1:53873 in memory (size: 4.3 KB, free: 912.0 MB)
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5934
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5722
19/07/31 10:08:55 INFO BlockManagerInfo: Removed broadcast_231_piece0 on 127.0.0.1:53873 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5931
19/07/31 10:08:55 INFO BlockManagerInfo: Removed broadcast_230_piece0 on 127.0.0.1:53873 in memory (size: 11.8 KB, free: 912.1 MB)
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5646
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5925
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5677
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5926
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5892
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5861
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5923
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5723
19/07/31 10:08:55 INFO BlockManagerInfo: Removed broadcast_225_piece0 on 127.0.0.1:53873 in memory (size: 23.8 KB, free: 912.1 MB)
19/07/31 10:08:55 INFO BlockManagerInfo: Removed broadcast_226_piece0 on 127.0.0.1:53873 in memory (size: 8.6 KB, free: 912.1 MB)
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5780
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5776
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5862
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5716
19/07/31 10:08:55 INFO ContextCleaner: Cleaned shuffle 64
19/07/31 10:08:55 INFO BlockManagerInfo: Removed broadcast_223_piece0 on 127.0.0.1:53873 in memory (size: 23.8 KB, free: 912.1 MB)
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5891
19/07/31 10:08:55 INFO BlockManagerInfo: Removed broadcast_216_piece0 on 127.0.0.1:53873 in memory (size: 8.6 KB, free: 912.1 MB)
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5863
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5708
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5705
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5680
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5718
19/07/31 10:08:55 INFO BlockManagerInfo: Removed broadcast_220_piece0 on 127.0.0.1:53873 in memory (size: 11.9 KB, free: 912.1 MB)
19/07/31 10:08:55 INFO BlockManagerInfo: Removed broadcast_219_piece0 on 127.0.0.1:53873 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5929
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5678
19/07/31 10:08:55 INFO BlockManagerInfo: Removed broadcast_213_piece0 on 127.0.0.1:53873 in memory (size: 23.8 KB, free: 912.2 MB)
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5720
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5717
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5778
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5860
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5858
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5775
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5679
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5783
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5570
19/07/31 10:08:55 INFO BlockManager: Removing RDD 657
19/07/31 10:08:55 INFO ContextCleaner: Cleaned RDD 657
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5497
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5569
19/07/31 10:08:55 INFO ContextCleaner: Cleaned shuffle 61
19/07/31 10:08:55 INFO BlockManagerInfo: Removed broadcast_207_piece0 on 127.0.0.1:53873 in memory (size: 24.0 KB, free: 912.2 MB)
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5564
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5561
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5494
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5571
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5496
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5493
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5562
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5498
19/07/31 10:08:55 INFO ContextCleaner: Cleaned accumulator 5563
19/07/31 10:25:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 10:25:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv`
LIMIT 1000
19/07/31 10:25:47 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 10:25:47 INFO DAGScheduler: Got job 151 (collect at utils.scala:204) with 1 output partitions
19/07/31 10:25:47 INFO DAGScheduler: Final stage: ResultStage 217 (collect at utils.scala:204)
19/07/31 10:25:47 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:25:47 INFO DAGScheduler: Missing parents: List()
19/07/31 10:25:47 INFO DAGScheduler: Submitting ResultStage 217 (MapPartitionsRDD[727] at collect at utils.scala:204), which has no missing parents
19/07/31 10:25:47 INFO MemoryStore: Block broadcast_232 stored as values in memory (estimated size 22.4 KB, free 911.9 MB)
19/07/31 10:25:47 INFO MemoryStore: Block broadcast_232_piece0 stored as bytes in memory (estimated size 10.4 KB, free 911.9 MB)
19/07/31 10:25:47 INFO BlockManagerInfo: Added broadcast_232_piece0 in memory on 127.0.0.1:53873 (size: 10.4 KB, free: 912.2 MB)
19/07/31 10:25:47 INFO SparkContext: Created broadcast 232 from broadcast at DAGScheduler.scala:1006
19/07/31 10:25:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 217 (MapPartitionsRDD[727] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:25:47 INFO TaskSchedulerImpl: Adding task set 217.0 with 1 tasks
19/07/31 10:25:47 INFO TaskSetManager: Starting task 0.0 in stage 217.0 (TID 379, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:25:47 INFO Executor: Running task 0.0 in stage 217.0 (TID 379)
19/07/31 10:25:47 INFO BlockManager: Found block rdd_713_0 locally
19/07/31 10:25:47 INFO CodeGenerator: Code generated in 53.104951 ms
19/07/31 10:25:47 INFO Executor: 1 block locks were not released by TID = 379:
[rdd_713_0]
19/07/31 10:25:47 INFO Executor: Finished task 0.0 in stage 217.0 (TID 379). 61263 bytes result sent to driver
19/07/31 10:25:47 INFO TaskSetManager: Finished task 0.0 in stage 217.0 (TID 379) in 153 ms on localhost (executor driver) (1/1)
19/07/31 10:25:47 INFO TaskSchedulerImpl: Removed TaskSet 217.0, whose tasks have all completed, from pool 
19/07/31 10:25:47 INFO DAGScheduler: ResultStage 217 (collect at utils.scala:204) finished in 0.154 s
19/07/31 10:25:47 INFO DAGScheduler: Job 151 finished: collect at utils.scala:204, took 0.181995 s
19/07/31 10:25:47 INFO CodeGenerator: Code generated in 14.520917 ms
19/07/31 10:26:17 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:26:17 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:26:17 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:26:17 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:26:17 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:26:17 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:26:17 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:26:17 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 10:26:17 INFO DAGScheduler: Got job 152 (collect at utils.scala:44) with 4 output partitions
19/07/31 10:26:17 INFO DAGScheduler: Final stage: ResultStage 218 (collect at utils.scala:44)
19/07/31 10:26:17 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:26:17 INFO DAGScheduler: Missing parents: List()
19/07/31 10:26:17 INFO DAGScheduler: Submitting ResultStage 218 (MapPartitionsRDD[732] at map at utils.scala:41), which has no missing parents
19/07/31 10:26:17 INFO MemoryStore: Block broadcast_233 stored as values in memory (estimated size 7.3 KB, free 911.9 MB)
19/07/31 10:26:17 INFO MemoryStore: Block broadcast_233_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.9 MB)
19/07/31 10:26:17 INFO BlockManagerInfo: Added broadcast_233_piece0 in memory on 127.0.0.1:53873 (size: 3.8 KB, free: 912.2 MB)
19/07/31 10:26:17 INFO SparkContext: Created broadcast 233 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:17 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 218 (MapPartitionsRDD[732] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 10:26:17 INFO TaskSchedulerImpl: Adding task set 218.0 with 4 tasks
19/07/31 10:26:17 INFO TaskSetManager: Starting task 0.0 in stage 218.0 (TID 380, localhost, executor driver, partition 0, PROCESS_LOCAL, 5084 bytes)
19/07/31 10:26:17 INFO TaskSetManager: Starting task 1.0 in stage 218.0 (TID 381, localhost, executor driver, partition 1, PROCESS_LOCAL, 5141 bytes)
19/07/31 10:26:17 INFO TaskSetManager: Starting task 2.0 in stage 218.0 (TID 382, localhost, executor driver, partition 2, PROCESS_LOCAL, 5100 bytes)
19/07/31 10:26:17 INFO TaskSetManager: Starting task 3.0 in stage 218.0 (TID 383, localhost, executor driver, partition 3, PROCESS_LOCAL, 5141 bytes)
19/07/31 10:26:17 INFO Executor: Running task 0.0 in stage 218.0 (TID 380)
19/07/31 10:26:17 INFO Executor: Running task 1.0 in stage 218.0 (TID 381)
19/07/31 10:26:17 INFO Executor: Running task 3.0 in stage 218.0 (TID 383)
19/07/31 10:26:17 INFO Executor: Running task 2.0 in stage 218.0 (TID 382)
19/07/31 10:26:17 INFO Executor: Finished task 1.0 in stage 218.0 (TID 381). 1035 bytes result sent to driver
19/07/31 10:26:17 INFO Executor: Finished task 2.0 in stage 218.0 (TID 382). 1026 bytes result sent to driver
19/07/31 10:26:17 INFO Executor: Finished task 3.0 in stage 218.0 (TID 383). 990 bytes result sent to driver
19/07/31 10:26:17 INFO TaskSetManager: Finished task 1.0 in stage 218.0 (TID 381) in 11 ms on localhost (executor driver) (1/4)
19/07/31 10:26:17 INFO Executor: Finished task 0.0 in stage 218.0 (TID 380). 969 bytes result sent to driver
19/07/31 10:26:17 INFO TaskSetManager: Finished task 2.0 in stage 218.0 (TID 382) in 11 ms on localhost (executor driver) (2/4)
19/07/31 10:26:17 INFO TaskSetManager: Finished task 3.0 in stage 218.0 (TID 383) in 12 ms on localhost (executor driver) (3/4)
19/07/31 10:26:17 INFO TaskSetManager: Finished task 0.0 in stage 218.0 (TID 380) in 12 ms on localhost (executor driver) (4/4)
19/07/31 10:26:17 INFO TaskSchedulerImpl: Removed TaskSet 218.0, whose tasks have all completed, from pool 
19/07/31 10:26:17 INFO DAGScheduler: ResultStage 218 (collect at utils.scala:44) finished in 0.012 s
19/07/31 10:26:17 INFO DAGScheduler: Job 152 finished: collect at utils.scala:44, took 0.028371 s
19/07/31 10:26:17 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 10:26:17 INFO MapPartitionsRDD: Removing RDD 713 from persistence list
19/07/31 10:26:17 INFO BlockManager: Removing RDD 713
19/07/31 10:26:17 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:26:17 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#9521)) > 0)
19/07/31 10:26:17 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 10:26:17 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:26:17 INFO MemoryStore: Block broadcast_234 stored as values in memory (estimated size 281.2 KB, free 911.6 MB)
19/07/31 10:26:17 INFO MemoryStore: Block broadcast_234_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.6 MB)
19/07/31 10:26:17 INFO BlockManagerInfo: Added broadcast_234_piece0 in memory on 127.0.0.1:53873 (size: 23.8 KB, free: 912.2 MB)
19/07/31 10:26:17 INFO SparkContext: Created broadcast 234 from csv at NativeMethodAccessorImpl.java:0
19/07/31 10:26:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:26:17 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 10:26:17 INFO DAGScheduler: Got job 153 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 10:26:17 INFO DAGScheduler: Final stage: ResultStage 219 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 10:26:17 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:26:17 INFO DAGScheduler: Missing parents: List()
19/07/31 10:26:17 INFO DAGScheduler: Submitting ResultStage 219 (MapPartitionsRDD[735] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:26:17 INFO MemoryStore: Block broadcast_235 stored as values in memory (estimated size 8.2 KB, free 911.6 MB)
19/07/31 10:26:17 INFO MemoryStore: Block broadcast_235_piece0 stored as bytes in memory (estimated size 4.3 KB, free 911.6 MB)
19/07/31 10:26:17 INFO BlockManagerInfo: Added broadcast_235_piece0 in memory on 127.0.0.1:53873 (size: 4.3 KB, free: 912.2 MB)
19/07/31 10:26:17 INFO SparkContext: Created broadcast 235 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 219 (MapPartitionsRDD[735] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:26:17 INFO TaskSchedulerImpl: Adding task set 219.0 with 1 tasks
19/07/31 10:26:17 INFO TaskSetManager: Starting task 0.0 in stage 219.0 (TID 384, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:26:17 INFO Executor: Running task 0.0 in stage 219.0 (TID 384)
19/07/31 10:26:17 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:26:17 INFO Executor: Finished task 0.0 in stage 219.0 (TID 384). 1394 bytes result sent to driver
19/07/31 10:26:17 INFO TaskSetManager: Finished task 0.0 in stage 219.0 (TID 384) in 6 ms on localhost (executor driver) (1/1)
19/07/31 10:26:17 INFO TaskSchedulerImpl: Removed TaskSet 219.0, whose tasks have all completed, from pool 
19/07/31 10:26:17 INFO DAGScheduler: ResultStage 219 (csv at NativeMethodAccessorImpl.java:0) finished in 0.006 s
19/07/31 10:26:17 INFO DAGScheduler: Job 153 finished: csv at NativeMethodAccessorImpl.java:0, took 0.018843 s
19/07/31 10:26:17 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:26:17 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 10:26:17 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 10:26:17 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:26:17 INFO MemoryStore: Block broadcast_236 stored as values in memory (estimated size 281.2 KB, free 911.3 MB)
19/07/31 10:26:17 INFO MemoryStore: Block broadcast_236_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.3 MB)
19/07/31 10:26:17 INFO BlockManagerInfo: Added broadcast_236_piece0 in memory on 127.0.0.1:53873 (size: 23.8 KB, free: 912.2 MB)
19/07/31 10:26:17 INFO SparkContext: Created broadcast 236 from csv at NativeMethodAccessorImpl.java:0
19/07/31 10:26:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:26:17 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 10:26:17 INFO DAGScheduler: Got job 154 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 10:26:17 INFO DAGScheduler: Final stage: ResultStage 220 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 10:26:17 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:26:17 INFO DAGScheduler: Missing parents: List()
19/07/31 10:26:17 INFO DAGScheduler: Submitting ResultStage 220 (MapPartitionsRDD[740] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:26:17 INFO MemoryStore: Block broadcast_237 stored as values in memory (estimated size 14.8 KB, free 911.3 MB)
19/07/31 10:26:17 INFO MemoryStore: Block broadcast_237_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.3 MB)
19/07/31 10:26:17 INFO BlockManagerInfo: Added broadcast_237_piece0 in memory on 127.0.0.1:53873 (size: 8.6 KB, free: 912.2 MB)
19/07/31 10:26:17 INFO SparkContext: Created broadcast 237 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 220 (MapPartitionsRDD[740] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:26:17 INFO TaskSchedulerImpl: Adding task set 220.0 with 1 tasks
19/07/31 10:26:17 INFO TaskSetManager: Starting task 0.0 in stage 220.0 (TID 385, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:26:17 INFO Executor: Running task 0.0 in stage 220.0 (TID 385)
19/07/31 10:26:17 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:26:17 INFO Executor: Finished task 0.0 in stage 220.0 (TID 385). 1584 bytes result sent to driver
19/07/31 10:26:17 INFO TaskSetManager: Finished task 0.0 in stage 220.0 (TID 385) in 16 ms on localhost (executor driver) (1/1)
19/07/31 10:26:17 INFO TaskSchedulerImpl: Removed TaskSet 220.0, whose tasks have all completed, from pool 
19/07/31 10:26:17 INFO DAGScheduler: ResultStage 220 (csv at NativeMethodAccessorImpl.java:0) finished in 0.017 s
19/07/31 10:26:17 INFO DAGScheduler: Job 154 finished: csv at NativeMethodAccessorImpl.java:0, took 0.026382 s
19/07/31 10:26:17 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:26:17 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:26:17 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:26:17 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:26:17 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:26:17 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:26:17 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:26:17 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 10:26:17 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 10:26:17 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 10:26:17 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:26:17 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 10:26:17 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 10:26:17 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:26:17 INFO MemoryStore: Block broadcast_238 stored as values in memory (estimated size 282.3 KB, free 911.0 MB)
19/07/31 10:26:17 INFO MemoryStore: Block broadcast_238_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.0 MB)
19/07/31 10:26:17 INFO BlockManagerInfo: Added broadcast_238_piece0 in memory on 127.0.0.1:53873 (size: 24.0 KB, free: 912.1 MB)
19/07/31 10:26:17 INFO SparkContext: Created broadcast 238 from sql at <unknown>:0
19/07/31 10:26:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:26:17 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 10:26:17 INFO DAGScheduler: Registering RDD 746 (sql at <unknown>:0)
19/07/31 10:26:17 INFO DAGScheduler: Got job 155 (sql at <unknown>:0) with 1 output partitions
19/07/31 10:26:17 INFO DAGScheduler: Final stage: ResultStage 222 (sql at <unknown>:0)
19/07/31 10:26:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 221)
19/07/31 10:26:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 221)
19/07/31 10:26:17 INFO DAGScheduler: Submitting ShuffleMapStage 221 (MapPartitionsRDD[746] at sql at <unknown>:0), which has no missing parents
19/07/31 10:26:17 INFO MemoryStore: Block broadcast_239 stored as values in memory (estimated size 26.3 KB, free 911.0 MB)
19/07/31 10:26:17 INFO MemoryStore: Block broadcast_239_piece0 stored as bytes in memory (estimated size 11.9 KB, free 910.9 MB)
19/07/31 10:26:17 INFO BlockManagerInfo: Added broadcast_239_piece0 in memory on 127.0.0.1:53873 (size: 11.9 KB, free: 912.1 MB)
19/07/31 10:26:17 INFO SparkContext: Created broadcast 239 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 221 (MapPartitionsRDD[746] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:26:17 INFO TaskSchedulerImpl: Adding task set 221.0 with 1 tasks
19/07/31 10:26:17 INFO TaskSetManager: Starting task 0.0 in stage 221.0 (TID 386, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 10:26:17 INFO Executor: Running task 0.0 in stage 221.0 (TID 386)
19/07/31 10:26:17 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:26:17 INFO MemoryStore: Block rdd_743_0 stored as values in memory (estimated size 48.9 KB, free 910.9 MB)
19/07/31 10:26:17 INFO BlockManagerInfo: Added rdd_743_0 in memory on 127.0.0.1:53873 (size: 48.9 KB, free: 912.1 MB)
19/07/31 10:26:17 INFO Executor: Finished task 0.0 in stage 221.0 (TID 386). 2461 bytes result sent to driver
19/07/31 10:26:17 INFO TaskSetManager: Finished task 0.0 in stage 221.0 (TID 386) in 42 ms on localhost (executor driver) (1/1)
19/07/31 10:26:17 INFO TaskSchedulerImpl: Removed TaskSet 221.0, whose tasks have all completed, from pool 
19/07/31 10:26:17 INFO DAGScheduler: ShuffleMapStage 221 (sql at <unknown>:0) finished in 0.043 s
19/07/31 10:26:17 INFO DAGScheduler: looking for newly runnable stages
19/07/31 10:26:17 INFO DAGScheduler: running: Set()
19/07/31 10:26:17 INFO DAGScheduler: waiting: Set(ResultStage 222)
19/07/31 10:26:17 INFO DAGScheduler: failed: Set()
19/07/31 10:26:17 INFO DAGScheduler: Submitting ResultStage 222 (MapPartitionsRDD[749] at sql at <unknown>:0), which has no missing parents
19/07/31 10:26:17 INFO MemoryStore: Block broadcast_240 stored as values in memory (estimated size 7.0 KB, free 910.9 MB)
19/07/31 10:26:17 INFO MemoryStore: Block broadcast_240_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.9 MB)
19/07/31 10:26:17 INFO BlockManagerInfo: Added broadcast_240_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 912.1 MB)
19/07/31 10:26:17 INFO SparkContext: Created broadcast 240 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 222 (MapPartitionsRDD[749] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:26:17 INFO TaskSchedulerImpl: Adding task set 222.0 with 1 tasks
19/07/31 10:26:17 INFO TaskSetManager: Starting task 0.0 in stage 222.0 (TID 387, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 10:26:17 INFO Executor: Running task 0.0 in stage 222.0 (TID 387)
19/07/31 10:26:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 10:26:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 10:26:17 INFO Executor: Finished task 0.0 in stage 222.0 (TID 387). 1581 bytes result sent to driver
19/07/31 10:26:17 INFO TaskSetManager: Finished task 0.0 in stage 222.0 (TID 387) in 4 ms on localhost (executor driver) (1/1)
19/07/31 10:26:17 INFO TaskSchedulerImpl: Removed TaskSet 222.0, whose tasks have all completed, from pool 
19/07/31 10:26:17 INFO DAGScheduler: ResultStage 222 (sql at <unknown>:0) finished in 0.004 s
19/07/31 10:26:17 INFO DAGScheduler: Job 155 finished: sql at <unknown>:0, took 0.065322 s
19/07/31 10:26:17 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 10:26:17 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:26:17 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:26:17 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 10:26:17 INFO DAGScheduler: Registering RDD 752 (collect at utils.scala:204)
19/07/31 10:26:17 INFO DAGScheduler: Got job 156 (collect at utils.scala:204) with 1 output partitions
19/07/31 10:26:17 INFO DAGScheduler: Final stage: ResultStage 224 (collect at utils.scala:204)
19/07/31 10:26:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 223)
19/07/31 10:26:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 223)
19/07/31 10:26:17 INFO DAGScheduler: Submitting ShuffleMapStage 223 (MapPartitionsRDD[752] at collect at utils.scala:204), which has no missing parents
19/07/31 10:26:17 INFO MemoryStore: Block broadcast_241 stored as values in memory (estimated size 26.3 KB, free 910.9 MB)
19/07/31 10:26:17 INFO MemoryStore: Block broadcast_241_piece0 stored as bytes in memory (estimated size 11.9 KB, free 910.8 MB)
19/07/31 10:26:17 INFO BlockManagerInfo: Added broadcast_241_piece0 in memory on 127.0.0.1:53873 (size: 11.9 KB, free: 912.1 MB)
19/07/31 10:26:17 INFO SparkContext: Created broadcast 241 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 223 (MapPartitionsRDD[752] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:26:17 INFO TaskSchedulerImpl: Adding task set 223.0 with 1 tasks
19/07/31 10:26:17 INFO TaskSetManager: Starting task 0.0 in stage 223.0 (TID 388, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 10:26:17 INFO Executor: Running task 0.0 in stage 223.0 (TID 388)
19/07/31 10:26:17 INFO BlockManager: Found block rdd_743_0 locally
19/07/31 10:26:17 INFO Executor: Finished task 0.0 in stage 223.0 (TID 388). 1780 bytes result sent to driver
19/07/31 10:26:17 INFO TaskSetManager: Finished task 0.0 in stage 223.0 (TID 388) in 11 ms on localhost (executor driver) (1/1)
19/07/31 10:26:17 INFO TaskSchedulerImpl: Removed TaskSet 223.0, whose tasks have all completed, from pool 
19/07/31 10:26:17 INFO DAGScheduler: ShuffleMapStage 223 (collect at utils.scala:204) finished in 0.012 s
19/07/31 10:26:17 INFO DAGScheduler: looking for newly runnable stages
19/07/31 10:26:17 INFO DAGScheduler: running: Set()
19/07/31 10:26:17 INFO DAGScheduler: waiting: Set(ResultStage 224)
19/07/31 10:26:17 INFO DAGScheduler: failed: Set()
19/07/31 10:26:17 INFO DAGScheduler: Submitting ResultStage 224 (MapPartitionsRDD[755] at collect at utils.scala:204), which has no missing parents
19/07/31 10:26:18 INFO MemoryStore: Block broadcast_242 stored as values in memory (estimated size 7.0 KB, free 910.8 MB)
19/07/31 10:26:18 INFO MemoryStore: Block broadcast_242_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.8 MB)
19/07/31 10:26:18 INFO BlockManagerInfo: Added broadcast_242_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 912.0 MB)
19/07/31 10:26:18 INFO SparkContext: Created broadcast 242 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 224 (MapPartitionsRDD[755] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:26:18 INFO TaskSchedulerImpl: Adding task set 224.0 with 1 tasks
19/07/31 10:26:18 INFO TaskSetManager: Starting task 0.0 in stage 224.0 (TID 389, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 10:26:18 INFO Executor: Running task 0.0 in stage 224.0 (TID 389)
19/07/31 10:26:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 10:26:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 10:26:18 INFO Executor: Finished task 0.0 in stage 224.0 (TID 389). 1581 bytes result sent to driver
19/07/31 10:26:18 INFO TaskSetManager: Finished task 0.0 in stage 224.0 (TID 389) in 6 ms on localhost (executor driver) (1/1)
19/07/31 10:26:18 INFO TaskSchedulerImpl: Removed TaskSet 224.0, whose tasks have all completed, from pool 
19/07/31 10:26:18 INFO DAGScheduler: ResultStage 224 (collect at utils.scala:204) finished in 0.007 s
19/07/31 10:26:18 INFO DAGScheduler: Job 156 finished: collect at utils.scala:204, took 0.055137 s
19/07/31 10:26:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz18`
WHERE (0 = 1)
19/07/31 10:26:18 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:26:18 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:26:18 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:26:18 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:26:18 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:26:18 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:26:18 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:26:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:26:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:26:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:26:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:26:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:26:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:26:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:26:36 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 10:26:36 INFO DAGScheduler: Got job 157 (collect at utils.scala:44) with 4 output partitions
19/07/31 10:26:36 INFO DAGScheduler: Final stage: ResultStage 225 (collect at utils.scala:44)
19/07/31 10:26:36 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:26:36 INFO DAGScheduler: Missing parents: List()
19/07/31 10:26:36 INFO DAGScheduler: Submitting ResultStage 225 (MapPartitionsRDD[760] at map at utils.scala:41), which has no missing parents
19/07/31 10:26:36 INFO MemoryStore: Block broadcast_243 stored as values in memory (estimated size 7.3 KB, free 910.8 MB)
19/07/31 10:26:36 INFO MemoryStore: Block broadcast_243_piece0 stored as bytes in memory (estimated size 3.8 KB, free 910.8 MB)
19/07/31 10:26:36 INFO BlockManagerInfo: Added broadcast_243_piece0 in memory on 127.0.0.1:53873 (size: 3.8 KB, free: 912.0 MB)
19/07/31 10:26:36 INFO SparkContext: Created broadcast 243 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:36 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 225 (MapPartitionsRDD[760] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 10:26:36 INFO TaskSchedulerImpl: Adding task set 225.0 with 4 tasks
19/07/31 10:26:36 INFO TaskSetManager: Starting task 0.0 in stage 225.0 (TID 390, localhost, executor driver, partition 0, PROCESS_LOCAL, 5084 bytes)
19/07/31 10:26:36 INFO TaskSetManager: Starting task 1.0 in stage 225.0 (TID 391, localhost, executor driver, partition 1, PROCESS_LOCAL, 5141 bytes)
19/07/31 10:26:36 INFO TaskSetManager: Starting task 2.0 in stage 225.0 (TID 392, localhost, executor driver, partition 2, PROCESS_LOCAL, 5100 bytes)
19/07/31 10:26:36 INFO TaskSetManager: Starting task 3.0 in stage 225.0 (TID 393, localhost, executor driver, partition 3, PROCESS_LOCAL, 5141 bytes)
19/07/31 10:26:36 INFO Executor: Running task 1.0 in stage 225.0 (TID 391)
19/07/31 10:26:36 INFO Executor: Running task 0.0 in stage 225.0 (TID 390)
19/07/31 10:26:36 INFO Executor: Running task 2.0 in stage 225.0 (TID 392)
19/07/31 10:26:36 INFO Executor: Running task 3.0 in stage 225.0 (TID 393)
19/07/31 10:26:36 INFO Executor: Finished task 2.0 in stage 225.0 (TID 392). 983 bytes result sent to driver
19/07/31 10:26:36 INFO Executor: Finished task 1.0 in stage 225.0 (TID 391). 1035 bytes result sent to driver
19/07/31 10:26:36 INFO TaskSetManager: Finished task 2.0 in stage 225.0 (TID 392) in 4 ms on localhost (executor driver) (1/4)
19/07/31 10:26:36 INFO TaskSetManager: Finished task 1.0 in stage 225.0 (TID 391) in 4 ms on localhost (executor driver) (2/4)
19/07/31 10:26:36 INFO Executor: Finished task 0.0 in stage 225.0 (TID 390). 1012 bytes result sent to driver
19/07/31 10:26:36 INFO Executor: Finished task 3.0 in stage 225.0 (TID 393). 990 bytes result sent to driver
19/07/31 10:26:36 INFO TaskSetManager: Finished task 0.0 in stage 225.0 (TID 390) in 6 ms on localhost (executor driver) (3/4)
19/07/31 10:26:36 INFO TaskSetManager: Finished task 3.0 in stage 225.0 (TID 393) in 5 ms on localhost (executor driver) (4/4)
19/07/31 10:26:36 INFO TaskSchedulerImpl: Removed TaskSet 225.0, whose tasks have all completed, from pool 
19/07/31 10:26:36 INFO DAGScheduler: ResultStage 225 (collect at utils.scala:44) finished in 0.007 s
19/07/31 10:26:36 INFO DAGScheduler: Job 157 finished: collect at utils.scala:44, took 0.013972 s
19/07/31 10:26:36 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 10:26:36 INFO MapPartitionsRDD: Removing RDD 743 from persistence list
19/07/31 10:26:36 INFO BlockManager: Removing RDD 743
19/07/31 10:26:36 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:26:36 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#9900)) > 0)
19/07/31 10:26:36 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 10:26:36 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:26:36 INFO MemoryStore: Block broadcast_244 stored as values in memory (estimated size 281.2 KB, free 910.6 MB)
19/07/31 10:26:36 INFO MemoryStore: Block broadcast_244_piece0 stored as bytes in memory (estimated size 23.8 KB, free 910.6 MB)
19/07/31 10:26:36 INFO BlockManagerInfo: Added broadcast_244_piece0 in memory on 127.0.0.1:53873 (size: 23.8 KB, free: 912.1 MB)
19/07/31 10:26:36 INFO SparkContext: Created broadcast 244 from csv at NativeMethodAccessorImpl.java:0
19/07/31 10:26:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:26:36 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 10:26:36 INFO DAGScheduler: Got job 158 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 10:26:36 INFO DAGScheduler: Final stage: ResultStage 226 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 10:26:36 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:26:36 INFO DAGScheduler: Missing parents: List()
19/07/31 10:26:36 INFO DAGScheduler: Submitting ResultStage 226 (MapPartitionsRDD[763] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:26:36 INFO MemoryStore: Block broadcast_245 stored as values in memory (estimated size 8.2 KB, free 910.6 MB)
19/07/31 10:26:36 INFO MemoryStore: Block broadcast_245_piece0 stored as bytes in memory (estimated size 4.3 KB, free 910.6 MB)
19/07/31 10:26:36 INFO BlockManagerInfo: Added broadcast_245_piece0 in memory on 127.0.0.1:53873 (size: 4.3 KB, free: 912.1 MB)
19/07/31 10:26:36 INFO SparkContext: Created broadcast 245 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 226 (MapPartitionsRDD[763] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:26:36 INFO TaskSchedulerImpl: Adding task set 226.0 with 1 tasks
19/07/31 10:26:36 INFO TaskSetManager: Starting task 0.0 in stage 226.0 (TID 394, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:26:36 INFO Executor: Running task 0.0 in stage 226.0 (TID 394)
19/07/31 10:26:36 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:26:36 INFO Executor: Finished task 0.0 in stage 226.0 (TID 394). 1394 bytes result sent to driver
19/07/31 10:26:36 INFO TaskSetManager: Finished task 0.0 in stage 226.0 (TID 394) in 8 ms on localhost (executor driver) (1/1)
19/07/31 10:26:36 INFO TaskSchedulerImpl: Removed TaskSet 226.0, whose tasks have all completed, from pool 
19/07/31 10:26:36 INFO DAGScheduler: ResultStage 226 (csv at NativeMethodAccessorImpl.java:0) finished in 0.007 s
19/07/31 10:26:36 INFO DAGScheduler: Job 158 finished: csv at NativeMethodAccessorImpl.java:0, took 0.021125 s
19/07/31 10:26:36 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:26:36 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 10:26:36 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 10:26:36 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:26:36 INFO MemoryStore: Block broadcast_246 stored as values in memory (estimated size 281.2 KB, free 910.3 MB)
19/07/31 10:26:36 INFO MemoryStore: Block broadcast_246_piece0 stored as bytes in memory (estimated size 23.8 KB, free 910.3 MB)
19/07/31 10:26:36 INFO BlockManagerInfo: Added broadcast_246_piece0 in memory on 127.0.0.1:53873 (size: 23.8 KB, free: 912.0 MB)
19/07/31 10:26:36 INFO SparkContext: Created broadcast 246 from csv at NativeMethodAccessorImpl.java:0
19/07/31 10:26:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:26:36 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 10:26:36 INFO DAGScheduler: Got job 159 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 10:26:36 INFO DAGScheduler: Final stage: ResultStage 227 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 10:26:36 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:26:36 INFO DAGScheduler: Missing parents: List()
19/07/31 10:26:36 INFO DAGScheduler: Submitting ResultStage 227 (MapPartitionsRDD[768] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:26:36 INFO MemoryStore: Block broadcast_247 stored as values in memory (estimated size 14.8 KB, free 910.2 MB)
19/07/31 10:26:36 INFO MemoryStore: Block broadcast_247_piece0 stored as bytes in memory (estimated size 8.6 KB, free 910.2 MB)
19/07/31 10:26:36 INFO BlockManagerInfo: Added broadcast_247_piece0 in memory on 127.0.0.1:53873 (size: 8.6 KB, free: 912.0 MB)
19/07/31 10:26:36 INFO SparkContext: Created broadcast 247 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 227 (MapPartitionsRDD[768] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:26:36 INFO TaskSchedulerImpl: Adding task set 227.0 with 1 tasks
19/07/31 10:26:36 INFO TaskSetManager: Starting task 0.0 in stage 227.0 (TID 395, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:26:36 INFO Executor: Running task 0.0 in stage 227.0 (TID 395)
19/07/31 10:26:36 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:26:36 INFO Executor: Finished task 0.0 in stage 227.0 (TID 395). 1584 bytes result sent to driver
19/07/31 10:26:36 INFO TaskSetManager: Finished task 0.0 in stage 227.0 (TID 395) in 15 ms on localhost (executor driver) (1/1)
19/07/31 10:26:36 INFO TaskSchedulerImpl: Removed TaskSet 227.0, whose tasks have all completed, from pool 
19/07/31 10:26:36 INFO DAGScheduler: ResultStage 227 (csv at NativeMethodAccessorImpl.java:0) finished in 0.016 s
19/07/31 10:26:36 INFO DAGScheduler: Job 159 finished: csv at NativeMethodAccessorImpl.java:0, took 0.022485 s
19/07/31 10:26:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:26:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:26:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:26:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:26:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:26:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:26:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:26:36 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 10:26:36 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 10:26:36 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 10:26:36 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:26:36 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 10:26:36 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 10:26:36 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:26:36 INFO MemoryStore: Block broadcast_248 stored as values in memory (estimated size 282.3 KB, free 910.0 MB)
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_248_piece0 stored as bytes in memory (estimated size 24.0 KB, free 909.9 MB)
19/07/31 10:26:37 INFO BlockManagerInfo: Added broadcast_248_piece0 in memory on 127.0.0.1:53873 (size: 24.0 KB, free: 912.0 MB)
19/07/31 10:26:37 INFO SparkContext: Created broadcast 248 from sql at <unknown>:0
19/07/31 10:26:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:26:37 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 10:26:37 INFO DAGScheduler: Registering RDD 774 (sql at <unknown>:0)
19/07/31 10:26:37 INFO DAGScheduler: Got job 160 (sql at <unknown>:0) with 1 output partitions
19/07/31 10:26:37 INFO DAGScheduler: Final stage: ResultStage 229 (sql at <unknown>:0)
19/07/31 10:26:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 228)
19/07/31 10:26:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 228)
19/07/31 10:26:37 INFO DAGScheduler: Submitting ShuffleMapStage 228 (MapPartitionsRDD[774] at sql at <unknown>:0), which has no missing parents
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_249 stored as values in memory (estimated size 26.3 KB, free 909.9 MB)
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_249_piece0 stored as bytes in memory (estimated size 11.8 KB, free 909.9 MB)
19/07/31 10:26:37 INFO BlockManagerInfo: Added broadcast_249_piece0 in memory on 127.0.0.1:53873 (size: 11.8 KB, free: 912.0 MB)
19/07/31 10:26:37 INFO SparkContext: Created broadcast 249 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 228 (MapPartitionsRDD[774] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:26:37 INFO TaskSchedulerImpl: Adding task set 228.0 with 1 tasks
19/07/31 10:26:37 INFO TaskSetManager: Starting task 0.0 in stage 228.0 (TID 396, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 10:26:37 INFO Executor: Running task 0.0 in stage 228.0 (TID 396)
19/07/31 10:26:37 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:26:37 INFO MemoryStore: Block rdd_771_0 stored as values in memory (estimated size 48.9 KB, free 909.9 MB)
19/07/31 10:26:37 INFO BlockManagerInfo: Added rdd_771_0 in memory on 127.0.0.1:53873 (size: 48.9 KB, free: 912.0 MB)
19/07/31 10:26:37 INFO Executor: Finished task 0.0 in stage 228.0 (TID 396). 2461 bytes result sent to driver
19/07/31 10:26:37 INFO TaskSetManager: Finished task 0.0 in stage 228.0 (TID 396) in 34 ms on localhost (executor driver) (1/1)
19/07/31 10:26:37 INFO TaskSchedulerImpl: Removed TaskSet 228.0, whose tasks have all completed, from pool 
19/07/31 10:26:37 INFO DAGScheduler: ShuffleMapStage 228 (sql at <unknown>:0) finished in 0.034 s
19/07/31 10:26:37 INFO DAGScheduler: looking for newly runnable stages
19/07/31 10:26:37 INFO DAGScheduler: running: Set()
19/07/31 10:26:37 INFO DAGScheduler: waiting: Set(ResultStage 229)
19/07/31 10:26:37 INFO DAGScheduler: failed: Set()
19/07/31 10:26:37 INFO DAGScheduler: Submitting ResultStage 229 (MapPartitionsRDD[777] at sql at <unknown>:0), which has no missing parents
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_250 stored as values in memory (estimated size 7.0 KB, free 909.8 MB)
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_250_piece0 stored as bytes in memory (estimated size 3.7 KB, free 909.8 MB)
19/07/31 10:26:37 INFO BlockManagerInfo: Added broadcast_250_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 911.9 MB)
19/07/31 10:26:37 INFO SparkContext: Created broadcast 250 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 229 (MapPartitionsRDD[777] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:26:37 INFO TaskSchedulerImpl: Adding task set 229.0 with 1 tasks
19/07/31 10:26:37 INFO TaskSetManager: Starting task 0.0 in stage 229.0 (TID 397, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 10:26:37 INFO Executor: Running task 0.0 in stage 229.0 (TID 397)
19/07/31 10:26:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 10:26:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 10:26:37 INFO Executor: Finished task 0.0 in stage 229.0 (TID 397). 1581 bytes result sent to driver
19/07/31 10:26:37 INFO TaskSetManager: Finished task 0.0 in stage 229.0 (TID 397) in 5 ms on localhost (executor driver) (1/1)
19/07/31 10:26:37 INFO TaskSchedulerImpl: Removed TaskSet 229.0, whose tasks have all completed, from pool 
19/07/31 10:26:37 INFO DAGScheduler: ResultStage 229 (sql at <unknown>:0) finished in 0.006 s
19/07/31 10:26:37 INFO DAGScheduler: Job 160 finished: sql at <unknown>:0, took 0.052257 s
19/07/31 10:26:37 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 10:26:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:26:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:26:37 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 10:26:37 INFO DAGScheduler: Registering RDD 780 (collect at utils.scala:204)
19/07/31 10:26:37 INFO DAGScheduler: Got job 161 (collect at utils.scala:204) with 1 output partitions
19/07/31 10:26:37 INFO DAGScheduler: Final stage: ResultStage 231 (collect at utils.scala:204)
19/07/31 10:26:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 230)
19/07/31 10:26:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 230)
19/07/31 10:26:37 INFO DAGScheduler: Submitting ShuffleMapStage 230 (MapPartitionsRDD[780] at collect at utils.scala:204), which has no missing parents
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_251 stored as values in memory (estimated size 26.3 KB, free 909.8 MB)
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_251_piece0 stored as bytes in memory (estimated size 11.8 KB, free 909.8 MB)
19/07/31 10:26:37 INFO BlockManagerInfo: Added broadcast_251_piece0 in memory on 127.0.0.1:53873 (size: 11.8 KB, free: 911.9 MB)
19/07/31 10:26:37 INFO SparkContext: Created broadcast 251 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 230 (MapPartitionsRDD[780] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:26:37 INFO TaskSchedulerImpl: Adding task set 230.0 with 1 tasks
19/07/31 10:26:37 INFO TaskSetManager: Starting task 0.0 in stage 230.0 (TID 398, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 10:26:37 INFO Executor: Running task 0.0 in stage 230.0 (TID 398)
19/07/31 10:26:37 INFO BlockManager: Found block rdd_771_0 locally
19/07/31 10:26:37 INFO Executor: Finished task 0.0 in stage 230.0 (TID 398). 1780 bytes result sent to driver
19/07/31 10:26:37 INFO TaskSetManager: Finished task 0.0 in stage 230.0 (TID 398) in 5 ms on localhost (executor driver) (1/1)
19/07/31 10:26:37 INFO TaskSchedulerImpl: Removed TaskSet 230.0, whose tasks have all completed, from pool 
19/07/31 10:26:37 INFO DAGScheduler: ShuffleMapStage 230 (collect at utils.scala:204) finished in 0.007 s
19/07/31 10:26:37 INFO DAGScheduler: looking for newly runnable stages
19/07/31 10:26:37 INFO DAGScheduler: running: Set()
19/07/31 10:26:37 INFO DAGScheduler: waiting: Set(ResultStage 231)
19/07/31 10:26:37 INFO DAGScheduler: failed: Set()
19/07/31 10:26:37 INFO DAGScheduler: Submitting ResultStage 231 (MapPartitionsRDD[783] at collect at utils.scala:204), which has no missing parents
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_252 stored as values in memory (estimated size 7.0 KB, free 909.8 MB)
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_252_piece0 stored as bytes in memory (estimated size 3.7 KB, free 909.8 MB)
19/07/31 10:26:37 INFO BlockManagerInfo: Added broadcast_252_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 911.9 MB)
19/07/31 10:26:37 INFO SparkContext: Created broadcast 252 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 231 (MapPartitionsRDD[783] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:26:37 INFO TaskSchedulerImpl: Adding task set 231.0 with 1 tasks
19/07/31 10:26:37 INFO TaskSetManager: Starting task 0.0 in stage 231.0 (TID 399, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 10:26:37 INFO Executor: Running task 0.0 in stage 231.0 (TID 399)
19/07/31 10:26:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 10:26:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 10:26:37 INFO Executor: Finished task 0.0 in stage 231.0 (TID 399). 1538 bytes result sent to driver
19/07/31 10:26:37 INFO TaskSetManager: Finished task 0.0 in stage 231.0 (TID 399) in 4 ms on localhost (executor driver) (1/1)
19/07/31 10:26:37 INFO TaskSchedulerImpl: Removed TaskSet 231.0, whose tasks have all completed, from pool 
19/07/31 10:26:37 INFO DAGScheduler: ResultStage 231 (collect at utils.scala:204) finished in 0.005 s
19/07/31 10:26:37 INFO DAGScheduler: Job 161 finished: collect at utils.scala:204, took 0.041507 s
19/07/31 10:26:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz19`
WHERE (0 = 1)
19/07/31 10:26:37 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:26:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:26:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:26:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:26:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:26:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:26:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:26:37 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:26:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:26:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:26:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:26:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:26:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:26:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:26:37 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 10:26:37 INFO DAGScheduler: Got job 162 (collect at utils.scala:44) with 4 output partitions
19/07/31 10:26:37 INFO DAGScheduler: Final stage: ResultStage 232 (collect at utils.scala:44)
19/07/31 10:26:37 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:26:37 INFO DAGScheduler: Missing parents: List()
19/07/31 10:26:37 INFO DAGScheduler: Submitting ResultStage 232 (MapPartitionsRDD[788] at map at utils.scala:41), which has no missing parents
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_253 stored as values in memory (estimated size 7.3 KB, free 909.8 MB)
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_253_piece0 stored as bytes in memory (estimated size 3.8 KB, free 909.8 MB)
19/07/31 10:26:37 INFO BlockManagerInfo: Added broadcast_253_piece0 in memory on 127.0.0.1:53873 (size: 3.8 KB, free: 911.9 MB)
19/07/31 10:26:37 INFO SparkContext: Created broadcast 253 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:37 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 232 (MapPartitionsRDD[788] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 10:26:37 INFO TaskSchedulerImpl: Adding task set 232.0 with 4 tasks
19/07/31 10:26:37 INFO TaskSetManager: Starting task 0.0 in stage 232.0 (TID 400, localhost, executor driver, partition 0, PROCESS_LOCAL, 5084 bytes)
19/07/31 10:26:37 INFO TaskSetManager: Starting task 1.0 in stage 232.0 (TID 401, localhost, executor driver, partition 1, PROCESS_LOCAL, 5141 bytes)
19/07/31 10:26:37 INFO TaskSetManager: Starting task 2.0 in stage 232.0 (TID 402, localhost, executor driver, partition 2, PROCESS_LOCAL, 5100 bytes)
19/07/31 10:26:37 INFO TaskSetManager: Starting task 3.0 in stage 232.0 (TID 403, localhost, executor driver, partition 3, PROCESS_LOCAL, 5141 bytes)
19/07/31 10:26:37 INFO Executor: Running task 0.0 in stage 232.0 (TID 400)
19/07/31 10:26:37 INFO Executor: Running task 1.0 in stage 232.0 (TID 401)
19/07/31 10:26:37 INFO Executor: Running task 2.0 in stage 232.0 (TID 402)
19/07/31 10:26:37 INFO Executor: Running task 3.0 in stage 232.0 (TID 403)
19/07/31 10:26:37 INFO Executor: Finished task 1.0 in stage 232.0 (TID 401). 992 bytes result sent to driver
19/07/31 10:26:37 INFO Executor: Finished task 2.0 in stage 232.0 (TID 402). 1026 bytes result sent to driver
19/07/31 10:26:37 INFO Executor: Finished task 0.0 in stage 232.0 (TID 400). 1012 bytes result sent to driver
19/07/31 10:26:37 INFO Executor: Finished task 3.0 in stage 232.0 (TID 403). 990 bytes result sent to driver
19/07/31 10:26:37 INFO TaskSetManager: Finished task 1.0 in stage 232.0 (TID 401) in 5 ms on localhost (executor driver) (1/4)
19/07/31 10:26:37 INFO TaskSetManager: Finished task 2.0 in stage 232.0 (TID 402) in 5 ms on localhost (executor driver) (2/4)
19/07/31 10:26:37 INFO TaskSetManager: Finished task 0.0 in stage 232.0 (TID 400) in 7 ms on localhost (executor driver) (3/4)
19/07/31 10:26:37 INFO TaskSetManager: Finished task 3.0 in stage 232.0 (TID 403) in 6 ms on localhost (executor driver) (4/4)
19/07/31 10:26:37 INFO TaskSchedulerImpl: Removed TaskSet 232.0, whose tasks have all completed, from pool 
19/07/31 10:26:37 INFO DAGScheduler: ResultStage 232 (collect at utils.scala:44) finished in 0.007 s
19/07/31 10:26:37 INFO DAGScheduler: Job 162 finished: collect at utils.scala:44, took 0.017068 s
19/07/31 10:26:37 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 10:26:37 INFO MapPartitionsRDD: Removing RDD 771 from persistence list
19/07/31 10:26:37 INFO BlockManager: Removing RDD 771
19/07/31 10:26:37 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:26:37 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#10279)) > 0)
19/07/31 10:26:37 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 10:26:37 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_254 stored as values in memory (estimated size 281.2 KB, free 909.6 MB)
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_254_piece0 stored as bytes in memory (estimated size 23.8 KB, free 909.5 MB)
19/07/31 10:26:37 INFO BlockManagerInfo: Added broadcast_254_piece0 in memory on 127.0.0.1:53873 (size: 23.8 KB, free: 912.0 MB)
19/07/31 10:26:37 INFO SparkContext: Created broadcast 254 from csv at NativeMethodAccessorImpl.java:0
19/07/31 10:26:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:26:37 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 10:26:37 INFO DAGScheduler: Got job 163 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 10:26:37 INFO DAGScheduler: Final stage: ResultStage 233 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 10:26:37 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:26:37 INFO DAGScheduler: Missing parents: List()
19/07/31 10:26:37 INFO DAGScheduler: Submitting ResultStage 233 (MapPartitionsRDD[791] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_255 stored as values in memory (estimated size 8.2 KB, free 909.5 MB)
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_255_piece0 stored as bytes in memory (estimated size 4.3 KB, free 909.5 MB)
19/07/31 10:26:37 INFO BlockManagerInfo: Added broadcast_255_piece0 in memory on 127.0.0.1:53873 (size: 4.3 KB, free: 911.9 MB)
19/07/31 10:26:37 INFO SparkContext: Created broadcast 255 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 233 (MapPartitionsRDD[791] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:26:37 INFO TaskSchedulerImpl: Adding task set 233.0 with 1 tasks
19/07/31 10:26:37 INFO TaskSetManager: Starting task 0.0 in stage 233.0 (TID 404, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:26:37 INFO Executor: Running task 0.0 in stage 233.0 (TID 404)
19/07/31 10:26:37 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:26:37 INFO Executor: Finished task 0.0 in stage 233.0 (TID 404). 1394 bytes result sent to driver
19/07/31 10:26:37 INFO TaskSetManager: Finished task 0.0 in stage 233.0 (TID 404) in 7 ms on localhost (executor driver) (1/1)
19/07/31 10:26:37 INFO TaskSchedulerImpl: Removed TaskSet 233.0, whose tasks have all completed, from pool 
19/07/31 10:26:37 INFO DAGScheduler: ResultStage 233 (csv at NativeMethodAccessorImpl.java:0) finished in 0.009 s
19/07/31 10:26:37 INFO DAGScheduler: Job 163 finished: csv at NativeMethodAccessorImpl.java:0, took 0.023665 s
19/07/31 10:26:37 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:26:37 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 10:26:37 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 10:26:37 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_256 stored as values in memory (estimated size 281.2 KB, free 909.2 MB)
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_256_piece0 stored as bytes in memory (estimated size 23.8 KB, free 909.2 MB)
19/07/31 10:26:37 INFO BlockManagerInfo: Added broadcast_256_piece0 in memory on 127.0.0.1:53873 (size: 23.8 KB, free: 911.9 MB)
19/07/31 10:26:37 INFO SparkContext: Created broadcast 256 from csv at NativeMethodAccessorImpl.java:0
19/07/31 10:26:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:26:37 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 10:26:37 INFO DAGScheduler: Got job 164 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 10:26:37 INFO DAGScheduler: Final stage: ResultStage 234 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 10:26:37 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:26:37 INFO DAGScheduler: Missing parents: List()
19/07/31 10:26:37 INFO DAGScheduler: Submitting ResultStage 234 (MapPartitionsRDD[796] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_257 stored as values in memory (estimated size 14.8 KB, free 909.2 MB)
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_257_piece0 stored as bytes in memory (estimated size 8.6 KB, free 909.2 MB)
19/07/31 10:26:37 INFO BlockManagerInfo: Added broadcast_257_piece0 in memory on 127.0.0.1:53873 (size: 8.6 KB, free: 911.9 MB)
19/07/31 10:26:37 INFO SparkContext: Created broadcast 257 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 234 (MapPartitionsRDD[796] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:26:37 INFO TaskSchedulerImpl: Adding task set 234.0 with 1 tasks
19/07/31 10:26:37 INFO TaskSetManager: Starting task 0.0 in stage 234.0 (TID 405, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:26:37 INFO Executor: Running task 0.0 in stage 234.0 (TID 405)
19/07/31 10:26:37 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:26:37 INFO Executor: Finished task 0.0 in stage 234.0 (TID 405). 1584 bytes result sent to driver
19/07/31 10:26:37 INFO TaskSetManager: Finished task 0.0 in stage 234.0 (TID 405) in 16 ms on localhost (executor driver) (1/1)
19/07/31 10:26:37 INFO TaskSchedulerImpl: Removed TaskSet 234.0, whose tasks have all completed, from pool 
19/07/31 10:26:37 INFO DAGScheduler: ResultStage 234 (csv at NativeMethodAccessorImpl.java:0) finished in 0.016 s
19/07/31 10:26:37 INFO DAGScheduler: Job 164 finished: csv at NativeMethodAccessorImpl.java:0, took 0.041280 s
19/07/31 10:26:37 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:26:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:26:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:26:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:26:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:26:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:26:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:26:37 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 10:26:37 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 10:26:37 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 10:26:37 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:26:37 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 10:26:37 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 10:26:37 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_258 stored as values in memory (estimated size 282.3 KB, free 908.9 MB)
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_258_piece0 stored as bytes in memory (estimated size 24.0 KB, free 908.9 MB)
19/07/31 10:26:37 INFO BlockManagerInfo: Added broadcast_258_piece0 in memory on 127.0.0.1:53873 (size: 24.0 KB, free: 911.9 MB)
19/07/31 10:26:37 INFO SparkContext: Created broadcast 258 from sql at <unknown>:0
19/07/31 10:26:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:26:37 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 10:26:37 INFO DAGScheduler: Registering RDD 802 (sql at <unknown>:0)
19/07/31 10:26:37 INFO DAGScheduler: Got job 165 (sql at <unknown>:0) with 1 output partitions
19/07/31 10:26:37 INFO DAGScheduler: Final stage: ResultStage 236 (sql at <unknown>:0)
19/07/31 10:26:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 235)
19/07/31 10:26:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 235)
19/07/31 10:26:37 INFO DAGScheduler: Submitting ShuffleMapStage 235 (MapPartitionsRDD[802] at sql at <unknown>:0), which has no missing parents
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_259 stored as values in memory (estimated size 26.3 KB, free 908.9 MB)
19/07/31 10:26:37 INFO MemoryStore: Block broadcast_259_piece0 stored as bytes in memory (estimated size 11.8 KB, free 908.9 MB)
19/07/31 10:26:37 INFO BlockManagerInfo: Added broadcast_259_piece0 in memory on 127.0.0.1:53873 (size: 11.8 KB, free: 911.9 MB)
19/07/31 10:26:37 INFO SparkContext: Created broadcast 259 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 235 (MapPartitionsRDD[802] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:26:37 INFO TaskSchedulerImpl: Adding task set 235.0 with 1 tasks
19/07/31 10:26:37 INFO TaskSetManager: Starting task 0.0 in stage 235.0 (TID 406, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 10:26:37 INFO Executor: Running task 0.0 in stage 235.0 (TID 406)
19/07/31 10:26:37 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:26:38 INFO MemoryStore: Block rdd_799_0 stored as values in memory (estimated size 48.9 KB, free 908.8 MB)
19/07/31 10:26:38 INFO BlockManagerInfo: Added rdd_799_0 in memory on 127.0.0.1:53873 (size: 48.9 KB, free: 911.8 MB)
19/07/31 10:26:38 INFO Executor: Finished task 0.0 in stage 235.0 (TID 406). 2461 bytes result sent to driver
19/07/31 10:26:38 INFO TaskSetManager: Finished task 0.0 in stage 235.0 (TID 406) in 126 ms on localhost (executor driver) (1/1)
19/07/31 10:26:38 INFO TaskSchedulerImpl: Removed TaskSet 235.0, whose tasks have all completed, from pool 
19/07/31 10:26:38 INFO DAGScheduler: ShuffleMapStage 235 (sql at <unknown>:0) finished in 0.127 s
19/07/31 10:26:38 INFO DAGScheduler: looking for newly runnable stages
19/07/31 10:26:38 INFO DAGScheduler: running: Set()
19/07/31 10:26:38 INFO DAGScheduler: waiting: Set(ResultStage 236)
19/07/31 10:26:38 INFO DAGScheduler: failed: Set()
19/07/31 10:26:38 INFO DAGScheduler: Submitting ResultStage 236 (MapPartitionsRDD[805] at sql at <unknown>:0), which has no missing parents
19/07/31 10:26:38 INFO MemoryStore: Block broadcast_260 stored as values in memory (estimated size 7.0 KB, free 908.8 MB)
19/07/31 10:26:38 INFO MemoryStore: Block broadcast_260_piece0 stored as bytes in memory (estimated size 3.7 KB, free 908.8 MB)
19/07/31 10:26:38 INFO BlockManagerInfo: Added broadcast_260_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 911.8 MB)
19/07/31 10:26:38 INFO SparkContext: Created broadcast 260 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 236 (MapPartitionsRDD[805] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:26:38 INFO TaskSchedulerImpl: Adding task set 236.0 with 1 tasks
19/07/31 10:26:38 INFO TaskSetManager: Starting task 0.0 in stage 236.0 (TID 407, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 10:26:38 INFO Executor: Running task 0.0 in stage 236.0 (TID 407)
19/07/31 10:26:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 10:26:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 10:26:38 INFO Executor: Finished task 0.0 in stage 236.0 (TID 407). 1581 bytes result sent to driver
19/07/31 10:26:38 INFO TaskSetManager: Finished task 0.0 in stage 236.0 (TID 407) in 8 ms on localhost (executor driver) (1/1)
19/07/31 10:26:38 INFO TaskSchedulerImpl: Removed TaskSet 236.0, whose tasks have all completed, from pool 
19/07/31 10:26:38 INFO DAGScheduler: ResultStage 236 (sql at <unknown>:0) finished in 0.008 s
19/07/31 10:26:38 INFO DAGScheduler: Job 165 finished: sql at <unknown>:0, took 0.194970 s
19/07/31 10:26:38 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 10:26:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:26:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:26:38 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 10:26:38 INFO DAGScheduler: Registering RDD 808 (collect at utils.scala:204)
19/07/31 10:26:38 INFO DAGScheduler: Got job 166 (collect at utils.scala:204) with 1 output partitions
19/07/31 10:26:38 INFO DAGScheduler: Final stage: ResultStage 238 (collect at utils.scala:204)
19/07/31 10:26:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 237)
19/07/31 10:26:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 237)
19/07/31 10:26:38 INFO DAGScheduler: Submitting ShuffleMapStage 237 (MapPartitionsRDD[808] at collect at utils.scala:204), which has no missing parents
19/07/31 10:26:38 INFO MemoryStore: Block broadcast_261 stored as values in memory (estimated size 26.3 KB, free 908.8 MB)
19/07/31 10:26:38 INFO MemoryStore: Block broadcast_261_piece0 stored as bytes in memory (estimated size 11.9 KB, free 908.8 MB)
19/07/31 10:26:38 INFO BlockManagerInfo: Added broadcast_261_piece0 in memory on 127.0.0.1:53873 (size: 11.9 KB, free: 911.8 MB)
19/07/31 10:26:38 INFO SparkContext: Created broadcast 261 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 237 (MapPartitionsRDD[808] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:26:38 INFO TaskSchedulerImpl: Adding task set 237.0 with 1 tasks
19/07/31 10:26:38 INFO TaskSetManager: Starting task 0.0 in stage 237.0 (TID 408, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 10:26:38 INFO Executor: Running task 0.0 in stage 237.0 (TID 408)
19/07/31 10:26:38 INFO BlockManager: Found block rdd_799_0 locally
19/07/31 10:26:38 INFO Executor: Finished task 0.0 in stage 237.0 (TID 408). 1780 bytes result sent to driver
19/07/31 10:26:38 INFO TaskSetManager: Finished task 0.0 in stage 237.0 (TID 408) in 8 ms on localhost (executor driver) (1/1)
19/07/31 10:26:38 INFO TaskSchedulerImpl: Removed TaskSet 237.0, whose tasks have all completed, from pool 
19/07/31 10:26:38 INFO DAGScheduler: ShuffleMapStage 237 (collect at utils.scala:204) finished in 0.008 s
19/07/31 10:26:38 INFO DAGScheduler: looking for newly runnable stages
19/07/31 10:26:38 INFO DAGScheduler: running: Set()
19/07/31 10:26:38 INFO DAGScheduler: waiting: Set(ResultStage 238)
19/07/31 10:26:38 INFO DAGScheduler: failed: Set()
19/07/31 10:26:38 INFO DAGScheduler: Submitting ResultStage 238 (MapPartitionsRDD[811] at collect at utils.scala:204), which has no missing parents
19/07/31 10:26:38 INFO MemoryStore: Block broadcast_262 stored as values in memory (estimated size 7.0 KB, free 908.8 MB)
19/07/31 10:26:38 INFO MemoryStore: Block broadcast_262_piece0 stored as bytes in memory (estimated size 3.7 KB, free 908.8 MB)
19/07/31 10:26:38 INFO BlockManagerInfo: Added broadcast_262_piece0 in memory on 127.0.0.1:53873 (size: 3.7 KB, free: 911.8 MB)
19/07/31 10:26:38 INFO SparkContext: Created broadcast 262 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 238 (MapPartitionsRDD[811] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:26:38 INFO TaskSchedulerImpl: Adding task set 238.0 with 1 tasks
19/07/31 10:26:38 INFO TaskSetManager: Starting task 0.0 in stage 238.0 (TID 409, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 10:26:38 INFO Executor: Running task 0.0 in stage 238.0 (TID 409)
19/07/31 10:26:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 10:26:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 10:26:38 INFO Executor: Finished task 0.0 in stage 238.0 (TID 409). 1581 bytes result sent to driver
19/07/31 10:26:38 INFO TaskSetManager: Finished task 0.0 in stage 238.0 (TID 409) in 7 ms on localhost (executor driver) (1/1)
19/07/31 10:26:38 INFO TaskSchedulerImpl: Removed TaskSet 238.0, whose tasks have all completed, from pool 
19/07/31 10:26:38 INFO DAGScheduler: ResultStage 238 (collect at utils.scala:204) finished in 0.008 s
19/07/31 10:26:38 INFO DAGScheduler: Job 166 finished: collect at utils.scala:204, took 0.064492 s
19/07/31 10:26:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz20`
WHERE (0 = 1)
19/07/31 10:26:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:26:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:26:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:26:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:26:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:26:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:26:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:26:43 INFO SparkSqlParser: Parsing command: SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 10:26:43 INFO SparkSqlParser: Parsing command: SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`
LIMIT 1000
19/07/31 10:26:43 INFO CodeGenerator: Code generated in 18.430252 ms
19/07/31 10:26:43 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 10:26:43 INFO DAGScheduler: Got job 167 (collect at utils.scala:204) with 1 output partitions
19/07/31 10:26:43 INFO DAGScheduler: Final stage: ResultStage 239 (collect at utils.scala:204)
19/07/31 10:26:43 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:26:43 INFO DAGScheduler: Missing parents: List()
19/07/31 10:26:43 INFO DAGScheduler: Submitting ResultStage 239 (MapPartitionsRDD[814] at collect at utils.scala:204), which has no missing parents
19/07/31 10:26:43 INFO MemoryStore: Block broadcast_263 stored as values in memory (estimated size 25.7 KB, free 908.7 MB)
19/07/31 10:26:43 INFO MemoryStore: Block broadcast_263_piece0 stored as bytes in memory (estimated size 11.2 KB, free 908.7 MB)
19/07/31 10:26:43 INFO BlockManagerInfo: Added broadcast_263_piece0 in memory on 127.0.0.1:53873 (size: 11.2 KB, free: 911.8 MB)
19/07/31 10:26:43 INFO SparkContext: Created broadcast 263 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 239 (MapPartitionsRDD[814] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:26:43 INFO TaskSchedulerImpl: Adding task set 239.0 with 1 tasks
19/07/31 10:26:43 INFO TaskSetManager: Starting task 0.0 in stage 239.0 (TID 410, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:26:43 INFO Executor: Running task 0.0 in stage 239.0 (TID 410)
19/07/31 10:26:43 INFO BlockManager: Found block rdd_799_0 locally
19/07/31 10:26:43 INFO CodeGenerator: Code generated in 15.265584 ms
19/07/31 10:26:43 INFO Executor: 1 block locks were not released by TID = 410:
[rdd_799_0]
19/07/31 10:26:43 INFO Executor: Finished task 0.0 in stage 239.0 (TID 410). 31077 bytes result sent to driver
19/07/31 10:26:43 INFO TaskSetManager: Finished task 0.0 in stage 239.0 (TID 410) in 28 ms on localhost (executor driver) (1/1)
19/07/31 10:26:43 INFO TaskSchedulerImpl: Removed TaskSet 239.0, whose tasks have all completed, from pool 
19/07/31 10:26:43 INFO DAGScheduler: ResultStage 239 (collect at utils.scala:204) finished in 0.029 s
19/07/31 10:26:43 INFO DAGScheduler: Job 167 finished: collect at utils.scala:204, took 0.061169 s
19/07/31 10:26:59 INFO SparkSqlParser: Parsing command: SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 10:26:59 INFO SparkSqlParser: Parsing command: SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`
LIMIT 1000
19/07/31 10:26:59 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 10:26:59 INFO DAGScheduler: Got job 168 (collect at utils.scala:204) with 1 output partitions
19/07/31 10:26:59 INFO DAGScheduler: Final stage: ResultStage 240 (collect at utils.scala:204)
19/07/31 10:26:59 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:26:59 INFO DAGScheduler: Missing parents: List()
19/07/31 10:26:59 INFO DAGScheduler: Submitting ResultStage 240 (MapPartitionsRDD[817] at collect at utils.scala:204), which has no missing parents
19/07/31 10:26:59 INFO MemoryStore: Block broadcast_264 stored as values in memory (estimated size 25.7 KB, free 908.7 MB)
19/07/31 10:26:59 INFO MemoryStore: Block broadcast_264_piece0 stored as bytes in memory (estimated size 11.3 KB, free 908.7 MB)
19/07/31 10:26:59 INFO BlockManagerInfo: Added broadcast_264_piece0 in memory on 127.0.0.1:53873 (size: 11.3 KB, free: 911.8 MB)
19/07/31 10:26:59 INFO SparkContext: Created broadcast 264 from broadcast at DAGScheduler.scala:1006
19/07/31 10:26:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 240 (MapPartitionsRDD[817] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:26:59 INFO TaskSchedulerImpl: Adding task set 240.0 with 1 tasks
19/07/31 10:26:59 INFO TaskSetManager: Starting task 0.0 in stage 240.0 (TID 411, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:26:59 INFO Executor: Running task 0.0 in stage 240.0 (TID 411)
19/07/31 10:26:59 INFO BlockManager: Found block rdd_799_0 locally
19/07/31 10:26:59 INFO Executor: 1 block locks were not released by TID = 411:
[rdd_799_0]
19/07/31 10:26:59 INFO Executor: Finished task 0.0 in stage 240.0 (TID 411). 31077 bytes result sent to driver
19/07/31 10:26:59 INFO TaskSetManager: Finished task 0.0 in stage 240.0 (TID 411) in 14 ms on localhost (executor driver) (1/1)
19/07/31 10:26:59 INFO TaskSchedulerImpl: Removed TaskSet 240.0, whose tasks have all completed, from pool 
19/07/31 10:26:59 INFO DAGScheduler: ResultStage 240 (collect at utils.scala:204) finished in 0.014 s
19/07/31 10:26:59 INFO DAGScheduler: Job 168 finished: collect at utils.scala:204, took 0.044155 s
19/07/31 10:28:40 INFO SparkContext: Invoking stop() from shutdown hook
19/07/31 10:28:40 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
19/07/31 10:28:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/07/31 10:28:40 INFO MemoryStore: MemoryStore cleared
19/07/31 10:28:40 INFO BlockManager: BlockManager stopped
19/07/31 10:28:40 INFO BlockManagerMaster: BlockManagerMaster stopped
19/07/31 10:28:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/07/31 10:28:40 INFO SparkContext: Successfully stopped SparkContext
19/07/31 10:28:40 INFO ShutdownHookManager: Shutdown hook called
19/07/31 10:28:40 INFO ShutdownHookManager: Deleting directory /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-c279cfc8-15b2-4f65-944e-9f2231113db3
19/07/31 10:28:49 INFO SparkContext: Running Spark version 2.2.0
19/07/31 10:28:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/07/31 10:28:49 INFO SparkContext: Submitted application: sparklyr
19/07/31 10:28:49 INFO SecurityManager: Changing view acls to: 6jncnk4f
19/07/31 10:28:49 INFO SecurityManager: Changing modify acls to: 6jncnk4f
19/07/31 10:28:49 INFO SecurityManager: Changing view acls groups to: 
19/07/31 10:28:49 INFO SecurityManager: Changing modify acls groups to: 
19/07/31 10:28:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(6jncnk4f); groups with view permissions: Set(); users  with modify permissions: Set(6jncnk4f); groups with modify permissions: Set()
19/07/31 10:28:49 INFO Utils: Successfully started service 'sparkDriver' on port 59788.
19/07/31 10:28:49 INFO SparkEnv: Registering MapOutputTracker
19/07/31 10:28:49 INFO SparkEnv: Registering BlockManagerMaster
19/07/31 10:28:49 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/07/31 10:28:49 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/07/31 10:28:49 INFO DiskBlockManager: Created local directory at /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/blockmgr-759ad824-0502-4c3f-8333-e26246a5bca1
19/07/31 10:28:49 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/07/31 10:28:49 INFO SparkEnv: Registering OutputCommitCoordinator
19/07/31 10:28:50 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/07/31 10:28:50 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
19/07/31 10:28:50 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:59788/jars/sparklyr-2.0-2.11.jar with timestamp 1564583330229
19/07/31 10:28:50 INFO Executor: Starting executor ID driver on host localhost
19/07/31 10:28:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59789.
19/07/31 10:28:50 INFO NettyBlockTransferService: Server created on 127.0.0.1:59789
19/07/31 10:28:50 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/07/31 10:28:50 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 59789, None)
19/07/31 10:28:50 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:59789 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 59789, None)
19/07/31 10:28:50 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 59789, None)
19/07/31 10:28:50 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 59789, None)
19/07/31 10:28:50 INFO SharedState: loading hive config file: file:/Users/6jncnk4f/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/07/31 10:28:50 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse').
19/07/31 10:28:50 INFO SharedState: Warehouse path is 'file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse'.
19/07/31 10:28:51 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/07/31 10:28:51 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/07/31 10:28:51 INFO ObjectStore: ObjectStore, initialize called
19/07/31 10:28:51 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/07/31 10:28:51 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/07/31 10:28:53 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/07/31 10:28:53 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 10:28:53 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 10:28:54 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 10:28:54 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 10:28:54 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/07/31 10:28:54 INFO ObjectStore: Initialized ObjectStore
19/07/31 10:28:54 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/07/31 10:28:54 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/07/31 10:28:54 INFO HiveMetaStore: Added admin role in metastore
19/07/31 10:28:54 INFO HiveMetaStore: Added public role in metastore
19/07/31 10:28:54 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/07/31 10:28:55 INFO HiveMetaStore: 0: get_all_databases
19/07/31 10:28:55 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_all_databases	
19/07/31 10:28:55 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/07/31 10:28:55 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/07/31 10:28:55 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 10:28:55 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/55a29dfb-cffb-4817-80c1-1ebf89810623_resources
19/07/31 10:28:55 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/55a29dfb-cffb-4817-80c1-1ebf89810623
19/07/31 10:28:55 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/55a29dfb-cffb-4817-80c1-1ebf89810623
19/07/31 10:28:55 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/55a29dfb-cffb-4817-80c1-1ebf89810623/_tmp_space.db
19/07/31 10:28:55 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 10:28:55 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:28:55 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:28:55 INFO HiveMetaStore: 0: get_database: global_temp
19/07/31 10:28:55 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/07/31 10:28:55 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/07/31 10:28:55 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/a27f538e-439c-4e04-b894-e401ef83c965_resources
19/07/31 10:28:55 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/a27f538e-439c-4e04-b894-e401ef83c965
19/07/31 10:28:55 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/a27f538e-439c-4e04-b894-e401ef83c965
19/07/31 10:28:55 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/a27f538e-439c-4e04-b894-e401ef83c965/_tmp_space.db
19/07/31 10:28:55 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 10:28:55 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/07/31 10:28:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:28:57 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:28:57 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:28:57 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:28:57 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:28:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:28:57 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:29:00 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:29:00 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:29:00 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:29:00 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:29:00 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:29:00 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:29:00 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:29:00 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 10:29:00 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/07/31 10:29:00 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/07/31 10:29:00 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:29:00 INFO DAGScheduler: Missing parents: List()
19/07/31 10:29:00 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/07/31 10:29:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/07/31 10:29:00 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/07/31 10:29:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:59789 (size: 3.4 KB, free: 912.3 MB)
19/07/31 10:29:00 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/07/31 10:29:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 10:29:00 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/07/31 10:29:00 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/07/31 10:29:00 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/07/31 10:29:00 INFO Executor: Fetching spark://127.0.0.1:59788/jars/sparklyr-2.0-2.11.jar with timestamp 1564583330229
19/07/31 10:29:00 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:59788 after 16 ms (0 ms spent in bootstraps)
19/07/31 10:29:00 INFO Utils: Fetching spark://127.0.0.1:59788/jars/sparklyr-2.0-2.11.jar to /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-33a74b48-ed34-45a6-96c9-66de13d64d36/userFiles-9c1f6164-6d82-46e0-8c13-3a19f97fe8bd/fetchFileTemp6164537159974235332.tmp
19/07/31 10:29:01 INFO Executor: Adding file:/private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-33a74b48-ed34-45a6-96c9-66de13d64d36/userFiles-9c1f6164-6d82-46e0-8c13-3a19f97fe8bd/sparklyr-2.0-2.11.jar to class loader
19/07/31 10:29:01 INFO CodeGenerator: Code generated in 310.789531 ms
19/07/31 10:29:01 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1056 bytes result sent to driver
19/07/31 10:29:01 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 762 ms on localhost (executor driver) (1/1)
19/07/31 10:29:01 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/07/31 10:29:01 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.785 s
19/07/31 10:29:01 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0.940261 s
19/07/31 10:29:02 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:29:02 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#17)) > 0)
19/07/31 10:29:02 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 10:29:02 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:29:02 INFO CodeGenerator: Code generated in 12.945424 ms
19/07/31 10:29:02 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 281.2 KB, free 912.0 MB)
19/07/31 10:29:02 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.8 KB, free 912.0 MB)
19/07/31 10:29:02 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:59789 (size: 23.8 KB, free: 912.3 MB)
19/07/31 10:29:02 INFO SparkContext: Created broadcast 1 from csv at NativeMethodAccessorImpl.java:0
19/07/31 10:29:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:29:02 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 10:29:02 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 10:29:02 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 10:29:02 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:29:02 INFO DAGScheduler: Missing parents: List()
19/07/31 10:29:02 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:29:02 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 912.0 MB)
19/07/31 10:29:02 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 912.0 MB)
19/07/31 10:29:02 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:59789 (size: 4.3 KB, free: 912.3 MB)
19/07/31 10:29:02 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/07/31 10:29:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:29:02 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/07/31 10:29:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:29:02 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/07/31 10:29:02 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:29:02 INFO CodeGenerator: Code generated in 9.152151 ms
19/07/31 10:29:02 INFO ContextCleaner: Cleaned accumulator 0
19/07/31 10:29:02 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1437 bytes result sent to driver
19/07/31 10:29:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 223 ms on localhost (executor driver) (1/1)
19/07/31 10:29:02 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/07/31 10:29:02 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0.224 s
19/07/31 10:29:02 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0.239049 s
19/07/31 10:29:02 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:59789 in memory (size: 3.4 KB, free: 912.3 MB)
19/07/31 10:29:02 INFO CodeGenerator: Code generated in 5.508857 ms
19/07/31 10:29:02 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:29:02 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 10:29:02 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 10:29:02 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:29:02 INFO CodeGenerator: Code generated in 5.285475 ms
19/07/31 10:29:02 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 281.2 KB, free 911.7 MB)
19/07/31 10:29:02 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.7 MB)
19/07/31 10:29:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:59789 (size: 23.8 KB, free: 912.2 MB)
19/07/31 10:29:02 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:0
19/07/31 10:29:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:29:02 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 10:29:02 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 10:29:02 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 10:29:02 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:29:02 INFO DAGScheduler: Missing parents: List()
19/07/31 10:29:02 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:29:02 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.8 KB, free 911.7 MB)
19/07/31 10:29:02 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.7 MB)
19/07/31 10:29:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:59789 (size: 8.6 KB, free: 912.2 MB)
19/07/31 10:29:02 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/07/31 10:29:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:29:02 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/07/31 10:29:02 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:29:02 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/07/31 10:29:02 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:29:02 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1627 bytes result sent to driver
19/07/31 10:29:02 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 70 ms on localhost (executor driver) (1/1)
19/07/31 10:29:02 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/07/31 10:29:02 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.071 s
19/07/31 10:29:02 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.079286 s
19/07/31 10:29:02 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:29:02 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:29:02 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:29:02 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:29:02 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:29:02 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:29:02 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:29:02 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 10:29:02 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 10:29:02 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 10:29:02 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:29:02 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 10:29:02 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 10:29:02 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:29:02 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 282.3 KB, free 911.4 MB)
19/07/31 10:29:02 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.4 MB)
19/07/31 10:29:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:59789 (size: 24.0 KB, free: 912.2 MB)
19/07/31 10:29:02 INFO SparkContext: Created broadcast 5 from sql at NativeMethodAccessorImpl.java:0
19/07/31 10:29:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:29:02 INFO CodeGenerator: Code generated in 15.10031 ms
19/07/31 10:29:02 INFO CodeGenerator: Code generated in 10.01708 ms
19/07/31 10:29:02 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 10:29:02 INFO DAGScheduler: Registering RDD 18 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 10:29:02 INFO DAGScheduler: Got job 3 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 10:29:02 INFO DAGScheduler: Final stage: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 10:29:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/07/31 10:29:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/07/31 10:29:02 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:29:02 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 26.3 KB, free 911.3 MB)
19/07/31 10:29:02 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.8 KB, free 911.3 MB)
19/07/31 10:29:02 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:59789 (size: 11.8 KB, free: 912.2 MB)
19/07/31 10:29:02 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/07/31 10:29:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:29:02 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/07/31 10:29:02 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 10:29:02 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/07/31 10:29:02 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:29:02 INFO CodeGenerator: Code generated in 15.105175 ms
19/07/31 10:29:03 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 48.9 KB, free 911.3 MB)
19/07/31 10:29:03 INFO BlockManagerInfo: Added rdd_15_0 in memory on 127.0.0.1:59789 (size: 48.9 KB, free: 912.2 MB)
19/07/31 10:29:03 INFO CodeGenerator: Code generated in 6.15495 ms
19/07/31 10:29:03 INFO CodeGenerator: Code generated in 16.078552 ms
19/07/31 10:29:03 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2504 bytes result sent to driver
19/07/31 10:29:03 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 238 ms on localhost (executor driver) (1/1)
19/07/31 10:29:03 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/07/31 10:29:03 INFO DAGScheduler: ShuffleMapStage 3 (sql at NativeMethodAccessorImpl.java:0) finished in 0.240 s
19/07/31 10:29:03 INFO DAGScheduler: looking for newly runnable stages
19/07/31 10:29:03 INFO DAGScheduler: running: Set()
19/07/31 10:29:03 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/07/31 10:29:03 INFO DAGScheduler: failed: Set()
19/07/31 10:29:03 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:29:03 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 911.3 MB)
19/07/31 10:29:03 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.3 MB)
19/07/31 10:29:03 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:59789 (size: 3.7 KB, free: 912.2 MB)
19/07/31 10:29:03 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/07/31 10:29:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:29:03 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/07/31 10:29:03 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 10:29:03 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/07/31 10:29:03 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 10:29:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
19/07/31 10:29:03 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1581 bytes result sent to driver
19/07/31 10:29:03 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 32 ms on localhost (executor driver) (1/1)
19/07/31 10:29:03 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/07/31 10:29:03 INFO DAGScheduler: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0) finished in 0.033 s
19/07/31 10:29:03 INFO DAGScheduler: Job 3 finished: sql at NativeMethodAccessorImpl.java:0, took 0.338005 s
19/07/31 10:29:03 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 10:29:03 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:29:03 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:29:03 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 10:29:03 INFO DAGScheduler: Registering RDD 24 (collect at utils.scala:204)
19/07/31 10:29:03 INFO DAGScheduler: Got job 4 (collect at utils.scala:204) with 1 output partitions
19/07/31 10:29:03 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
19/07/31 10:29:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/07/31 10:29:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/07/31 10:29:03 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204), which has no missing parents
19/07/31 10:29:03 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 26.3 KB, free 911.2 MB)
19/07/31 10:29:03 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.9 KB, free 911.2 MB)
19/07/31 10:29:03 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:59789 (size: 11.9 KB, free: 912.1 MB)
19/07/31 10:29:03 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/07/31 10:29:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:29:03 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/07/31 10:29:03 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 10:29:03 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/07/31 10:29:03 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 10:29:03 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1780 bytes result sent to driver
19/07/31 10:29:03 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 11 ms on localhost (executor driver) (1/1)
19/07/31 10:29:03 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/07/31 10:29:03 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:204) finished in 0.013 s
19/07/31 10:29:03 INFO DAGScheduler: looking for newly runnable stages
19/07/31 10:29:03 INFO DAGScheduler: running: Set()
19/07/31 10:29:03 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/07/31 10:29:03 INFO DAGScheduler: failed: Set()
19/07/31 10:29:03 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204), which has no missing parents
19/07/31 10:29:03 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 911.2 MB)
19/07/31 10:29:03 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.2 MB)
19/07/31 10:29:03 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:59789 (size: 3.7 KB, free: 912.1 MB)
19/07/31 10:29:03 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/07/31 10:29:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:29:03 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/07/31 10:29:03 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 10:29:03 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/07/31 10:29:03 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 10:29:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 10:29:03 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1581 bytes result sent to driver
19/07/31 10:29:03 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 4 ms on localhost (executor driver) (1/1)
19/07/31 10:29:03 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/07/31 10:29:03 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.006 s
19/07/31 10:29:03 INFO DAGScheduler: Job 4 finished: collect at utils.scala:204, took 0.032621 s
19/07/31 10:29:03 INFO CodeGenerator: Code generated in 6.091854 ms
19/07/31 10:29:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz21`
WHERE (0 = 1)
19/07/31 10:29:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:29:03 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:29:03 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:29:03 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:29:03 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:29:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:29:03 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:29:03 INFO CodeGenerator: Code generated in 7.482716 ms
19/07/31 10:30:20 INFO SparkSqlParser: Parsing command: SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 10:30:20 INFO SparkSqlParser: Parsing command: SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`
LIMIT 1000
19/07/31 10:30:20 INFO CodeGenerator: Code generated in 37.624874 ms
19/07/31 10:30:20 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 10:30:20 INFO DAGScheduler: Got job 5 (collect at utils.scala:204) with 1 output partitions
19/07/31 10:30:20 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:204)
19/07/31 10:30:20 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:30:20 INFO DAGScheduler: Missing parents: List()
19/07/31 10:30:20 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[30] at collect at utils.scala:204), which has no missing parents
19/07/31 10:30:20 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 25.7 KB, free 911.2 MB)
19/07/31 10:30:20 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 11.3 KB, free 911.2 MB)
19/07/31 10:30:20 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:59789 (size: 11.3 KB, free: 912.1 MB)
19/07/31 10:30:20 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/07/31 10:30:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[30] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:30:20 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/07/31 10:30:20 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:30:20 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
19/07/31 10:30:20 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 10:30:20 INFO CodeGenerator: Code generated in 28.594952 ms
19/07/31 10:30:20 INFO Executor: 1 block locks were not released by TID = 7:
[rdd_15_0]
19/07/31 10:30:20 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 31120 bytes result sent to driver
19/07/31 10:30:20 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 85 ms on localhost (executor driver) (1/1)
19/07/31 10:30:20 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/07/31 10:30:20 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:204) finished in 0.087 s
19/07/31 10:30:20 INFO DAGScheduler: Job 5 finished: collect at utils.scala:204, took 0.114045 s
19/07/31 10:30:20 INFO CodeGenerator: Code generated in 9.154648 ms
19/07/31 10:36:46 INFO SparkSqlParser: Parsing command: SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 10:36:46 INFO SparkSqlParser: Parsing command: SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`
LIMIT 1000
19/07/31 10:36:46 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 10:36:46 INFO DAGScheduler: Got job 6 (collect at utils.scala:204) with 1 output partitions
19/07/31 10:36:46 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:204)
19/07/31 10:36:46 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:36:46 INFO DAGScheduler: Missing parents: List()
19/07/31 10:36:46 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[33] at collect at utils.scala:204), which has no missing parents
19/07/31 10:36:46 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 25.7 KB, free 911.2 MB)
19/07/31 10:36:46 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 11.3 KB, free 911.2 MB)
19/07/31 10:36:46 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:59789 (size: 11.3 KB, free: 912.1 MB)
19/07/31 10:36:46 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/07/31 10:36:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[33] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:36:46 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/07/31 10:36:46 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:36:46 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
19/07/31 10:36:46 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 10:36:46 INFO Executor: 1 block locks were not released by TID = 8:
[rdd_15_0]
19/07/31 10:36:46 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 31077 bytes result sent to driver
19/07/31 10:36:46 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 11 ms on localhost (executor driver) (1/1)
19/07/31 10:36:46 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/07/31 10:36:46 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:204) finished in 0.013 s
19/07/31 10:36:46 INFO DAGScheduler: Job 6 finished: collect at utils.scala:204, took 0.025663 s
19/07/31 10:45:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:45:20 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:45:20 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:45:20 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:45:20 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:45:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:45:20 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:45:20 INFO CodeGenerator: Code generated in 25.654491 ms
19/07/31 10:45:20 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 10:45:20 INFO DAGScheduler: Got job 7 (collect at utils.scala:44) with 1 output partitions
19/07/31 10:45:20 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:44)
19/07/31 10:45:20 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:45:20 INFO DAGScheduler: Missing parents: List()
19/07/31 10:45:20 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[38] at map at utils.scala:41), which has no missing parents
19/07/31 10:45:20 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 6.3 KB, free 911.1 MB)
19/07/31 10:45:20 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.5 KB, free 911.1 MB)
19/07/31 10:45:20 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:59789 (size: 3.5 KB, free: 912.1 MB)
19/07/31 10:45:20 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/07/31 10:45:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[38] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 10:45:20 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/07/31 10:45:20 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 10:45:20 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
19/07/31 10:45:20 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1007 bytes result sent to driver
19/07/31 10:45:20 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 9 ms on localhost (executor driver) (1/1)
19/07/31 10:45:20 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/07/31 10:45:20 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:44) finished in 0.011 s
19/07/31 10:45:20 INFO DAGScheduler: Job 7 finished: collect at utils.scala:44, took 0.033562 s
19/07/31 10:45:20 INFO SparkSqlParser: Parsing command: SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 10:45:20 INFO SparkSqlParser: Parsing command: SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 10:45:21 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 10:45:21 INFO DAGScheduler: Got job 8 (collect at utils.scala:204) with 1 output partitions
19/07/31 10:45:21 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:204)
19/07/31 10:45:21 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:45:21 INFO DAGScheduler: Missing parents: List()
19/07/31 10:45:21 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[41] at collect at utils.scala:204), which has no missing parents
19/07/31 10:45:21 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 25.8 KB, free 911.1 MB)
19/07/31 10:45:21 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 11.3 KB, free 911.1 MB)
19/07/31 10:45:21 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:59789 (size: 11.3 KB, free: 912.1 MB)
19/07/31 10:45:21 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/07/31 10:45:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[41] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:45:21 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/07/31 10:45:21 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:45:21 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
19/07/31 10:45:21 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 10:45:21 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 37152 bytes result sent to driver
19/07/31 10:45:21 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 11 ms on localhost (executor driver) (1/1)
19/07/31 10:45:21 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/07/31 10:45:21 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:204) finished in 0.011 s
19/07/31 10:45:21 INFO DAGScheduler: Job 8 finished: collect at utils.scala:204, took 0.022331 s
19/07/31 10:45:21 INFO SparkSqlParser: Parsing command: df
19/07/31 10:45:21 INFO SparkSqlParser: Parsing command: CACHE TABLE `df`
19/07/31 10:45:21 INFO SparkSqlParser: Parsing command: `df`
19/07/31 10:45:21 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 10:45:21 INFO DAGScheduler: Registering RDD 49 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 10:45:21 INFO DAGScheduler: Got job 9 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 10:45:21 INFO DAGScheduler: Final stage: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 10:45:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
19/07/31 10:45:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
19/07/31 10:45:21 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[49] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:45:21 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 18.2 KB, free 911.1 MB)
19/07/31 10:45:21 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 8.4 KB, free 911.1 MB)
19/07/31 10:45:21 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:59789 (size: 8.4 KB, free: 912.1 MB)
19/07/31 10:45:21 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/07/31 10:45:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[49] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:45:21 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/07/31 10:45:21 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 54567 bytes)
19/07/31 10:45:21 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
19/07/31 10:45:21 INFO CodeGenerator: Code generated in 12.240112 ms
19/07/31 10:45:21 INFO CodeGenerator: Code generated in 55.029282 ms
19/07/31 10:45:21 INFO MemoryStore: Block rdd_46_0 stored as values in memory (estimated size 16.1 KB, free 911.1 MB)
19/07/31 10:45:21 INFO BlockManagerInfo: Added rdd_46_0 in memory on 127.0.0.1:59789 (size: 16.1 KB, free: 912.1 MB)
19/07/31 10:45:21 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 2328 bytes result sent to driver
19/07/31 10:45:21 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 168 ms on localhost (executor driver) (1/1)
19/07/31 10:45:21 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/07/31 10:45:21 INFO DAGScheduler: ShuffleMapStage 11 (sql at NativeMethodAccessorImpl.java:0) finished in 0.169 s
19/07/31 10:45:21 INFO DAGScheduler: looking for newly runnable stages
19/07/31 10:45:21 INFO DAGScheduler: running: Set()
19/07/31 10:45:21 INFO DAGScheduler: waiting: Set(ResultStage 12)
19/07/31 10:45:21 INFO DAGScheduler: failed: Set()
19/07/31 10:45:21 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[52] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:45:21 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 911.1 MB)
19/07/31 10:45:21 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.1 MB)
19/07/31 10:45:21 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:59789 (size: 3.7 KB, free: 912.1 MB)
19/07/31 10:45:21 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
19/07/31 10:45:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[52] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:45:21 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/07/31 10:45:21 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 10:45:21 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
19/07/31 10:45:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 10:45:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 10:45:21 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1581 bytes result sent to driver
19/07/31 10:45:21 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 7 ms on localhost (executor driver) (1/1)
19/07/31 10:45:21 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/07/31 10:45:21 INFO DAGScheduler: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0) finished in 0.009 s
19/07/31 10:45:21 INFO DAGScheduler: Job 9 finished: sql at NativeMethodAccessorImpl.java:0, took 0.216999 s
19/07/31 10:45:21 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `df`
19/07/31 10:45:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:45:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:45:21 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 10:45:21 INFO DAGScheduler: Registering RDD 55 (collect at utils.scala:204)
19/07/31 10:45:21 INFO DAGScheduler: Got job 10 (collect at utils.scala:204) with 1 output partitions
19/07/31 10:45:21 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:204)
19/07/31 10:45:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
19/07/31 10:45:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
19/07/31 10:45:21 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[55] at collect at utils.scala:204), which has no missing parents
19/07/31 10:45:21 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 18.2 KB, free 911.0 MB)
19/07/31 10:45:21 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 8.5 KB, free 911.0 MB)
19/07/31 10:45:21 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:59789 (size: 8.5 KB, free: 912.1 MB)
19/07/31 10:45:21 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/07/31 10:45:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[55] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:45:21 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/07/31 10:45:21 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 54567 bytes)
19/07/31 10:45:21 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
19/07/31 10:45:21 INFO BlockManager: Found block rdd_46_0 locally
19/07/31 10:45:21 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1690 bytes result sent to driver
19/07/31 10:45:21 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 16 ms on localhost (executor driver) (1/1)
19/07/31 10:45:21 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/07/31 10:45:21 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:204) finished in 0.017 s
19/07/31 10:45:21 INFO DAGScheduler: looking for newly runnable stages
19/07/31 10:45:21 INFO DAGScheduler: running: Set()
19/07/31 10:45:21 INFO DAGScheduler: waiting: Set(ResultStage 14)
19/07/31 10:45:21 INFO DAGScheduler: failed: Set()
19/07/31 10:45:21 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[58] at collect at utils.scala:204), which has no missing parents
19/07/31 10:45:21 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 911.0 MB)
19/07/31 10:45:21 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.0 MB)
19/07/31 10:45:21 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:59789 (size: 3.7 KB, free: 912.1 MB)
19/07/31 10:45:21 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/07/31 10:45:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[58] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:45:21 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/07/31 10:45:21 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 10:45:21 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
19/07/31 10:45:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 10:45:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 10:45:21 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1581 bytes result sent to driver
19/07/31 10:45:21 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 8 ms on localhost (executor driver) (1/1)
19/07/31 10:45:21 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/07/31 10:45:21 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:204) finished in 0.009 s
19/07/31 10:45:21 INFO DAGScheduler: Job 10 finished: collect at utils.scala:204, took 0.055802 s
19/07/31 10:45:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df` AS `zzz22`
WHERE (0 = 1)
19/07/31 10:45:21 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:45:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:45:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:45:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:45:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:45:21 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:45:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:45:54 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:45:54 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:45:54 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:45:54 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:45:54 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:45:54 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:45:54 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:45:54 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 10:45:54 INFO DAGScheduler: Got job 11 (collect at utils.scala:44) with 2 output partitions
19/07/31 10:45:54 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:44)
19/07/31 10:45:54 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:45:54 INFO DAGScheduler: Missing parents: List()
19/07/31 10:45:54 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[63] at map at utils.scala:41), which has no missing parents
19/07/31 10:45:54 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 6.4 KB, free 911.0 MB)
19/07/31 10:45:54 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.6 KB, free 911.0 MB)
19/07/31 10:45:54 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:59789 (size: 3.6 KB, free: 912.1 MB)
19/07/31 10:45:54 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
19/07/31 10:45:54 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 15 (MapPartitionsRDD[63] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
19/07/31 10:45:54 INFO TaskSchedulerImpl: Adding task set 15.0 with 2 tasks
19/07/31 10:45:54 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 10:45:54 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 16, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/07/31 10:45:54 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
19/07/31 10:45:54 INFO Executor: Running task 1.0 in stage 15.0 (TID 16)
19/07/31 10:45:54 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1007 bytes result sent to driver
19/07/31 10:45:54 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 13 ms on localhost (executor driver) (1/2)
19/07/31 10:45:54 INFO Executor: Finished task 1.0 in stage 15.0 (TID 16). 975 bytes result sent to driver
19/07/31 10:45:54 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 16) in 12 ms on localhost (executor driver) (2/2)
19/07/31 10:45:54 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/07/31 10:45:54 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:44) finished in 0.014 s
19/07/31 10:45:54 INFO DAGScheduler: Job 11 finished: collect at utils.scala:44, took 0.035766 s
19/07/31 10:46:34 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:46:34 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:46:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:46:34 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:46:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:46:34 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:46:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:46:35 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 10:46:35 INFO DAGScheduler: Got job 12 (collect at utils.scala:44) with 2 output partitions
19/07/31 10:46:35 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:44)
19/07/31 10:46:35 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:46:35 INFO DAGScheduler: Missing parents: List()
19/07/31 10:46:35 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[68] at map at utils.scala:41), which has no missing parents
19/07/31 10:46:35 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 6.4 KB, free 911.0 MB)
19/07/31 10:46:35 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.6 KB, free 911.0 MB)
19/07/31 10:46:35 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:59789 (size: 3.6 KB, free: 912.1 MB)
19/07/31 10:46:35 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/07/31 10:46:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 16 (MapPartitionsRDD[68] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
19/07/31 10:46:35 INFO TaskSchedulerImpl: Adding task set 16.0 with 2 tasks
19/07/31 10:46:35 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 10:46:35 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 18, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/07/31 10:46:35 INFO Executor: Running task 0.0 in stage 16.0 (TID 17)
19/07/31 10:46:35 INFO Executor: Running task 1.0 in stage 16.0 (TID 18)
19/07/31 10:46:35 INFO Executor: Finished task 0.0 in stage 16.0 (TID 17). 1007 bytes result sent to driver
19/07/31 10:46:35 INFO Executor: Finished task 1.0 in stage 16.0 (TID 18). 932 bytes result sent to driver
19/07/31 10:46:35 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 17) in 7 ms on localhost (executor driver) (1/2)
19/07/31 10:46:35 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 18) in 7 ms on localhost (executor driver) (2/2)
19/07/31 10:46:35 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/07/31 10:46:35 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:44) finished in 0.008 s
19/07/31 10:46:35 INFO DAGScheduler: Job 12 finished: collect at utils.scala:44, took 0.019058 s
19/07/31 10:46:35 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 10:46:35 INFO MapPartitionsRDD: Removing RDD 15 from persistence list
19/07/31 10:46:35 INFO BlockManager: Removing RDD 15
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 116
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 406
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 115
19/07/31 10:46:35 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:59789 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 113
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 343
19/07/31 10:46:35 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:59789 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 408
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 180
19/07/31 10:46:35 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:59789 in memory (size: 8.6 KB, free: 912.1 MB)
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 119
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 350
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 110
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 263
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 123
19/07/31 10:46:35 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:59789 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 10:46:35 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:59789 in memory (size: 8.4 KB, free: 912.1 MB)
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 342
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 345
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 402
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 409
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 117
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 187
19/07/31 10:46:35 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:59789 in memory (size: 11.9 KB, free: 912.1 MB)
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 120
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 118
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 341
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 404
19/07/31 10:46:35 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:59789 in memory (size: 11.3 KB, free: 912.2 MB)
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 346
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 183
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 236
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 126
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 463
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 349
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 109
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 237
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 405
19/07/31 10:46:35 INFO ContextCleaner: Cleaned shuffle 2
19/07/31 10:46:35 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:59789 in memory (size: 11.3 KB, free: 912.2 MB)
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 488
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 111
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 124
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 112
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 347
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 177
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 403
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 353
19/07/31 10:46:35 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:59789 in memory (size: 11.8 KB, free: 912.2 MB)
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 348
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 410
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 262
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 314
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 411
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 121
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 181
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 176
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 182
19/07/31 10:46:35 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:59789 in memory (size: 11.3 KB, free: 912.2 MB)
19/07/31 10:46:35 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:59789 in memory (size: 8.5 KB, free: 912.2 MB)
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 412
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 185
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 175
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 186
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 414
19/07/31 10:46:35 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:59789 in memory (size: 24.0 KB, free: 912.2 MB)
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 344
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 108
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 122
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 184
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 413
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 313
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 407
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 179
19/07/31 10:46:35 INFO ContextCleaner: Cleaned shuffle 0
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 178
19/07/31 10:46:35 INFO ContextCleaner: Cleaned shuffle 3
19/07/31 10:46:35 INFO ContextCleaner: Cleaned shuffle 1
19/07/31 10:46:35 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:59789 in memory (size: 3.6 KB, free: 912.2 MB)
19/07/31 10:46:35 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:59789 in memory (size: 3.6 KB, free: 912.2 MB)
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 125
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 288
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 351
19/07/31 10:46:35 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:59789 in memory (size: 3.7 KB, free: 912.2 MB)
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 114
19/07/31 10:46:35 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:59789 in memory (size: 3.5 KB, free: 912.2 MB)
19/07/31 10:46:35 INFO BlockManager: Removing RDD 15
19/07/31 10:46:35 INFO ContextCleaner: Cleaned RDD 15
19/07/31 10:46:35 INFO ContextCleaner: Cleaned accumulator 352
19/07/31 10:46:35 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:46:35 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#828)) > 0)
19/07/31 10:46:35 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 10:46:35 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:46:35 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 281.2 KB, free 911.4 MB)
19/07/31 10:46:35 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.4 MB)
19/07/31 10:46:35 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:59789 (size: 23.8 KB, free: 912.2 MB)
19/07/31 10:46:35 INFO SparkContext: Created broadcast 20 from csv at NativeMethodAccessorImpl.java:0
19/07/31 10:46:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:46:35 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 10:46:35 INFO DAGScheduler: Got job 13 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 10:46:35 INFO DAGScheduler: Final stage: ResultStage 17 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 10:46:35 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:46:35 INFO DAGScheduler: Missing parents: List()
19/07/31 10:46:35 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[71] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:46:35 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 8.2 KB, free 911.4 MB)
19/07/31 10:46:35 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 4.3 KB, free 911.4 MB)
19/07/31 10:46:35 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:59789 (size: 4.3 KB, free: 912.2 MB)
19/07/31 10:46:35 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
19/07/31 10:46:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[71] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:46:35 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
19/07/31 10:46:35 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:46:35 INFO Executor: Running task 0.0 in stage 17.0 (TID 19)
19/07/31 10:46:35 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:46:35 INFO Executor: Finished task 0.0 in stage 17.0 (TID 19). 1394 bytes result sent to driver
19/07/31 10:46:35 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 19) in 8 ms on localhost (executor driver) (1/1)
19/07/31 10:46:35 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/07/31 10:46:35 INFO DAGScheduler: ResultStage 17 (csv at NativeMethodAccessorImpl.java:0) finished in 0.009 s
19/07/31 10:46:35 INFO DAGScheduler: Job 13 finished: csv at NativeMethodAccessorImpl.java:0, took 0.028310 s
19/07/31 10:46:35 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:46:35 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 10:46:35 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 10:46:35 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:46:35 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 281.2 KB, free 911.1 MB)
19/07/31 10:46:35 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.1 MB)
19/07/31 10:46:35 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:59789 (size: 23.8 KB, free: 912.2 MB)
19/07/31 10:46:35 INFO SparkContext: Created broadcast 22 from csv at NativeMethodAccessorImpl.java:0
19/07/31 10:46:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:46:35 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 10:46:35 INFO DAGScheduler: Got job 14 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 10:46:35 INFO DAGScheduler: Final stage: ResultStage 18 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 10:46:35 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:46:35 INFO DAGScheduler: Missing parents: List()
19/07/31 10:46:35 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[76] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:46:35 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 14.8 KB, free 911.1 MB)
19/07/31 10:46:35 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.0 MB)
19/07/31 10:46:35 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:59789 (size: 8.6 KB, free: 912.2 MB)
19/07/31 10:46:35 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
19/07/31 10:46:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[76] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:46:35 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
19/07/31 10:46:35 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:46:35 INFO Executor: Running task 0.0 in stage 18.0 (TID 20)
19/07/31 10:46:35 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:46:35 INFO Executor: Finished task 0.0 in stage 18.0 (TID 20). 1584 bytes result sent to driver
19/07/31 10:46:35 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 20) in 32 ms on localhost (executor driver) (1/1)
19/07/31 10:46:35 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/07/31 10:46:35 INFO DAGScheduler: ResultStage 18 (csv at NativeMethodAccessorImpl.java:0) finished in 0.033 s
19/07/31 10:46:35 INFO DAGScheduler: Job 14 finished: csv at NativeMethodAccessorImpl.java:0, took 0.047005 s
19/07/31 10:46:35 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:46:35 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:46:35 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:46:35 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:46:35 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:46:35 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:46:35 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:46:35 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 10:46:35 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 10:46:35 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 10:46:35 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:46:35 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 10:46:35 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 10:46:35 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:46:35 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 282.3 KB, free 910.8 MB)
19/07/31 10:46:35 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 24.0 KB, free 910.7 MB)
19/07/31 10:46:35 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:59789 (size: 24.0 KB, free: 912.2 MB)
19/07/31 10:46:35 INFO SparkContext: Created broadcast 24 from sql at <unknown>:0
19/07/31 10:46:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:46:35 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 10:46:35 INFO DAGScheduler: Registering RDD 82 (sql at <unknown>:0)
19/07/31 10:46:35 INFO DAGScheduler: Got job 15 (sql at <unknown>:0) with 1 output partitions
19/07/31 10:46:35 INFO DAGScheduler: Final stage: ResultStage 20 (sql at <unknown>:0)
19/07/31 10:46:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
19/07/31 10:46:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
19/07/31 10:46:35 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[82] at sql at <unknown>:0), which has no missing parents
19/07/31 10:46:35 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 26.3 KB, free 910.7 MB)
19/07/31 10:46:35 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 11.9 KB, free 910.7 MB)
19/07/31 10:46:35 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:59789 (size: 11.9 KB, free: 912.1 MB)
19/07/31 10:46:35 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
19/07/31 10:46:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[82] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:46:35 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/07/31 10:46:35 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 10:46:35 INFO Executor: Running task 0.0 in stage 19.0 (TID 21)
19/07/31 10:46:35 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:46:36 INFO MemoryStore: Block rdd_79_0 stored as values in memory (estimated size 48.9 KB, free 910.7 MB)
19/07/31 10:46:36 INFO BlockManagerInfo: Added rdd_79_0 in memory on 127.0.0.1:59789 (size: 48.9 KB, free: 912.1 MB)
19/07/31 10:46:36 INFO Executor: Finished task 0.0 in stage 19.0 (TID 21). 2461 bytes result sent to driver
19/07/31 10:46:36 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 21) in 75 ms on localhost (executor driver) (1/1)
19/07/31 10:46:36 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/07/31 10:46:36 INFO DAGScheduler: ShuffleMapStage 19 (sql at <unknown>:0) finished in 0.075 s
19/07/31 10:46:36 INFO DAGScheduler: looking for newly runnable stages
19/07/31 10:46:36 INFO DAGScheduler: running: Set()
19/07/31 10:46:36 INFO DAGScheduler: waiting: Set(ResultStage 20)
19/07/31 10:46:36 INFO DAGScheduler: failed: Set()
19/07/31 10:46:36 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[85] at sql at <unknown>:0), which has no missing parents
19/07/31 10:46:36 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 7.0 KB, free 910.7 MB)
19/07/31 10:46:36 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.7 MB)
19/07/31 10:46:36 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:59789 (size: 3.7 KB, free: 912.1 MB)
19/07/31 10:46:36 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
19/07/31 10:46:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[85] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:46:36 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/07/31 10:46:36 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 22, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 10:46:36 INFO Executor: Running task 0.0 in stage 20.0 (TID 22)
19/07/31 10:46:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 10:46:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 10:46:36 INFO Executor: Finished task 0.0 in stage 20.0 (TID 22). 1581 bytes result sent to driver
19/07/31 10:46:36 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 22) in 6 ms on localhost (executor driver) (1/1)
19/07/31 10:46:36 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/07/31 10:46:36 INFO DAGScheduler: ResultStage 20 (sql at <unknown>:0) finished in 0.007 s
19/07/31 10:46:36 INFO DAGScheduler: Job 15 finished: sql at <unknown>:0, took 0.116796 s
19/07/31 10:46:36 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 10:46:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:46:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:46:36 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 10:46:36 INFO DAGScheduler: Registering RDD 88 (collect at utils.scala:204)
19/07/31 10:46:36 INFO DAGScheduler: Got job 16 (collect at utils.scala:204) with 1 output partitions
19/07/31 10:46:36 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:204)
19/07/31 10:46:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
19/07/31 10:46:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
19/07/31 10:46:36 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[88] at collect at utils.scala:204), which has no missing parents
19/07/31 10:46:36 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 26.3 KB, free 910.6 MB)
19/07/31 10:46:36 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 11.9 KB, free 910.6 MB)
19/07/31 10:46:36 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:59789 (size: 11.9 KB, free: 912.1 MB)
19/07/31 10:46:36 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
19/07/31 10:46:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[88] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:46:36 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
19/07/31 10:46:36 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 10:46:36 INFO Executor: Running task 0.0 in stage 21.0 (TID 23)
19/07/31 10:46:36 INFO BlockManager: Found block rdd_79_0 locally
19/07/31 10:46:36 INFO Executor: Finished task 0.0 in stage 21.0 (TID 23). 1780 bytes result sent to driver
19/07/31 10:46:36 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 23) in 11 ms on localhost (executor driver) (1/1)
19/07/31 10:46:36 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/07/31 10:46:36 INFO DAGScheduler: ShuffleMapStage 21 (collect at utils.scala:204) finished in 0.012 s
19/07/31 10:46:36 INFO DAGScheduler: looking for newly runnable stages
19/07/31 10:46:36 INFO DAGScheduler: running: Set()
19/07/31 10:46:36 INFO DAGScheduler: waiting: Set(ResultStage 22)
19/07/31 10:46:36 INFO DAGScheduler: failed: Set()
19/07/31 10:46:36 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[91] at collect at utils.scala:204), which has no missing parents
19/07/31 10:46:36 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 7.0 KB, free 910.6 MB)
19/07/31 10:46:36 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.6 MB)
19/07/31 10:46:36 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:59789 (size: 3.7 KB, free: 912.1 MB)
19/07/31 10:46:36 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
19/07/31 10:46:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[91] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:46:36 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
19/07/31 10:46:36 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 24, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 10:46:36 INFO Executor: Running task 0.0 in stage 22.0 (TID 24)
19/07/31 10:46:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 10:46:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 10:46:36 INFO Executor: Finished task 0.0 in stage 22.0 (TID 24). 1538 bytes result sent to driver
19/07/31 10:46:36 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 24) in 5 ms on localhost (executor driver) (1/1)
19/07/31 10:46:36 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/07/31 10:46:36 INFO DAGScheduler: ResultStage 22 (collect at utils.scala:204) finished in 0.006 s
19/07/31 10:46:36 INFO DAGScheduler: Job 16 finished: collect at utils.scala:204, took 0.039274 s
19/07/31 10:46:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz23`
WHERE (0 = 1)
19/07/31 10:46:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:46:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:46:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:46:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:46:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:46:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:46:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:46:43 INFO SparkSqlParser: Parsing command: SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 10:46:43 INFO SparkSqlParser: Parsing command: SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`
LIMIT 1000
19/07/31 10:46:43 INFO CodeGenerator: Code generated in 28.214695 ms
19/07/31 10:46:43 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 10:46:43 INFO DAGScheduler: Got job 17 (collect at utils.scala:204) with 1 output partitions
19/07/31 10:46:43 INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:204)
19/07/31 10:46:43 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:46:43 INFO DAGScheduler: Missing parents: List()
19/07/31 10:46:43 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[94] at collect at utils.scala:204), which has no missing parents
19/07/31 10:46:43 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 25.7 KB, free 910.6 MB)
19/07/31 10:46:43 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 11.3 KB, free 910.6 MB)
19/07/31 10:46:43 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:59789 (size: 11.3 KB, free: 912.1 MB)
19/07/31 10:46:43 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
19/07/31 10:46:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[94] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:46:43 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
19/07/31 10:46:43 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:46:43 INFO Executor: Running task 0.0 in stage 23.0 (TID 25)
19/07/31 10:46:43 INFO BlockManager: Found block rdd_79_0 locally
19/07/31 10:46:43 INFO CodeGenerator: Code generated in 22.693907 ms
19/07/31 10:46:43 INFO Executor: 1 block locks were not released by TID = 25:
[rdd_79_0]
19/07/31 10:46:43 INFO Executor: Finished task 0.0 in stage 23.0 (TID 25). 31120 bytes result sent to driver
19/07/31 10:46:43 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 25) in 40 ms on localhost (executor driver) (1/1)
19/07/31 10:46:43 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
19/07/31 10:46:43 INFO DAGScheduler: ResultStage 23 (collect at utils.scala:204) finished in 0.040 s
19/07/31 10:46:43 INFO DAGScheduler: Job 17 finished: collect at utils.scala:204, took 0.051959 s
19/07/31 10:48:06 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:48:06 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:48:06 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:48:06 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:48:06 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:48:06 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:48:06 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:48:06 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 10:48:06 INFO DAGScheduler: Got job 18 (collect at utils.scala:44) with 2 output partitions
19/07/31 10:48:06 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:44)
19/07/31 10:48:06 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:48:06 INFO DAGScheduler: Missing parents: List()
19/07/31 10:48:06 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[99] at map at utils.scala:41), which has no missing parents
19/07/31 10:48:06 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 6.4 KB, free 910.6 MB)
19/07/31 10:48:06 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 3.6 KB, free 910.6 MB)
19/07/31 10:48:06 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:59789 (size: 3.6 KB, free: 912.1 MB)
19/07/31 10:48:06 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
19/07/31 10:48:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 24 (MapPartitionsRDD[99] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
19/07/31 10:48:06 INFO TaskSchedulerImpl: Adding task set 24.0 with 2 tasks
19/07/31 10:48:06 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 10:48:06 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 27, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/07/31 10:48:06 INFO Executor: Running task 0.0 in stage 24.0 (TID 26)
19/07/31 10:48:06 INFO Executor: Running task 1.0 in stage 24.0 (TID 27)
19/07/31 10:48:06 INFO Executor: Finished task 1.0 in stage 24.0 (TID 27). 975 bytes result sent to driver
19/07/31 10:48:06 INFO Executor: Finished task 0.0 in stage 24.0 (TID 26). 1007 bytes result sent to driver
19/07/31 10:48:06 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 27) in 9 ms on localhost (executor driver) (1/2)
19/07/31 10:48:06 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 26) in 9 ms on localhost (executor driver) (2/2)
19/07/31 10:48:06 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
19/07/31 10:48:06 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:44) finished in 0.010 s
19/07/31 10:48:06 INFO DAGScheduler: Job 18 finished: collect at utils.scala:44, took 0.033825 s
19/07/31 10:48:06 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 10:48:06 INFO MapPartitionsRDD: Removing RDD 79 from persistence list
19/07/31 10:48:06 INFO BlockManager: Removing RDD 79
19/07/31 10:48:06 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:48:06 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1299)) > 0)
19/07/31 10:48:06 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 10:48:06 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:48:06 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 281.2 KB, free 910.3 MB)
19/07/31 10:48:06 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 23.8 KB, free 910.3 MB)
19/07/31 10:48:06 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:59789 (size: 23.8 KB, free: 912.1 MB)
19/07/31 10:48:06 INFO SparkContext: Created broadcast 31 from csv at NativeMethodAccessorImpl.java:0
19/07/31 10:48:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:48:06 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 10:48:06 INFO DAGScheduler: Got job 19 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 10:48:06 INFO DAGScheduler: Final stage: ResultStage 25 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 10:48:06 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:48:06 INFO DAGScheduler: Missing parents: List()
19/07/31 10:48:06 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[102] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:48:06 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 8.2 KB, free 910.3 MB)
19/07/31 10:48:06 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 4.3 KB, free 910.3 MB)
19/07/31 10:48:06 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:59789 (size: 4.3 KB, free: 912.1 MB)
19/07/31 10:48:06 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
19/07/31 10:48:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[102] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:48:06 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
19/07/31 10:48:06 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:48:06 INFO Executor: Running task 0.0 in stage 25.0 (TID 28)
19/07/31 10:48:06 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:48:06 INFO Executor: Finished task 0.0 in stage 25.0 (TID 28). 1394 bytes result sent to driver
19/07/31 10:48:06 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 28) in 8 ms on localhost (executor driver) (1/1)
19/07/31 10:48:06 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
19/07/31 10:48:06 INFO DAGScheduler: ResultStage 25 (csv at NativeMethodAccessorImpl.java:0) finished in 0.008 s
19/07/31 10:48:06 INFO DAGScheduler: Job 19 finished: csv at NativeMethodAccessorImpl.java:0, took 0.027205 s
19/07/31 10:48:06 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:48:06 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 10:48:06 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 10:48:06 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:48:06 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 281.2 KB, free 910.0 MB)
19/07/31 10:48:06 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 23.8 KB, free 910.0 MB)
19/07/31 10:48:06 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:59789 (size: 23.8 KB, free: 912.1 MB)
19/07/31 10:48:06 INFO SparkContext: Created broadcast 33 from csv at NativeMethodAccessorImpl.java:0
19/07/31 10:48:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:48:06 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 10:48:06 INFO DAGScheduler: Got job 20 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 10:48:06 INFO DAGScheduler: Final stage: ResultStage 26 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 10:48:06 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:48:06 INFO DAGScheduler: Missing parents: List()
19/07/31 10:48:06 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[107] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 10:48:06 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 14.8 KB, free 910.0 MB)
19/07/31 10:48:06 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 8.6 KB, free 910.0 MB)
19/07/31 10:48:06 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:59789 (size: 8.6 KB, free: 912.0 MB)
19/07/31 10:48:06 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
19/07/31 10:48:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[107] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:48:06 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
19/07/31 10:48:06 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:48:06 INFO Executor: Running task 0.0 in stage 26.0 (TID 29)
19/07/31 10:48:06 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:48:06 INFO Executor: Finished task 0.0 in stage 26.0 (TID 29). 1584 bytes result sent to driver
19/07/31 10:48:06 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 29) in 28 ms on localhost (executor driver) (1/1)
19/07/31 10:48:06 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
19/07/31 10:48:06 INFO DAGScheduler: ResultStage 26 (csv at NativeMethodAccessorImpl.java:0) finished in 0.029 s
19/07/31 10:48:06 INFO DAGScheduler: Job 20 finished: csv at NativeMethodAccessorImpl.java:0, took 0.046374 s
19/07/31 10:48:06 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:48:06 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:48:06 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:48:06 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:48:06 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:48:06 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:48:06 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:48:06 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 10:48:06 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 10:48:06 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 10:48:06 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 10:48:06 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 10:48:06 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 10:48:06 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 10:48:06 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 282.3 KB, free 909.7 MB)
19/07/31 10:48:06 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 24.0 KB, free 909.7 MB)
19/07/31 10:48:06 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:59789 (size: 24.0 KB, free: 912.0 MB)
19/07/31 10:48:06 INFO SparkContext: Created broadcast 35 from sql at <unknown>:0
19/07/31 10:48:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 10:48:06 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 10:48:06 INFO DAGScheduler: Registering RDD 113 (sql at <unknown>:0)
19/07/31 10:48:06 INFO DAGScheduler: Got job 21 (sql at <unknown>:0) with 1 output partitions
19/07/31 10:48:06 INFO DAGScheduler: Final stage: ResultStage 28 (sql at <unknown>:0)
19/07/31 10:48:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)
19/07/31 10:48:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 27)
19/07/31 10:48:06 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[113] at sql at <unknown>:0), which has no missing parents
19/07/31 10:48:06 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 26.3 KB, free 909.6 MB)
19/07/31 10:48:06 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 11.8 KB, free 909.6 MB)
19/07/31 10:48:06 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:59789 (size: 11.8 KB, free: 912.0 MB)
19/07/31 10:48:06 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
19/07/31 10:48:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[113] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:48:06 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
19/07/31 10:48:06 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 10:48:06 INFO Executor: Running task 0.0 in stage 27.0 (TID 30)
19/07/31 10:48:06 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 10:48:06 INFO MemoryStore: Block rdd_110_0 stored as values in memory (estimated size 48.9 KB, free 909.6 MB)
19/07/31 10:48:06 INFO BlockManagerInfo: Added rdd_110_0 in memory on 127.0.0.1:59789 (size: 48.9 KB, free: 912.0 MB)
19/07/31 10:48:06 INFO Executor: Finished task 0.0 in stage 27.0 (TID 30). 2461 bytes result sent to driver
19/07/31 10:48:06 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 30) in 56 ms on localhost (executor driver) (1/1)
19/07/31 10:48:06 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
19/07/31 10:48:06 INFO DAGScheduler: ShuffleMapStage 27 (sql at <unknown>:0) finished in 0.057 s
19/07/31 10:48:06 INFO DAGScheduler: looking for newly runnable stages
19/07/31 10:48:06 INFO DAGScheduler: running: Set()
19/07/31 10:48:06 INFO DAGScheduler: waiting: Set(ResultStage 28)
19/07/31 10:48:06 INFO DAGScheduler: failed: Set()
19/07/31 10:48:06 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[116] at sql at <unknown>:0), which has no missing parents
19/07/31 10:48:06 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 7.0 KB, free 909.6 MB)
19/07/31 10:48:06 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 3.7 KB, free 909.6 MB)
19/07/31 10:48:06 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:59789 (size: 3.7 KB, free: 912.0 MB)
19/07/31 10:48:06 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
19/07/31 10:48:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[116] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 10:48:06 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
19/07/31 10:48:06 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 31, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 10:48:06 INFO Executor: Running task 0.0 in stage 28.0 (TID 31)
19/07/31 10:48:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 10:48:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 10:48:06 INFO Executor: Finished task 0.0 in stage 28.0 (TID 31). 1538 bytes result sent to driver
19/07/31 10:48:06 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 31) in 5 ms on localhost (executor driver) (1/1)
19/07/31 10:48:06 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
19/07/31 10:48:06 INFO DAGScheduler: ResultStage 28 (sql at <unknown>:0) finished in 0.005 s
19/07/31 10:48:06 INFO DAGScheduler: Job 21 finished: sql at <unknown>:0, took 0.084811 s
19/07/31 10:48:06 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 10:48:06 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:48:06 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:48:07 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 10:48:07 INFO DAGScheduler: Registering RDD 119 (collect at utils.scala:204)
19/07/31 10:48:07 INFO DAGScheduler: Got job 22 (collect at utils.scala:204) with 1 output partitions
19/07/31 10:48:07 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:204)
19/07/31 10:48:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
19/07/31 10:48:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 29)
19/07/31 10:48:07 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[119] at collect at utils.scala:204), which has no missing parents
19/07/31 10:48:07 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 26.3 KB, free 909.6 MB)
19/07/31 10:48:07 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 11.9 KB, free 909.5 MB)
19/07/31 10:48:07 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:59789 (size: 11.9 KB, free: 911.9 MB)
19/07/31 10:48:07 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
19/07/31 10:48:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[119] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:48:07 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
19/07/31 10:48:07 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 10:48:07 INFO Executor: Running task 0.0 in stage 29.0 (TID 32)
19/07/31 10:48:07 INFO BlockManager: Found block rdd_110_0 locally
19/07/31 10:48:07 INFO Executor: Finished task 0.0 in stage 29.0 (TID 32). 1780 bytes result sent to driver
19/07/31 10:48:07 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 32) in 11 ms on localhost (executor driver) (1/1)
19/07/31 10:48:07 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
19/07/31 10:48:07 INFO DAGScheduler: ShuffleMapStage 29 (collect at utils.scala:204) finished in 0.011 s
19/07/31 10:48:07 INFO DAGScheduler: looking for newly runnable stages
19/07/31 10:48:07 INFO DAGScheduler: running: Set()
19/07/31 10:48:07 INFO DAGScheduler: waiting: Set(ResultStage 30)
19/07/31 10:48:07 INFO DAGScheduler: failed: Set()
19/07/31 10:48:07 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[122] at collect at utils.scala:204), which has no missing parents
19/07/31 10:48:07 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 7.0 KB, free 909.5 MB)
19/07/31 10:48:07 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 3.7 KB, free 909.5 MB)
19/07/31 10:48:07 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:59789 (size: 3.7 KB, free: 911.9 MB)
19/07/31 10:48:07 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
19/07/31 10:48:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[122] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:48:07 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
19/07/31 10:48:07 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 33, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 10:48:07 INFO Executor: Running task 0.0 in stage 30.0 (TID 33)
19/07/31 10:48:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 10:48:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 10:48:07 INFO Executor: Finished task 0.0 in stage 30.0 (TID 33). 1538 bytes result sent to driver
19/07/31 10:48:07 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 33) in 4 ms on localhost (executor driver) (1/1)
19/07/31 10:48:07 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
19/07/31 10:48:07 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:204) finished in 0.005 s
19/07/31 10:48:07 INFO DAGScheduler: Job 22 finished: collect at utils.scala:204, took 0.038598 s
19/07/31 10:48:07 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz24`
WHERE (0 = 1)
19/07/31 10:48:07 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 10:48:07 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:48:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:48:07 INFO HiveMetaStore: 0: get_database: default
19/07/31 10:48:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 10:48:07 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 10:48:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 10:48:40 INFO SparkSqlParser: Parsing command: SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 10:48:40 INFO SparkSqlParser: Parsing command: SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 10:48:40 INFO CodeGenerator: Code generated in 9.597697 ms
19/07/31 10:48:40 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 10:48:40 INFO DAGScheduler: Got job 23 (collect at utils.scala:204) with 1 output partitions
19/07/31 10:48:40 INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:204)
19/07/31 10:48:40 INFO DAGScheduler: Parents of final stage: List()
19/07/31 10:48:40 INFO DAGScheduler: Missing parents: List()
19/07/31 10:48:40 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[125] at collect at utils.scala:204), which has no missing parents
19/07/31 10:48:40 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 25.8 KB, free 909.5 MB)
19/07/31 10:48:40 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 11.3 KB, free 909.5 MB)
19/07/31 10:48:40 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:59789 (size: 11.3 KB, free: 911.9 MB)
19/07/31 10:48:40 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
19/07/31 10:48:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[125] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 10:48:40 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
19/07/31 10:48:40 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 10:48:40 INFO Executor: Running task 0.0 in stage 31.0 (TID 34)
19/07/31 10:48:40 INFO BlockManager: Found block rdd_110_0 locally
19/07/31 10:48:40 INFO CodeGenerator: Code generated in 11.846406 ms
19/07/31 10:48:40 INFO Executor: Finished task 0.0 in stage 31.0 (TID 34). 37152 bytes result sent to driver
19/07/31 10:48:40 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 34) in 23 ms on localhost (executor driver) (1/1)
19/07/31 10:48:40 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
19/07/31 10:48:40 INFO DAGScheduler: ResultStage 31 (collect at utils.scala:204) finished in 0.024 s
19/07/31 10:48:40 INFO DAGScheduler: Job 23 finished: collect at utils.scala:204, took 0.030249 s
19/07/31 11:33:05 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 11:33:05 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:33:05 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:33:05 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:33:05 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:33:05 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 11:33:05 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 11:33:06 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 11:33:06 INFO DAGScheduler: Got job 24 (collect at utils.scala:44) with 2 output partitions
19/07/31 11:33:06 INFO DAGScheduler: Final stage: ResultStage 32 (collect at utils.scala:44)
19/07/31 11:33:06 INFO DAGScheduler: Parents of final stage: List()
19/07/31 11:33:06 INFO DAGScheduler: Missing parents: List()
19/07/31 11:33:06 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[130] at map at utils.scala:41), which has no missing parents
19/07/31 11:33:06 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 6.4 KB, free 909.5 MB)
19/07/31 11:33:06 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 3.6 KB, free 909.5 MB)
19/07/31 11:33:06 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:59789 (size: 3.6 KB, free: 911.9 MB)
19/07/31 11:33:06 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
19/07/31 11:33:06 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 32 (MapPartitionsRDD[130] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
19/07/31 11:33:06 INFO TaskSchedulerImpl: Adding task set 32.0 with 2 tasks
19/07/31 11:33:06 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 11:33:06 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 36, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/07/31 11:33:06 INFO Executor: Running task 0.0 in stage 32.0 (TID 35)
19/07/31 11:33:06 INFO Executor: Running task 1.0 in stage 32.0 (TID 36)
19/07/31 11:33:06 INFO Executor: Finished task 0.0 in stage 32.0 (TID 35). 1007 bytes result sent to driver
19/07/31 11:33:06 INFO Executor: Finished task 1.0 in stage 32.0 (TID 36). 975 bytes result sent to driver
19/07/31 11:33:06 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 35) in 8 ms on localhost (executor driver) (1/2)
19/07/31 11:33:06 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 36) in 8 ms on localhost (executor driver) (2/2)
19/07/31 11:33:06 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
19/07/31 11:33:06 INFO DAGScheduler: ResultStage 32 (collect at utils.scala:44) finished in 0.009 s
19/07/31 11:33:06 INFO DAGScheduler: Job 24 finished: collect at utils.scala:44, took 0.037955 s
19/07/31 11:33:06 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 11:33:06 INFO MapPartitionsRDD: Removing RDD 110 from persistence list
19/07/31 11:33:06 INFO BlockManager: Removing RDD 110
19/07/31 11:33:06 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 11:33:06 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1770)) > 0)
19/07/31 11:33:06 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 11:33:06 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 11:33:06 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 281.2 KB, free 909.3 MB)
19/07/31 11:33:06 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 23.8 KB, free 909.2 MB)
19/07/31 11:33:06 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:59789 (size: 23.8 KB, free: 912.0 MB)
19/07/31 11:33:06 INFO SparkContext: Created broadcast 42 from csv at NativeMethodAccessorImpl.java:0
19/07/31 11:33:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 11:33:06 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 11:33:06 INFO DAGScheduler: Got job 25 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 11:33:06 INFO DAGScheduler: Final stage: ResultStage 33 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 11:33:06 INFO DAGScheduler: Parents of final stage: List()
19/07/31 11:33:06 INFO DAGScheduler: Missing parents: List()
19/07/31 11:33:06 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[133] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 11:33:06 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 8.2 KB, free 909.2 MB)
19/07/31 11:33:06 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 4.3 KB, free 909.2 MB)
19/07/31 11:33:06 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:59789 (size: 4.3 KB, free: 912.0 MB)
19/07/31 11:33:06 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
19/07/31 11:33:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[133] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 11:33:06 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
19/07/31 11:33:06 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 11:33:06 INFO Executor: Running task 0.0 in stage 33.0 (TID 37)
19/07/31 11:33:06 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 11:33:06 INFO Executor: Finished task 0.0 in stage 33.0 (TID 37). 1394 bytes result sent to driver
19/07/31 11:33:06 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 37) in 20 ms on localhost (executor driver) (1/1)
19/07/31 11:33:06 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
19/07/31 11:33:06 INFO DAGScheduler: ResultStage 33 (csv at NativeMethodAccessorImpl.java:0) finished in 0.022 s
19/07/31 11:33:06 INFO DAGScheduler: Job 25 finished: csv at NativeMethodAccessorImpl.java:0, took 0.034013 s
19/07/31 11:33:06 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 11:33:06 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 11:33:06 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 11:33:06 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 11:33:06 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 281.2 KB, free 908.9 MB)
19/07/31 11:33:06 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 23.8 KB, free 908.9 MB)
19/07/31 11:33:06 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:59789 (size: 23.8 KB, free: 911.9 MB)
19/07/31 11:33:06 INFO SparkContext: Created broadcast 44 from csv at NativeMethodAccessorImpl.java:0
19/07/31 11:33:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 11:33:06 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 11:33:06 INFO DAGScheduler: Got job 26 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 11:33:06 INFO DAGScheduler: Final stage: ResultStage 34 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 11:33:06 INFO DAGScheduler: Parents of final stage: List()
19/07/31 11:33:06 INFO DAGScheduler: Missing parents: List()
19/07/31 11:33:06 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[138] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 11:33:06 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 14.8 KB, free 908.9 MB)
19/07/31 11:33:06 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 8.6 KB, free 908.9 MB)
19/07/31 11:33:06 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:59789 (size: 8.6 KB, free: 911.9 MB)
19/07/31 11:33:06 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
19/07/31 11:33:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[138] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 11:33:06 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
19/07/31 11:33:06 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 11:33:06 INFO Executor: Running task 0.0 in stage 34.0 (TID 38)
19/07/31 11:33:06 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 11:33:06 INFO Executor: Finished task 0.0 in stage 34.0 (TID 38). 1584 bytes result sent to driver
19/07/31 11:33:06 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 38) in 17 ms on localhost (executor driver) (1/1)
19/07/31 11:33:06 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
19/07/31 11:33:06 INFO DAGScheduler: ResultStage 34 (csv at NativeMethodAccessorImpl.java:0) finished in 0.018 s
19/07/31 11:33:06 INFO DAGScheduler: Job 26 finished: csv at NativeMethodAccessorImpl.java:0, took 0.031470 s
19/07/31 11:33:06 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 11:33:06 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:33:06 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:33:06 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:33:06 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:33:06 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 11:33:06 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 11:33:06 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 11:33:06 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 11:33:06 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 11:33:06 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 11:33:06 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 11:33:06 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 11:33:06 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 11:33:06 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 282.3 KB, free 908.6 MB)
19/07/31 11:33:06 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 24.0 KB, free 908.6 MB)
19/07/31 11:33:06 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:59789 (size: 24.0 KB, free: 911.9 MB)
19/07/31 11:33:06 INFO SparkContext: Created broadcast 46 from sql at <unknown>:0
19/07/31 11:33:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 11:33:06 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 11:33:06 INFO DAGScheduler: Registering RDD 144 (sql at <unknown>:0)
19/07/31 11:33:06 INFO DAGScheduler: Got job 27 (sql at <unknown>:0) with 1 output partitions
19/07/31 11:33:06 INFO DAGScheduler: Final stage: ResultStage 36 (sql at <unknown>:0)
19/07/31 11:33:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
19/07/31 11:33:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 35)
19/07/31 11:33:06 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[144] at sql at <unknown>:0), which has no missing parents
19/07/31 11:33:06 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 26.3 KB, free 908.6 MB)
19/07/31 11:33:06 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 11.8 KB, free 908.6 MB)
19/07/31 11:33:06 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:59789 (size: 11.8 KB, free: 911.9 MB)
19/07/31 11:33:06 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
19/07/31 11:33:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[144] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 11:33:06 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
19/07/31 11:33:06 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 11:33:06 INFO Executor: Running task 0.0 in stage 35.0 (TID 39)
19/07/31 11:33:06 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 11:33:06 INFO MemoryStore: Block rdd_141_0 stored as values in memory (estimated size 48.9 KB, free 908.5 MB)
19/07/31 11:33:06 INFO BlockManagerInfo: Added rdd_141_0 in memory on 127.0.0.1:59789 (size: 48.9 KB, free: 911.8 MB)
19/07/31 11:33:06 INFO Executor: Finished task 0.0 in stage 35.0 (TID 39). 2461 bytes result sent to driver
19/07/31 11:33:06 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 39) in 66 ms on localhost (executor driver) (1/1)
19/07/31 11:33:06 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
19/07/31 11:33:06 INFO DAGScheduler: ShuffleMapStage 35 (sql at <unknown>:0) finished in 0.067 s
19/07/31 11:33:06 INFO DAGScheduler: looking for newly runnable stages
19/07/31 11:33:06 INFO DAGScheduler: running: Set()
19/07/31 11:33:06 INFO DAGScheduler: waiting: Set(ResultStage 36)
19/07/31 11:33:06 INFO DAGScheduler: failed: Set()
19/07/31 11:33:06 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[147] at sql at <unknown>:0), which has no missing parents
19/07/31 11:33:06 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 7.0 KB, free 908.5 MB)
19/07/31 11:33:06 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 3.7 KB, free 908.5 MB)
19/07/31 11:33:06 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:59789 (size: 3.7 KB, free: 911.8 MB)
19/07/31 11:33:06 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1006
19/07/31 11:33:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[147] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 11:33:06 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
19/07/31 11:33:06 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 40, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 11:33:06 INFO Executor: Running task 0.0 in stage 36.0 (TID 40)
19/07/31 11:33:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 11:33:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 11:33:06 INFO Executor: Finished task 0.0 in stage 36.0 (TID 40). 1581 bytes result sent to driver
19/07/31 11:33:06 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 40) in 10 ms on localhost (executor driver) (1/1)
19/07/31 11:33:06 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
19/07/31 11:33:06 INFO DAGScheduler: ResultStage 36 (sql at <unknown>:0) finished in 0.010 s
19/07/31 11:33:06 INFO DAGScheduler: Job 27 finished: sql at <unknown>:0, took 0.116554 s
19/07/31 11:33:06 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 11:33:06 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:33:06 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:33:06 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 11:33:06 INFO DAGScheduler: Registering RDD 150 (collect at utils.scala:204)
19/07/31 11:33:06 INFO DAGScheduler: Got job 28 (collect at utils.scala:204) with 1 output partitions
19/07/31 11:33:06 INFO DAGScheduler: Final stage: ResultStage 38 (collect at utils.scala:204)
19/07/31 11:33:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)
19/07/31 11:33:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 37)
19/07/31 11:33:06 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[150] at collect at utils.scala:204), which has no missing parents
19/07/31 11:33:06 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 26.3 KB, free 908.5 MB)
19/07/31 11:33:06 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 11.9 KB, free 908.5 MB)
19/07/31 11:33:06 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:59789 (size: 11.9 KB, free: 911.8 MB)
19/07/31 11:33:06 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
19/07/31 11:33:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[150] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 11:33:06 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
19/07/31 11:33:06 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 11:33:06 INFO Executor: Running task 0.0 in stage 37.0 (TID 41)
19/07/31 11:33:06 INFO BlockManager: Found block rdd_141_0 locally
19/07/31 11:33:06 INFO Executor: Finished task 0.0 in stage 37.0 (TID 41). 1780 bytes result sent to driver
19/07/31 11:33:06 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 41) in 10 ms on localhost (executor driver) (1/1)
19/07/31 11:33:06 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
19/07/31 11:33:06 INFO DAGScheduler: ShuffleMapStage 37 (collect at utils.scala:204) finished in 0.011 s
19/07/31 11:33:06 INFO DAGScheduler: looking for newly runnable stages
19/07/31 11:33:06 INFO DAGScheduler: running: Set()
19/07/31 11:33:06 INFO DAGScheduler: waiting: Set(ResultStage 38)
19/07/31 11:33:06 INFO DAGScheduler: failed: Set()
19/07/31 11:33:06 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[153] at collect at utils.scala:204), which has no missing parents
19/07/31 11:33:06 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 7.0 KB, free 908.5 MB)
19/07/31 11:33:07 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 3.7 KB, free 908.5 MB)
19/07/31 11:33:07 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:59789 (size: 3.7 KB, free: 911.8 MB)
19/07/31 11:33:07 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
19/07/31 11:33:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[153] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 11:33:07 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
19/07/31 11:33:07 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 42, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 11:33:07 INFO Executor: Running task 0.0 in stage 38.0 (TID 42)
19/07/31 11:33:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 11:33:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 11:33:07 INFO Executor: Finished task 0.0 in stage 38.0 (TID 42). 1581 bytes result sent to driver
19/07/31 11:33:07 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 42) in 4 ms on localhost (executor driver) (1/1)
19/07/31 11:33:07 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
19/07/31 11:33:07 INFO DAGScheduler: ResultStage 38 (collect at utils.scala:204) finished in 0.005 s
19/07/31 11:33:07 INFO DAGScheduler: Job 28 finished: collect at utils.scala:204, took 0.044122 s
19/07/31 11:33:07 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz25`
WHERE (0 = 1)
19/07/31 11:33:07 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 11:33:07 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:33:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:33:07 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:33:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:33:07 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 11:33:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 49
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 52
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:59789 in memory (size: 23.8 KB, free: 911.8 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 824
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 587
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 884
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 827
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 889
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 812
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 1066
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 546
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 888
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 782
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 825
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 756
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 1059
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 752
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 880
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 828
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 881
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 584
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 575
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 964
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:59789 in memory (size: 23.8 KB, free: 911.9 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 1063
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 826
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 647
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:59789 in memory (size: 3.7 KB, free: 911.9 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 517
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 781
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:59789 in memory (size: 11.9 KB, free: 911.9 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 886
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 989
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 814
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:59789 in memory (size: 23.8 KB, free: 911.9 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 785
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 1054
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:59789 in memory (size: 11.9 KB, free: 911.9 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 877
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:59789 in memory (size: 3.6 KB, free: 911.9 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 643
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 821
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 589
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 583
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:59789 in memory (size: 4.3 KB, free: 911.9 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 650
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 1065
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 1055
19/07/31 11:35:38 INFO ContextCleaner: Cleaned shuffle 6
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 1115
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:59789 in memory (size: 11.9 KB, free: 911.9 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 577
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 651
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 701
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 815
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:59789 in memory (size: 4.3 KB, free: 911.9 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 810
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 755
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:59789 in memory (size: 23.8 KB, free: 912.0 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 813
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 938
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 1056
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 590
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 882
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 1022
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 1023
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:59789 in memory (size: 24.0 KB, free: 912.0 MB)
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:59789 in memory (size: 23.8 KB, free: 912.0 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 783
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 547
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 811
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 879
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 645
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 1064
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:59789 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 641
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:59789 in memory (size: 11.3 KB, free: 912.0 MB)
19/07/31 11:35:38 INFO BlockManager: Removing RDD 79
19/07/31 11:35:38 INFO ContextCleaner: Cleaned RDD 79
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 878
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 1062
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:59789 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:59789 in memory (size: 4.3 KB, free: 912.0 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 820
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:59789 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 639
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 700
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 515
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:59789 in memory (size: 24.0 KB, free: 912.1 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 1019
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 648
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 816
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 883
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 993
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:59789 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:59789 in memory (size: 8.6 KB, free: 912.1 MB)
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:59789 in memory (size: 11.8 KB, free: 912.1 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 543
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 819
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 649
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 1020
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 588
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 754
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 817
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 823
19/07/31 11:35:38 INFO BlockManager: Removing RDD 110
19/07/31 11:35:38 INFO ContextCleaner: Cleaned RDD 110
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 1061
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 581
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 578
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 784
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 518
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:59789 in memory (size: 11.3 KB, free: 912.1 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 1057
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 580
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 545
19/07/31 11:35:38 INFO ContextCleaner: Cleaned shuffle 8
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:59789 in memory (size: 8.6 KB, free: 912.1 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 646
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:59789 in memory (size: 11.9 KB, free: 912.1 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned shuffle 7
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:59789 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 726
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 994
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 572
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 753
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 586
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 990
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 1060
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 516
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 513
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 582
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 887
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 1021
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 574
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 1058
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 751
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 818
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 514
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 573
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 585
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 939
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 991
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 579
19/07/31 11:35:38 INFO ContextCleaner: Cleaned shuffle 5
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:59789 in memory (size: 11.8 KB, free: 912.1 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 822
19/07/31 11:35:38 INFO ContextCleaner: Cleaned shuffle 4
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:59789 in memory (size: 3.6 KB, free: 912.1 MB)
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:59789 in memory (size: 23.8 KB, free: 912.2 MB)
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:59789 in memory (size: 8.6 KB, free: 912.2 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 640
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 576
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 642
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:59789 in memory (size: 23.8 KB, free: 912.2 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 885
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 992
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 644
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 544
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:59789 in memory (size: 23.8 KB, free: 912.2 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 51
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 79
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 83
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 81
19/07/31 11:35:38 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:59789 in memory (size: 4.3 KB, free: 912.2 MB)
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 50
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 80
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 54
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 53
19/07/31 11:35:38 INFO ContextCleaner: Cleaned accumulator 82
19/07/31 11:52:19 INFO SparkSqlParser: Parsing command: SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 11:52:19 INFO SparkSqlParser: Parsing command: SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 11:52:19 INFO CodeGenerator: Code generated in 32.712723 ms
19/07/31 11:52:19 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 11:52:19 INFO DAGScheduler: Got job 29 (collect at utils.scala:204) with 1 output partitions
19/07/31 11:52:19 INFO DAGScheduler: Final stage: ResultStage 39 (collect at utils.scala:204)
19/07/31 11:52:19 INFO DAGScheduler: Parents of final stage: List()
19/07/31 11:52:19 INFO DAGScheduler: Missing parents: List()
19/07/31 11:52:19 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[156] at collect at utils.scala:204), which has no missing parents
19/07/31 11:52:19 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 25.8 KB, free 911.9 MB)
19/07/31 11:52:19 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 11.3 KB, free 911.9 MB)
19/07/31 11:52:19 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:59789 (size: 11.3 KB, free: 912.2 MB)
19/07/31 11:52:19 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
19/07/31 11:52:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[156] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 11:52:19 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
19/07/31 11:52:19 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 11:52:19 INFO Executor: Running task 0.0 in stage 39.0 (TID 43)
19/07/31 11:52:19 INFO BlockManager: Found block rdd_141_0 locally
19/07/31 11:52:19 INFO CodeGenerator: Code generated in 13.504186 ms
19/07/31 11:52:19 INFO Executor: Finished task 0.0 in stage 39.0 (TID 43). 37152 bytes result sent to driver
19/07/31 11:52:19 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 43) in 33 ms on localhost (executor driver) (1/1)
19/07/31 11:52:19 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
19/07/31 11:52:19 INFO DAGScheduler: ResultStage 39 (collect at utils.scala:204) finished in 0.034 s
19/07/31 11:52:19 INFO DAGScheduler: Job 29 finished: collect at utils.scala:204, took 0.057937 s
19/07/31 11:54:59 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 11:54:59 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:54:59 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:54:59 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:54:59 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:54:59 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 11:54:59 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 11:54:59 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 11:54:59 INFO DAGScheduler: Got job 30 (collect at utils.scala:44) with 2 output partitions
19/07/31 11:54:59 INFO DAGScheduler: Final stage: ResultStage 40 (collect at utils.scala:44)
19/07/31 11:54:59 INFO DAGScheduler: Parents of final stage: List()
19/07/31 11:54:59 INFO DAGScheduler: Missing parents: List()
19/07/31 11:54:59 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[161] at map at utils.scala:41), which has no missing parents
19/07/31 11:54:59 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 6.4 KB, free 911.9 MB)
19/07/31 11:54:59 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 3.6 KB, free 911.9 MB)
19/07/31 11:54:59 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:59789 (size: 3.6 KB, free: 912.2 MB)
19/07/31 11:54:59 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1006
19/07/31 11:54:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 40 (MapPartitionsRDD[161] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
19/07/31 11:54:59 INFO TaskSchedulerImpl: Adding task set 40.0 with 2 tasks
19/07/31 11:54:59 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 11:54:59 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 45, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/07/31 11:54:59 INFO Executor: Running task 0.0 in stage 40.0 (TID 44)
19/07/31 11:54:59 INFO Executor: Running task 1.0 in stage 40.0 (TID 45)
19/07/31 11:54:59 INFO Executor: Finished task 1.0 in stage 40.0 (TID 45). 975 bytes result sent to driver
19/07/31 11:54:59 INFO Executor: Finished task 0.0 in stage 40.0 (TID 44). 1007 bytes result sent to driver
19/07/31 11:54:59 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 45) in 7 ms on localhost (executor driver) (1/2)
19/07/31 11:54:59 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 44) in 9 ms on localhost (executor driver) (2/2)
19/07/31 11:54:59 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
19/07/31 11:54:59 INFO DAGScheduler: ResultStage 40 (collect at utils.scala:44) finished in 0.012 s
19/07/31 11:54:59 INFO DAGScheduler: Job 30 finished: collect at utils.scala:44, took 0.053551 s
19/07/31 11:54:59 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 11:54:59 INFO MapPartitionsRDD: Removing RDD 141 from persistence list
19/07/31 11:54:59 INFO BlockManager: Removing RDD 141
19/07/31 11:54:59 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 11:54:59 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#2241)) > 0)
19/07/31 11:54:59 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 11:54:59 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 11:54:59 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 281.2 KB, free 911.7 MB)
19/07/31 11:54:59 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.6 MB)
19/07/31 11:54:59 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:59789 (size: 23.8 KB, free: 912.2 MB)
19/07/31 11:54:59 INFO SparkContext: Created broadcast 53 from csv at NativeMethodAccessorImpl.java:0
19/07/31 11:54:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 11:54:59 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 11:54:59 INFO DAGScheduler: Got job 31 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 11:54:59 INFO DAGScheduler: Final stage: ResultStage 41 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 11:54:59 INFO DAGScheduler: Parents of final stage: List()
19/07/31 11:54:59 INFO DAGScheduler: Missing parents: List()
19/07/31 11:54:59 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[164] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 11:54:59 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 8.2 KB, free 911.6 MB)
19/07/31 11:54:59 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 4.3 KB, free 911.6 MB)
19/07/31 11:54:59 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:59789 (size: 4.3 KB, free: 912.2 MB)
19/07/31 11:54:59 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1006
19/07/31 11:54:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[164] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 11:54:59 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
19/07/31 11:54:59 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 11:54:59 INFO Executor: Running task 0.0 in stage 41.0 (TID 46)
19/07/31 11:54:59 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 11:54:59 INFO Executor: Finished task 0.0 in stage 41.0 (TID 46). 1394 bytes result sent to driver
19/07/31 11:54:59 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 46) in 13 ms on localhost (executor driver) (1/1)
19/07/31 11:54:59 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
19/07/31 11:54:59 INFO DAGScheduler: ResultStage 41 (csv at NativeMethodAccessorImpl.java:0) finished in 0.014 s
19/07/31 11:54:59 INFO DAGScheduler: Job 31 finished: csv at NativeMethodAccessorImpl.java:0, took 0.037870 s
19/07/31 11:54:59 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 11:54:59 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 11:54:59 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 11:54:59 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 11:54:59 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 281.2 KB, free 911.4 MB)
19/07/31 11:54:59 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.3 MB)
19/07/31 11:54:59 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:59789 (size: 23.8 KB, free: 912.2 MB)
19/07/31 11:54:59 INFO SparkContext: Created broadcast 55 from csv at NativeMethodAccessorImpl.java:0
19/07/31 11:54:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 11:54:59 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 11:54:59 INFO DAGScheduler: Got job 32 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 11:54:59 INFO DAGScheduler: Final stage: ResultStage 42 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 11:54:59 INFO DAGScheduler: Parents of final stage: List()
19/07/31 11:54:59 INFO DAGScheduler: Missing parents: List()
19/07/31 11:54:59 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[169] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 11:54:59 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 14.8 KB, free 911.3 MB)
19/07/31 11:54:59 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.3 MB)
19/07/31 11:54:59 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:59789 (size: 8.6 KB, free: 912.2 MB)
19/07/31 11:54:59 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
19/07/31 11:54:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[169] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 11:54:59 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
19/07/31 11:54:59 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 11:54:59 INFO Executor: Running task 0.0 in stage 42.0 (TID 47)
19/07/31 11:54:59 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 11:55:00 INFO Executor: Finished task 0.0 in stage 42.0 (TID 47). 1584 bytes result sent to driver
19/07/31 11:55:00 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 47) in 34 ms on localhost (executor driver) (1/1)
19/07/31 11:55:00 INFO DAGScheduler: ResultStage 42 (csv at NativeMethodAccessorImpl.java:0) finished in 0.035 s
19/07/31 11:55:00 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
19/07/31 11:55:00 INFO DAGScheduler: Job 32 finished: csv at NativeMethodAccessorImpl.java:0, took 0.049978 s
19/07/31 11:55:00 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 11:55:00 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:55:00 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:55:00 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:55:00 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:55:00 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 11:55:00 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 11:55:00 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 11:55:00 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 11:55:00 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 11:55:00 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 11:55:00 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 11:55:00 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 11:55:00 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 11:55:00 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 282.3 KB, free 911.0 MB)
19/07/31 11:55:00 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.0 MB)
19/07/31 11:55:00 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:59789 (size: 24.0 KB, free: 912.2 MB)
19/07/31 11:55:00 INFO SparkContext: Created broadcast 57 from sql at <unknown>:0
19/07/31 11:55:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 11:55:00 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 11:55:00 INFO DAGScheduler: Registering RDD 175 (sql at <unknown>:0)
19/07/31 11:55:00 INFO DAGScheduler: Got job 33 (sql at <unknown>:0) with 1 output partitions
19/07/31 11:55:00 INFO DAGScheduler: Final stage: ResultStage 44 (sql at <unknown>:0)
19/07/31 11:55:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
19/07/31 11:55:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 43)
19/07/31 11:55:00 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[175] at sql at <unknown>:0), which has no missing parents
19/07/31 11:55:00 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 26.3 KB, free 911.0 MB)
19/07/31 11:55:00 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 11.8 KB, free 911.0 MB)
19/07/31 11:55:00 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:59789 (size: 11.8 KB, free: 912.2 MB)
19/07/31 11:55:00 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1006
19/07/31 11:55:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[175] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 11:55:00 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
19/07/31 11:55:00 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 11:55:00 INFO Executor: Running task 0.0 in stage 43.0 (TID 48)
19/07/31 11:55:00 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 11:55:00 INFO MemoryStore: Block rdd_172_0 stored as values in memory (estimated size 48.9 KB, free 910.9 MB)
19/07/31 11:55:00 INFO BlockManagerInfo: Added rdd_172_0 in memory on 127.0.0.1:59789 (size: 48.9 KB, free: 912.1 MB)
19/07/31 11:55:00 INFO Executor: Finished task 0.0 in stage 43.0 (TID 48). 2461 bytes result sent to driver
19/07/31 11:55:00 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 48) in 71 ms on localhost (executor driver) (1/1)
19/07/31 11:55:00 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
19/07/31 11:55:00 INFO DAGScheduler: ShuffleMapStage 43 (sql at <unknown>:0) finished in 0.072 s
19/07/31 11:55:00 INFO DAGScheduler: looking for newly runnable stages
19/07/31 11:55:00 INFO DAGScheduler: running: Set()
19/07/31 11:55:00 INFO DAGScheduler: waiting: Set(ResultStage 44)
19/07/31 11:55:00 INFO DAGScheduler: failed: Set()
19/07/31 11:55:00 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[178] at sql at <unknown>:0), which has no missing parents
19/07/31 11:55:00 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 7.0 KB, free 910.9 MB)
19/07/31 11:55:00 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.9 MB)
19/07/31 11:55:00 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:59789 (size: 3.7 KB, free: 912.1 MB)
19/07/31 11:55:00 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
19/07/31 11:55:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[178] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 11:55:00 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
19/07/31 11:55:00 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 49, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 11:55:00 INFO Executor: Running task 0.0 in stage 44.0 (TID 49)
19/07/31 11:55:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 11:55:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 11:55:00 INFO Executor: Finished task 0.0 in stage 44.0 (TID 49). 1538 bytes result sent to driver
19/07/31 11:55:00 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 49) in 6 ms on localhost (executor driver) (1/1)
19/07/31 11:55:00 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
19/07/31 11:55:00 INFO DAGScheduler: ResultStage 44 (sql at <unknown>:0) finished in 0.008 s
19/07/31 11:55:00 INFO DAGScheduler: Job 33 finished: sql at <unknown>:0, took 0.129833 s
19/07/31 11:55:00 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 11:55:00 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:55:00 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:55:00 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 11:55:00 INFO DAGScheduler: Registering RDD 181 (collect at utils.scala:204)
19/07/31 11:55:00 INFO DAGScheduler: Got job 34 (collect at utils.scala:204) with 1 output partitions
19/07/31 11:55:00 INFO DAGScheduler: Final stage: ResultStage 46 (collect at utils.scala:204)
19/07/31 11:55:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 45)
19/07/31 11:55:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 45)
19/07/31 11:55:00 INFO DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[181] at collect at utils.scala:204), which has no missing parents
19/07/31 11:55:00 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 26.3 KB, free 910.9 MB)
19/07/31 11:55:00 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 11.9 KB, free 910.9 MB)
19/07/31 11:55:00 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:59789 (size: 11.9 KB, free: 912.1 MB)
19/07/31 11:55:00 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
19/07/31 11:55:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[181] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 11:55:00 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
19/07/31 11:55:00 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 11:55:00 INFO Executor: Running task 0.0 in stage 45.0 (TID 50)
19/07/31 11:55:00 INFO BlockManager: Found block rdd_172_0 locally
19/07/31 11:55:00 INFO Executor: Finished task 0.0 in stage 45.0 (TID 50). 1780 bytes result sent to driver
19/07/31 11:55:00 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 50) in 20 ms on localhost (executor driver) (1/1)
19/07/31 11:55:00 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
19/07/31 11:55:00 INFO DAGScheduler: ShuffleMapStage 45 (collect at utils.scala:204) finished in 0.021 s
19/07/31 11:55:00 INFO DAGScheduler: looking for newly runnable stages
19/07/31 11:55:00 INFO DAGScheduler: running: Set()
19/07/31 11:55:00 INFO DAGScheduler: waiting: Set(ResultStage 46)
19/07/31 11:55:00 INFO DAGScheduler: failed: Set()
19/07/31 11:55:00 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[184] at collect at utils.scala:204), which has no missing parents
19/07/31 11:55:00 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 7.0 KB, free 910.9 MB)
19/07/31 11:55:00 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.9 MB)
19/07/31 11:55:00 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:59789 (size: 3.7 KB, free: 912.1 MB)
19/07/31 11:55:00 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
19/07/31 11:55:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[184] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 11:55:00 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
19/07/31 11:55:00 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 51, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 11:55:00 INFO Executor: Running task 0.0 in stage 46.0 (TID 51)
19/07/31 11:55:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 11:55:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 11:55:00 INFO Executor: Finished task 0.0 in stage 46.0 (TID 51). 1581 bytes result sent to driver
19/07/31 11:55:00 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 51) in 4 ms on localhost (executor driver) (1/1)
19/07/31 11:55:00 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
19/07/31 11:55:00 INFO DAGScheduler: ResultStage 46 (collect at utils.scala:204) finished in 0.009 s
19/07/31 11:55:00 INFO DAGScheduler: Job 34 finished: collect at utils.scala:204, took 0.088918 s
19/07/31 11:55:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz26`
WHERE (0 = 1)
19/07/31 11:55:00 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 11:55:00 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:55:00 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:55:00 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:55:00 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:55:00 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 11:55:00 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 11:55:00 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 11:55:00 INFO DAGScheduler: Got job 35 (collect at utils.scala:44) with 2 output partitions
19/07/31 11:55:00 INFO DAGScheduler: Final stage: ResultStage 47 (collect at utils.scala:44)
19/07/31 11:55:00 INFO DAGScheduler: Parents of final stage: List()
19/07/31 11:55:00 INFO DAGScheduler: Missing parents: List()
19/07/31 11:55:00 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[189] at map at utils.scala:41), which has no missing parents
19/07/31 11:55:00 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 6.4 KB, free 910.9 MB)
19/07/31 11:55:00 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 3.6 KB, free 910.9 MB)
19/07/31 11:55:00 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:59789 (size: 3.6 KB, free: 912.1 MB)
19/07/31 11:55:00 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
19/07/31 11:55:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 47 (MapPartitionsRDD[189] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
19/07/31 11:55:00 INFO TaskSchedulerImpl: Adding task set 47.0 with 2 tasks
19/07/31 11:55:00 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 11:55:00 INFO TaskSetManager: Starting task 1.0 in stage 47.0 (TID 53, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/07/31 11:55:00 INFO Executor: Running task 0.0 in stage 47.0 (TID 52)
19/07/31 11:55:00 INFO Executor: Running task 1.0 in stage 47.0 (TID 53)
19/07/31 11:55:00 INFO Executor: Finished task 1.0 in stage 47.0 (TID 53). 1018 bytes result sent to driver
19/07/31 11:55:00 INFO TaskSetManager: Finished task 1.0 in stage 47.0 (TID 53) in 7 ms on localhost (executor driver) (1/2)
19/07/31 11:55:00 INFO Executor: Finished task 0.0 in stage 47.0 (TID 52). 1007 bytes result sent to driver
19/07/31 11:55:00 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 52) in 10 ms on localhost (executor driver) (2/2)
19/07/31 11:55:00 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
19/07/31 11:55:00 INFO DAGScheduler: ResultStage 47 (collect at utils.scala:44) finished in 0.010 s
19/07/31 11:55:00 INFO DAGScheduler: Job 35 finished: collect at utils.scala:44, took 0.025946 s
19/07/31 11:55:00 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 11:55:00 INFO MapPartitionsRDD: Removing RDD 172 from persistence list
19/07/31 11:55:00 INFO BlockManager: Removing RDD 172
19/07/31 11:55:00 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 11:55:00 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#2613)) > 0)
19/07/31 11:55:00 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 11:55:00 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 11:55:00 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 281.2 KB, free 910.6 MB)
19/07/31 11:55:00 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 23.8 KB, free 910.6 MB)
19/07/31 11:55:00 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:59789 (size: 23.8 KB, free: 912.1 MB)
19/07/31 11:55:00 INFO SparkContext: Created broadcast 63 from csv at NativeMethodAccessorImpl.java:0
19/07/31 11:55:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 11:55:00 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 11:55:00 INFO DAGScheduler: Got job 36 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 11:55:00 INFO DAGScheduler: Final stage: ResultStage 48 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 11:55:00 INFO DAGScheduler: Parents of final stage: List()
19/07/31 11:55:00 INFO DAGScheduler: Missing parents: List()
19/07/31 11:55:00 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[192] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 11:55:00 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 8.2 KB, free 910.6 MB)
19/07/31 11:55:00 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 4.3 KB, free 910.6 MB)
19/07/31 11:55:00 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:59789 (size: 4.3 KB, free: 912.1 MB)
19/07/31 11:55:00 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1006
19/07/31 11:55:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[192] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 11:55:00 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
19/07/31 11:55:00 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 11:55:00 INFO Executor: Running task 0.0 in stage 48.0 (TID 54)
19/07/31 11:55:00 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 11:55:01 INFO Executor: Finished task 0.0 in stage 48.0 (TID 54). 1394 bytes result sent to driver
19/07/31 11:55:01 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 54) in 7 ms on localhost (executor driver) (1/1)
19/07/31 11:55:01 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
19/07/31 11:55:01 INFO DAGScheduler: ResultStage 48 (csv at NativeMethodAccessorImpl.java:0) finished in 0.007 s
19/07/31 11:55:01 INFO DAGScheduler: Job 36 finished: csv at NativeMethodAccessorImpl.java:0, took 0.017081 s
19/07/31 11:55:01 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 11:55:01 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 11:55:01 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 11:55:01 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 11:55:01 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 281.2 KB, free 910.3 MB)
19/07/31 11:55:01 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 23.8 KB, free 910.3 MB)
19/07/31 11:55:01 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:59789 (size: 23.8 KB, free: 912.1 MB)
19/07/31 11:55:01 INFO SparkContext: Created broadcast 65 from csv at NativeMethodAccessorImpl.java:0
19/07/31 11:55:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 11:55:01 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 11:55:01 INFO DAGScheduler: Got job 37 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 11:55:01 INFO DAGScheduler: Final stage: ResultStage 49 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 11:55:01 INFO DAGScheduler: Parents of final stage: List()
19/07/31 11:55:01 INFO DAGScheduler: Missing parents: List()
19/07/31 11:55:01 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[197] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 11:55:01 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 14.8 KB, free 910.3 MB)
19/07/31 11:55:01 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 8.6 KB, free 910.3 MB)
19/07/31 11:55:01 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:59789 (size: 8.6 KB, free: 912.1 MB)
19/07/31 11:55:01 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1006
19/07/31 11:55:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[197] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 11:55:01 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
19/07/31 11:55:01 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 11:55:01 INFO Executor: Running task 0.0 in stage 49.0 (TID 55)
19/07/31 11:55:01 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 11:55:01 INFO Executor: Finished task 0.0 in stage 49.0 (TID 55). 1584 bytes result sent to driver
19/07/31 11:55:01 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 55) in 27 ms on localhost (executor driver) (1/1)
19/07/31 11:55:01 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
19/07/31 11:55:01 INFO DAGScheduler: ResultStage 49 (csv at NativeMethodAccessorImpl.java:0) finished in 0.027 s
19/07/31 11:55:01 INFO DAGScheduler: Job 37 finished: csv at NativeMethodAccessorImpl.java:0, took 0.034840 s
19/07/31 11:55:01 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 11:55:01 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:55:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:55:01 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:55:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:55:01 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 11:55:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 11:55:01 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 11:55:01 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 11:55:01 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 11:55:01 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 11:55:01 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 11:55:01 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 11:55:01 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 11:55:01 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 282.3 KB, free 910.0 MB)
19/07/31 11:55:01 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 24.0 KB, free 910.0 MB)
19/07/31 11:55:01 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:59789 (size: 24.0 KB, free: 912.0 MB)
19/07/31 11:55:01 INFO SparkContext: Created broadcast 67 from sql at <unknown>:0
19/07/31 11:55:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 11:55:01 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 11:55:01 INFO DAGScheduler: Registering RDD 203 (sql at <unknown>:0)
19/07/31 11:55:01 INFO DAGScheduler: Got job 38 (sql at <unknown>:0) with 1 output partitions
19/07/31 11:55:01 INFO DAGScheduler: Final stage: ResultStage 51 (sql at <unknown>:0)
19/07/31 11:55:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
19/07/31 11:55:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 50)
19/07/31 11:55:01 INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[203] at sql at <unknown>:0), which has no missing parents
19/07/31 11:55:01 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 26.3 KB, free 909.9 MB)
19/07/31 11:55:01 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 11.9 KB, free 909.9 MB)
19/07/31 11:55:01 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:59789 (size: 11.9 KB, free: 912.0 MB)
19/07/31 11:55:01 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1006
19/07/31 11:55:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[203] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 11:55:01 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
19/07/31 11:55:01 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 11:55:01 INFO Executor: Running task 0.0 in stage 50.0 (TID 56)
19/07/31 11:55:01 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 11:55:01 INFO MemoryStore: Block rdd_200_0 stored as values in memory (estimated size 48.9 KB, free 909.9 MB)
19/07/31 11:55:01 INFO BlockManagerInfo: Added rdd_200_0 in memory on 127.0.0.1:59789 (size: 48.9 KB, free: 912.0 MB)
19/07/31 11:55:01 INFO Executor: Finished task 0.0 in stage 50.0 (TID 56). 2461 bytes result sent to driver
19/07/31 11:55:01 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 56) in 44 ms on localhost (executor driver) (1/1)
19/07/31 11:55:01 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
19/07/31 11:55:01 INFO DAGScheduler: ShuffleMapStage 50 (sql at <unknown>:0) finished in 0.044 s
19/07/31 11:55:01 INFO DAGScheduler: looking for newly runnable stages
19/07/31 11:55:01 INFO DAGScheduler: running: Set()
19/07/31 11:55:01 INFO DAGScheduler: waiting: Set(ResultStage 51)
19/07/31 11:55:01 INFO DAGScheduler: failed: Set()
19/07/31 11:55:01 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[206] at sql at <unknown>:0), which has no missing parents
19/07/31 11:55:01 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 7.0 KB, free 909.9 MB)
19/07/31 11:55:01 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 3.7 KB, free 909.9 MB)
19/07/31 11:55:01 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:59789 (size: 3.7 KB, free: 912.0 MB)
19/07/31 11:55:01 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1006
19/07/31 11:55:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[206] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 11:55:01 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
19/07/31 11:55:01 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 57, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 11:55:01 INFO Executor: Running task 0.0 in stage 51.0 (TID 57)
19/07/31 11:55:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 11:55:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 11:55:01 INFO Executor: Finished task 0.0 in stage 51.0 (TID 57). 1581 bytes result sent to driver
19/07/31 11:55:01 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 57) in 4 ms on localhost (executor driver) (1/1)
19/07/31 11:55:01 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
19/07/31 11:55:01 INFO DAGScheduler: ResultStage 51 (sql at <unknown>:0) finished in 0.005 s
19/07/31 11:55:01 INFO DAGScheduler: Job 38 finished: sql at <unknown>:0, took 0.069747 s
19/07/31 11:55:01 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 11:55:01 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:55:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:55:01 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 11:55:01 INFO DAGScheduler: Registering RDD 209 (collect at utils.scala:204)
19/07/31 11:55:01 INFO DAGScheduler: Got job 39 (collect at utils.scala:204) with 1 output partitions
19/07/31 11:55:01 INFO DAGScheduler: Final stage: ResultStage 53 (collect at utils.scala:204)
19/07/31 11:55:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 52)
19/07/31 11:55:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 52)
19/07/31 11:55:01 INFO DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[209] at collect at utils.scala:204), which has no missing parents
19/07/31 11:55:01 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 26.3 KB, free 909.9 MB)
19/07/31 11:55:01 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 11.9 KB, free 909.8 MB)
19/07/31 11:55:01 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:59789 (size: 11.9 KB, free: 912.0 MB)
19/07/31 11:55:01 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1006
19/07/31 11:55:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[209] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 11:55:01 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
19/07/31 11:55:01 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 58, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 11:55:01 INFO Executor: Running task 0.0 in stage 52.0 (TID 58)
19/07/31 11:55:01 INFO BlockManager: Found block rdd_200_0 locally
19/07/31 11:55:01 INFO Executor: Finished task 0.0 in stage 52.0 (TID 58). 1780 bytes result sent to driver
19/07/31 11:55:01 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 58) in 12 ms on localhost (executor driver) (1/1)
19/07/31 11:55:01 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
19/07/31 11:55:01 INFO DAGScheduler: ShuffleMapStage 52 (collect at utils.scala:204) finished in 0.013 s
19/07/31 11:55:01 INFO DAGScheduler: looking for newly runnable stages
19/07/31 11:55:01 INFO DAGScheduler: running: Set()
19/07/31 11:55:01 INFO DAGScheduler: waiting: Set(ResultStage 53)
19/07/31 11:55:01 INFO DAGScheduler: failed: Set()
19/07/31 11:55:01 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[212] at collect at utils.scala:204), which has no missing parents
19/07/31 11:55:01 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 7.0 KB, free 909.8 MB)
19/07/31 11:55:01 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 3.7 KB, free 909.8 MB)
19/07/31 11:55:01 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:59789 (size: 3.7 KB, free: 912.0 MB)
19/07/31 11:55:01 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1006
19/07/31 11:55:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[212] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 11:55:01 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
19/07/31 11:55:01 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 59, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 11:55:01 INFO Executor: Running task 0.0 in stage 53.0 (TID 59)
19/07/31 11:55:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 11:55:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 11:55:01 INFO Executor: Finished task 0.0 in stage 53.0 (TID 59). 1538 bytes result sent to driver
19/07/31 11:55:01 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 59) in 3 ms on localhost (executor driver) (1/1)
19/07/31 11:55:01 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
19/07/31 11:55:01 INFO DAGScheduler: ResultStage 53 (collect at utils.scala:204) finished in 0.005 s
19/07/31 11:55:01 INFO DAGScheduler: Job 39 finished: collect at utils.scala:204, took 0.074138 s
19/07/31 11:55:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz27`
WHERE (0 = 1)
19/07/31 11:55:01 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 11:55:01 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:55:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:55:01 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:55:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:55:01 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 11:55:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 11:55:01 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 11:55:01 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:55:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:55:01 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:55:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:55:01 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 11:55:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 11:55:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 11:55:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 11:55:08 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 11:55:08 INFO DAGScheduler: Got job 40 (collect at utils.scala:204) with 1 output partitions
19/07/31 11:55:08 INFO DAGScheduler: Final stage: ResultStage 54 (collect at utils.scala:204)
19/07/31 11:55:08 INFO DAGScheduler: Parents of final stage: List()
19/07/31 11:55:08 INFO DAGScheduler: Missing parents: List()
19/07/31 11:55:08 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[214] at collect at utils.scala:204), which has no missing parents
19/07/31 11:55:08 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 22.6 KB, free 909.8 MB)
19/07/31 11:55:08 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 10.4 KB, free 909.8 MB)
19/07/31 11:55:08 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:59789 (size: 10.4 KB, free: 912.0 MB)
19/07/31 11:55:08 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1006
19/07/31 11:55:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[214] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 11:55:08 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
19/07/31 11:55:08 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 60, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 11:55:08 INFO Executor: Running task 0.0 in stage 54.0 (TID 60)
19/07/31 11:55:08 INFO BlockManager: Found block rdd_200_0 locally
19/07/31 11:55:08 INFO CodeGenerator: Code generated in 24.493174 ms
19/07/31 11:55:08 INFO Executor: Finished task 0.0 in stage 54.0 (TID 60). 73364 bytes result sent to driver
19/07/31 11:55:08 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 60) in 43 ms on localhost (executor driver) (1/1)
19/07/31 11:55:08 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
19/07/31 11:55:08 INFO DAGScheduler: ResultStage 54 (collect at utils.scala:204) finished in 0.043 s
19/07/31 11:55:08 INFO DAGScheduler: Job 40 finished: collect at utils.scala:204, took 0.053077 s
19/07/31 11:55:08 INFO CodeGenerator: Code generated in 19.247254 ms
19/07/31 11:55:56 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 11:55:56 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:55:56 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:55:56 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:55:56 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:55:56 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 11:55:56 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 11:55:56 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 11:55:56 INFO DAGScheduler: Got job 41 (collect at utils.scala:44) with 2 output partitions
19/07/31 11:55:56 INFO DAGScheduler: Final stage: ResultStage 55 (collect at utils.scala:44)
19/07/31 11:55:56 INFO DAGScheduler: Parents of final stage: List()
19/07/31 11:55:56 INFO DAGScheduler: Missing parents: List()
19/07/31 11:55:56 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[219] at map at utils.scala:41), which has no missing parents
19/07/31 11:55:56 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 6.4 KB, free 909.8 MB)
19/07/31 11:55:56 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 3.6 KB, free 909.8 MB)
19/07/31 11:55:56 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:59789 (size: 3.6 KB, free: 912.0 MB)
19/07/31 11:55:56 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1006
19/07/31 11:55:56 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 55 (MapPartitionsRDD[219] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
19/07/31 11:55:56 INFO TaskSchedulerImpl: Adding task set 55.0 with 2 tasks
19/07/31 11:55:56 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 11:55:56 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 62, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/07/31 11:55:56 INFO Executor: Running task 0.0 in stage 55.0 (TID 61)
19/07/31 11:55:56 INFO Executor: Running task 1.0 in stage 55.0 (TID 62)
19/07/31 11:55:56 INFO Executor: Finished task 0.0 in stage 55.0 (TID 61). 1007 bytes result sent to driver
19/07/31 11:55:56 INFO Executor: Finished task 1.0 in stage 55.0 (TID 62). 975 bytes result sent to driver
19/07/31 11:55:56 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 61) in 11 ms on localhost (executor driver) (1/2)
19/07/31 11:55:56 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 62) in 16 ms on localhost (executor driver) (2/2)
19/07/31 11:55:56 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
19/07/31 11:55:56 INFO DAGScheduler: ResultStage 55 (collect at utils.scala:44) finished in 0.017 s
19/07/31 11:55:56 INFO DAGScheduler: Job 41 finished: collect at utils.scala:44, took 0.031554 s
19/07/31 11:55:56 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 11:55:56 INFO MapPartitionsRDD: Removing RDD 200 from persistence list
19/07/31 11:55:56 INFO BlockManager: Removing RDD 200
19/07/31 11:55:56 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 11:55:56 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#3099)) > 0)
19/07/31 11:55:56 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 11:55:56 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 11:55:56 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 281.2 KB, free 909.6 MB)
19/07/31 11:55:56 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 23.8 KB, free 909.5 MB)
19/07/31 11:55:56 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:59789 (size: 23.8 KB, free: 912.0 MB)
19/07/31 11:55:56 INFO SparkContext: Created broadcast 74 from csv at NativeMethodAccessorImpl.java:0
19/07/31 11:55:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 11:55:56 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 11:55:56 INFO DAGScheduler: Got job 42 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 11:55:56 INFO DAGScheduler: Final stage: ResultStage 56 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 11:55:56 INFO DAGScheduler: Parents of final stage: List()
19/07/31 11:55:56 INFO DAGScheduler: Missing parents: List()
19/07/31 11:55:56 INFO DAGScheduler: Submitting ResultStage 56 (MapPartitionsRDD[222] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 11:55:56 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 8.2 KB, free 909.5 MB)
19/07/31 11:55:56 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 4.3 KB, free 909.5 MB)
19/07/31 11:55:56 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:59789 (size: 4.3 KB, free: 912.0 MB)
19/07/31 11:55:56 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1006
19/07/31 11:55:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (MapPartitionsRDD[222] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 11:55:56 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
19/07/31 11:55:56 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 63, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 11:55:56 INFO Executor: Running task 0.0 in stage 56.0 (TID 63)
19/07/31 11:55:56 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 11:55:56 INFO Executor: Finished task 0.0 in stage 56.0 (TID 63). 1394 bytes result sent to driver
19/07/31 11:55:56 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 63) in 9 ms on localhost (executor driver) (1/1)
19/07/31 11:55:56 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
19/07/31 11:55:56 INFO DAGScheduler: ResultStage 56 (csv at NativeMethodAccessorImpl.java:0) finished in 0.010 s
19/07/31 11:55:56 INFO DAGScheduler: Job 42 finished: csv at NativeMethodAccessorImpl.java:0, took 0.019602 s
19/07/31 11:55:56 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 11:55:56 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 11:55:56 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 11:55:56 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 11:55:56 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 281.2 KB, free 909.3 MB)
19/07/31 11:55:56 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 23.8 KB, free 909.2 MB)
19/07/31 11:55:56 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:59789 (size: 23.8 KB, free: 912.0 MB)
19/07/31 11:55:56 INFO SparkContext: Created broadcast 76 from csv at NativeMethodAccessorImpl.java:0
19/07/31 11:55:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 11:55:56 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 11:55:56 INFO DAGScheduler: Got job 43 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 11:55:56 INFO DAGScheduler: Final stage: ResultStage 57 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 11:55:56 INFO DAGScheduler: Parents of final stage: List()
19/07/31 11:55:56 INFO DAGScheduler: Missing parents: List()
19/07/31 11:55:56 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[227] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 11:55:56 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 14.8 KB, free 909.2 MB)
19/07/31 11:55:56 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 8.6 KB, free 909.2 MB)
19/07/31 11:55:56 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:59789 (size: 8.6 KB, free: 911.9 MB)
19/07/31 11:55:56 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1006
19/07/31 11:55:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[227] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 11:55:56 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
19/07/31 11:55:56 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 11:55:56 INFO Executor: Running task 0.0 in stage 57.0 (TID 64)
19/07/31 11:55:56 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 11:55:56 INFO Executor: Finished task 0.0 in stage 57.0 (TID 64). 1584 bytes result sent to driver
19/07/31 11:55:56 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 64) in 18 ms on localhost (executor driver) (1/1)
19/07/31 11:55:56 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
19/07/31 11:55:56 INFO DAGScheduler: ResultStage 57 (csv at NativeMethodAccessorImpl.java:0) finished in 0.018 s
19/07/31 11:55:56 INFO DAGScheduler: Job 43 finished: csv at NativeMethodAccessorImpl.java:0, took 0.028980 s
19/07/31 11:55:57 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 11:55:57 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:55:57 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:55:57 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:55:57 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:55:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 11:55:57 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 11:55:57 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 11:55:57 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 11:55:57 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 11:55:57 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 11:55:57 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 11:55:57 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 11:55:57 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 11:55:57 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 282.3 KB, free 908.9 MB)
19/07/31 11:55:57 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 24.0 KB, free 908.9 MB)
19/07/31 11:55:57 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:59789 (size: 24.0 KB, free: 911.9 MB)
19/07/31 11:55:57 INFO SparkContext: Created broadcast 78 from sql at <unknown>:0
19/07/31 11:55:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 11:55:57 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 11:55:57 INFO DAGScheduler: Registering RDD 233 (sql at <unknown>:0)
19/07/31 11:55:57 INFO DAGScheduler: Got job 44 (sql at <unknown>:0) with 1 output partitions
19/07/31 11:55:57 INFO DAGScheduler: Final stage: ResultStage 59 (sql at <unknown>:0)
19/07/31 11:55:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58)
19/07/31 11:55:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 58)
19/07/31 11:55:57 INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[233] at sql at <unknown>:0), which has no missing parents
19/07/31 11:55:57 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 26.3 KB, free 908.9 MB)
19/07/31 11:55:57 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 11.8 KB, free 908.9 MB)
19/07/31 11:55:57 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:59789 (size: 11.8 KB, free: 911.9 MB)
19/07/31 11:55:57 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1006
19/07/31 11:55:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[233] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 11:55:57 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
19/07/31 11:55:57 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 11:55:57 INFO Executor: Running task 0.0 in stage 58.0 (TID 65)
19/07/31 11:55:57 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 11:55:57 INFO MemoryStore: Block rdd_230_0 stored as values in memory (estimated size 48.9 KB, free 908.8 MB)
19/07/31 11:55:57 INFO BlockManagerInfo: Added rdd_230_0 in memory on 127.0.0.1:59789 (size: 48.9 KB, free: 911.9 MB)
19/07/31 11:55:57 INFO Executor: Finished task 0.0 in stage 58.0 (TID 65). 2461 bytes result sent to driver
19/07/31 11:55:57 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 65) in 41 ms on localhost (executor driver) (1/1)
19/07/31 11:55:57 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
19/07/31 11:55:57 INFO DAGScheduler: ShuffleMapStage 58 (sql at <unknown>:0) finished in 0.042 s
19/07/31 11:55:57 INFO DAGScheduler: looking for newly runnable stages
19/07/31 11:55:57 INFO DAGScheduler: running: Set()
19/07/31 11:55:57 INFO DAGScheduler: waiting: Set(ResultStage 59)
19/07/31 11:55:57 INFO DAGScheduler: failed: Set()
19/07/31 11:55:57 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[236] at sql at <unknown>:0), which has no missing parents
19/07/31 11:55:57 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 7.0 KB, free 908.8 MB)
19/07/31 11:55:57 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 3.7 KB, free 908.8 MB)
19/07/31 11:55:57 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:59789 (size: 3.7 KB, free: 911.9 MB)
19/07/31 11:55:57 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1006
19/07/31 11:55:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[236] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 11:55:57 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
19/07/31 11:55:57 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 66, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 11:55:57 INFO Executor: Running task 0.0 in stage 59.0 (TID 66)
19/07/31 11:55:57 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 11:55:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 11:55:57 INFO Executor: Finished task 0.0 in stage 59.0 (TID 66). 1581 bytes result sent to driver
19/07/31 11:55:57 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 66) in 3 ms on localhost (executor driver) (1/1)
19/07/31 11:55:57 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
19/07/31 11:55:57 INFO DAGScheduler: ResultStage 59 (sql at <unknown>:0) finished in 0.004 s
19/07/31 11:55:57 INFO DAGScheduler: Job 44 finished: sql at <unknown>:0, took 0.065876 s
19/07/31 11:55:57 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 11:55:57 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:55:57 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:55:57 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 11:55:57 INFO DAGScheduler: Registering RDD 239 (collect at utils.scala:204)
19/07/31 11:55:57 INFO DAGScheduler: Got job 45 (collect at utils.scala:204) with 1 output partitions
19/07/31 11:55:57 INFO DAGScheduler: Final stage: ResultStage 61 (collect at utils.scala:204)
19/07/31 11:55:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 60)
19/07/31 11:55:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 60)
19/07/31 11:55:57 INFO DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[239] at collect at utils.scala:204), which has no missing parents
19/07/31 11:55:57 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 26.3 KB, free 908.8 MB)
19/07/31 11:55:57 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 11.9 KB, free 908.8 MB)
19/07/31 11:55:57 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:59789 (size: 11.9 KB, free: 911.8 MB)
19/07/31 11:55:57 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1006
19/07/31 11:55:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[239] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 11:55:57 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
19/07/31 11:55:57 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 11:55:57 INFO Executor: Running task 0.0 in stage 60.0 (TID 67)
19/07/31 11:55:57 INFO BlockManager: Found block rdd_230_0 locally
19/07/31 11:55:57 INFO Executor: Finished task 0.0 in stage 60.0 (TID 67). 1780 bytes result sent to driver
19/07/31 11:55:57 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 67) in 12 ms on localhost (executor driver) (1/1)
19/07/31 11:55:57 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
19/07/31 11:55:57 INFO DAGScheduler: ShuffleMapStage 60 (collect at utils.scala:204) finished in 0.013 s
19/07/31 11:55:57 INFO DAGScheduler: looking for newly runnable stages
19/07/31 11:55:57 INFO DAGScheduler: running: Set()
19/07/31 11:55:57 INFO DAGScheduler: waiting: Set(ResultStage 61)
19/07/31 11:55:57 INFO DAGScheduler: failed: Set()
19/07/31 11:55:57 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[242] at collect at utils.scala:204), which has no missing parents
19/07/31 11:55:57 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 7.0 KB, free 908.8 MB)
19/07/31 11:55:57 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 3.7 KB, free 908.8 MB)
19/07/31 11:55:57 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:59789 (size: 3.7 KB, free: 911.8 MB)
19/07/31 11:55:57 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1006
19/07/31 11:55:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[242] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 11:55:57 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
19/07/31 11:55:57 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 68, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 11:55:57 INFO Executor: Running task 0.0 in stage 61.0 (TID 68)
19/07/31 11:55:57 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 11:55:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 11:55:57 INFO Executor: Finished task 0.0 in stage 61.0 (TID 68). 1581 bytes result sent to driver
19/07/31 11:55:57 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 68) in 7 ms on localhost (executor driver) (1/1)
19/07/31 11:55:57 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
19/07/31 11:55:57 INFO DAGScheduler: ResultStage 61 (collect at utils.scala:204) finished in 0.007 s
19/07/31 11:55:57 INFO DAGScheduler: Job 45 finished: collect at utils.scala:204, took 0.057452 s
19/07/31 11:55:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz28`
WHERE (0 = 1)
19/07/31 11:55:57 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 11:55:57 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:55:57 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:55:57 INFO HiveMetaStore: 0: get_database: default
19/07/31 11:55:57 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 11:55:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 11:55:57 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 11:55:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 11:55:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 11:55:59 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 11:55:59 INFO DAGScheduler: Got job 46 (collect at utils.scala:204) with 1 output partitions
19/07/31 11:55:59 INFO DAGScheduler: Final stage: ResultStage 62 (collect at utils.scala:204)
19/07/31 11:55:59 INFO DAGScheduler: Parents of final stage: List()
19/07/31 11:55:59 INFO DAGScheduler: Missing parents: List()
19/07/31 11:55:59 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[244] at collect at utils.scala:204), which has no missing parents
19/07/31 11:55:59 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 22.6 KB, free 908.7 MB)
19/07/31 11:55:59 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 10.4 KB, free 908.7 MB)
19/07/31 11:55:59 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:59789 (size: 10.4 KB, free: 911.8 MB)
19/07/31 11:55:59 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1006
19/07/31 11:55:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[244] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 11:55:59 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
19/07/31 11:55:59 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 69, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 11:55:59 INFO Executor: Running task 0.0 in stage 62.0 (TID 69)
19/07/31 11:55:59 INFO BlockManager: Found block rdd_230_0 locally
19/07/31 11:55:59 INFO Executor: Finished task 0.0 in stage 62.0 (TID 69). 73364 bytes result sent to driver
19/07/31 11:55:59 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 69) in 11 ms on localhost (executor driver) (1/1)
19/07/31 11:55:59 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
19/07/31 11:55:59 INFO DAGScheduler: ResultStage 62 (collect at utils.scala:204) finished in 0.011 s
19/07/31 11:55:59 INFO DAGScheduler: Job 46 finished: collect at utils.scala:204, took 0.019048 s
19/07/31 12:00:00 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:00:00 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:00:00 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:00:00 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:00:00 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:00:00 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:00:00 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:00:00 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 12:00:00 INFO DAGScheduler: Got job 47 (collect at utils.scala:44) with 2 output partitions
19/07/31 12:00:00 INFO DAGScheduler: Final stage: ResultStage 63 (collect at utils.scala:44)
19/07/31 12:00:00 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:00:00 INFO DAGScheduler: Missing parents: List()
19/07/31 12:00:00 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[249] at map at utils.scala:41), which has no missing parents
19/07/31 12:00:00 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 6.4 KB, free 908.7 MB)
19/07/31 12:00:00 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 3.6 KB, free 908.7 MB)
19/07/31 12:00:00 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:59789 (size: 3.6 KB, free: 911.8 MB)
19/07/31 12:00:00 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1006
19/07/31 12:00:00 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 63 (MapPartitionsRDD[249] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
19/07/31 12:00:00 INFO TaskSchedulerImpl: Adding task set 63.0 with 2 tasks
19/07/31 12:00:00 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 70, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 12:00:00 INFO TaskSetManager: Starting task 1.0 in stage 63.0 (TID 71, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/07/31 12:00:00 INFO Executor: Running task 0.0 in stage 63.0 (TID 70)
19/07/31 12:00:00 INFO Executor: Running task 1.0 in stage 63.0 (TID 71)
19/07/31 12:00:00 INFO Executor: Finished task 0.0 in stage 63.0 (TID 70). 1007 bytes result sent to driver
19/07/31 12:00:00 INFO Executor: Finished task 1.0 in stage 63.0 (TID 71). 975 bytes result sent to driver
19/07/31 12:00:00 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 70) in 5 ms on localhost (executor driver) (1/2)
19/07/31 12:00:00 INFO TaskSetManager: Finished task 1.0 in stage 63.0 (TID 71) in 4 ms on localhost (executor driver) (2/2)
19/07/31 12:00:00 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
19/07/31 12:00:00 INFO DAGScheduler: ResultStage 63 (collect at utils.scala:44) finished in 0.006 s
19/07/31 12:00:00 INFO DAGScheduler: Job 47 finished: collect at utils.scala:44, took 0.020893 s
19/07/31 12:00:00 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 12:00:00 INFO MapPartitionsRDD: Removing RDD 230 from persistence list
19/07/31 12:00:00 INFO BlockManager: Removing RDD 230
19/07/31 12:00:00 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:00:00 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#3578)) > 0)
19/07/31 12:00:00 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:00:00 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:00:00 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 281.2 KB, free 908.5 MB)
19/07/31 12:00:00 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 23.8 KB, free 908.5 MB)
19/07/31 12:00:00 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:59789 (size: 23.8 KB, free: 911.9 MB)
19/07/31 12:00:00 INFO SparkContext: Created broadcast 85 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:00:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:00:00 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:00:00 INFO DAGScheduler: Got job 48 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:00:00 INFO DAGScheduler: Final stage: ResultStage 64 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:00:00 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:00:00 INFO DAGScheduler: Missing parents: List()
19/07/31 12:00:00 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[252] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:00:00 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 8.2 KB, free 908.5 MB)
19/07/31 12:00:00 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 4.3 KB, free 908.5 MB)
19/07/31 12:00:00 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:59789 (size: 4.3 KB, free: 911.8 MB)
19/07/31 12:00:00 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1006
19/07/31 12:00:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[252] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:00:00 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
19/07/31 12:00:00 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 72, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:00:00 INFO Executor: Running task 0.0 in stage 64.0 (TID 72)
19/07/31 12:00:00 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:00:00 INFO Executor: Finished task 0.0 in stage 64.0 (TID 72). 1437 bytes result sent to driver
19/07/31 12:00:00 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 72) in 17 ms on localhost (executor driver) (1/1)
19/07/31 12:00:00 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
19/07/31 12:00:00 INFO DAGScheduler: ResultStage 64 (csv at NativeMethodAccessorImpl.java:0) finished in 0.018 s
19/07/31 12:00:00 INFO DAGScheduler: Job 48 finished: csv at NativeMethodAccessorImpl.java:0, took 0.042666 s
19/07/31 12:00:00 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:00:00 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:00:00 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:00:00 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:00:00 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 281.2 KB, free 908.2 MB)
19/07/31 12:00:00 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 23.8 KB, free 908.2 MB)
19/07/31 12:00:00 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:59789 (size: 23.8 KB, free: 911.8 MB)
19/07/31 12:00:00 INFO SparkContext: Created broadcast 87 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:00:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:00:00 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:00:00 INFO DAGScheduler: Got job 49 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:00:00 INFO DAGScheduler: Final stage: ResultStage 65 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:00:00 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:00:00 INFO DAGScheduler: Missing parents: List()
19/07/31 12:00:00 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[257] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:00:00 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 14.8 KB, free 908.1 MB)
19/07/31 12:00:00 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 8.6 KB, free 908.1 MB)
19/07/31 12:00:00 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:59789 (size: 8.6 KB, free: 911.8 MB)
19/07/31 12:00:00 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1006
19/07/31 12:00:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[257] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:00:00 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
19/07/31 12:00:00 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:00:00 INFO Executor: Running task 0.0 in stage 65.0 (TID 73)
19/07/31 12:00:00 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:00:00 INFO Executor: Finished task 0.0 in stage 65.0 (TID 73). 1584 bytes result sent to driver
19/07/31 12:00:00 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 73) in 12 ms on localhost (executor driver) (1/1)
19/07/31 12:00:00 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
19/07/31 12:00:00 INFO DAGScheduler: ResultStage 65 (csv at NativeMethodAccessorImpl.java:0) finished in 0.013 s
19/07/31 12:00:00 INFO DAGScheduler: Job 49 finished: csv at NativeMethodAccessorImpl.java:0, took 0.024467 s
19/07/31 12:00:00 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:00:00 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:00:00 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:00:00 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:00:00 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:00:00 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:00:00 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:00:00 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 12:00:00 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 12:00:00 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 12:00:00 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:00:00 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:00:00 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 12:00:00 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:00:00 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 282.3 KB, free 907.9 MB)
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:59789 in memory (size: 11.9 KB, free: 911.8 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1516
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1355
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:59789 in memory (size: 3.6 KB, free: 911.8 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1506
19/07/31 12:00:00 INFO ContextCleaner: Cleaned shuffle 15
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1470
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:59789 in memory (size: 10.4 KB, free: 911.8 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1750
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:59789 in memory (size: 11.8 KB, free: 911.9 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1513
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:59789 in memory (size: 4.3 KB, free: 911.9 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1915
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1710
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1230
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1301
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1364
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1294
19/07/31 12:00:00 INFO BlockManager: Removing RDD 172
19/07/31 12:00:00 INFO ContextCleaner: Cleaned RDD 172
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1651
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1676
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1507
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1443
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1677
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1808
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1291
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1258
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:59789 in memory (size: 23.8 KB, free: 911.9 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1353
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1363
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:59789 in memory (size: 3.6 KB, free: 911.9 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1304
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1439
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1508
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:59789 in memory (size: 3.7 KB, free: 911.9 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1515
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 127.0.0.1:59789 in memory (size: 8.6 KB, free: 911.9 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1806
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1943
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:59789 in memory (size: 11.9 KB, free: 911.9 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1814
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1749
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1292
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1177
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1566
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1512
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1744
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1510
19/07/31 12:00:00 INFO ContextCleaner: Cleaned shuffle 14
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1505
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:59789 in memory (size: 3.7 KB, free: 911.9 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1803
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1231
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1709
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1202
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1810
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:59789 in memory (size: 11.8 KB, free: 911.9 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1297
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1228
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1746
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1812
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1469
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:59789 in memory (size: 3.6 KB, free: 911.9 MB)
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:59789 in memory (size: 11.9 KB, free: 911.9 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1359
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1299
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1681
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1569
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1293
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1743
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1471
19/07/31 12:00:00 INFO ContextCleaner: Cleaned shuffle 10
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1947
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1259
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1570
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1509
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1442
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1577
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:59789 in memory (size: 3.7 KB, free: 911.9 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1813
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1888
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:59789 in memory (size: 11.9 KB, free: 912.0 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1176
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:59789 in memory (size: 8.6 KB, free: 912.0 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1361
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:59789 in memory (size: 24.0 KB, free: 912.0 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1945
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:59789 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1356
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1295
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1288
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1679
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1567
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:59789 in memory (size: 23.8 KB, free: 912.0 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1504
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1572
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:59789 in memory (size: 8.6 KB, free: 912.0 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1354
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1946
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1302
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:59789 in memory (size: 8.6 KB, free: 912.0 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1296
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1232
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 127.0.0.1:59789 in memory (size: 23.8 KB, free: 912.1 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1678
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:59789 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:59789 in memory (size: 23.8 KB, free: 912.1 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1944
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1414
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1362
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:59789 in memory (size: 10.4 KB, free: 912.1 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1287
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1472
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1573
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1227
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1707
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1916
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1576
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1804
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1706
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:59789 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1575
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1257
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1444
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1571
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1809
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1290
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1289
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1752
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1913
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1360
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1365
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1441
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1747
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1802
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:59789 in memory (size: 11.3 KB, free: 912.1 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1680
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1511
19/07/31 12:00:00 INFO ContextCleaner: Cleaned shuffle 12
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:59789 in memory (size: 23.8 KB, free: 912.1 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1303
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1473
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1753
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:59789 in memory (size: 3.6 KB, free: 912.1 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1565
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1807
19/07/31 12:00:00 INFO ContextCleaner: Cleaned shuffle 11
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1514
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1748
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:59789 in memory (size: 23.8 KB, free: 912.2 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1574
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1568
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1741
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1286
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 127.0.0.1:59789 in memory (size: 4.3 KB, free: 912.2 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1440
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1914
19/07/31 12:00:00 INFO ContextCleaner: Cleaned shuffle 13
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1300
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1357
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:59789 in memory (size: 23.8 KB, free: 912.2 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1751
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1260
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:59789 in memory (size: 4.3 KB, free: 912.2 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1805
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:59789 in memory (size: 23.8 KB, free: 912.2 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1229
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1918
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1745
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1298
19/07/31 12:00:00 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:59789 in memory (size: 4.3 KB, free: 912.2 MB)
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1742
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1261
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1708
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1358
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1917
19/07/31 12:00:00 INFO ContextCleaner: Cleaned accumulator 1811
19/07/31 12:00:00 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.1 MB)
19/07/31 12:00:00 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:59789 (size: 24.0 KB, free: 912.2 MB)
19/07/31 12:00:00 INFO SparkContext: Created broadcast 89 from sql at <unknown>:0
19/07/31 12:00:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:00:00 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 12:00:00 INFO DAGScheduler: Registering RDD 263 (sql at <unknown>:0)
19/07/31 12:00:00 INFO DAGScheduler: Got job 50 (sql at <unknown>:0) with 1 output partitions
19/07/31 12:00:00 INFO DAGScheduler: Final stage: ResultStage 67 (sql at <unknown>:0)
19/07/31 12:00:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)
19/07/31 12:00:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 66)
19/07/31 12:00:00 INFO DAGScheduler: Submitting ShuffleMapStage 66 (MapPartitionsRDD[263] at sql at <unknown>:0), which has no missing parents
19/07/31 12:00:00 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 26.3 KB, free 911.1 MB)
19/07/31 12:00:00 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 11.8 KB, free 911.1 MB)
19/07/31 12:00:00 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:59789 (size: 11.8 KB, free: 912.2 MB)
19/07/31 12:00:00 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1006
19/07/31 12:00:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[263] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:00:00 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
19/07/31 12:00:00 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 74, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:00:00 INFO Executor: Running task 0.0 in stage 66.0 (TID 74)
19/07/31 12:00:00 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:00:00 INFO MemoryStore: Block rdd_260_0 stored as values in memory (estimated size 48.9 KB, free 911.0 MB)
19/07/31 12:00:00 INFO BlockManagerInfo: Added rdd_260_0 in memory on 127.0.0.1:59789 (size: 48.9 KB, free: 912.1 MB)
19/07/31 12:00:00 INFO Executor: Finished task 0.0 in stage 66.0 (TID 74). 2461 bytes result sent to driver
19/07/31 12:00:00 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 74) in 52 ms on localhost (executor driver) (1/1)
19/07/31 12:00:00 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
19/07/31 12:00:00 INFO DAGScheduler: ShuffleMapStage 66 (sql at <unknown>:0) finished in 0.053 s
19/07/31 12:00:00 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:00:00 INFO DAGScheduler: running: Set()
19/07/31 12:00:00 INFO DAGScheduler: waiting: Set(ResultStage 67)
19/07/31 12:00:00 INFO DAGScheduler: failed: Set()
19/07/31 12:00:00 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[266] at sql at <unknown>:0), which has no missing parents
19/07/31 12:00:00 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 7.0 KB, free 911.0 MB)
19/07/31 12:00:00 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.0 MB)
19/07/31 12:00:00 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:59789 (size: 3.7 KB, free: 912.1 MB)
19/07/31 12:00:00 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1006
19/07/31 12:00:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[266] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:00:00 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks
19/07/31 12:00:00 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 75, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:00:00 INFO Executor: Running task 0.0 in stage 67.0 (TID 75)
19/07/31 12:00:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:00:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:00:00 INFO Executor: Finished task 0.0 in stage 67.0 (TID 75). 1581 bytes result sent to driver
19/07/31 12:00:00 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 75) in 8 ms on localhost (executor driver) (1/1)
19/07/31 12:00:00 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
19/07/31 12:00:00 INFO DAGScheduler: ResultStage 67 (sql at <unknown>:0) finished in 0.011 s
19/07/31 12:00:00 INFO DAGScheduler: Job 50 finished: sql at <unknown>:0, took 0.083104 s
19/07/31 12:00:00 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 12:00:00 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:00:00 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:00:00 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:00:00 INFO DAGScheduler: Registering RDD 269 (collect at utils.scala:204)
19/07/31 12:00:00 INFO DAGScheduler: Got job 51 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:00:00 INFO DAGScheduler: Final stage: ResultStage 69 (collect at utils.scala:204)
19/07/31 12:00:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)
19/07/31 12:00:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 68)
19/07/31 12:00:00 INFO DAGScheduler: Submitting ShuffleMapStage 68 (MapPartitionsRDD[269] at collect at utils.scala:204), which has no missing parents
19/07/31 12:00:00 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 26.3 KB, free 911.0 MB)
19/07/31 12:00:00 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 11.9 KB, free 911.0 MB)
19/07/31 12:00:00 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 127.0.0.1:59789 (size: 11.9 KB, free: 912.1 MB)
19/07/31 12:00:00 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1006
19/07/31 12:00:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[269] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:00:00 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks
19/07/31 12:00:00 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 76, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:00:00 INFO Executor: Running task 0.0 in stage 68.0 (TID 76)
19/07/31 12:00:00 INFO BlockManager: Found block rdd_260_0 locally
19/07/31 12:00:00 INFO Executor: Finished task 0.0 in stage 68.0 (TID 76). 1780 bytes result sent to driver
19/07/31 12:00:00 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 76) in 16 ms on localhost (executor driver) (1/1)
19/07/31 12:00:00 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
19/07/31 12:00:00 INFO DAGScheduler: ShuffleMapStage 68 (collect at utils.scala:204) finished in 0.017 s
19/07/31 12:00:00 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:00:00 INFO DAGScheduler: running: Set()
19/07/31 12:00:00 INFO DAGScheduler: waiting: Set(ResultStage 69)
19/07/31 12:00:00 INFO DAGScheduler: failed: Set()
19/07/31 12:00:00 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[272] at collect at utils.scala:204), which has no missing parents
19/07/31 12:00:00 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 7.0 KB, free 910.9 MB)
19/07/31 12:00:00 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.9 MB)
19/07/31 12:00:00 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 127.0.0.1:59789 (size: 3.7 KB, free: 912.1 MB)
19/07/31 12:00:00 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1006
19/07/31 12:00:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[272] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:00:00 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks
19/07/31 12:00:00 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 77, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:00:00 INFO Executor: Running task 0.0 in stage 69.0 (TID 77)
19/07/31 12:00:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:00:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:00:00 INFO Executor: Finished task 0.0 in stage 69.0 (TID 77). 1581 bytes result sent to driver
19/07/31 12:00:00 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 77) in 9 ms on localhost (executor driver) (1/1)
19/07/31 12:00:00 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
19/07/31 12:00:00 INFO DAGScheduler: ResultStage 69 (collect at utils.scala:204) finished in 0.010 s
19/07/31 12:00:00 INFO DAGScheduler: Job 51 finished: collect at utils.scala:204, took 0.046558 s
19/07/31 12:00:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz29`
WHERE (0 = 1)
19/07/31 12:00:01 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:00:01 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:00:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:00:01 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:00:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:00:01 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:00:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:00:01 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 12:00:01 INFO DAGScheduler: Got job 52 (collect at utils.scala:44) with 2 output partitions
19/07/31 12:00:01 INFO DAGScheduler: Final stage: ResultStage 70 (collect at utils.scala:44)
19/07/31 12:00:01 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:00:01 INFO DAGScheduler: Missing parents: List()
19/07/31 12:00:01 INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[277] at map at utils.scala:41), which has no missing parents
19/07/31 12:00:01 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 6.4 KB, free 910.9 MB)
19/07/31 12:00:01 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 3.6 KB, free 910.9 MB)
19/07/31 12:00:01 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 127.0.0.1:59789 (size: 3.6 KB, free: 912.1 MB)
19/07/31 12:00:01 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1006
19/07/31 12:00:01 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 70 (MapPartitionsRDD[277] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
19/07/31 12:00:01 INFO TaskSchedulerImpl: Adding task set 70.0 with 2 tasks
19/07/31 12:00:01 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 78, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 12:00:01 INFO TaskSetManager: Starting task 1.0 in stage 70.0 (TID 79, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/07/31 12:00:01 INFO Executor: Running task 0.0 in stage 70.0 (TID 78)
19/07/31 12:00:01 INFO Executor: Running task 1.0 in stage 70.0 (TID 79)
19/07/31 12:00:01 INFO Executor: Finished task 1.0 in stage 70.0 (TID 79). 932 bytes result sent to driver
19/07/31 12:00:01 INFO Executor: Finished task 0.0 in stage 70.0 (TID 78). 964 bytes result sent to driver
19/07/31 12:00:01 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 78) in 2 ms on localhost (executor driver) (1/2)
19/07/31 12:00:01 INFO TaskSetManager: Finished task 1.0 in stage 70.0 (TID 79) in 3 ms on localhost (executor driver) (2/2)
19/07/31 12:00:01 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
19/07/31 12:00:01 INFO DAGScheduler: ResultStage 70 (collect at utils.scala:44) finished in 0.004 s
19/07/31 12:00:01 INFO DAGScheduler: Job 52 finished: collect at utils.scala:44, took 0.007923 s
19/07/31 12:00:01 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 12:00:01 INFO MapPartitionsRDD: Removing RDD 260 from persistence list
19/07/31 12:00:01 INFO BlockManager: Removing RDD 260
19/07/31 12:00:01 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:00:01 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#3950)) > 0)
19/07/31 12:00:01 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:00:01 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:00:01 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 281.2 KB, free 910.7 MB)
19/07/31 12:00:01 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 23.8 KB, free 910.7 MB)
19/07/31 12:00:01 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 127.0.0.1:59789 (size: 23.8 KB, free: 912.1 MB)
19/07/31 12:00:01 INFO SparkContext: Created broadcast 95 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:00:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:00:01 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:00:01 INFO DAGScheduler: Got job 53 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:00:01 INFO DAGScheduler: Final stage: ResultStage 71 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:00:01 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:00:01 INFO DAGScheduler: Missing parents: List()
19/07/31 12:00:01 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[280] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:00:01 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 8.2 KB, free 910.7 MB)
19/07/31 12:00:01 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 4.3 KB, free 910.7 MB)
19/07/31 12:00:01 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 127.0.0.1:59789 (size: 4.3 KB, free: 912.1 MB)
19/07/31 12:00:01 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1006
19/07/31 12:00:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[280] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:00:01 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks
19/07/31 12:00:01 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 80, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:00:01 INFO Executor: Running task 0.0 in stage 71.0 (TID 80)
19/07/31 12:00:01 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:00:01 INFO Executor: Finished task 0.0 in stage 71.0 (TID 80). 1394 bytes result sent to driver
19/07/31 12:00:01 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 80) in 5 ms on localhost (executor driver) (1/1)
19/07/31 12:00:01 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
19/07/31 12:00:01 INFO DAGScheduler: ResultStage 71 (csv at NativeMethodAccessorImpl.java:0) finished in 0.006 s
19/07/31 12:00:01 INFO DAGScheduler: Job 53 finished: csv at NativeMethodAccessorImpl.java:0, took 0.015998 s
19/07/31 12:00:01 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:00:01 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:00:01 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:00:01 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:00:01 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 281.2 KB, free 910.4 MB)
19/07/31 12:00:01 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 23.8 KB, free 910.4 MB)
19/07/31 12:00:01 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 127.0.0.1:59789 (size: 23.8 KB, free: 912.1 MB)
19/07/31 12:00:01 INFO SparkContext: Created broadcast 97 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:00:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:00:01 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:00:01 INFO DAGScheduler: Got job 54 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:00:01 INFO DAGScheduler: Final stage: ResultStage 72 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:00:01 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:00:01 INFO DAGScheduler: Missing parents: List()
19/07/31 12:00:01 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[285] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:00:01 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 14.8 KB, free 910.4 MB)
19/07/31 12:00:01 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 8.6 KB, free 910.4 MB)
19/07/31 12:00:01 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 127.0.0.1:59789 (size: 8.6 KB, free: 912.1 MB)
19/07/31 12:00:01 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1006
19/07/31 12:00:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[285] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:00:01 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks
19/07/31 12:00:01 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:00:01 INFO Executor: Running task 0.0 in stage 72.0 (TID 81)
19/07/31 12:00:01 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:00:01 INFO Executor: Finished task 0.0 in stage 72.0 (TID 81). 1584 bytes result sent to driver
19/07/31 12:00:01 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 81) in 11 ms on localhost (executor driver) (1/1)
19/07/31 12:00:01 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
19/07/31 12:00:01 INFO DAGScheduler: ResultStage 72 (csv at NativeMethodAccessorImpl.java:0) finished in 0.012 s
19/07/31 12:00:01 INFO DAGScheduler: Job 54 finished: csv at NativeMethodAccessorImpl.java:0, took 0.021571 s
19/07/31 12:00:01 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:00:01 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:00:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:00:01 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:00:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:00:01 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:00:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:00:01 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 12:00:01 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 12:00:01 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 12:00:01 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:00:01 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:00:01 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 12:00:01 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:00:01 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 282.3 KB, free 910.1 MB)
19/07/31 12:00:01 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 24.0 KB, free 910.1 MB)
19/07/31 12:00:01 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 127.0.0.1:59789 (size: 24.0 KB, free: 912.1 MB)
19/07/31 12:00:01 INFO SparkContext: Created broadcast 99 from sql at <unknown>:0
19/07/31 12:00:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:00:01 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 12:00:01 INFO DAGScheduler: Registering RDD 291 (sql at <unknown>:0)
19/07/31 12:00:01 INFO DAGScheduler: Got job 55 (sql at <unknown>:0) with 1 output partitions
19/07/31 12:00:01 INFO DAGScheduler: Final stage: ResultStage 74 (sql at <unknown>:0)
19/07/31 12:00:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)
19/07/31 12:00:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 73)
19/07/31 12:00:01 INFO DAGScheduler: Submitting ShuffleMapStage 73 (MapPartitionsRDD[291] at sql at <unknown>:0), which has no missing parents
19/07/31 12:00:01 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 26.3 KB, free 910.0 MB)
19/07/31 12:00:01 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 11.9 KB, free 910.0 MB)
19/07/31 12:00:01 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 127.0.0.1:59789 (size: 11.9 KB, free: 912.1 MB)
19/07/31 12:00:01 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1006
19/07/31 12:00:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 73 (MapPartitionsRDD[291] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:00:01 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks
19/07/31 12:00:01 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 82, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:00:01 INFO Executor: Running task 0.0 in stage 73.0 (TID 82)
19/07/31 12:00:01 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:00:01 INFO MemoryStore: Block rdd_288_0 stored as values in memory (estimated size 48.9 KB, free 910.0 MB)
19/07/31 12:00:01 INFO BlockManagerInfo: Added rdd_288_0 in memory on 127.0.0.1:59789 (size: 48.9 KB, free: 912.0 MB)
19/07/31 12:00:01 INFO Executor: Finished task 0.0 in stage 73.0 (TID 82). 2461 bytes result sent to driver
19/07/31 12:00:01 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 82) in 24 ms on localhost (executor driver) (1/1)
19/07/31 12:00:01 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
19/07/31 12:00:01 INFO DAGScheduler: ShuffleMapStage 73 (sql at <unknown>:0) finished in 0.024 s
19/07/31 12:00:01 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:00:01 INFO DAGScheduler: running: Set()
19/07/31 12:00:01 INFO DAGScheduler: waiting: Set(ResultStage 74)
19/07/31 12:00:01 INFO DAGScheduler: failed: Set()
19/07/31 12:00:01 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[294] at sql at <unknown>:0), which has no missing parents
19/07/31 12:00:01 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 7.0 KB, free 910.0 MB)
19/07/31 12:00:01 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.0 MB)
19/07/31 12:00:01 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 127.0.0.1:59789 (size: 3.7 KB, free: 912.0 MB)
19/07/31 12:00:01 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1006
19/07/31 12:00:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[294] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:00:01 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks
19/07/31 12:00:01 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 83, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:00:01 INFO Executor: Running task 0.0 in stage 74.0 (TID 83)
19/07/31 12:00:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:00:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:00:01 INFO Executor: Finished task 0.0 in stage 74.0 (TID 83). 1538 bytes result sent to driver
19/07/31 12:00:01 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 83) in 2 ms on localhost (executor driver) (1/1)
19/07/31 12:00:01 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
19/07/31 12:00:01 INFO DAGScheduler: ResultStage 74 (sql at <unknown>:0) finished in 0.003 s
19/07/31 12:00:01 INFO DAGScheduler: Job 55 finished: sql at <unknown>:0, took 0.036305 s
19/07/31 12:00:01 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 12:00:01 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:00:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:00:01 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:00:01 INFO DAGScheduler: Registering RDD 297 (collect at utils.scala:204)
19/07/31 12:00:01 INFO DAGScheduler: Got job 56 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:00:01 INFO DAGScheduler: Final stage: ResultStage 76 (collect at utils.scala:204)
19/07/31 12:00:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)
19/07/31 12:00:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 75)
19/07/31 12:00:01 INFO DAGScheduler: Submitting ShuffleMapStage 75 (MapPartitionsRDD[297] at collect at utils.scala:204), which has no missing parents
19/07/31 12:00:01 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 26.3 KB, free 909.9 MB)
19/07/31 12:00:01 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 11.8 KB, free 909.9 MB)
19/07/31 12:00:01 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 127.0.0.1:59789 (size: 11.8 KB, free: 912.0 MB)
19/07/31 12:00:01 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1006
19/07/31 12:00:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 75 (MapPartitionsRDD[297] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:00:01 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks
19/07/31 12:00:01 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 84, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:00:01 INFO Executor: Running task 0.0 in stage 75.0 (TID 84)
19/07/31 12:00:01 INFO BlockManager: Found block rdd_288_0 locally
19/07/31 12:00:01 INFO Executor: Finished task 0.0 in stage 75.0 (TID 84). 1780 bytes result sent to driver
19/07/31 12:00:01 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 84) in 6 ms on localhost (executor driver) (1/1)
19/07/31 12:00:01 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
19/07/31 12:00:01 INFO DAGScheduler: ShuffleMapStage 75 (collect at utils.scala:204) finished in 0.006 s
19/07/31 12:00:01 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:00:01 INFO DAGScheduler: running: Set()
19/07/31 12:00:01 INFO DAGScheduler: waiting: Set(ResultStage 76)
19/07/31 12:00:01 INFO DAGScheduler: failed: Set()
19/07/31 12:00:01 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[300] at collect at utils.scala:204), which has no missing parents
19/07/31 12:00:01 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 7.0 KB, free 909.9 MB)
19/07/31 12:00:01 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 3.7 KB, free 909.9 MB)
19/07/31 12:00:01 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 127.0.0.1:59789 (size: 3.7 KB, free: 912.0 MB)
19/07/31 12:00:01 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1006
19/07/31 12:00:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[300] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:00:01 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks
19/07/31 12:00:01 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 85, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:00:01 INFO Executor: Running task 0.0 in stage 76.0 (TID 85)
19/07/31 12:00:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:00:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:00:01 INFO Executor: Finished task 0.0 in stage 76.0 (TID 85). 1581 bytes result sent to driver
19/07/31 12:00:01 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 85) in 3 ms on localhost (executor driver) (1/1)
19/07/31 12:00:01 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
19/07/31 12:00:01 INFO DAGScheduler: ResultStage 76 (collect at utils.scala:204) finished in 0.003 s
19/07/31 12:00:01 INFO DAGScheduler: Job 56 finished: collect at utils.scala:204, took 0.017175 s
19/07/31 12:00:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz30`
WHERE (0 = 1)
19/07/31 12:00:01 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:00:01 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:00:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:00:01 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:00:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:00:01 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:00:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:00:01 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:00:01 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:00:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:00:01 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:00:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:00:01 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:00:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:01:15 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:01:15 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:01:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:01:15 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:01:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:01:15 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:01:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:01:15 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 12:01:15 INFO DAGScheduler: Got job 57 (collect at utils.scala:44) with 2 output partitions
19/07/31 12:01:15 INFO DAGScheduler: Final stage: ResultStage 77 (collect at utils.scala:44)
19/07/31 12:01:15 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:01:15 INFO DAGScheduler: Missing parents: List()
19/07/31 12:01:15 INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[305] at map at utils.scala:41), which has no missing parents
19/07/31 12:01:15 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 6.4 KB, free 909.9 MB)
19/07/31 12:01:15 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 3.6 KB, free 909.9 MB)
19/07/31 12:01:15 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 127.0.0.1:59789 (size: 3.6 KB, free: 912.0 MB)
19/07/31 12:01:15 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1006
19/07/31 12:01:15 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 77 (MapPartitionsRDD[305] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0, 1))
19/07/31 12:01:15 INFO TaskSchedulerImpl: Adding task set 77.0 with 2 tasks
19/07/31 12:01:15 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 12:01:15 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 87, localhost, executor driver, partition 1, PROCESS_LOCAL, 5011 bytes)
19/07/31 12:01:15 INFO Executor: Running task 0.0 in stage 77.0 (TID 86)
19/07/31 12:01:15 INFO Executor: Running task 1.0 in stage 77.0 (TID 87)
19/07/31 12:01:15 INFO Executor: Finished task 1.0 in stage 77.0 (TID 87). 932 bytes result sent to driver
19/07/31 12:01:15 INFO Executor: Finished task 0.0 in stage 77.0 (TID 86). 1007 bytes result sent to driver
19/07/31 12:01:15 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 87) in 3 ms on localhost (executor driver) (1/2)
19/07/31 12:01:15 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 86) in 3 ms on localhost (executor driver) (2/2)
19/07/31 12:01:15 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
19/07/31 12:01:15 INFO DAGScheduler: ResultStage 77 (collect at utils.scala:44) finished in 0.003 s
19/07/31 12:01:15 INFO DAGScheduler: Job 57 finished: collect at utils.scala:44, took 0.010092 s
19/07/31 12:01:15 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 12:01:15 INFO MapPartitionsRDD: Removing RDD 288 from persistence list
19/07/31 12:01:15 INFO BlockManager: Removing RDD 288
19/07/31 12:01:15 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:01:15 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#4336)) > 0)
19/07/31 12:01:15 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:01:15 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:01:15 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 281.2 KB, free 909.7 MB)
19/07/31 12:01:15 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 23.8 KB, free 909.6 MB)
19/07/31 12:01:15 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 127.0.0.1:59789 (size: 23.8 KB, free: 912.0 MB)
19/07/31 12:01:15 INFO SparkContext: Created broadcast 105 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:01:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:01:15 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:01:15 INFO DAGScheduler: Got job 58 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:01:15 INFO DAGScheduler: Final stage: ResultStage 78 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:01:15 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:01:15 INFO DAGScheduler: Missing parents: List()
19/07/31 12:01:15 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[308] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:01:15 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 8.2 KB, free 909.6 MB)
19/07/31 12:01:15 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 4.3 KB, free 909.6 MB)
19/07/31 12:01:15 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 127.0.0.1:59789 (size: 4.3 KB, free: 912.0 MB)
19/07/31 12:01:15 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1006
19/07/31 12:01:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[308] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:01:15 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks
19/07/31 12:01:15 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 88, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:01:15 INFO Executor: Running task 0.0 in stage 78.0 (TID 88)
19/07/31 12:01:15 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:01:15 INFO Executor: Finished task 0.0 in stage 78.0 (TID 88). 1394 bytes result sent to driver
19/07/31 12:01:15 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 88) in 6 ms on localhost (executor driver) (1/1)
19/07/31 12:01:15 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
19/07/31 12:01:15 INFO DAGScheduler: ResultStage 78 (csv at NativeMethodAccessorImpl.java:0) finished in 0.007 s
19/07/31 12:01:16 INFO DAGScheduler: Job 58 finished: csv at NativeMethodAccessorImpl.java:0, took 0.014671 s
19/07/31 12:01:16 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:01:16 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:01:16 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:01:16 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:01:16 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 281.2 KB, free 909.4 MB)
19/07/31 12:01:16 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 23.8 KB, free 909.3 MB)
19/07/31 12:01:16 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 127.0.0.1:59789 (size: 23.8 KB, free: 912.0 MB)
19/07/31 12:01:16 INFO SparkContext: Created broadcast 107 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:01:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:01:16 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:01:16 INFO DAGScheduler: Got job 59 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:01:16 INFO DAGScheduler: Final stage: ResultStage 79 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:01:16 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:01:16 INFO DAGScheduler: Missing parents: List()
19/07/31 12:01:16 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[313] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:01:16 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 14.8 KB, free 909.3 MB)
19/07/31 12:01:16 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 8.6 KB, free 909.3 MB)
19/07/31 12:01:16 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 127.0.0.1:59789 (size: 8.6 KB, free: 912.0 MB)
19/07/31 12:01:16 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1006
19/07/31 12:01:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[313] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:01:16 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks
19/07/31 12:01:16 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 89, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:01:16 INFO Executor: Running task 0.0 in stage 79.0 (TID 89)
19/07/31 12:01:16 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:01:16 INFO Executor: Finished task 0.0 in stage 79.0 (TID 89). 1584 bytes result sent to driver
19/07/31 12:01:16 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 89) in 13 ms on localhost (executor driver) (1/1)
19/07/31 12:01:16 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
19/07/31 12:01:16 INFO DAGScheduler: ResultStage 79 (csv at NativeMethodAccessorImpl.java:0) finished in 0.014 s
19/07/31 12:01:16 INFO DAGScheduler: Job 59 finished: csv at NativeMethodAccessorImpl.java:0, took 0.022594 s
19/07/31 12:01:16 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:01:16 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:01:16 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:01:16 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:01:16 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:01:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:01:16 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:01:16 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 12:01:16 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 12:01:16 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 12:01:16 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:01:16 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:01:16 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 12:01:16 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:01:16 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 282.3 KB, free 909.0 MB)
19/07/31 12:01:16 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 24.0 KB, free 909.0 MB)
19/07/31 12:01:16 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 127.0.0.1:59789 (size: 24.0 KB, free: 912.0 MB)
19/07/31 12:01:16 INFO SparkContext: Created broadcast 109 from sql at <unknown>:0
19/07/31 12:01:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:01:16 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 12:01:16 INFO DAGScheduler: Registering RDD 319 (sql at <unknown>:0)
19/07/31 12:01:16 INFO DAGScheduler: Got job 60 (sql at <unknown>:0) with 1 output partitions
19/07/31 12:01:16 INFO DAGScheduler: Final stage: ResultStage 81 (sql at <unknown>:0)
19/07/31 12:01:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 80)
19/07/31 12:01:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 80)
19/07/31 12:01:16 INFO DAGScheduler: Submitting ShuffleMapStage 80 (MapPartitionsRDD[319] at sql at <unknown>:0), which has no missing parents
19/07/31 12:01:16 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 26.3 KB, free 909.0 MB)
19/07/31 12:01:16 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 11.8 KB, free 909.0 MB)
19/07/31 12:01:16 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 127.0.0.1:59789 (size: 11.8 KB, free: 911.9 MB)
19/07/31 12:01:16 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1006
19/07/31 12:01:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 80 (MapPartitionsRDD[319] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:01:16 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks
19/07/31 12:01:16 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 90, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:01:16 INFO Executor: Running task 0.0 in stage 80.0 (TID 90)
19/07/31 12:01:16 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:01:16 INFO MemoryStore: Block rdd_316_0 stored as values in memory (estimated size 48.9 KB, free 908.9 MB)
19/07/31 12:01:16 INFO BlockManagerInfo: Added rdd_316_0 in memory on 127.0.0.1:59789 (size: 48.9 KB, free: 911.9 MB)
19/07/31 12:01:16 INFO Executor: Finished task 0.0 in stage 80.0 (TID 90). 2461 bytes result sent to driver
19/07/31 12:01:16 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 90) in 22 ms on localhost (executor driver) (1/1)
19/07/31 12:01:16 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
19/07/31 12:01:16 INFO DAGScheduler: ShuffleMapStage 80 (sql at <unknown>:0) finished in 0.022 s
19/07/31 12:01:16 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:01:16 INFO DAGScheduler: running: Set()
19/07/31 12:01:16 INFO DAGScheduler: waiting: Set(ResultStage 81)
19/07/31 12:01:16 INFO DAGScheduler: failed: Set()
19/07/31 12:01:16 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[322] at sql at <unknown>:0), which has no missing parents
19/07/31 12:01:16 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 7.0 KB, free 908.9 MB)
19/07/31 12:01:16 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 3.7 KB, free 908.9 MB)
19/07/31 12:01:16 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 127.0.0.1:59789 (size: 3.7 KB, free: 911.9 MB)
19/07/31 12:01:16 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1006
19/07/31 12:01:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[322] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:01:16 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks
19/07/31 12:01:16 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 91, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:01:16 INFO Executor: Running task 0.0 in stage 81.0 (TID 91)
19/07/31 12:01:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:01:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:01:16 INFO Executor: Finished task 0.0 in stage 81.0 (TID 91). 1581 bytes result sent to driver
19/07/31 12:01:16 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 91) in 2 ms on localhost (executor driver) (1/1)
19/07/31 12:01:16 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
19/07/31 12:01:16 INFO DAGScheduler: ResultStage 81 (sql at <unknown>:0) finished in 0.003 s
19/07/31 12:01:16 INFO DAGScheduler: Job 60 finished: sql at <unknown>:0, took 0.033595 s
19/07/31 12:01:16 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 12:01:16 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:01:16 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:01:16 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:01:16 INFO DAGScheduler: Registering RDD 325 (collect at utils.scala:204)
19/07/31 12:01:16 INFO DAGScheduler: Got job 61 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:01:16 INFO DAGScheduler: Final stage: ResultStage 83 (collect at utils.scala:204)
19/07/31 12:01:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 82)
19/07/31 12:01:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 82)
19/07/31 12:01:16 INFO DAGScheduler: Submitting ShuffleMapStage 82 (MapPartitionsRDD[325] at collect at utils.scala:204), which has no missing parents
19/07/31 12:01:16 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 26.3 KB, free 908.9 MB)
19/07/31 12:01:16 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 11.9 KB, free 908.9 MB)
19/07/31 12:01:16 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 127.0.0.1:59789 (size: 11.9 KB, free: 911.9 MB)
19/07/31 12:01:16 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1006
19/07/31 12:01:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 82 (MapPartitionsRDD[325] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:01:16 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks
19/07/31 12:01:16 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:01:16 INFO Executor: Running task 0.0 in stage 82.0 (TID 92)
19/07/31 12:01:16 INFO BlockManager: Found block rdd_316_0 locally
19/07/31 12:01:16 INFO Executor: Finished task 0.0 in stage 82.0 (TID 92). 1780 bytes result sent to driver
19/07/31 12:01:16 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 92) in 5 ms on localhost (executor driver) (1/1)
19/07/31 12:01:16 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
19/07/31 12:01:16 INFO DAGScheduler: ShuffleMapStage 82 (collect at utils.scala:204) finished in 0.006 s
19/07/31 12:01:16 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:01:16 INFO DAGScheduler: running: Set()
19/07/31 12:01:16 INFO DAGScheduler: waiting: Set(ResultStage 83)
19/07/31 12:01:16 INFO DAGScheduler: failed: Set()
19/07/31 12:01:16 INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[328] at collect at utils.scala:204), which has no missing parents
19/07/31 12:01:16 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 7.0 KB, free 908.9 MB)
19/07/31 12:01:16 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 3.7 KB, free 908.9 MB)
19/07/31 12:01:16 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 127.0.0.1:59789 (size: 3.7 KB, free: 911.9 MB)
19/07/31 12:01:16 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1006
19/07/31 12:01:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 83 (MapPartitionsRDD[328] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:01:16 INFO TaskSchedulerImpl: Adding task set 83.0 with 1 tasks
19/07/31 12:01:16 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 93, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:01:16 INFO Executor: Running task 0.0 in stage 83.0 (TID 93)
19/07/31 12:01:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:01:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:01:16 INFO Executor: Finished task 0.0 in stage 83.0 (TID 93). 1581 bytes result sent to driver
19/07/31 12:01:16 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 93) in 5 ms on localhost (executor driver) (1/1)
19/07/31 12:01:16 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
19/07/31 12:01:16 INFO DAGScheduler: ResultStage 83 (collect at utils.scala:204) finished in 0.005 s
19/07/31 12:01:16 INFO DAGScheduler: Job 61 finished: collect at utils.scala:204, took 0.027904 s
19/07/31 12:01:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz31`
WHERE (0 = 1)
19/07/31 12:01:16 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:01:16 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:01:16 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:01:16 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:01:16 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:01:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:01:16 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:01:27 INFO SparkContext: Invoking stop() from shutdown hook
19/07/31 12:01:27 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
19/07/31 12:01:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/07/31 12:01:28 INFO MemoryStore: MemoryStore cleared
19/07/31 12:01:28 INFO BlockManager: BlockManager stopped
19/07/31 12:01:28 INFO BlockManagerMaster: BlockManagerMaster stopped
19/07/31 12:01:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/07/31 12:01:28 INFO SparkContext: Successfully stopped SparkContext
19/07/31 12:01:28 INFO ShutdownHookManager: Shutdown hook called
19/07/31 12:01:28 INFO ShutdownHookManager: Deleting directory /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-33a74b48-ed34-45a6-96c9-66de13d64d36
19/07/31 12:02:02 INFO SparkContext: Running Spark version 2.2.0
19/07/31 12:02:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/07/31 12:02:02 INFO SparkContext: Submitted application: sparklyr
19/07/31 12:02:02 INFO SecurityManager: Changing view acls to: 6jncnk4f
19/07/31 12:02:02 INFO SecurityManager: Changing modify acls to: 6jncnk4f
19/07/31 12:02:02 INFO SecurityManager: Changing view acls groups to: 
19/07/31 12:02:02 INFO SecurityManager: Changing modify acls groups to: 
19/07/31 12:02:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(6jncnk4f); groups with view permissions: Set(); users  with modify permissions: Set(6jncnk4f); groups with modify permissions: Set()
19/07/31 12:02:02 INFO Utils: Successfully started service 'sparkDriver' on port 61443.
19/07/31 12:02:02 INFO SparkEnv: Registering MapOutputTracker
19/07/31 12:02:02 INFO SparkEnv: Registering BlockManagerMaster
19/07/31 12:02:02 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/07/31 12:02:02 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/07/31 12:02:02 INFO DiskBlockManager: Created local directory at /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/blockmgr-226c8b1d-c9c0-455f-8856-b667736fde5f
19/07/31 12:02:02 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/07/31 12:02:02 INFO SparkEnv: Registering OutputCommitCoordinator
19/07/31 12:02:03 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/07/31 12:02:03 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
19/07/31 12:02:03 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:61443/jars/sparklyr-2.0-2.11.jar with timestamp 1564588923192
19/07/31 12:02:03 INFO Executor: Starting executor ID driver on host localhost
19/07/31 12:02:03 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61444.
19/07/31 12:02:03 INFO NettyBlockTransferService: Server created on 127.0.0.1:61444
19/07/31 12:02:03 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/07/31 12:02:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 61444, None)
19/07/31 12:02:03 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:61444 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 61444, None)
19/07/31 12:02:03 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 61444, None)
19/07/31 12:02:03 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 61444, None)
19/07/31 12:02:03 INFO SharedState: loading hive config file: file:/Users/6jncnk4f/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/07/31 12:02:03 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse').
19/07/31 12:02:03 INFO SharedState: Warehouse path is 'file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse'.
19/07/31 12:02:04 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/07/31 12:02:04 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/07/31 12:02:04 INFO ObjectStore: ObjectStore, initialize called
19/07/31 12:02:04 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/07/31 12:02:04 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/07/31 12:02:05 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/07/31 12:02:06 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:02:06 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:02:07 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:02:07 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:02:07 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/07/31 12:02:07 INFO ObjectStore: Initialized ObjectStore
19/07/31 12:02:07 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/07/31 12:02:07 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/07/31 12:02:07 INFO HiveMetaStore: Added admin role in metastore
19/07/31 12:02:07 INFO HiveMetaStore: Added public role in metastore
19/07/31 12:02:07 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/07/31 12:02:07 INFO HiveMetaStore: 0: get_all_databases
19/07/31 12:02:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_all_databases	
19/07/31 12:02:07 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/07/31 12:02:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/07/31 12:02:07 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:02:07 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/74ff0e7d-397b-4104-90c4-f239d99ac08c_resources
19/07/31 12:02:07 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/74ff0e7d-397b-4104-90c4-f239d99ac08c
19/07/31 12:02:07 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/74ff0e7d-397b-4104-90c4-f239d99ac08c
19/07/31 12:02:07 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/74ff0e7d-397b-4104-90c4-f239d99ac08c/_tmp_space.db
19/07/31 12:02:07 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 12:02:07 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:02:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:02:07 INFO HiveMetaStore: 0: get_database: global_temp
19/07/31 12:02:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/07/31 12:02:07 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/07/31 12:02:08 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/08bf8e4c-05c8-4cff-9c60-e0373a533236_resources
19/07/31 12:02:08 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/08bf8e4c-05c8-4cff-9c60-e0373a533236
19/07/31 12:02:08 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/08bf8e4c-05c8-4cff-9c60-e0373a533236
19/07/31 12:02:08 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/08bf8e4c-05c8-4cff-9c60-e0373a533236/_tmp_space.db
19/07/31 12:02:08 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 12:02:08 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/07/31 12:02:08 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:02:09 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:02:09 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:02:09 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:02:09 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:02:09 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:02:09 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:16:37 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:16:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:16:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:16:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:16:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:16:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:16:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:16:38 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 12:16:38 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/07/31 12:16:38 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/07/31 12:16:38 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:16:38 INFO DAGScheduler: Missing parents: List()
19/07/31 12:16:38 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/07/31 12:16:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/07/31 12:16:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/07/31 12:16:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:61444 (size: 3.4 KB, free: 912.3 MB)
19/07/31 12:16:38 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/07/31 12:16:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 12:16:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/07/31 12:16:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/07/31 12:16:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/07/31 12:16:39 INFO Executor: Fetching spark://127.0.0.1:61443/jars/sparklyr-2.0-2.11.jar with timestamp 1564588923192
19/07/31 12:16:39 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:61443 after 16 ms (0 ms spent in bootstraps)
19/07/31 12:16:39 INFO Utils: Fetching spark://127.0.0.1:61443/jars/sparklyr-2.0-2.11.jar to /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-b8ab69f7-87c0-41d4-87bc-4692ed863ea4/userFiles-fda68367-c771-4d3d-aea6-bd850ff88ed5/fetchFileTemp5248814202331223548.tmp
19/07/31 12:16:39 INFO Executor: Adding file:/private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-b8ab69f7-87c0-41d4-87bc-4692ed863ea4/userFiles-fda68367-c771-4d3d-aea6-bd850ff88ed5/sparklyr-2.0-2.11.jar to class loader
19/07/31 12:16:39 INFO CodeGenerator: Code generated in 244.834305 ms
19/07/31 12:16:39 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
19/07/31 12:16:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 733 ms on localhost (executor driver) (1/1)
19/07/31 12:16:39 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/07/31 12:16:39 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.854 s
19/07/31 12:16:39 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 1.121089 s
19/07/31 12:16:40 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:16:40 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#17)) > 0)
19/07/31 12:16:40 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:16:40 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:16:40 INFO CodeGenerator: Code generated in 12.906571 ms
19/07/31 12:16:40 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 281.2 KB, free 912.0 MB)
19/07/31 12:16:40 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.8 KB, free 912.0 MB)
19/07/31 12:16:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:61444 (size: 23.8 KB, free: 912.3 MB)
19/07/31 12:16:40 INFO SparkContext: Created broadcast 1 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:16:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:16:40 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:16:40 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:16:40 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:16:40 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:16:40 INFO DAGScheduler: Missing parents: List()
19/07/31 12:16:40 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:16:40 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 912.0 MB)
19/07/31 12:16:40 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 912.0 MB)
19/07/31 12:16:40 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:61444 in memory (size: 3.4 KB, free: 912.3 MB)
19/07/31 12:16:40 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:61444 (size: 4.3 KB, free: 912.3 MB)
19/07/31 12:16:40 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/07/31 12:16:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:16:40 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/07/31 12:16:40 INFO ContextCleaner: Cleaned accumulator 0
19/07/31 12:16:40 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:16:40 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/07/31 12:16:40 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:16:40 INFO CodeGenerator: Code generated in 9.150434 ms
19/07/31 12:16:40 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1394 bytes result sent to driver
19/07/31 12:16:40 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 82 ms on localhost (executor driver) (1/1)
19/07/31 12:16:40 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/07/31 12:16:40 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0.083 s
19/07/31 12:16:40 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0.099210 s
19/07/31 12:16:40 INFO CodeGenerator: Code generated in 6.845441 ms
19/07/31 12:16:41 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:16:41 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:16:41 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:16:41 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:16:41 INFO CodeGenerator: Code generated in 6.84472 ms
19/07/31 12:16:41 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 281.2 KB, free 911.7 MB)
19/07/31 12:16:41 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.7 MB)
19/07/31 12:16:41 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:61444 (size: 23.8 KB, free: 912.2 MB)
19/07/31 12:16:41 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:16:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:16:41 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:16:41 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:16:41 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:16:41 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:16:41 INFO DAGScheduler: Missing parents: List()
19/07/31 12:16:41 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:16:41 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.8 KB, free 911.7 MB)
19/07/31 12:16:41 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.7 MB)
19/07/31 12:16:41 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:61444 (size: 8.6 KB, free: 912.2 MB)
19/07/31 12:16:41 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/07/31 12:16:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:16:41 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/07/31 12:16:41 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:16:41 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/07/31 12:16:41 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:16:41 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1627 bytes result sent to driver
19/07/31 12:16:41 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 77 ms on localhost (executor driver) (1/1)
19/07/31 12:16:41 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/07/31 12:16:41 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.077 s
19/07/31 12:16:41 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.085773 s
19/07/31 12:16:41 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:16:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:16:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:16:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:16:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:16:41 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:16:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:16:41 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 12:16:41 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 12:16:41 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 12:16:41 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:16:41 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:16:41 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 12:16:41 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:16:41 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 282.3 KB, free 911.4 MB)
19/07/31 12:16:41 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.4 MB)
19/07/31 12:16:41 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:61444 (size: 24.0 KB, free: 912.2 MB)
19/07/31 12:16:41 INFO SparkContext: Created broadcast 5 from sql at NativeMethodAccessorImpl.java:0
19/07/31 12:16:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:16:41 INFO CodeGenerator: Code generated in 9.503936 ms
19/07/31 12:16:41 INFO CodeGenerator: Code generated in 8.591948 ms
19/07/31 12:16:41 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 12:16:41 INFO DAGScheduler: Registering RDD 18 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 12:16:41 INFO DAGScheduler: Got job 3 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:16:41 INFO DAGScheduler: Final stage: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 12:16:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/07/31 12:16:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/07/31 12:16:41 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:16:41 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 26.3 KB, free 911.3 MB)
19/07/31 12:16:41 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.8 KB, free 911.3 MB)
19/07/31 12:16:41 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:61444 (size: 11.8 KB, free: 912.2 MB)
19/07/31 12:16:41 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/07/31 12:16:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:16:41 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/07/31 12:16:41 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:16:41 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/07/31 12:16:41 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:16:41 INFO CodeGenerator: Code generated in 13.947688 ms
19/07/31 12:16:41 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 48.9 KB, free 911.3 MB)
19/07/31 12:16:41 INFO BlockManagerInfo: Added rdd_15_0 in memory on 127.0.0.1:61444 (size: 48.9 KB, free: 912.2 MB)
19/07/31 12:16:41 INFO CodeGenerator: Code generated in 4.094893 ms
19/07/31 12:16:41 INFO CodeGenerator: Code generated in 16.328948 ms
19/07/31 12:16:41 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2504 bytes result sent to driver
19/07/31 12:16:41 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 239 ms on localhost (executor driver) (1/1)
19/07/31 12:16:41 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/07/31 12:16:41 INFO DAGScheduler: ShuffleMapStage 3 (sql at NativeMethodAccessorImpl.java:0) finished in 0.240 s
19/07/31 12:16:41 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:16:41 INFO DAGScheduler: running: Set()
19/07/31 12:16:41 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/07/31 12:16:41 INFO DAGScheduler: failed: Set()
19/07/31 12:16:41 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:16:41 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 911.3 MB)
19/07/31 12:16:41 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.3 MB)
19/07/31 12:16:41 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:61444 (size: 3.7 KB, free: 912.2 MB)
19/07/31 12:16:41 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/07/31 12:16:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:16:41 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/07/31 12:16:41 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:16:41 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/07/31 12:16:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:16:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
19/07/31 12:16:41 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1581 bytes result sent to driver
19/07/31 12:16:41 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 36 ms on localhost (executor driver) (1/1)
19/07/31 12:16:41 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/07/31 12:16:41 INFO DAGScheduler: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0) finished in 0.038 s
19/07/31 12:16:41 INFO DAGScheduler: Job 3 finished: sql at NativeMethodAccessorImpl.java:0, took 0.327250 s
19/07/31 12:16:41 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 12:16:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:16:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:16:41 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:16:41 INFO DAGScheduler: Registering RDD 24 (collect at utils.scala:204)
19/07/31 12:16:41 INFO DAGScheduler: Got job 4 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:16:41 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
19/07/31 12:16:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/07/31 12:16:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/07/31 12:16:41 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204), which has no missing parents
19/07/31 12:16:41 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 26.3 KB, free 911.2 MB)
19/07/31 12:16:41 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.9 KB, free 911.2 MB)
19/07/31 12:16:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:61444 (size: 11.9 KB, free: 912.1 MB)
19/07/31 12:16:41 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/07/31 12:16:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:16:41 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/07/31 12:16:41 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:16:41 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/07/31 12:16:41 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:16:42 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1823 bytes result sent to driver
19/07/31 12:16:42 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 9 ms on localhost (executor driver) (1/1)
19/07/31 12:16:42 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/07/31 12:16:42 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:204) finished in 0.011 s
19/07/31 12:16:42 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:16:42 INFO DAGScheduler: running: Set()
19/07/31 12:16:42 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/07/31 12:16:42 INFO DAGScheduler: failed: Set()
19/07/31 12:16:42 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204), which has no missing parents
19/07/31 12:16:42 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 911.2 MB)
19/07/31 12:16:42 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.2 MB)
19/07/31 12:16:42 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:61444 (size: 3.7 KB, free: 912.1 MB)
19/07/31 12:16:42 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/07/31 12:16:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:16:42 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/07/31 12:16:42 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:16:42 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/07/31 12:16:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:16:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:16:42 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1581 bytes result sent to driver
19/07/31 12:16:42 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 4 ms on localhost (executor driver) (1/1)
19/07/31 12:16:42 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/07/31 12:16:42 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.005 s
19/07/31 12:16:42 INFO DAGScheduler: Job 4 finished: collect at utils.scala:204, took 0.031858 s
19/07/31 12:16:42 INFO CodeGenerator: Code generated in 5.564845 ms
19/07/31 12:16:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz1`
WHERE (0 = 1)
19/07/31 12:16:42 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:16:42 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:16:42 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:16:42 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:16:42 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:16:42 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:16:42 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:16:42 INFO CodeGenerator: Code generated in 19.257798 ms
19/07/31 12:16:44 INFO SparkSqlParser: Parsing command: SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 12:16:44 INFO SparkSqlParser: Parsing command: SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 12:16:44 INFO CodeGenerator: Code generated in 9.835723 ms
19/07/31 12:16:44 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:16:44 INFO DAGScheduler: Got job 5 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:16:44 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:204)
19/07/31 12:16:44 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:16:44 INFO DAGScheduler: Missing parents: List()
19/07/31 12:16:44 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[30] at collect at utils.scala:204), which has no missing parents
19/07/31 12:16:44 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 25.8 KB, free 911.2 MB)
19/07/31 12:16:44 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 11.3 KB, free 911.2 MB)
19/07/31 12:16:44 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:61444 (size: 11.3 KB, free: 912.1 MB)
19/07/31 12:16:44 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/07/31 12:16:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[30] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:16:44 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/07/31 12:16:44 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:16:44 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
19/07/31 12:16:44 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:16:44 INFO CodeGenerator: Code generated in 14.75297 ms
19/07/31 12:16:44 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 37152 bytes result sent to driver
19/07/31 12:16:44 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 39 ms on localhost (executor driver) (1/1)
19/07/31 12:16:44 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/07/31 12:16:44 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:204) finished in 0.040 s
19/07/31 12:16:44 INFO DAGScheduler: Job 5 finished: collect at utils.scala:204, took 0.049727 s
19/07/31 12:16:44 INFO CodeGenerator: Code generated in 7.065615 ms
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 83
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 51
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 81
19/07/31 12:32:18 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:61444 in memory (size: 23.8 KB, free: 912.2 MB)
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 175
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 124
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 126
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 117
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 121
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 123
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 120
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 122
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 115
19/07/31 12:32:18 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:61444 in memory (size: 3.7 KB, free: 912.2 MB)
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 114
19/07/31 12:32:18 INFO ContextCleaner: Cleaned shuffle 0
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 119
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 125
19/07/31 12:32:18 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:61444 in memory (size: 4.3 KB, free: 912.2 MB)
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 116
19/07/31 12:32:18 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:61444 in memory (size: 11.8 KB, free: 912.2 MB)
19/07/31 12:32:18 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:61444 in memory (size: 11.3 KB, free: 912.2 MB)
19/07/31 12:32:18 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:61444 in memory (size: 11.9 KB, free: 912.2 MB)
19/07/31 12:32:18 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:61444 in memory (size: 3.7 KB, free: 912.2 MB)
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 118
19/07/31 12:32:18 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:61444 in memory (size: 8.6 KB, free: 912.2 MB)
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 82
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 52
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 80
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 49
19/07/31 12:32:18 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:61444 in memory (size: 23.8 KB, free: 912.2 MB)
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 79
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 54
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 50
19/07/31 12:32:18 INFO ContextCleaner: Cleaned accumulator 53
19/07/31 12:34:59 INFO SparkContext: Invoking stop() from shutdown hook
19/07/31 12:34:59 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
19/07/31 12:34:59 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/07/31 12:34:59 INFO MemoryStore: MemoryStore cleared
19/07/31 12:34:59 INFO BlockManager: BlockManager stopped
19/07/31 12:34:59 INFO BlockManagerMaster: BlockManagerMaster stopped
19/07/31 12:34:59 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/07/31 12:34:59 INFO SparkContext: Successfully stopped SparkContext
19/07/31 12:34:59 INFO ShutdownHookManager: Shutdown hook called
19/07/31 12:34:59 INFO ShutdownHookManager: Deleting directory /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-b8ab69f7-87c0-41d4-87bc-4692ed863ea4
19/07/31 12:46:33 INFO SparkContext: Running Spark version 2.2.0
19/07/31 12:46:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/07/31 12:46:34 INFO SparkContext: Submitted application: sparklyr
19/07/31 12:46:34 INFO SecurityManager: Changing view acls to: 6jncnk4f
19/07/31 12:46:34 INFO SecurityManager: Changing modify acls to: 6jncnk4f
19/07/31 12:46:34 INFO SecurityManager: Changing view acls groups to: 
19/07/31 12:46:34 INFO SecurityManager: Changing modify acls groups to: 
19/07/31 12:46:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(6jncnk4f); groups with view permissions: Set(); users  with modify permissions: Set(6jncnk4f); groups with modify permissions: Set()
19/07/31 12:46:34 INFO Utils: Successfully started service 'sparkDriver' on port 62225.
19/07/31 12:46:34 INFO SparkEnv: Registering MapOutputTracker
19/07/31 12:46:34 INFO SparkEnv: Registering BlockManagerMaster
19/07/31 12:46:34 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/07/31 12:46:34 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/07/31 12:46:34 INFO DiskBlockManager: Created local directory at /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/blockmgr-c75ee9ab-e90c-4221-aa36-33372ba1480f
19/07/31 12:46:34 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/07/31 12:46:34 INFO SparkEnv: Registering OutputCommitCoordinator
19/07/31 12:46:34 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/07/31 12:46:34 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
19/07/31 12:46:34 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:62225/jars/sparklyr-2.0-2.11.jar with timestamp 1564591594907
19/07/31 12:46:35 INFO Executor: Starting executor ID driver on host localhost
19/07/31 12:46:35 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62226.
19/07/31 12:46:35 INFO NettyBlockTransferService: Server created on 127.0.0.1:62226
19/07/31 12:46:35 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/07/31 12:46:35 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 62226, None)
19/07/31 12:46:35 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:62226 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 62226, None)
19/07/31 12:46:35 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 62226, None)
19/07/31 12:46:35 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 62226, None)
19/07/31 12:46:35 INFO SharedState: loading hive config file: file:/Users/6jncnk4f/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/07/31 12:46:35 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse').
19/07/31 12:46:35 INFO SharedState: Warehouse path is 'file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse'.
19/07/31 12:46:36 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/07/31 12:46:36 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/07/31 12:46:36 INFO ObjectStore: ObjectStore, initialize called
19/07/31 12:46:36 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/07/31 12:46:36 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/07/31 12:46:38 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/07/31 12:46:39 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:46:39 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:46:39 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:46:39 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:46:39 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/07/31 12:46:39 INFO ObjectStore: Initialized ObjectStore
19/07/31 12:46:39 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/07/31 12:46:40 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/07/31 12:46:40 INFO HiveMetaStore: Added admin role in metastore
19/07/31 12:46:40 INFO HiveMetaStore: Added public role in metastore
19/07/31 12:46:40 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/07/31 12:46:40 INFO HiveMetaStore: 0: get_all_databases
19/07/31 12:46:40 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_all_databases	
19/07/31 12:46:40 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/07/31 12:46:40 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/07/31 12:46:40 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:46:40 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/3be410fc-4f27-4c3a-9253-68ed4ffc9857_resources
19/07/31 12:46:40 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/3be410fc-4f27-4c3a-9253-68ed4ffc9857
19/07/31 12:46:40 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/3be410fc-4f27-4c3a-9253-68ed4ffc9857
19/07/31 12:46:40 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/3be410fc-4f27-4c3a-9253-68ed4ffc9857/_tmp_space.db
19/07/31 12:46:40 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 12:46:40 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:46:40 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:46:40 INFO HiveMetaStore: 0: get_database: global_temp
19/07/31 12:46:40 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/07/31 12:46:40 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/07/31 12:46:40 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/63c9b15c-7b34-4176-a75a-e8ba1005aaa8_resources
19/07/31 12:46:40 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/63c9b15c-7b34-4176-a75a-e8ba1005aaa8
19/07/31 12:46:40 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/63c9b15c-7b34-4176-a75a-e8ba1005aaa8
19/07/31 12:46:40 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/63c9b15c-7b34-4176-a75a-e8ba1005aaa8/_tmp_space.db
19/07/31 12:46:40 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 12:46:40 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/07/31 12:46:40 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:46:42 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:46:42 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:46:42 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:46:42 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:46:42 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:46:42 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:46:43 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:46:43 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:46:43 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:46:43 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:46:43 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:46:43 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:46:43 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:46:44 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 12:46:44 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/07/31 12:46:44 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/07/31 12:46:44 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:46:44 INFO DAGScheduler: Missing parents: List()
19/07/31 12:46:44 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/07/31 12:46:44 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/07/31 12:46:44 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/07/31 12:46:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:62226 (size: 3.4 KB, free: 912.3 MB)
19/07/31 12:46:44 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/07/31 12:46:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 12:46:44 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/07/31 12:46:44 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/07/31 12:46:44 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/07/31 12:46:44 INFO Executor: Fetching spark://127.0.0.1:62225/jars/sparklyr-2.0-2.11.jar with timestamp 1564591594907
19/07/31 12:46:44 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:62225 after 18 ms (0 ms spent in bootstraps)
19/07/31 12:46:44 INFO Utils: Fetching spark://127.0.0.1:62225/jars/sparklyr-2.0-2.11.jar to /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-481bfba8-fe75-4033-9e32-7667ff6e4e17/userFiles-e20eb72a-5370-4836-8dea-b93c9ec4ecc9/fetchFileTemp8392170011088602028.tmp
19/07/31 12:46:44 INFO Executor: Adding file:/private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-481bfba8-fe75-4033-9e32-7667ff6e4e17/userFiles-e20eb72a-5370-4836-8dea-b93c9ec4ecc9/sparklyr-2.0-2.11.jar to class loader
19/07/31 12:46:45 INFO CodeGenerator: Code generated in 254.903962 ms
19/07/31 12:46:45 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
19/07/31 12:46:45 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 680 ms on localhost (executor driver) (1/1)
19/07/31 12:46:45 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/07/31 12:46:45 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.707 s
19/07/31 12:46:45 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0.971895 s
19/07/31 12:46:45 INFO ContextCleaner: Cleaned accumulator 0
19/07/31 12:46:45 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:62226 in memory (size: 3.4 KB, free: 912.3 MB)
19/07/31 12:46:46 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:46:46 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#17)) > 0)
19/07/31 12:46:46 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:46:46 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:46:46 INFO CodeGenerator: Code generated in 15.045461 ms
19/07/31 12:46:46 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 281.2 KB, free 912.0 MB)
19/07/31 12:46:46 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.8 KB, free 912.0 MB)
19/07/31 12:46:46 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:62226 (size: 23.8 KB, free: 912.3 MB)
19/07/31 12:46:46 INFO SparkContext: Created broadcast 1 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:46:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:46:46 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:46:46 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:46:46 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:46:46 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:46:46 INFO DAGScheduler: Missing parents: List()
19/07/31 12:46:46 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:46:46 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 912.0 MB)
19/07/31 12:46:46 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 912.0 MB)
19/07/31 12:46:46 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:62226 (size: 4.3 KB, free: 912.3 MB)
19/07/31 12:46:46 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/07/31 12:46:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:46:46 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/07/31 12:46:46 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:46:46 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/07/31 12:46:46 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:46:46 INFO CodeGenerator: Code generated in 8.982977 ms
19/07/31 12:46:46 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1394 bytes result sent to driver
19/07/31 12:46:46 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 79 ms on localhost (executor driver) (1/1)
19/07/31 12:46:46 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/07/31 12:46:46 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0.080 s
19/07/31 12:46:46 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0.235770 s
19/07/31 12:46:46 INFO CodeGenerator: Code generated in 6.081103 ms
19/07/31 12:46:46 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:46:46 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:46:46 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:46:46 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:46:46 INFO CodeGenerator: Code generated in 4.900156 ms
19/07/31 12:46:46 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 281.2 KB, free 911.7 MB)
19/07/31 12:46:46 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.7 MB)
19/07/31 12:46:46 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:62226 (size: 23.8 KB, free: 912.2 MB)
19/07/31 12:46:46 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:46:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:46:46 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:46:46 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:46:46 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:46:46 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:46:46 INFO DAGScheduler: Missing parents: List()
19/07/31 12:46:46 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:46:46 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.8 KB, free 911.7 MB)
19/07/31 12:46:46 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.7 MB)
19/07/31 12:46:46 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:62226 (size: 8.6 KB, free: 912.2 MB)
19/07/31 12:46:46 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/07/31 12:46:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:46:46 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/07/31 12:46:46 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:46:46 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/07/31 12:46:46 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:46:46 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1584 bytes result sent to driver
19/07/31 12:46:46 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 79 ms on localhost (executor driver) (1/1)
19/07/31 12:46:46 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/07/31 12:46:46 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.080 s
19/07/31 12:46:46 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.088316 s
19/07/31 12:46:46 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:46:46 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:46:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:46:46 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:46:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:46:46 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:46:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:46:46 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 12:46:46 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 12:46:46 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 12:46:46 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:46:46 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:46:46 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 12:46:46 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:46:46 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 282.3 KB, free 911.4 MB)
19/07/31 12:46:46 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.4 MB)
19/07/31 12:46:46 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:62226 (size: 24.0 KB, free: 912.2 MB)
19/07/31 12:46:46 INFO SparkContext: Created broadcast 5 from sql at NativeMethodAccessorImpl.java:0
19/07/31 12:46:46 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:46:47 INFO CodeGenerator: Code generated in 7.984022 ms
19/07/31 12:46:47 INFO CodeGenerator: Code generated in 8.810918 ms
19/07/31 12:46:47 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 12:46:47 INFO DAGScheduler: Registering RDD 18 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 12:46:47 INFO DAGScheduler: Got job 3 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:46:47 INFO DAGScheduler: Final stage: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 12:46:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/07/31 12:46:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/07/31 12:46:47 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:46:47 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 26.3 KB, free 911.3 MB)
19/07/31 12:46:47 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.8 KB, free 911.3 MB)
19/07/31 12:46:47 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:62226 (size: 11.8 KB, free: 912.2 MB)
19/07/31 12:46:47 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/07/31 12:46:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:46:47 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/07/31 12:46:47 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:46:47 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/07/31 12:46:47 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:46:47 INFO CodeGenerator: Code generated in 17.967683 ms
19/07/31 12:46:47 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 48.9 KB, free 911.3 MB)
19/07/31 12:46:47 INFO BlockManagerInfo: Added rdd_15_0 in memory on 127.0.0.1:62226 (size: 48.9 KB, free: 912.2 MB)
19/07/31 12:46:47 INFO CodeGenerator: Code generated in 4.730683 ms
19/07/31 12:46:47 INFO CodeGenerator: Code generated in 16.78938 ms
19/07/31 12:46:47 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2504 bytes result sent to driver
19/07/31 12:46:47 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 242 ms on localhost (executor driver) (1/1)
19/07/31 12:46:47 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/07/31 12:46:47 INFO DAGScheduler: ShuffleMapStage 3 (sql at NativeMethodAccessorImpl.java:0) finished in 0.243 s
19/07/31 12:46:47 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:46:47 INFO DAGScheduler: running: Set()
19/07/31 12:46:47 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/07/31 12:46:47 INFO DAGScheduler: failed: Set()
19/07/31 12:46:47 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:46:47 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 911.3 MB)
19/07/31 12:46:47 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.3 MB)
19/07/31 12:46:47 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:62226 (size: 3.7 KB, free: 912.2 MB)
19/07/31 12:46:47 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/07/31 12:46:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:46:47 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/07/31 12:46:47 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:46:47 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/07/31 12:46:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:46:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
19/07/31 12:46:47 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1624 bytes result sent to driver
19/07/31 12:46:47 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 36 ms on localhost (executor driver) (1/1)
19/07/31 12:46:47 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/07/31 12:46:47 INFO DAGScheduler: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0) finished in 0.037 s
19/07/31 12:46:47 INFO DAGScheduler: Job 3 finished: sql at NativeMethodAccessorImpl.java:0, took 0.329905 s
19/07/31 12:46:47 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 12:46:47 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:46:47 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:46:47 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:46:47 INFO DAGScheduler: Registering RDD 24 (collect at utils.scala:204)
19/07/31 12:46:47 INFO DAGScheduler: Got job 4 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:46:47 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
19/07/31 12:46:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/07/31 12:46:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/07/31 12:46:47 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204), which has no missing parents
19/07/31 12:46:47 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 26.3 KB, free 911.2 MB)
19/07/31 12:46:47 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.9 KB, free 911.2 MB)
19/07/31 12:46:47 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:62226 (size: 11.9 KB, free: 912.1 MB)
19/07/31 12:46:47 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/07/31 12:46:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:46:47 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/07/31 12:46:47 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:46:47 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/07/31 12:46:47 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:46:47 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1780 bytes result sent to driver
19/07/31 12:46:47 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 14 ms on localhost (executor driver) (1/1)
19/07/31 12:46:47 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/07/31 12:46:47 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:204) finished in 0.015 s
19/07/31 12:46:47 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:46:47 INFO DAGScheduler: running: Set()
19/07/31 12:46:47 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/07/31 12:46:47 INFO DAGScheduler: failed: Set()
19/07/31 12:46:47 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204), which has no missing parents
19/07/31 12:46:47 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 911.2 MB)
19/07/31 12:46:47 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.2 MB)
19/07/31 12:46:47 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:62226 (size: 3.7 KB, free: 912.1 MB)
19/07/31 12:46:47 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/07/31 12:46:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:46:47 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/07/31 12:46:47 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:46:47 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/07/31 12:46:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:46:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:46:47 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1581 bytes result sent to driver
19/07/31 12:46:47 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 4 ms on localhost (executor driver) (1/1)
19/07/31 12:46:47 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/07/31 12:46:47 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.005 s
19/07/31 12:46:47 INFO DAGScheduler: Job 4 finished: collect at utils.scala:204, took 0.039080 s
19/07/31 12:46:47 INFO CodeGenerator: Code generated in 5.443967 ms
19/07/31 12:46:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz1`
WHERE (0 = 1)
19/07/31 12:46:47 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:46:47 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:46:47 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:46:47 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:46:47 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:46:47 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:46:47 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:46:47 INFO CodeGenerator: Code generated in 7.00289 ms
19/07/31 12:46:47 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:46:47 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:46:47 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:46:47 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:46:47 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:46:47 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:46:47 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:46:47 INFO CodeGenerator: Code generated in 5.782195 ms
19/07/31 12:46:47 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 12:46:47 INFO DAGScheduler: Got job 5 (collect at utils.scala:44) with 1 output partitions
19/07/31 12:46:47 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:44)
19/07/31 12:46:47 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:46:47 INFO DAGScheduler: Missing parents: List()
19/07/31 12:46:47 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[32] at map at utils.scala:41), which has no missing parents
19/07/31 12:46:47 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 6.3 KB, free 911.2 MB)
19/07/31 12:46:47 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.5 KB, free 911.2 MB)
19/07/31 12:46:47 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:62226 (size: 3.5 KB, free: 912.1 MB)
19/07/31 12:46:47 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/07/31 12:46:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 12:46:47 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/07/31 12:46:47 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 12:46:47 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
19/07/31 12:46:47 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1007 bytes result sent to driver
19/07/31 12:46:47 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 5 ms on localhost (executor driver) (1/1)
19/07/31 12:46:47 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/07/31 12:46:47 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:44) finished in 0.005 s
19/07/31 12:46:47 INFO DAGScheduler: Job 5 finished: collect at utils.scala:44, took 0.011261 s
19/07/31 12:46:47 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 12:46:47 INFO MapPartitionsRDD: Removing RDD 15 from persistence list
19/07/31 12:46:47 INFO BlockManager: Removing RDD 15
19/07/31 12:46:48 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:46:48 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#396)) > 0)
19/07/31 12:46:48 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:46:48 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:46:48 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 281.2 KB, free 911.0 MB)
19/07/31 12:46:48 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.0 MB)
19/07/31 12:46:48 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:62226 (size: 23.8 KB, free: 912.2 MB)
19/07/31 12:46:48 INFO SparkContext: Created broadcast 11 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:46:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:46:48 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:46:48 INFO DAGScheduler: Got job 6 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:46:48 INFO DAGScheduler: Final stage: ResultStage 8 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:46:48 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:46:48 INFO DAGScheduler: Missing parents: List()
19/07/31 12:46:48 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[35] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:46:48 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.2 KB, free 911.0 MB)
19/07/31 12:46:48 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.3 KB, free 911.0 MB)
19/07/31 12:46:48 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:62226 (size: 4.3 KB, free: 912.2 MB)
19/07/31 12:46:48 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/07/31 12:46:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[35] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:46:48 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/07/31 12:46:48 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:46:48 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
19/07/31 12:46:48 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:46:48 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1394 bytes result sent to driver
19/07/31 12:46:48 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 6 ms on localhost (executor driver) (1/1)
19/07/31 12:46:48 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/07/31 12:46:48 INFO DAGScheduler: ResultStage 8 (csv at NativeMethodAccessorImpl.java:0) finished in 0.006 s
19/07/31 12:46:48 INFO DAGScheduler: Job 6 finished: csv at NativeMethodAccessorImpl.java:0, took 0.011775 s
19/07/31 12:46:48 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:46:48 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:46:48 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:46:48 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:46:48 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 281.2 KB, free 910.7 MB)
19/07/31 12:46:48 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 23.8 KB, free 910.7 MB)
19/07/31 12:46:48 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:62226 (size: 23.8 KB, free: 912.1 MB)
19/07/31 12:46:48 INFO SparkContext: Created broadcast 13 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:46:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:46:48 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:46:48 INFO DAGScheduler: Got job 7 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:46:48 INFO DAGScheduler: Final stage: ResultStage 9 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:46:48 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:46:48 INFO DAGScheduler: Missing parents: List()
19/07/31 12:46:48 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[40] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:46:48 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 14.8 KB, free 910.6 MB)
19/07/31 12:46:48 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 8.6 KB, free 910.6 MB)
19/07/31 12:46:48 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:62226 (size: 8.6 KB, free: 912.1 MB)
19/07/31 12:46:48 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/07/31 12:46:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[40] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:46:48 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/07/31 12:46:48 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:46:48 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
19/07/31 12:46:48 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:46:48 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1584 bytes result sent to driver
19/07/31 12:46:48 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 21 ms on localhost (executor driver) (1/1)
19/07/31 12:46:48 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/07/31 12:46:48 INFO DAGScheduler: ResultStage 9 (csv at NativeMethodAccessorImpl.java:0) finished in 0.021 s
19/07/31 12:46:48 INFO DAGScheduler: Job 7 finished: csv at NativeMethodAccessorImpl.java:0, took 0.027807 s
19/07/31 12:46:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:46:48 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:46:48 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:46:48 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:46:48 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:46:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:46:48 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:46:48 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 12:46:48 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 12:46:48 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 12:46:48 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:46:48 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:46:48 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 12:46:48 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:46:48 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 282.3 KB, free 910.4 MB)
19/07/31 12:46:48 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 24.0 KB, free 910.3 MB)
19/07/31 12:46:48 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:62226 (size: 24.0 KB, free: 912.1 MB)
19/07/31 12:46:48 INFO SparkContext: Created broadcast 15 from sql at NativeMethodAccessorImpl.java:0
19/07/31 12:46:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:46:48 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 12:46:48 INFO DAGScheduler: Registering RDD 46 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 12:46:48 INFO DAGScheduler: Got job 8 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:46:48 INFO DAGScheduler: Final stage: ResultStage 11 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 12:46:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
19/07/31 12:46:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
19/07/31 12:46:48 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[46] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:46:48 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 26.3 KB, free 910.3 MB)
19/07/31 12:46:48 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 11.9 KB, free 910.3 MB)
19/07/31 12:46:48 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:62226 (size: 11.9 KB, free: 912.1 MB)
19/07/31 12:46:48 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/07/31 12:46:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[46] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:46:48 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/07/31 12:46:48 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:46:48 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
19/07/31 12:46:48 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:46:48 INFO MemoryStore: Block rdd_43_0 stored as values in memory (estimated size 48.9 KB, free 910.3 MB)
19/07/31 12:46:48 INFO BlockManagerInfo: Added rdd_43_0 in memory on 127.0.0.1:62226 (size: 48.9 KB, free: 912.0 MB)
19/07/31 12:46:48 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2461 bytes result sent to driver
19/07/31 12:46:48 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 86 ms on localhost (executor driver) (1/1)
19/07/31 12:46:48 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/07/31 12:46:48 INFO DAGScheduler: ShuffleMapStage 10 (sql at NativeMethodAccessorImpl.java:0) finished in 0.087 s
19/07/31 12:46:48 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:46:48 INFO DAGScheduler: running: Set()
19/07/31 12:46:48 INFO DAGScheduler: waiting: Set(ResultStage 11)
19/07/31 12:46:48 INFO DAGScheduler: failed: Set()
19/07/31 12:46:48 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[49] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:46:48 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 910.2 MB)
19/07/31 12:46:48 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.2 MB)
19/07/31 12:46:48 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:62226 (size: 3.7 KB, free: 912.0 MB)
19/07/31 12:46:48 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/07/31 12:46:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[49] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:46:48 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/07/31 12:46:48 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:46:48 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
19/07/31 12:46:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:46:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 12:46:48 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1581 bytes result sent to driver
19/07/31 12:46:48 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 4 ms on localhost (executor driver) (1/1)
19/07/31 12:46:48 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/07/31 12:46:48 INFO DAGScheduler: ResultStage 11 (sql at NativeMethodAccessorImpl.java:0) finished in 0.006 s
19/07/31 12:46:48 INFO DAGScheduler: Job 8 finished: sql at NativeMethodAccessorImpl.java:0, took 0.110072 s
19/07/31 12:46:48 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 12:46:48 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:46:48 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:46:48 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:46:48 INFO DAGScheduler: Registering RDD 52 (collect at utils.scala:204)
19/07/31 12:46:48 INFO DAGScheduler: Got job 9 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:46:48 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:204)
19/07/31 12:46:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
19/07/31 12:46:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
19/07/31 12:46:48 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[52] at collect at utils.scala:204), which has no missing parents
19/07/31 12:46:48 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 26.3 KB, free 910.2 MB)
19/07/31 12:46:48 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 11.8 KB, free 910.2 MB)
19/07/31 12:46:48 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:62226 (size: 11.8 KB, free: 912.0 MB)
19/07/31 12:46:48 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
19/07/31 12:46:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[52] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:46:48 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/07/31 12:46:48 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:46:48 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
19/07/31 12:46:48 INFO BlockManager: Found block rdd_43_0 locally
19/07/31 12:46:48 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1780 bytes result sent to driver
19/07/31 12:46:48 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 10 ms on localhost (executor driver) (1/1)
19/07/31 12:46:48 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/07/31 12:46:48 INFO DAGScheduler: ShuffleMapStage 12 (collect at utils.scala:204) finished in 0.011 s
19/07/31 12:46:48 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:46:48 INFO DAGScheduler: running: Set()
19/07/31 12:46:48 INFO DAGScheduler: waiting: Set(ResultStage 13)
19/07/31 12:46:48 INFO DAGScheduler: failed: Set()
19/07/31 12:46:48 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[55] at collect at utils.scala:204), which has no missing parents
19/07/31 12:46:48 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 7.0 KB, free 910.2 MB)
19/07/31 12:46:48 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.2 MB)
19/07/31 12:46:48 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:62226 (size: 3.7 KB, free: 912.0 MB)
19/07/31 12:46:48 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/07/31 12:46:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[55] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:46:48 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/07/31 12:46:48 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:46:48 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
19/07/31 12:46:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:46:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:46:48 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1624 bytes result sent to driver
19/07/31 12:46:48 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 11 ms on localhost (executor driver) (1/1)
19/07/31 12:46:48 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/07/31 12:46:48 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:204) finished in 0.011 s
19/07/31 12:46:48 INFO DAGScheduler: Job 9 finished: collect at utils.scala:204, took 0.045007 s
19/07/31 12:46:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz2`
WHERE (0 = 1)
19/07/31 12:46:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:46:48 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:46:48 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:46:48 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:46:48 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:46:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:46:48 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:47:06 INFO SparkSqlParser: Parsing command: SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 12:47:06 INFO SparkSqlParser: Parsing command: SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`
LIMIT 1000
19/07/31 12:47:06 INFO CodeGenerator: Code generated in 8.826207 ms
19/07/31 12:47:06 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:47:06 INFO DAGScheduler: Got job 10 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:47:06 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:204)
19/07/31 12:47:06 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:47:06 INFO DAGScheduler: Missing parents: List()
19/07/31 12:47:06 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[58] at collect at utils.scala:204), which has no missing parents
19/07/31 12:47:06 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 25.7 KB, free 910.2 MB)
19/07/31 12:47:06 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 11.3 KB, free 910.2 MB)
19/07/31 12:47:06 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:62226 (size: 11.3 KB, free: 912.0 MB)
19/07/31 12:47:06 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
19/07/31 12:47:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[58] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:47:06 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/07/31 12:47:06 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:47:06 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
19/07/31 12:47:06 INFO BlockManager: Found block rdd_43_0 locally
19/07/31 12:47:06 INFO CodeGenerator: Code generated in 16.807828 ms
19/07/31 12:47:06 INFO Executor: 1 block locks were not released by TID = 14:
[rdd_43_0]
19/07/31 12:47:06 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 31077 bytes result sent to driver
19/07/31 12:47:06 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 53 ms on localhost (executor driver) (1/1)
19/07/31 12:47:06 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/07/31 12:47:06 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:204) finished in 0.053 s
19/07/31 12:47:06 INFO DAGScheduler: Job 10 finished: collect at utils.scala:204, took 0.062368 s
19/07/31 12:47:06 INFO CodeGenerator: Code generated in 9.982328 ms
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 119
19/07/31 12:47:06 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:62226 in memory (size: 4.3 KB, free: 912.0 MB)
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 334
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 124
19/07/31 12:47:06 INFO ContextCleaner: Cleaned shuffle 2
19/07/31 12:47:06 INFO ContextCleaner: Cleaned shuffle 1
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 261
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 110
19/07/31 12:47:06 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:62226 in memory (size: 8.6 KB, free: 912.0 MB)
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 182
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 262
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 291
19/07/31 12:47:06 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:62226 in memory (size: 11.9 KB, free: 912.0 MB)
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 115
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 327
19/07/31 12:47:06 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:62226 in memory (size: 11.8 KB, free: 912.0 MB)
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 292
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 186
19/07/31 12:47:06 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:62226 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 331
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 117
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 114
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 180
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 112
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 109
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 185
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 326
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 108
19/07/31 12:47:06 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:62226 in memory (size: 3.5 KB, free: 912.1 MB)
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 176
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 113
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 337
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 120
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 330
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 266
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 236
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 183
19/07/31 12:47:06 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:62226 in memory (size: 24.0 KB, free: 912.1 MB)
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 181
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 123
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 293
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 184
19/07/31 12:47:06 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:62226 in memory (size: 8.6 KB, free: 912.1 MB)
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 294
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 265
19/07/31 12:47:06 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:62226 in memory (size: 23.8 KB, free: 912.1 MB)
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 333
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 118
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 264
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 126
19/07/31 12:47:06 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:62226 in memory (size: 23.8 KB, free: 912.1 MB)
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 177
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 336
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 178
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 122
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 329
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 175
19/07/31 12:47:06 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:62226 in memory (size: 11.3 KB, free: 912.1 MB)
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 335
19/07/31 12:47:06 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:62226 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 179
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 111
19/07/31 12:47:06 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:62226 in memory (size: 11.8 KB, free: 912.2 MB)
19/07/31 12:47:06 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:62226 in memory (size: 4.3 KB, free: 912.2 MB)
19/07/31 12:47:06 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:62226 in memory (size: 3.7 KB, free: 912.2 MB)
19/07/31 12:47:06 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:62226 in memory (size: 3.7 KB, free: 912.2 MB)
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 187
19/07/31 12:47:06 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:62226 in memory (size: 11.9 KB, free: 912.2 MB)
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 263
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 338
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 116
19/07/31 12:47:06 INFO BlockManager: Removing RDD 15
19/07/31 12:47:06 INFO ContextCleaner: Cleaned RDD 15
19/07/31 12:47:06 INFO ContextCleaner: Cleaned shuffle 0
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 121
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 332
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 387
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 295
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 328
19/07/31 12:47:06 INFO ContextCleaner: Cleaned accumulator 125
19/07/31 12:47:18 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_001`) `dbplyr_002`
ORDER BY `date`) `dbplyr_003`
19/07/31 12:47:18 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:47:18 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:47:18 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_004`) `dbplyr_005`
ORDER BY `date`) `dbplyr_006`
LIMIT 1000
19/07/31 12:47:18 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:47:18 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:47:18 INFO CodeGenerator: Code generated in 8.468201 ms
19/07/31 12:47:18 INFO CodeGenerator: Code generated in 14.416313 ms
19/07/31 12:47:18 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:47:18 INFO DAGScheduler: Got job 11 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:47:18 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:204)
19/07/31 12:47:18 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:47:18 INFO DAGScheduler: Missing parents: List()
19/07/31 12:47:18 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[62] at collect at utils.scala:204), which has no missing parents
19/07/31 12:47:18 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 70.8 KB, free 911.3 MB)
19/07/31 12:47:18 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 30.1 KB, free 911.3 MB)
19/07/31 12:47:18 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:62226 (size: 30.1 KB, free: 912.2 MB)
19/07/31 12:47:18 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
19/07/31 12:47:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[62] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:47:18 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
19/07/31 12:47:18 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:47:18 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
19/07/31 12:47:18 INFO BlockManager: Found block rdd_43_0 locally
19/07/31 12:47:18 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 93116 bytes result sent to driver
19/07/31 12:47:18 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 65 ms on localhost (executor driver) (1/1)
19/07/31 12:47:18 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/07/31 12:47:18 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:204) finished in 0.066 s
19/07/31 12:47:18 INFO DAGScheduler: Job 11 finished: collect at utils.scala:204, took 0.075899 s
19/07/31 12:47:18 INFO CodeGenerator: Code generated in 9.017503 ms
19/07/31 12:47:18 INFO CodeGenerator: Code generated in 25.908177 ms
19/07/31 12:47:56 INFO SparkContext: Running Spark version 2.2.0
19/07/31 12:47:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/07/31 12:47:56 INFO SparkContext: Submitted application: sparklyr
19/07/31 12:47:56 INFO SecurityManager: Changing view acls to: 6jncnk4f
19/07/31 12:47:56 INFO SecurityManager: Changing modify acls to: 6jncnk4f
19/07/31 12:47:56 INFO SecurityManager: Changing view acls groups to: 
19/07/31 12:47:56 INFO SecurityManager: Changing modify acls groups to: 
19/07/31 12:47:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(6jncnk4f); groups with view permissions: Set(); users  with modify permissions: Set(6jncnk4f); groups with modify permissions: Set()
19/07/31 12:47:56 INFO Utils: Successfully started service 'sparkDriver' on port 62350.
19/07/31 12:47:56 INFO SparkEnv: Registering MapOutputTracker
19/07/31 12:47:56 INFO SparkEnv: Registering BlockManagerMaster
19/07/31 12:47:56 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/07/31 12:47:56 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/07/31 12:47:56 INFO DiskBlockManager: Created local directory at /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/blockmgr-4107b1cd-8055-4606-97d2-a62e103d69e7
19/07/31 12:47:56 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/07/31 12:47:56 INFO SparkEnv: Registering OutputCommitCoordinator
19/07/31 12:47:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/07/31 12:47:56 INFO Utils: Successfully started service 'SparkUI' on port 4041.
19/07/31 12:47:56 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
19/07/31 12:47:56 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:62350/jars/sparklyr-2.0-2.11.jar with timestamp 1564591676860
19/07/31 12:47:56 INFO Executor: Starting executor ID driver on host localhost
19/07/31 12:47:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62351.
19/07/31 12:47:56 INFO NettyBlockTransferService: Server created on 127.0.0.1:62351
19/07/31 12:47:56 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/07/31 12:47:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 62351, None)
19/07/31 12:47:56 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:62351 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 62351, None)
19/07/31 12:47:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 62351, None)
19/07/31 12:47:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 62351, None)
19/07/31 12:47:57 INFO SharedState: loading hive config file: file:/Users/6jncnk4f/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/07/31 12:47:57 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse').
19/07/31 12:47:57 INFO SharedState: Warehouse path is 'file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse'.
19/07/31 12:47:57 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/07/31 12:47:58 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/07/31 12:47:58 INFO ObjectStore: ObjectStore, initialize called
19/07/31 12:47:58 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/07/31 12:47:58 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/07/31 12:47:59 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/07/31 12:48:00 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:48:00 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:48:00 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:48:00 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:48:01 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/07/31 12:48:01 INFO ObjectStore: Initialized ObjectStore
19/07/31 12:48:01 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/07/31 12:48:01 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/07/31 12:48:01 INFO HiveMetaStore: Added admin role in metastore
19/07/31 12:48:01 INFO HiveMetaStore: Added public role in metastore
19/07/31 12:48:01 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/07/31 12:48:01 INFO HiveMetaStore: 0: get_all_databases
19/07/31 12:48:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_all_databases	
19/07/31 12:48:01 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/07/31 12:48:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/07/31 12:48:01 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:48:01 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/ecf16140-5028-48ff-8b19-b2e540779e2f_resources
19/07/31 12:48:01 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/ecf16140-5028-48ff-8b19-b2e540779e2f
19/07/31 12:48:01 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/ecf16140-5028-48ff-8b19-b2e540779e2f
19/07/31 12:48:01 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/ecf16140-5028-48ff-8b19-b2e540779e2f/_tmp_space.db
19/07/31 12:48:01 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 12:48:01 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:48:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:48:01 INFO HiveMetaStore: 0: get_database: global_temp
19/07/31 12:48:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/07/31 12:48:01 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/07/31 12:48:01 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/5d5d6cd1-3e97-43e6-83f0-dda727506da9_resources
19/07/31 12:48:01 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/5d5d6cd1-3e97-43e6-83f0-dda727506da9
19/07/31 12:48:01 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/5d5d6cd1-3e97-43e6-83f0-dda727506da9
19/07/31 12:48:01 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/5d5d6cd1-3e97-43e6-83f0-dda727506da9/_tmp_space.db
19/07/31 12:48:01 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 12:48:01 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/07/31 12:48:01 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:48:03 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:48:03 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:48:03 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:48:03 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:48:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:48:03 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:48:03 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 12:48:03 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/07/31 12:48:03 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/07/31 12:48:03 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:48:03 INFO DAGScheduler: Missing parents: List()
19/07/31 12:48:03 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/07/31 12:48:03 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/07/31 12:48:03 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/07/31 12:48:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:62351 (size: 3.4 KB, free: 912.3 MB)
19/07/31 12:48:03 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/07/31 12:48:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 12:48:03 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/07/31 12:48:03 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/07/31 12:48:03 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/07/31 12:48:03 INFO Executor: Fetching spark://127.0.0.1:62350/jars/sparklyr-2.0-2.11.jar with timestamp 1564591676860
19/07/31 12:48:03 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:62350 after 20 ms (0 ms spent in bootstraps)
19/07/31 12:48:03 INFO Utils: Fetching spark://127.0.0.1:62350/jars/sparklyr-2.0-2.11.jar to /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-704b5673-b6cb-4b4e-9ecf-aa4138a45eea/userFiles-5192ee80-90f9-484f-bede-66557d2ed017/fetchFileTemp1663836315822371314.tmp
19/07/31 12:48:03 INFO Executor: Adding file:/private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-704b5673-b6cb-4b4e-9ecf-aa4138a45eea/userFiles-5192ee80-90f9-484f-bede-66557d2ed017/sparklyr-2.0-2.11.jar to class loader
19/07/31 12:48:04 INFO CodeGenerator: Code generated in 173.85181 ms
19/07/31 12:48:04 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
19/07/31 12:48:04 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 517 ms on localhost (executor driver) (1/1)
19/07/31 12:48:04 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/07/31 12:48:04 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.542 s
19/07/31 12:48:04 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0.682470 s
19/07/31 12:48:04 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:48:04 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#10)) > 0)
19/07/31 12:48:04 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:48:04 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:48:04 INFO CodeGenerator: Code generated in 22.007691 ms
19/07/31 12:48:04 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 281.2 KB, free 912.0 MB)
19/07/31 12:48:04 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.8 KB, free 912.0 MB)
19/07/31 12:48:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:62351 (size: 23.8 KB, free: 912.3 MB)
19/07/31 12:48:04 INFO SparkContext: Created broadcast 1 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:48:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:48:04 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:48:04 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:48:04 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:48:04 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:48:04 INFO DAGScheduler: Missing parents: List()
19/07/31 12:48:04 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:48:04 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 912.0 MB)
19/07/31 12:48:04 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 912.0 MB)
19/07/31 12:48:04 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:62351 (size: 4.3 KB, free: 912.3 MB)
19/07/31 12:48:04 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/07/31 12:48:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:48:04 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/07/31 12:48:04 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:48:04 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/07/31 12:48:04 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:48:04 INFO CodeGenerator: Code generated in 7.742329 ms
19/07/31 12:48:05 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:62351 in memory (size: 3.4 KB, free: 912.3 MB)
19/07/31 12:48:05 INFO ContextCleaner: Cleaned accumulator 0
19/07/31 12:48:05 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1437 bytes result sent to driver
19/07/31 12:48:05 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 282 ms on localhost (executor driver) (1/1)
19/07/31 12:48:05 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/07/31 12:48:05 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0.283 s
19/07/31 12:48:05 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0.296195 s
19/07/31 12:48:05 INFO CodeGenerator: Code generated in 6.311217 ms
19/07/31 12:48:05 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:48:05 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:48:05 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:48:05 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:48:05 INFO CodeGenerator: Code generated in 5.385929 ms
19/07/31 12:48:05 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 281.2 KB, free 911.7 MB)
19/07/31 12:48:05 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.7 MB)
19/07/31 12:48:05 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:62351 (size: 23.8 KB, free: 912.2 MB)
19/07/31 12:48:05 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:48:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:48:05 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:48:05 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:48:05 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:48:05 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:48:05 INFO DAGScheduler: Missing parents: List()
19/07/31 12:48:05 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:48:05 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.8 KB, free 911.7 MB)
19/07/31 12:48:05 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.7 MB)
19/07/31 12:48:05 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:62351 (size: 8.6 KB, free: 912.2 MB)
19/07/31 12:48:05 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/07/31 12:48:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:48:05 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/07/31 12:48:05 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:48:05 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/07/31 12:48:05 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:48:05 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1627 bytes result sent to driver
19/07/31 12:48:05 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 69 ms on localhost (executor driver) (1/1)
19/07/31 12:48:05 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/07/31 12:48:05 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.070 s
19/07/31 12:48:05 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.077455 s
19/07/31 12:48:05 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:48:05 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:48:05 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:48:05 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:48:05 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:48:05 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:48:05 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:48:05 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 12:48:05 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 12:48:05 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 12:48:05 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:48:05 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:48:05 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 12:48:05 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:48:05 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 282.3 KB, free 911.4 MB)
19/07/31 12:48:05 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.4 MB)
19/07/31 12:48:05 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:62351 (size: 24.0 KB, free: 912.2 MB)
19/07/31 12:48:05 INFO SparkContext: Created broadcast 5 from sql at NativeMethodAccessorImpl.java:0
19/07/31 12:48:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:48:05 INFO CodeGenerator: Code generated in 7.569564 ms
19/07/31 12:48:05 INFO CodeGenerator: Code generated in 6.934584 ms
19/07/31 12:48:05 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 12:48:05 INFO DAGScheduler: Registering RDD 18 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 12:48:05 INFO DAGScheduler: Got job 3 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:48:05 INFO DAGScheduler: Final stage: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 12:48:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/07/31 12:48:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/07/31 12:48:05 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:48:05 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 26.3 KB, free 911.3 MB)
19/07/31 12:48:05 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.8 KB, free 911.3 MB)
19/07/31 12:48:05 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:62351 (size: 11.8 KB, free: 912.2 MB)
19/07/31 12:48:05 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/07/31 12:48:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:48:05 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/07/31 12:48:05 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:48:05 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/07/31 12:48:05 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:48:05 INFO CodeGenerator: Code generated in 14.300513 ms
19/07/31 12:48:05 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 48.9 KB, free 911.3 MB)
19/07/31 12:48:05 INFO BlockManagerInfo: Added rdd_15_0 in memory on 127.0.0.1:62351 (size: 48.9 KB, free: 912.2 MB)
19/07/31 12:48:05 INFO CodeGenerator: Code generated in 4.534885 ms
19/07/31 12:48:05 INFO CodeGenerator: Code generated in 17.121581 ms
19/07/31 12:48:05 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2504 bytes result sent to driver
19/07/31 12:48:05 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 214 ms on localhost (executor driver) (1/1)
19/07/31 12:48:05 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/07/31 12:48:05 INFO DAGScheduler: ShuffleMapStage 3 (sql at NativeMethodAccessorImpl.java:0) finished in 0.215 s
19/07/31 12:48:05 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:48:05 INFO DAGScheduler: running: Set()
19/07/31 12:48:05 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/07/31 12:48:05 INFO DAGScheduler: failed: Set()
19/07/31 12:48:05 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:48:05 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 911.3 MB)
19/07/31 12:48:05 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.3 MB)
19/07/31 12:48:05 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:62351 (size: 3.7 KB, free: 912.2 MB)
19/07/31 12:48:05 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/07/31 12:48:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:48:05 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/07/31 12:48:05 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:48:05 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/07/31 12:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
19/07/31 12:48:05 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1581 bytes result sent to driver
19/07/31 12:48:05 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 30 ms on localhost (executor driver) (1/1)
19/07/31 12:48:05 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/07/31 12:48:05 INFO DAGScheduler: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0) finished in 0.031 s
19/07/31 12:48:05 INFO DAGScheduler: Job 3 finished: sql at NativeMethodAccessorImpl.java:0, took 0.290815 s
19/07/31 12:48:05 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 12:48:05 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:48:05 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:48:05 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:48:05 INFO DAGScheduler: Registering RDD 24 (collect at utils.scala:204)
19/07/31 12:48:05 INFO DAGScheduler: Got job 4 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:48:05 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
19/07/31 12:48:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/07/31 12:48:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/07/31 12:48:05 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204), which has no missing parents
19/07/31 12:48:05 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 26.3 KB, free 911.2 MB)
19/07/31 12:48:05 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.9 KB, free 911.2 MB)
19/07/31 12:48:05 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:62351 (size: 11.9 KB, free: 912.1 MB)
19/07/31 12:48:05 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/07/31 12:48:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:48:05 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/07/31 12:48:05 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:48:05 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/07/31 12:48:05 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:48:05 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1780 bytes result sent to driver
19/07/31 12:48:05 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 16 ms on localhost (executor driver) (1/1)
19/07/31 12:48:05 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/07/31 12:48:05 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:204) finished in 0.017 s
19/07/31 12:48:05 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:48:05 INFO DAGScheduler: running: Set()
19/07/31 12:48:05 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/07/31 12:48:05 INFO DAGScheduler: failed: Set()
19/07/31 12:48:05 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204), which has no missing parents
19/07/31 12:48:05 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 911.2 MB)
19/07/31 12:48:05 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.2 MB)
19/07/31 12:48:05 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:62351 (size: 3.7 KB, free: 912.1 MB)
19/07/31 12:48:05 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/07/31 12:48:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:48:05 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/07/31 12:48:05 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:48:05 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/07/31 12:48:05 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:48:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:48:05 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1538 bytes result sent to driver
19/07/31 12:48:05 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 4 ms on localhost (executor driver) (1/1)
19/07/31 12:48:05 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/07/31 12:48:05 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.004 s
19/07/31 12:48:05 INFO DAGScheduler: Job 4 finished: collect at utils.scala:204, took 0.042836 s
19/07/31 12:48:05 INFO CodeGenerator: Code generated in 6.313809 ms
19/07/31 12:48:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz1`
WHERE (0 = 1)
19/07/31 12:48:07 INFO SparkContext: Invoking stop() from shutdown hook
19/07/31 12:48:07 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
19/07/31 12:48:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/07/31 12:48:07 INFO MemoryStore: MemoryStore cleared
19/07/31 12:48:07 INFO BlockManager: BlockManager stopped
19/07/31 12:48:07 INFO BlockManagerMaster: BlockManagerMaster stopped
19/07/31 12:48:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/07/31 12:48:07 INFO SparkContext: Successfully stopped SparkContext
19/07/31 12:48:07 INFO ShutdownHookManager: Shutdown hook called
19/07/31 12:48:07 INFO ShutdownHookManager: Deleting directory /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-704b5673-b6cb-4b4e-9ecf-aa4138a45eea
19/07/31 12:48:35 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:48:35 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:48:35 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:48:35 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:48:35 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:48:35 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:48:35 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:48:35 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 12:48:35 INFO DAGScheduler: Got job 12 (collect at utils.scala:44) with 1 output partitions
19/07/31 12:48:35 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:44)
19/07/31 12:48:35 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:48:35 INFO DAGScheduler: Missing parents: List()
19/07/31 12:48:35 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[67] at map at utils.scala:41), which has no missing parents
19/07/31 12:48:35 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 6.3 KB, free 911.3 MB)
19/07/31 12:48:35 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 3.5 KB, free 911.2 MB)
19/07/31 12:48:35 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:62226 (size: 3.5 KB, free: 912.1 MB)
19/07/31 12:48:35 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
19/07/31 12:48:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[67] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 12:48:35 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/07/31 12:48:35 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 12:48:35 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
19/07/31 12:48:35 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1007 bytes result sent to driver
19/07/31 12:48:35 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 4 ms on localhost (executor driver) (1/1)
19/07/31 12:48:35 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/07/31 12:48:35 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:44) finished in 0.005 s
19/07/31 12:48:35 INFO DAGScheduler: Job 12 finished: collect at utils.scala:44, took 0.010785 s
19/07/31 12:48:35 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 12:48:35 INFO MapPartitionsRDD: Removing RDD 43 from persistence list
19/07/31 12:48:35 INFO BlockManager: Removing RDD 43
19/07/31 12:48:35 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:48:35 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#965)) > 0)
19/07/31 12:48:35 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:48:35 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:48:35 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 281.2 KB, free 911.0 MB)
19/07/31 12:48:35 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.0 MB)
19/07/31 12:48:35 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:62226 (size: 23.8 KB, free: 912.2 MB)
19/07/31 12:48:35 INFO SparkContext: Created broadcast 23 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:48:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:48:35 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:48:35 INFO DAGScheduler: Got job 13 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:48:35 INFO DAGScheduler: Final stage: ResultStage 17 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:48:35 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:48:35 INFO DAGScheduler: Missing parents: List()
19/07/31 12:48:35 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[70] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:48:35 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 8.2 KB, free 911.0 MB)
19/07/31 12:48:35 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 4.3 KB, free 911.0 MB)
19/07/31 12:48:35 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:62226 (size: 4.3 KB, free: 912.2 MB)
19/07/31 12:48:35 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
19/07/31 12:48:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[70] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:48:35 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
19/07/31 12:48:35 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:48:35 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
19/07/31 12:48:35 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:48:35 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 1394 bytes result sent to driver
19/07/31 12:48:35 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 5 ms on localhost (executor driver) (1/1)
19/07/31 12:48:35 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/07/31 12:48:35 INFO DAGScheduler: ResultStage 17 (csv at NativeMethodAccessorImpl.java:0) finished in 0.006 s
19/07/31 12:48:35 INFO DAGScheduler: Job 13 finished: csv at NativeMethodAccessorImpl.java:0, took 0.011062 s
19/07/31 12:48:35 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:48:35 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:48:35 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:48:35 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:48:35 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 281.2 KB, free 910.7 MB)
19/07/31 12:48:35 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 23.8 KB, free 910.7 MB)
19/07/31 12:48:35 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:62226 (size: 23.8 KB, free: 912.1 MB)
19/07/31 12:48:35 INFO SparkContext: Created broadcast 25 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:48:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:48:35 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:48:35 INFO DAGScheduler: Got job 14 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:48:35 INFO DAGScheduler: Final stage: ResultStage 18 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:48:35 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:48:35 INFO DAGScheduler: Missing parents: List()
19/07/31 12:48:35 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[75] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:48:35 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 14.8 KB, free 910.7 MB)
19/07/31 12:48:35 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 8.6 KB, free 910.7 MB)
19/07/31 12:48:35 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:62226 (size: 8.6 KB, free: 912.1 MB)
19/07/31 12:48:35 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
19/07/31 12:48:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[75] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:48:35 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
19/07/31 12:48:35 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:48:35 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
19/07/31 12:48:35 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:48:35 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 1584 bytes result sent to driver
19/07/31 12:48:35 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 20 ms on localhost (executor driver) (1/1)
19/07/31 12:48:35 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/07/31 12:48:35 INFO DAGScheduler: ResultStage 18 (csv at NativeMethodAccessorImpl.java:0) finished in 0.020 s
19/07/31 12:48:35 INFO DAGScheduler: Job 14 finished: csv at NativeMethodAccessorImpl.java:0, took 0.024344 s
19/07/31 12:48:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:48:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:48:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:48:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:48:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:48:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:48:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:48:36 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 12:48:36 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 12:48:36 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 12:48:36 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:48:36 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:48:36 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 12:48:36 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:48:36 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 282.3 KB, free 910.4 MB)
19/07/31 12:48:36 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 24.0 KB, free 910.4 MB)
19/07/31 12:48:36 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:62226 (size: 24.0 KB, free: 912.1 MB)
19/07/31 12:48:36 INFO SparkContext: Created broadcast 27 from sql at <unknown>:0
19/07/31 12:48:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:48:36 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 12:48:36 INFO DAGScheduler: Registering RDD 81 (sql at <unknown>:0)
19/07/31 12:48:36 INFO DAGScheduler: Got job 15 (sql at <unknown>:0) with 1 output partitions
19/07/31 12:48:36 INFO DAGScheduler: Final stage: ResultStage 20 (sql at <unknown>:0)
19/07/31 12:48:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
19/07/31 12:48:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
19/07/31 12:48:36 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[81] at sql at <unknown>:0), which has no missing parents
19/07/31 12:48:36 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 26.3 KB, free 910.3 MB)
19/07/31 12:48:36 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 11.8 KB, free 910.3 MB)
19/07/31 12:48:36 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:62226 (size: 11.8 KB, free: 912.1 MB)
19/07/31 12:48:36 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
19/07/31 12:48:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[81] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:48:36 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/07/31 12:48:36 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:48:36 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
19/07/31 12:48:36 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:48:36 INFO MemoryStore: Block rdd_78_0 stored as values in memory (estimated size 48.9 KB, free 910.3 MB)
19/07/31 12:48:36 INFO BlockManagerInfo: Added rdd_78_0 in memory on 127.0.0.1:62226 (size: 48.9 KB, free: 912.1 MB)
19/07/31 12:48:36 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 2461 bytes result sent to driver
19/07/31 12:48:36 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 49 ms on localhost (executor driver) (1/1)
19/07/31 12:48:36 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/07/31 12:48:36 INFO DAGScheduler: ShuffleMapStage 19 (sql at <unknown>:0) finished in 0.049 s
19/07/31 12:48:36 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:48:36 INFO DAGScheduler: running: Set()
19/07/31 12:48:36 INFO DAGScheduler: waiting: Set(ResultStage 20)
19/07/31 12:48:36 INFO DAGScheduler: failed: Set()
19/07/31 12:48:36 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[84] at sql at <unknown>:0), which has no missing parents
19/07/31 12:48:36 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 7.0 KB, free 910.3 MB)
19/07/31 12:48:36 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.3 MB)
19/07/31 12:48:36 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:62226 (size: 3.7 KB, free: 912.1 MB)
19/07/31 12:48:36 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
19/07/31 12:48:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[84] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:48:36 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/07/31 12:48:36 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:48:36 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
19/07/31 12:48:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:48:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:48:36 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1581 bytes result sent to driver
19/07/31 12:48:36 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 4 ms on localhost (executor driver) (1/1)
19/07/31 12:48:36 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/07/31 12:48:36 INFO DAGScheduler: ResultStage 20 (sql at <unknown>:0) finished in 0.004 s
19/07/31 12:48:36 INFO DAGScheduler: Job 15 finished: sql at <unknown>:0, took 0.064172 s
19/07/31 12:48:36 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 12:48:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:48:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:48:36 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:48:36 INFO DAGScheduler: Registering RDD 87 (collect at utils.scala:204)
19/07/31 12:48:36 INFO DAGScheduler: Got job 16 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:48:36 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:204)
19/07/31 12:48:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
19/07/31 12:48:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
19/07/31 12:48:36 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[87] at collect at utils.scala:204), which has no missing parents
19/07/31 12:48:36 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 26.3 KB, free 910.2 MB)
19/07/31 12:48:36 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 11.9 KB, free 910.2 MB)
19/07/31 12:48:36 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:62226 (size: 11.9 KB, free: 912.0 MB)
19/07/31 12:48:36 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
19/07/31 12:48:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[87] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:48:36 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
19/07/31 12:48:36 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:48:36 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
19/07/31 12:48:36 INFO BlockManager: Found block rdd_78_0 locally
19/07/31 12:48:36 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1780 bytes result sent to driver
19/07/31 12:48:36 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 7 ms on localhost (executor driver) (1/1)
19/07/31 12:48:36 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/07/31 12:48:36 INFO DAGScheduler: ShuffleMapStage 21 (collect at utils.scala:204) finished in 0.008 s
19/07/31 12:48:36 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:48:36 INFO DAGScheduler: running: Set()
19/07/31 12:48:36 INFO DAGScheduler: waiting: Set(ResultStage 22)
19/07/31 12:48:36 INFO DAGScheduler: failed: Set()
19/07/31 12:48:36 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[90] at collect at utils.scala:204), which has no missing parents
19/07/31 12:48:36 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 7.0 KB, free 910.2 MB)
19/07/31 12:48:36 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.2 MB)
19/07/31 12:48:36 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:62226 (size: 3.7 KB, free: 912.0 MB)
19/07/31 12:48:36 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
19/07/31 12:48:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[90] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:48:36 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
19/07/31 12:48:36 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:48:36 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
19/07/31 12:48:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:48:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:48:36 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1581 bytes result sent to driver
19/07/31 12:48:36 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 5 ms on localhost (executor driver) (1/1)
19/07/31 12:48:36 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/07/31 12:48:36 INFO DAGScheduler: ResultStage 22 (collect at utils.scala:204) finished in 0.006 s
19/07/31 12:48:36 INFO DAGScheduler: Job 16 finished: collect at utils.scala:204, took 0.027364 s
19/07/31 12:48:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz3`
WHERE (0 = 1)
19/07/31 12:48:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:48:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:48:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:48:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:48:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:48:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:48:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:51:05 INFO SparkContext: Running Spark version 2.2.0
19/07/31 12:51:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/07/31 12:51:05 INFO SparkContext: Submitted application: sparklyr
19/07/31 12:51:05 INFO SecurityManager: Changing view acls to: 6jncnk4f
19/07/31 12:51:05 INFO SecurityManager: Changing modify acls to: 6jncnk4f
19/07/31 12:51:05 INFO SecurityManager: Changing view acls groups to: 
19/07/31 12:51:05 INFO SecurityManager: Changing modify acls groups to: 
19/07/31 12:51:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(6jncnk4f); groups with view permissions: Set(); users  with modify permissions: Set(6jncnk4f); groups with modify permissions: Set()
19/07/31 12:51:05 INFO Utils: Successfully started service 'sparkDriver' on port 62459.
19/07/31 12:51:05 INFO SparkEnv: Registering MapOutputTracker
19/07/31 12:51:05 INFO SparkEnv: Registering BlockManagerMaster
19/07/31 12:51:05 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/07/31 12:51:05 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/07/31 12:51:05 INFO DiskBlockManager: Created local directory at /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/blockmgr-f9ba0701-1e84-46e8-9707-f26349f67556
19/07/31 12:51:05 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/07/31 12:51:05 INFO SparkEnv: Registering OutputCommitCoordinator
19/07/31 12:51:06 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/07/31 12:51:06 INFO Utils: Successfully started service 'SparkUI' on port 4041.
19/07/31 12:51:06 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
19/07/31 12:51:06 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:62459/jars/sparklyr-2.0-2.11.jar with timestamp 1564591866090
19/07/31 12:51:06 INFO Executor: Starting executor ID driver on host localhost
19/07/31 12:51:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62460.
19/07/31 12:51:06 INFO NettyBlockTransferService: Server created on 127.0.0.1:62460
19/07/31 12:51:06 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/07/31 12:51:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 62460, None)
19/07/31 12:51:06 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:62460 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 62460, None)
19/07/31 12:51:06 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 62460, None)
19/07/31 12:51:06 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 62460, None)
19/07/31 12:51:06 INFO SharedState: loading hive config file: file:/Users/6jncnk4f/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/07/31 12:51:06 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse').
19/07/31 12:51:06 INFO SharedState: Warehouse path is 'file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse'.
19/07/31 12:51:07 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/07/31 12:51:07 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/07/31 12:51:07 INFO ObjectStore: ObjectStore, initialize called
19/07/31 12:51:07 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/07/31 12:51:07 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/07/31 12:51:08 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/07/31 12:51:09 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:51:09 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:51:10 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:51:10 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:51:10 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/07/31 12:51:10 INFO ObjectStore: Initialized ObjectStore
19/07/31 12:51:10 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/07/31 12:51:10 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/07/31 12:51:10 INFO HiveMetaStore: Added admin role in metastore
19/07/31 12:51:10 INFO HiveMetaStore: Added public role in metastore
19/07/31 12:51:10 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/07/31 12:51:10 INFO HiveMetaStore: 0: get_all_databases
19/07/31 12:51:10 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_all_databases	
19/07/31 12:51:10 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/07/31 12:51:10 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/07/31 12:51:10 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:51:10 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/3084ca4b-d6ce-41ca-a917-cae037349b9e_resources
19/07/31 12:51:10 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/3084ca4b-d6ce-41ca-a917-cae037349b9e
19/07/31 12:51:10 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/3084ca4b-d6ce-41ca-a917-cae037349b9e
19/07/31 12:51:10 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/3084ca4b-d6ce-41ca-a917-cae037349b9e/_tmp_space.db
19/07/31 12:51:10 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 12:51:10 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:51:10 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:51:10 INFO HiveMetaStore: 0: get_database: global_temp
19/07/31 12:51:10 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/07/31 12:51:10 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/07/31 12:51:10 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/2eeb3913-db64-439f-82c6-14225556ff1c_resources
19/07/31 12:51:10 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/2eeb3913-db64-439f-82c6-14225556ff1c
19/07/31 12:51:10 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/2eeb3913-db64-439f-82c6-14225556ff1c
19/07/31 12:51:10 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/2eeb3913-db64-439f-82c6-14225556ff1c/_tmp_space.db
19/07/31 12:51:10 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 12:51:11 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/07/31 12:51:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:51:12 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:51:12 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:51:12 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:51:12 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:51:12 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:51:12 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:51:12 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 12:51:12 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/07/31 12:51:12 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/07/31 12:51:12 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:51:12 INFO DAGScheduler: Missing parents: List()
19/07/31 12:51:12 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/07/31 12:51:12 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/07/31 12:51:12 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/07/31 12:51:12 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:62460 (size: 3.4 KB, free: 912.3 MB)
19/07/31 12:51:12 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/07/31 12:51:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 12:51:12 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/07/31 12:51:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/07/31 12:51:12 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/07/31 12:51:12 INFO Executor: Fetching spark://127.0.0.1:62459/jars/sparklyr-2.0-2.11.jar with timestamp 1564591866090
19/07/31 12:51:12 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:62459 after 10 ms (0 ms spent in bootstraps)
19/07/31 12:51:12 INFO Utils: Fetching spark://127.0.0.1:62459/jars/sparklyr-2.0-2.11.jar to /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-1998119b-1acb-4da9-837e-c7a5ae753834/userFiles-c021ee1c-8105-425e-8a54-ac4c45dfd17b/fetchFileTemp7864759983219385621.tmp
19/07/31 12:51:12 INFO Executor: Adding file:/private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-1998119b-1acb-4da9-837e-c7a5ae753834/userFiles-c021ee1c-8105-425e-8a54-ac4c45dfd17b/sparklyr-2.0-2.11.jar to class loader
19/07/31 12:51:13 INFO CodeGenerator: Code generated in 198.246042 ms
19/07/31 12:51:13 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
19/07/31 12:51:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 449 ms on localhost (executor driver) (1/1)
19/07/31 12:51:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/07/31 12:51:13 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.463 s
19/07/31 12:51:13 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0.587449 s
19/07/31 12:51:13 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:51:13 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#10)) > 0)
19/07/31 12:51:13 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:51:13 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:51:13 INFO CodeGenerator: Code generated in 17.396155 ms
19/07/31 12:51:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 281.2 KB, free 912.0 MB)
19/07/31 12:51:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.8 KB, free 912.0 MB)
19/07/31 12:51:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:62460 (size: 23.8 KB, free: 912.3 MB)
19/07/31 12:51:13 INFO SparkContext: Created broadcast 1 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:51:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:51:13 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:51:13 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:51:13 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:51:13 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:51:13 INFO DAGScheduler: Missing parents: List()
19/07/31 12:51:13 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:51:13 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 912.0 MB)
19/07/31 12:51:13 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 912.0 MB)
19/07/31 12:51:13 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:62460 (size: 4.3 KB, free: 912.3 MB)
19/07/31 12:51:13 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/07/31 12:51:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:51:14 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/07/31 12:51:14 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:51:14 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/07/31 12:51:14 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:51:14 INFO CodeGenerator: Code generated in 8.15482 ms
19/07/31 12:51:14 INFO ContextCleaner: Cleaned accumulator 0
19/07/31 12:51:14 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:62460 in memory (size: 3.4 KB, free: 912.3 MB)
19/07/31 12:51:14 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1480 bytes result sent to driver
19/07/31 12:51:14 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 208 ms on localhost (executor driver) (1/1)
19/07/31 12:51:14 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/07/31 12:51:14 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0.208 s
19/07/31 12:51:14 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0.221226 s
19/07/31 12:51:14 INFO CodeGenerator: Code generated in 4.897142 ms
19/07/31 12:51:14 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:51:14 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:51:14 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:51:14 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:51:14 INFO CodeGenerator: Code generated in 6.838357 ms
19/07/31 12:51:14 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 281.2 KB, free 911.7 MB)
19/07/31 12:51:14 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.7 MB)
19/07/31 12:51:14 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:62460 (size: 23.8 KB, free: 912.2 MB)
19/07/31 12:51:14 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:51:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:51:14 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:51:14 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:51:14 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:51:14 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:51:14 INFO DAGScheduler: Missing parents: List()
19/07/31 12:51:14 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:51:14 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.8 KB, free 911.7 MB)
19/07/31 12:51:14 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.7 MB)
19/07/31 12:51:14 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:62460 (size: 8.6 KB, free: 912.2 MB)
19/07/31 12:51:14 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/07/31 12:51:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:51:14 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/07/31 12:51:14 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:51:14 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/07/31 12:51:14 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:51:14 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1627 bytes result sent to driver
19/07/31 12:51:14 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 67 ms on localhost (executor driver) (1/1)
19/07/31 12:51:14 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/07/31 12:51:14 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.067 s
19/07/31 12:51:14 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.074210 s
19/07/31 12:51:14 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:51:14 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:51:14 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:51:14 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:51:14 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:51:14 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:51:14 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:51:14 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 12:51:14 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 12:51:14 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 12:51:14 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:51:14 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:51:14 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 12:51:14 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:51:14 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 282.3 KB, free 911.4 MB)
19/07/31 12:51:14 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.4 MB)
19/07/31 12:51:14 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:62460 (size: 24.0 KB, free: 912.2 MB)
19/07/31 12:51:14 INFO SparkContext: Created broadcast 5 from sql at NativeMethodAccessorImpl.java:0
19/07/31 12:51:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:51:14 INFO CodeGenerator: Code generated in 10.751181 ms
19/07/31 12:51:14 INFO CodeGenerator: Code generated in 9.009737 ms
19/07/31 12:51:14 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 12:51:14 INFO DAGScheduler: Registering RDD 18 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 12:51:14 INFO DAGScheduler: Got job 3 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:51:14 INFO DAGScheduler: Final stage: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 12:51:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/07/31 12:51:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/07/31 12:51:14 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:51:14 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 26.3 KB, free 911.3 MB)
19/07/31 12:51:14 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.8 KB, free 911.3 MB)
19/07/31 12:51:14 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:62460 (size: 11.8 KB, free: 912.2 MB)
19/07/31 12:51:14 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/07/31 12:51:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:51:14 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/07/31 12:51:14 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:51:14 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/07/31 12:51:14 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:51:14 INFO CodeGenerator: Code generated in 15.345303 ms
19/07/31 12:51:14 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 48.9 KB, free 911.3 MB)
19/07/31 12:51:14 INFO BlockManagerInfo: Added rdd_15_0 in memory on 127.0.0.1:62460 (size: 48.9 KB, free: 912.2 MB)
19/07/31 12:51:14 INFO CodeGenerator: Code generated in 5.123759 ms
19/07/31 12:51:14 INFO CodeGenerator: Code generated in 15.75355 ms
19/07/31 12:51:14 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2504 bytes result sent to driver
19/07/31 12:51:14 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 233 ms on localhost (executor driver) (1/1)
19/07/31 12:51:14 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/07/31 12:51:14 INFO DAGScheduler: ShuffleMapStage 3 (sql at NativeMethodAccessorImpl.java:0) finished in 0.234 s
19/07/31 12:51:14 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:51:14 INFO DAGScheduler: running: Set()
19/07/31 12:51:14 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/07/31 12:51:14 INFO DAGScheduler: failed: Set()
19/07/31 12:51:14 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:51:14 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 911.3 MB)
19/07/31 12:51:14 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.3 MB)
19/07/31 12:51:14 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:62460 (size: 3.7 KB, free: 912.2 MB)
19/07/31 12:51:14 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/07/31 12:51:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:51:14 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/07/31 12:51:14 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:51:14 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/07/31 12:51:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:51:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
19/07/31 12:51:14 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1538 bytes result sent to driver
19/07/31 12:51:14 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 32 ms on localhost (executor driver) (1/1)
19/07/31 12:51:14 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/07/31 12:51:14 INFO DAGScheduler: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0) finished in 0.034 s
19/07/31 12:51:14 INFO DAGScheduler: Job 3 finished: sql at NativeMethodAccessorImpl.java:0, took 0.313572 s
19/07/31 12:51:15 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 12:51:15 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:51:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:51:15 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:51:15 INFO DAGScheduler: Registering RDD 24 (collect at utils.scala:204)
19/07/31 12:51:15 INFO DAGScheduler: Got job 4 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:51:15 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
19/07/31 12:51:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/07/31 12:51:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/07/31 12:51:15 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204), which has no missing parents
19/07/31 12:51:15 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 26.3 KB, free 911.2 MB)
19/07/31 12:51:15 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.9 KB, free 911.2 MB)
19/07/31 12:51:15 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:62460 (size: 11.9 KB, free: 912.1 MB)
19/07/31 12:51:15 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/07/31 12:51:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:51:15 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/07/31 12:51:15 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:51:15 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/07/31 12:51:15 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:51:15 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1780 bytes result sent to driver
19/07/31 12:51:15 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 12 ms on localhost (executor driver) (1/1)
19/07/31 12:51:15 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/07/31 12:51:15 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:204) finished in 0.012 s
19/07/31 12:51:15 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:51:15 INFO DAGScheduler: running: Set()
19/07/31 12:51:15 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/07/31 12:51:15 INFO DAGScheduler: failed: Set()
19/07/31 12:51:15 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204), which has no missing parents
19/07/31 12:51:15 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 911.2 MB)
19/07/31 12:51:15 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.2 MB)
19/07/31 12:51:15 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:62460 (size: 3.7 KB, free: 912.1 MB)
19/07/31 12:51:15 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/07/31 12:51:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:51:15 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/07/31 12:51:15 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:51:15 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/07/31 12:51:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:51:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:51:15 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1581 bytes result sent to driver
19/07/31 12:51:15 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 4 ms on localhost (executor driver) (1/1)
19/07/31 12:51:15 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/07/31 12:51:15 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.005 s
19/07/31 12:51:15 INFO DAGScheduler: Job 4 finished: collect at utils.scala:204, took 0.039265 s
19/07/31 12:51:15 INFO CodeGenerator: Code generated in 5.100387 ms
19/07/31 12:51:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz1`
WHERE (0 = 1)
19/07/31 12:51:16 INFO SparkContext: Invoking stop() from shutdown hook
19/07/31 12:51:16 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
19/07/31 12:51:16 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/07/31 12:51:16 INFO MemoryStore: MemoryStore cleared
19/07/31 12:51:16 INFO BlockManager: BlockManager stopped
19/07/31 12:51:16 INFO BlockManagerMaster: BlockManagerMaster stopped
19/07/31 12:51:16 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/07/31 12:51:16 INFO SparkContext: Successfully stopped SparkContext
19/07/31 12:51:16 INFO ShutdownHookManager: Shutdown hook called
19/07/31 12:51:16 INFO ShutdownHookManager: Deleting directory /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-1998119b-1acb-4da9-837e-c7a5ae753834
19/07/31 12:51:49 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:51:49 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:51:49 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:51:49 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:51:49 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:51:49 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:51:49 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:51:49 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 12:51:49 INFO DAGScheduler: Got job 17 (collect at utils.scala:44) with 1 output partitions
19/07/31 12:51:49 INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:44)
19/07/31 12:51:49 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:51:49 INFO DAGScheduler: Missing parents: List()
19/07/31 12:51:49 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[95] at map at utils.scala:41), which has no missing parents
19/07/31 12:51:49 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 6.3 KB, free 910.2 MB)
19/07/31 12:51:49 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 3.5 KB, free 910.2 MB)
19/07/31 12:51:49 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:62226 (size: 3.5 KB, free: 912.0 MB)
19/07/31 12:51:49 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
19/07/31 12:51:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[95] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 12:51:49 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
19/07/31 12:51:49 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 12:51:49 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
19/07/31 12:51:49 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 1007 bytes result sent to driver
19/07/31 12:51:49 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 4 ms on localhost (executor driver) (1/1)
19/07/31 12:51:49 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
19/07/31 12:51:49 INFO DAGScheduler: ResultStage 23 (collect at utils.scala:44) finished in 0.004 s
19/07/31 12:51:49 INFO DAGScheduler: Job 17 finished: collect at utils.scala:44, took 0.011851 s
19/07/31 12:51:49 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 12:51:49 INFO MapPartitionsRDD: Removing RDD 78 from persistence list
19/07/31 12:51:49 INFO BlockManager: Removing RDD 78
19/07/31 12:51:49 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:51:49 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1344)) > 0)
19/07/31 12:51:49 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:51:49 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:51:49 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 281.2 KB, free 910.0 MB)
19/07/31 12:51:49 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 23.8 KB, free 910.0 MB)
19/07/31 12:51:49 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:62226 (size: 23.8 KB, free: 912.1 MB)
19/07/31 12:51:49 INFO SparkContext: Created broadcast 33 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:51:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:51:49 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:51:49 INFO DAGScheduler: Got job 18 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:51:49 INFO DAGScheduler: Final stage: ResultStage 24 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:51:49 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:51:49 INFO DAGScheduler: Missing parents: List()
19/07/31 12:51:49 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[98] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:51:49 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 8.2 KB, free 910.0 MB)
19/07/31 12:51:49 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 4.3 KB, free 910.0 MB)
19/07/31 12:51:49 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:62226 (size: 4.3 KB, free: 912.1 MB)
19/07/31 12:51:49 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
19/07/31 12:51:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[98] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:51:49 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
19/07/31 12:51:49 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:51:49 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
19/07/31 12:51:49 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:51:49 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 1394 bytes result sent to driver
19/07/31 12:51:49 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 5 ms on localhost (executor driver) (1/1)
19/07/31 12:51:49 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
19/07/31 12:51:49 INFO DAGScheduler: ResultStage 24 (csv at NativeMethodAccessorImpl.java:0) finished in 0.005 s
19/07/31 12:51:49 INFO DAGScheduler: Job 18 finished: csv at NativeMethodAccessorImpl.java:0, took 0.008670 s
19/07/31 12:51:49 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:51:49 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:51:49 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:51:49 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:51:49 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 281.2 KB, free 909.7 MB)
19/07/31 12:51:49 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 23.8 KB, free 909.7 MB)
19/07/31 12:51:49 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:62226 (size: 23.8 KB, free: 912.0 MB)
19/07/31 12:51:49 INFO SparkContext: Created broadcast 35 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:51:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:51:49 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:51:49 INFO DAGScheduler: Got job 19 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:51:49 INFO DAGScheduler: Final stage: ResultStage 25 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:51:49 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:51:49 INFO DAGScheduler: Missing parents: List()
19/07/31 12:51:49 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[103] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:51:49 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 14.8 KB, free 909.6 MB)
19/07/31 12:51:49 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 8.6 KB, free 909.6 MB)
19/07/31 12:51:49 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:62226 (size: 8.6 KB, free: 912.0 MB)
19/07/31 12:51:49 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
19/07/31 12:51:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[103] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:51:49 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
19/07/31 12:51:49 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:51:49 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
19/07/31 12:51:49 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:51:49 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 1584 bytes result sent to driver
19/07/31 12:51:49 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 12 ms on localhost (executor driver) (1/1)
19/07/31 12:51:49 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
19/07/31 12:51:49 INFO DAGScheduler: ResultStage 25 (csv at NativeMethodAccessorImpl.java:0) finished in 0.012 s
19/07/31 12:51:49 INFO DAGScheduler: Job 19 finished: csv at NativeMethodAccessorImpl.java:0, took 0.017061 s
19/07/31 12:51:49 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:51:49 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:51:49 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:51:49 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:51:49 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:51:49 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:51:49 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:51:49 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 12:51:49 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 12:51:49 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 12:51:49 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:51:49 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:51:49 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 12:51:49 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:51:49 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 282.3 KB, free 909.4 MB)
19/07/31 12:51:49 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 24.0 KB, free 909.3 MB)
19/07/31 12:51:49 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:62226 (size: 24.0 KB, free: 912.0 MB)
19/07/31 12:51:49 INFO SparkContext: Created broadcast 37 from sql at <unknown>:0
19/07/31 12:51:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:51:49 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 12:51:49 INFO DAGScheduler: Registering RDD 109 (sql at <unknown>:0)
19/07/31 12:51:49 INFO DAGScheduler: Got job 20 (sql at <unknown>:0) with 1 output partitions
19/07/31 12:51:49 INFO DAGScheduler: Final stage: ResultStage 27 (sql at <unknown>:0)
19/07/31 12:51:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
19/07/31 12:51:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 26)
19/07/31 12:51:49 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[109] at sql at <unknown>:0), which has no missing parents
19/07/31 12:51:49 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 26.3 KB, free 909.3 MB)
19/07/31 12:51:49 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 11.9 KB, free 909.3 MB)
19/07/31 12:51:49 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:62226 (size: 11.9 KB, free: 912.0 MB)
19/07/31 12:51:49 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
19/07/31 12:51:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[109] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:51:49 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
19/07/31 12:51:49 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:51:49 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
19/07/31 12:51:49 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:51:49 INFO MemoryStore: Block rdd_106_0 stored as values in memory (estimated size 48.9 KB, free 909.2 MB)
19/07/31 12:51:49 INFO BlockManagerInfo: Added rdd_106_0 in memory on 127.0.0.1:62226 (size: 48.9 KB, free: 911.9 MB)
19/07/31 12:51:49 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 2461 bytes result sent to driver
19/07/31 12:51:49 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 39 ms on localhost (executor driver) (1/1)
19/07/31 12:51:49 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
19/07/31 12:51:49 INFO DAGScheduler: ShuffleMapStage 26 (sql at <unknown>:0) finished in 0.039 s
19/07/31 12:51:49 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:51:49 INFO DAGScheduler: running: Set()
19/07/31 12:51:49 INFO DAGScheduler: waiting: Set(ResultStage 27)
19/07/31 12:51:49 INFO DAGScheduler: failed: Set()
19/07/31 12:51:49 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[112] at sql at <unknown>:0), which has no missing parents
19/07/31 12:51:49 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 7.0 KB, free 909.2 MB)
19/07/31 12:51:49 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 3.7 KB, free 909.2 MB)
19/07/31 12:51:49 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:62226 (size: 3.7 KB, free: 911.9 MB)
19/07/31 12:51:49 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
19/07/31 12:51:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[112] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:51:49 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
19/07/31 12:51:49 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:51:49 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
19/07/31 12:51:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:51:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:51:49 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 1581 bytes result sent to driver
19/07/31 12:51:49 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 4 ms on localhost (executor driver) (1/1)
19/07/31 12:51:49 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
19/07/31 12:51:49 INFO DAGScheduler: ResultStage 27 (sql at <unknown>:0) finished in 0.004 s
19/07/31 12:51:49 INFO DAGScheduler: Job 20 finished: sql at <unknown>:0, took 0.052181 s
19/07/31 12:51:49 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 12:51:49 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:51:49 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:51:49 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:51:49 INFO DAGScheduler: Registering RDD 115 (collect at utils.scala:204)
19/07/31 12:51:49 INFO DAGScheduler: Got job 21 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:51:49 INFO DAGScheduler: Final stage: ResultStage 29 (collect at utils.scala:204)
19/07/31 12:51:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
19/07/31 12:51:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 28)
19/07/31 12:51:49 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[115] at collect at utils.scala:204), which has no missing parents
19/07/31 12:51:49 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 26.3 KB, free 909.2 MB)
19/07/31 12:51:49 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 11.9 KB, free 909.2 MB)
19/07/31 12:51:49 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:62226 (size: 11.9 KB, free: 911.9 MB)
19/07/31 12:51:49 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
19/07/31 12:51:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[115] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:51:49 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
19/07/31 12:51:49 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:51:49 INFO Executor: Running task 0.0 in stage 28.0 (TID 28)
19/07/31 12:51:49 INFO BlockManager: Found block rdd_106_0 locally
19/07/31 12:51:49 INFO Executor: Finished task 0.0 in stage 28.0 (TID 28). 1780 bytes result sent to driver
19/07/31 12:51:49 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 28) in 6 ms on localhost (executor driver) (1/1)
19/07/31 12:51:49 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
19/07/31 12:51:49 INFO DAGScheduler: ShuffleMapStage 28 (collect at utils.scala:204) finished in 0.007 s
19/07/31 12:51:49 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:51:49 INFO DAGScheduler: running: Set()
19/07/31 12:51:49 INFO DAGScheduler: waiting: Set(ResultStage 29)
19/07/31 12:51:49 INFO DAGScheduler: failed: Set()
19/07/31 12:51:49 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[118] at collect at utils.scala:204), which has no missing parents
19/07/31 12:51:49 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 7.0 KB, free 909.2 MB)
19/07/31 12:51:49 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 3.7 KB, free 909.2 MB)
19/07/31 12:51:49 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:62226 (size: 3.7 KB, free: 911.9 MB)
19/07/31 12:51:49 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
19/07/31 12:51:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[118] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:51:49 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
19/07/31 12:51:49 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 29, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:51:49 INFO Executor: Running task 0.0 in stage 29.0 (TID 29)
19/07/31 12:51:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:51:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:51:49 INFO Executor: Finished task 0.0 in stage 29.0 (TID 29). 1581 bytes result sent to driver
19/07/31 12:51:49 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 29) in 2 ms on localhost (executor driver) (1/1)
19/07/31 12:51:49 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
19/07/31 12:51:49 INFO DAGScheduler: ResultStage 29 (collect at utils.scala:204) finished in 0.004 s
19/07/31 12:51:49 INFO DAGScheduler: Job 21 finished: collect at utils.scala:204, took 0.019720 s
19/07/31 12:51:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz4`
WHERE (0 = 1)
19/07/31 12:51:50 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:51:50 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:51:50 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:51:50 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:51:50 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:51:50 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:51:50 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:54:22 INFO SparkContext: Running Spark version 2.2.0
19/07/31 12:54:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/07/31 12:54:22 INFO SparkContext: Submitted application: sparklyr
19/07/31 12:54:22 INFO SecurityManager: Changing view acls to: 6jncnk4f
19/07/31 12:54:22 INFO SecurityManager: Changing modify acls to: 6jncnk4f
19/07/31 12:54:22 INFO SecurityManager: Changing view acls groups to: 
19/07/31 12:54:22 INFO SecurityManager: Changing modify acls groups to: 
19/07/31 12:54:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(6jncnk4f); groups with view permissions: Set(); users  with modify permissions: Set(6jncnk4f); groups with modify permissions: Set()
19/07/31 12:54:22 INFO Utils: Successfully started service 'sparkDriver' on port 62561.
19/07/31 12:54:22 INFO SparkEnv: Registering MapOutputTracker
19/07/31 12:54:22 INFO SparkEnv: Registering BlockManagerMaster
19/07/31 12:54:22 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/07/31 12:54:22 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/07/31 12:54:22 INFO DiskBlockManager: Created local directory at /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/blockmgr-a7d6851c-6799-4b3f-9f0b-f5d0de0125e0
19/07/31 12:54:22 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/07/31 12:54:22 INFO SparkEnv: Registering OutputCommitCoordinator
19/07/31 12:54:22 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/07/31 12:54:22 INFO Utils: Successfully started service 'SparkUI' on port 4041.
19/07/31 12:54:22 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
19/07/31 12:54:22 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:62561/jars/sparklyr-2.0-2.11.jar with timestamp 1564592062867
19/07/31 12:54:22 INFO Executor: Starting executor ID driver on host localhost
19/07/31 12:54:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62562.
19/07/31 12:54:22 INFO NettyBlockTransferService: Server created on 127.0.0.1:62562
19/07/31 12:54:22 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/07/31 12:54:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 62562, None)
19/07/31 12:54:22 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:62562 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 62562, None)
19/07/31 12:54:22 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 62562, None)
19/07/31 12:54:22 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 62562, None)
19/07/31 12:54:23 INFO SharedState: loading hive config file: file:/Users/6jncnk4f/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/07/31 12:54:23 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse').
19/07/31 12:54:23 INFO SharedState: Warehouse path is 'file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse'.
19/07/31 12:54:23 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/07/31 12:54:24 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/07/31 12:54:24 INFO ObjectStore: ObjectStore, initialize called
19/07/31 12:54:24 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/07/31 12:54:24 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/07/31 12:54:25 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/07/31 12:54:26 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:54:26 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:54:27 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:54:27 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:54:27 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/07/31 12:54:27 INFO ObjectStore: Initialized ObjectStore
19/07/31 12:54:27 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/07/31 12:54:27 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/07/31 12:54:27 INFO HiveMetaStore: Added admin role in metastore
19/07/31 12:54:28 INFO HiveMetaStore: Added public role in metastore
19/07/31 12:54:28 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/07/31 12:54:28 INFO HiveMetaStore: 0: get_all_databases
19/07/31 12:54:28 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_all_databases	
19/07/31 12:54:28 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/07/31 12:54:28 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/07/31 12:54:28 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:54:28 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/d8fbdfb9-3bd6-4c6e-89a7-2d8491b5cc76_resources
19/07/31 12:54:28 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/d8fbdfb9-3bd6-4c6e-89a7-2d8491b5cc76
19/07/31 12:54:28 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/d8fbdfb9-3bd6-4c6e-89a7-2d8491b5cc76
19/07/31 12:54:28 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/d8fbdfb9-3bd6-4c6e-89a7-2d8491b5cc76/_tmp_space.db
19/07/31 12:54:28 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 12:54:28 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:54:28 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:54:28 INFO HiveMetaStore: 0: get_database: global_temp
19/07/31 12:54:28 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/07/31 12:54:28 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/07/31 12:54:28 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/09d56af9-e7b4-45d4-98f9-18fb2d41d79d_resources
19/07/31 12:54:28 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/09d56af9-e7b4-45d4-98f9-18fb2d41d79d
19/07/31 12:54:28 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/09d56af9-e7b4-45d4-98f9-18fb2d41d79d
19/07/31 12:54:28 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/09d56af9-e7b4-45d4-98f9-18fb2d41d79d/_tmp_space.db
19/07/31 12:54:28 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 12:54:28 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/07/31 12:54:28 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:54:30 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:54:30 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:54:30 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:54:30 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:54:30 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:54:30 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:54:30 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 12:54:30 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/07/31 12:54:30 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/07/31 12:54:30 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:54:30 INFO DAGScheduler: Missing parents: List()
19/07/31 12:54:30 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/07/31 12:54:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/07/31 12:54:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/07/31 12:54:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:62562 (size: 3.4 KB, free: 912.3 MB)
19/07/31 12:54:31 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/07/31 12:54:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 12:54:31 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/07/31 12:54:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/07/31 12:54:31 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/07/31 12:54:31 INFO Executor: Fetching spark://127.0.0.1:62561/jars/sparklyr-2.0-2.11.jar with timestamp 1564592062867
19/07/31 12:54:31 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:62561 after 11 ms (0 ms spent in bootstraps)
19/07/31 12:54:31 INFO Utils: Fetching spark://127.0.0.1:62561/jars/sparklyr-2.0-2.11.jar to /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-13c6afbd-8e03-4aad-a900-cd5bb6b01a08/userFiles-432c320f-8ac9-45a0-8833-31de1b8bf8b3/fetchFileTemp734846382097091926.tmp
19/07/31 12:54:31 INFO Executor: Adding file:/private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-13c6afbd-8e03-4aad-a900-cd5bb6b01a08/userFiles-432c320f-8ac9-45a0-8833-31de1b8bf8b3/sparklyr-2.0-2.11.jar to class loader
19/07/31 12:54:31 INFO CodeGenerator: Code generated in 292.651249 ms
19/07/31 12:54:31 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
19/07/31 12:54:31 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 575 ms on localhost (executor driver) (1/1)
19/07/31 12:54:31 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/07/31 12:54:31 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.595 s
19/07/31 12:54:31 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0.741741 s
19/07/31 12:54:32 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:54:32 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#10)) > 0)
19/07/31 12:54:32 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:54:32 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:54:32 INFO CodeGenerator: Code generated in 14.98478 ms
19/07/31 12:54:32 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 281.2 KB, free 912.0 MB)
19/07/31 12:54:32 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.8 KB, free 912.0 MB)
19/07/31 12:54:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:62562 (size: 23.8 KB, free: 912.3 MB)
19/07/31 12:54:32 INFO SparkContext: Created broadcast 1 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:54:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:54:32 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:54:32 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:54:32 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:54:32 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:54:32 INFO DAGScheduler: Missing parents: List()
19/07/31 12:54:32 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:54:32 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 912.0 MB)
19/07/31 12:54:32 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 912.0 MB)
19/07/31 12:54:32 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:62562 (size: 4.3 KB, free: 912.3 MB)
19/07/31 12:54:32 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/07/31 12:54:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:54:32 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/07/31 12:54:32 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:54:32 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/07/31 12:54:32 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:54:32 INFO CodeGenerator: Code generated in 8.608648 ms
19/07/31 12:54:32 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:62562 in memory (size: 3.4 KB, free: 912.3 MB)
19/07/31 12:54:32 INFO ContextCleaner: Cleaned accumulator 0
19/07/31 12:54:32 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1437 bytes result sent to driver
19/07/31 12:54:32 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 258 ms on localhost (executor driver) (1/1)
19/07/31 12:54:32 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/07/31 12:54:32 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0.260 s
19/07/31 12:54:32 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0.279104 s
19/07/31 12:54:32 INFO CodeGenerator: Code generated in 12.017738 ms
19/07/31 12:54:32 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:54:32 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:54:32 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:54:32 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:54:32 INFO CodeGenerator: Code generated in 9.443501 ms
19/07/31 12:54:32 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 281.2 KB, free 911.7 MB)
19/07/31 12:54:32 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.7 MB)
19/07/31 12:54:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:62562 (size: 23.8 KB, free: 912.2 MB)
19/07/31 12:54:32 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:54:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:54:32 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:54:32 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:54:32 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:54:32 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:54:32 INFO DAGScheduler: Missing parents: List()
19/07/31 12:54:32 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:54:32 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.8 KB, free 911.7 MB)
19/07/31 12:54:32 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.7 MB)
19/07/31 12:54:32 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:62562 (size: 8.6 KB, free: 912.2 MB)
19/07/31 12:54:32 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/07/31 12:54:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:54:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/07/31 12:54:32 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:54:32 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/07/31 12:54:32 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:54:32 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1627 bytes result sent to driver
19/07/31 12:54:32 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 77 ms on localhost (executor driver) (1/1)
19/07/31 12:54:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/07/31 12:54:32 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.078 s
19/07/31 12:54:32 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.085077 s
19/07/31 12:54:32 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:54:32 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:54:32 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:54:32 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:54:32 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:54:32 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:54:32 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:54:32 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 12:54:32 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 12:54:32 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 12:54:32 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:54:32 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:54:32 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 12:54:32 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:54:32 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 282.3 KB, free 911.4 MB)
19/07/31 12:54:32 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.4 MB)
19/07/31 12:54:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:62562 (size: 24.0 KB, free: 912.2 MB)
19/07/31 12:54:32 INFO SparkContext: Created broadcast 5 from sql at NativeMethodAccessorImpl.java:0
19/07/31 12:54:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:54:33 INFO CodeGenerator: Code generated in 14.79403 ms
19/07/31 12:54:33 INFO CodeGenerator: Code generated in 29.448265 ms
19/07/31 12:54:33 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 12:54:33 INFO DAGScheduler: Registering RDD 18 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 12:54:33 INFO DAGScheduler: Got job 3 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:54:33 INFO DAGScheduler: Final stage: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 12:54:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/07/31 12:54:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/07/31 12:54:33 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:54:33 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 26.3 KB, free 911.3 MB)
19/07/31 12:54:33 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.8 KB, free 911.3 MB)
19/07/31 12:54:33 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:62562 (size: 11.8 KB, free: 912.2 MB)
19/07/31 12:54:33 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/07/31 12:54:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:54:33 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/07/31 12:54:33 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:54:33 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/07/31 12:54:33 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:54:33 INFO CodeGenerator: Code generated in 21.983221 ms
19/07/31 12:54:33 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 48.9 KB, free 911.3 MB)
19/07/31 12:54:33 INFO BlockManagerInfo: Added rdd_15_0 in memory on 127.0.0.1:62562 (size: 48.9 KB, free: 912.2 MB)
19/07/31 12:54:33 INFO CodeGenerator: Code generated in 3.80786 ms
19/07/31 12:54:33 INFO CodeGenerator: Code generated in 13.295909 ms
19/07/31 12:54:33 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2504 bytes result sent to driver
19/07/31 12:54:33 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 281 ms on localhost (executor driver) (1/1)
19/07/31 12:54:33 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/07/31 12:54:33 INFO DAGScheduler: ShuffleMapStage 3 (sql at NativeMethodAccessorImpl.java:0) finished in 0.283 s
19/07/31 12:54:33 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:54:33 INFO DAGScheduler: running: Set()
19/07/31 12:54:33 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/07/31 12:54:33 INFO DAGScheduler: failed: Set()
19/07/31 12:54:33 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:54:33 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 911.3 MB)
19/07/31 12:54:33 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.3 MB)
19/07/31 12:54:33 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:62562 (size: 3.7 KB, free: 912.2 MB)
19/07/31 12:54:33 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/07/31 12:54:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:54:33 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/07/31 12:54:33 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:54:33 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/07/31 12:54:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:54:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
19/07/31 12:54:33 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1581 bytes result sent to driver
19/07/31 12:54:33 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 27 ms on localhost (executor driver) (1/1)
19/07/31 12:54:33 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/07/31 12:54:33 INFO DAGScheduler: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0) finished in 0.029 s
19/07/31 12:54:33 INFO DAGScheduler: Job 3 finished: sql at NativeMethodAccessorImpl.java:0, took 0.359196 s
19/07/31 12:54:33 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 12:54:33 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:54:33 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:54:33 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:54:33 INFO DAGScheduler: Registering RDD 24 (collect at utils.scala:204)
19/07/31 12:54:33 INFO DAGScheduler: Got job 4 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:54:33 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
19/07/31 12:54:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/07/31 12:54:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/07/31 12:54:33 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204), which has no missing parents
19/07/31 12:54:33 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 26.3 KB, free 911.2 MB)
19/07/31 12:54:33 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.9 KB, free 911.2 MB)
19/07/31 12:54:33 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:62562 (size: 11.9 KB, free: 912.1 MB)
19/07/31 12:54:33 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/07/31 12:54:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:54:33 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/07/31 12:54:33 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:54:33 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/07/31 12:54:33 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:54:33 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1780 bytes result sent to driver
19/07/31 12:54:33 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 12 ms on localhost (executor driver) (1/1)
19/07/31 12:54:33 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/07/31 12:54:33 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:204) finished in 0.013 s
19/07/31 12:54:33 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:54:33 INFO DAGScheduler: running: Set()
19/07/31 12:54:33 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/07/31 12:54:33 INFO DAGScheduler: failed: Set()
19/07/31 12:54:33 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204), which has no missing parents
19/07/31 12:54:33 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 911.2 MB)
19/07/31 12:54:33 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.2 MB)
19/07/31 12:54:33 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:62562 (size: 3.7 KB, free: 912.1 MB)
19/07/31 12:54:33 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/07/31 12:54:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:54:33 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/07/31 12:54:33 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:54:33 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/07/31 12:54:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:54:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:54:33 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1581 bytes result sent to driver
19/07/31 12:54:33 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 4 ms on localhost (executor driver) (1/1)
19/07/31 12:54:33 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/07/31 12:54:33 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.004 s
19/07/31 12:54:33 INFO DAGScheduler: Job 4 finished: collect at utils.scala:204, took 0.035632 s
19/07/31 12:54:33 INFO CodeGenerator: Code generated in 6.648382 ms
19/07/31 12:54:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz1`
WHERE (0 = 1)
19/07/31 12:54:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_001`) `dbplyr_002`
ORDER BY `date`) `dbplyr_003`) `dbplyr_004`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 12:54:34 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:54:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:54:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_005`) `dbplyr_006`
ORDER BY `date`) `dbplyr_007`) `dbplyr_008`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 12:54:34 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:54:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:54:34 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#442 - cust_prospect_ind.nullCount#441) > 0)
19/07/31 12:54:34 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#447 - visit_device_type.nullCount#446) > 0)
19/07/31 12:54:34 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#440 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#439))
19/07/31 12:54:34 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#445 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#444))
19/07/31 12:54:34 INFO CodeGenerator: Code generated in 20.616426 ms
19/07/31 12:54:34 INFO CodeGenerator: Code generated in 18.430327 ms
19/07/31 12:54:34 INFO CodeGenerator: Code generated in 5.98554 ms
19/07/31 12:54:34 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:54:34 INFO DAGScheduler: Got job 5 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:54:34 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:204)
19/07/31 12:54:34 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:54:34 INFO DAGScheduler: Missing parents: List()
19/07/31 12:54:34 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[32] at collect at utils.scala:204), which has no missing parents
19/07/31 12:54:34 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 72.1 KB, free 911.2 MB)
19/07/31 12:54:34 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 30.5 KB, free 911.1 MB)
19/07/31 12:54:34 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:62562 (size: 30.5 KB, free: 912.1 MB)
19/07/31 12:54:34 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/07/31 12:54:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:54:34 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/07/31 12:54:34 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:54:34 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
19/07/31 12:54:34 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:54:34 INFO CodeGenerator: Code generated in 7.253008 ms
19/07/31 12:54:34 INFO CodeGenerator: Code generated in 11.438969 ms
19/07/31 12:54:34 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 7585 bytes result sent to driver
19/07/31 12:54:34 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 49 ms on localhost (executor driver) (1/1)
19/07/31 12:54:34 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/07/31 12:54:34 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:204) finished in 0.049 s
19/07/31 12:54:34 INFO DAGScheduler: Job 5 finished: collect at utils.scala:204, took 0.059961 s
19/07/31 12:54:34 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:54:34 INFO DAGScheduler: Registering RDD 33 (collect at utils.scala:204)
19/07/31 12:54:34 INFO DAGScheduler: Got job 6 (collect at utils.scala:204) with 4 output partitions
19/07/31 12:54:34 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:204)
19/07/31 12:54:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
19/07/31 12:54:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
19/07/31 12:54:34 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[33] at collect at utils.scala:204), which has no missing parents
19/07/31 12:54:34 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 74.6 KB, free 911.1 MB)
19/07/31 12:54:34 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.0 MB)
19/07/31 12:54:34 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:62562 (size: 31.8 KB, free: 912.1 MB)
19/07/31 12:54:34 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/07/31 12:54:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[33] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:54:34 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/07/31 12:54:34 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:54:34 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
19/07/31 12:54:34 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:54:34 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1687 bytes result sent to driver
19/07/31 12:54:34 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 21 ms on localhost (executor driver) (1/1)
19/07/31 12:54:34 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/07/31 12:54:34 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:204) finished in 0.021 s
19/07/31 12:54:34 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:54:34 INFO DAGScheduler: running: Set()
19/07/31 12:54:34 INFO DAGScheduler: waiting: Set(ResultStage 9)
19/07/31 12:54:34 INFO DAGScheduler: failed: Set()
19/07/31 12:54:34 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[36] at collect at utils.scala:204), which has no missing parents
19/07/31 12:54:34 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 16.8 KB, free 911.0 MB)
19/07/31 12:54:34 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 8.1 KB, free 911.0 MB)
19/07/31 12:54:34 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:62562 (size: 8.1 KB, free: 912.1 MB)
19/07/31 12:54:34 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/07/31 12:54:34 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 9 (MapPartitionsRDD[36] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 12:54:34 INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks
19/07/31 12:54:34 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:54:34 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 10, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 12:54:34 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 11, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 12:54:34 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 12, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 12:54:34 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
19/07/31 12:54:34 INFO Executor: Running task 1.0 in stage 9.0 (TID 10)
19/07/31 12:54:34 INFO Executor: Running task 2.0 in stage 9.0 (TID 11)
19/07/31 12:54:34 INFO Executor: Running task 3.0 in stage 9.0 (TID 12)
19/07/31 12:54:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:54:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:54:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:54:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:54:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:54:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:54:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:54:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 12:54:34 INFO CodeGenerator: Code generated in 6.561792 ms
19/07/31 12:54:34 INFO Executor: Finished task 2.0 in stage 9.0 (TID 11). 2364 bytes result sent to driver
19/07/31 12:54:34 INFO Executor: Finished task 3.0 in stage 9.0 (TID 12). 2342 bytes result sent to driver
19/07/31 12:54:34 INFO Executor: Finished task 1.0 in stage 9.0 (TID 10). 2368 bytes result sent to driver
19/07/31 12:54:34 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 11) in 60 ms on localhost (executor driver) (1/4)
19/07/31 12:54:34 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 12) in 59 ms on localhost (executor driver) (2/4)
19/07/31 12:54:34 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 10) in 60 ms on localhost (executor driver) (3/4)
19/07/31 12:54:34 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2408 bytes result sent to driver
19/07/31 12:54:34 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 64 ms on localhost (executor driver) (4/4)
19/07/31 12:54:34 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/07/31 12:54:34 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:204) finished in 0.065 s
19/07/31 12:54:34 INFO DAGScheduler: Job 6 finished: collect at utils.scala:204, took 0.105655 s
19/07/31 12:54:34 INFO CodeGenerator: Code generated in 14.242402 ms
19/07/31 12:54:36 INFO SparkContext: Invoking stop() from shutdown hook
19/07/31 12:54:36 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
19/07/31 12:54:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/07/31 12:54:36 INFO MemoryStore: MemoryStore cleared
19/07/31 12:54:36 INFO BlockManager: BlockManager stopped
19/07/31 12:54:36 INFO BlockManagerMaster: BlockManagerMaster stopped
19/07/31 12:54:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/07/31 12:54:36 INFO SparkContext: Successfully stopped SparkContext
19/07/31 12:54:36 INFO ShutdownHookManager: Shutdown hook called
19/07/31 12:54:36 INFO ShutdownHookManager: Deleting directory /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-13c6afbd-8e03-4aad-a900-cd5bb6b01a08
19/07/31 12:57:20 INFO SparkContext: Running Spark version 2.2.0
19/07/31 12:57:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/07/31 12:57:21 INFO SparkContext: Submitted application: sparklyr
19/07/31 12:57:21 INFO SecurityManager: Changing view acls to: 6jncnk4f
19/07/31 12:57:21 INFO SecurityManager: Changing modify acls to: 6jncnk4f
19/07/31 12:57:21 INFO SecurityManager: Changing view acls groups to: 
19/07/31 12:57:21 INFO SecurityManager: Changing modify acls groups to: 
19/07/31 12:57:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(6jncnk4f); groups with view permissions: Set(); users  with modify permissions: Set(6jncnk4f); groups with modify permissions: Set()
19/07/31 12:57:21 INFO Utils: Successfully started service 'sparkDriver' on port 62619.
19/07/31 12:57:21 INFO SparkEnv: Registering MapOutputTracker
19/07/31 12:57:21 INFO SparkEnv: Registering BlockManagerMaster
19/07/31 12:57:21 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/07/31 12:57:21 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/07/31 12:57:21 INFO DiskBlockManager: Created local directory at /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/blockmgr-ea98878c-8abf-4da7-8102-1bebb10430d3
19/07/31 12:57:21 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/07/31 12:57:21 INFO SparkEnv: Registering OutputCommitCoordinator
19/07/31 12:57:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/07/31 12:57:21 INFO Utils: Successfully started service 'SparkUI' on port 4041.
19/07/31 12:57:21 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
19/07/31 12:57:21 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:62619/jars/sparklyr-2.0-2.11.jar with timestamp 1564592241764
19/07/31 12:57:21 INFO Executor: Starting executor ID driver on host localhost
19/07/31 12:57:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62620.
19/07/31 12:57:21 INFO NettyBlockTransferService: Server created on 127.0.0.1:62620
19/07/31 12:57:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/07/31 12:57:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 62620, None)
19/07/31 12:57:21 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:62620 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 62620, None)
19/07/31 12:57:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 62620, None)
19/07/31 12:57:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 62620, None)
19/07/31 12:57:22 INFO SharedState: loading hive config file: file:/Users/6jncnk4f/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/07/31 12:57:22 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse').
19/07/31 12:57:22 INFO SharedState: Warehouse path is 'file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse'.
19/07/31 12:57:22 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/07/31 12:57:23 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/07/31 12:57:23 INFO ObjectStore: ObjectStore, initialize called
19/07/31 12:57:23 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/07/31 12:57:23 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/07/31 12:57:24 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/07/31 12:57:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:57:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:57:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:57:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:57:25 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/07/31 12:57:25 INFO ObjectStore: Initialized ObjectStore
19/07/31 12:57:25 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/07/31 12:57:25 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/07/31 12:57:25 INFO HiveMetaStore: Added admin role in metastore
19/07/31 12:57:25 INFO HiveMetaStore: Added public role in metastore
19/07/31 12:57:26 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/07/31 12:57:26 INFO HiveMetaStore: 0: get_all_databases
19/07/31 12:57:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_all_databases	
19/07/31 12:57:26 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/07/31 12:57:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/07/31 12:57:26 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 12:57:26 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/2ea29cc8-94b2-46f4-8f9b-46921b5f63d8_resources
19/07/31 12:57:26 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/2ea29cc8-94b2-46f4-8f9b-46921b5f63d8
19/07/31 12:57:26 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/2ea29cc8-94b2-46f4-8f9b-46921b5f63d8
19/07/31 12:57:26 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/2ea29cc8-94b2-46f4-8f9b-46921b5f63d8/_tmp_space.db
19/07/31 12:57:26 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 12:57:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:26 INFO HiveMetaStore: 0: get_database: global_temp
19/07/31 12:57:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/07/31 12:57:26 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/07/31 12:57:26 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/e8101e81-eddc-490a-b503-1721d4123532_resources
19/07/31 12:57:26 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/e8101e81-eddc-490a-b503-1721d4123532
19/07/31 12:57:26 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/e8101e81-eddc-490a-b503-1721d4123532
19/07/31 12:57:26 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/e8101e81-eddc-490a-b503-1721d4123532/_tmp_space.db
19/07/31 12:57:26 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 12:57:26 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/07/31 12:57:26 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:57:27 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:27 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:27 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:27 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:27 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:57:27 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:57:28 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 12:57:28 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/07/31 12:57:28 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/07/31 12:57:28 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:57:28 INFO DAGScheduler: Missing parents: List()
19/07/31 12:57:28 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/07/31 12:57:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/07/31 12:57:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/07/31 12:57:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:62620 (size: 3.4 KB, free: 912.3 MB)
19/07/31 12:57:28 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/07/31 12:57:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/07/31 12:57:28 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/07/31 12:57:28 INFO Executor: Fetching spark://127.0.0.1:62619/jars/sparklyr-2.0-2.11.jar with timestamp 1564592241764
19/07/31 12:57:28 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:62619 after 12 ms (0 ms spent in bootstraps)
19/07/31 12:57:28 INFO Utils: Fetching spark://127.0.0.1:62619/jars/sparklyr-2.0-2.11.jar to /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-a3b19faf-681e-4802-884a-4c4a32641455/userFiles-74ba051c-0e8e-4ba1-8039-8669ba5cb0f0/fetchFileTemp9180288722531947051.tmp
19/07/31 12:57:28 INFO Executor: Adding file:/private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-a3b19faf-681e-4802-884a-4c4a32641455/userFiles-74ba051c-0e8e-4ba1-8039-8669ba5cb0f0/sparklyr-2.0-2.11.jar to class loader
19/07/31 12:57:28 INFO CodeGenerator: Code generated in 187.967067 ms
19/07/31 12:57:28 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
19/07/31 12:57:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 454 ms on localhost (executor driver) (1/1)
19/07/31 12:57:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/07/31 12:57:28 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.470 s
19/07/31 12:57:28 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0.589816 s
19/07/31 12:57:29 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:57:29 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#10)) > 0)
19/07/31 12:57:29 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:57:29 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:57:29 INFO CodeGenerator: Code generated in 19.258366 ms
19/07/31 12:57:29 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 281.2 KB, free 912.0 MB)
19/07/31 12:57:29 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.8 KB, free 912.0 MB)
19/07/31 12:57:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:62620 (size: 23.8 KB, free: 912.3 MB)
19/07/31 12:57:29 INFO SparkContext: Created broadcast 1 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:57:29 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:62620 in memory (size: 3.4 KB, free: 912.3 MB)
19/07/31 12:57:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:57:29 INFO ContextCleaner: Cleaned accumulator 0
19/07/31 12:57:29 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:57:29 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:57:29 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:57:29 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:57:29 INFO DAGScheduler: Missing parents: List()
19/07/31 12:57:29 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:57:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 912.0 MB)
19/07/31 12:57:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 912.0 MB)
19/07/31 12:57:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:62620 (size: 4.3 KB, free: 912.3 MB)
19/07/31 12:57:29 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/07/31 12:57:29 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:57:29 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/07/31 12:57:29 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:57:29 INFO CodeGenerator: Code generated in 8.935238 ms
19/07/31 12:57:29 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1437 bytes result sent to driver
19/07/31 12:57:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 174 ms on localhost (executor driver) (1/1)
19/07/31 12:57:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/07/31 12:57:29 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0.174 s
19/07/31 12:57:29 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0.188360 s
19/07/31 12:57:29 INFO CodeGenerator: Code generated in 4.835464 ms
19/07/31 12:57:29 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:57:29 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:57:29 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 12:57:29 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:57:29 INFO CodeGenerator: Code generated in 5.619226 ms
19/07/31 12:57:29 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 281.2 KB, free 911.7 MB)
19/07/31 12:57:29 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.7 MB)
19/07/31 12:57:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:62620 (size: 23.8 KB, free: 912.2 MB)
19/07/31 12:57:29 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:0
19/07/31 12:57:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:57:29 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:57:29 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:57:29 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:57:29 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:57:29 INFO DAGScheduler: Missing parents: List()
19/07/31 12:57:29 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:57:29 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.8 KB, free 911.7 MB)
19/07/31 12:57:29 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.7 MB)
19/07/31 12:57:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:62620 (size: 8.6 KB, free: 912.2 MB)
19/07/31 12:57:29 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:29 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/07/31 12:57:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:57:29 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/07/31 12:57:29 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:57:29 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1584 bytes result sent to driver
19/07/31 12:57:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 79 ms on localhost (executor driver) (1/1)
19/07/31 12:57:29 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/07/31 12:57:29 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.080 s
19/07/31 12:57:29 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.087646 s
19/07/31 12:57:29 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:57:29 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:29 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:29 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:29 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:29 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:57:29 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:57:29 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 12:57:29 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 12:57:29 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 12:57:29 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 12:57:29 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 12:57:29 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 12:57:29 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 12:57:29 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 282.3 KB, free 911.4 MB)
19/07/31 12:57:30 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.4 MB)
19/07/31 12:57:30 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:62620 (size: 24.0 KB, free: 912.2 MB)
19/07/31 12:57:30 INFO SparkContext: Created broadcast 5 from sql at NativeMethodAccessorImpl.java:0
19/07/31 12:57:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 12:57:30 INFO CodeGenerator: Code generated in 9.0915 ms
19/07/31 12:57:30 INFO CodeGenerator: Code generated in 8.402844 ms
19/07/31 12:57:30 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 12:57:30 INFO DAGScheduler: Registering RDD 18 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 12:57:30 INFO DAGScheduler: Got job 3 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:57:30 INFO DAGScheduler: Final stage: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 12:57:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/07/31 12:57:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/07/31 12:57:30 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:57:30 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 26.3 KB, free 911.3 MB)
19/07/31 12:57:30 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.8 KB, free 911.3 MB)
19/07/31 12:57:30 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:62620 (size: 11.8 KB, free: 912.2 MB)
19/07/31 12:57:30 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:30 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/07/31 12:57:30 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:57:30 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/07/31 12:57:30 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 12:57:30 INFO CodeGenerator: Code generated in 15.725074 ms
19/07/31 12:57:30 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 48.9 KB, free 911.3 MB)
19/07/31 12:57:30 INFO BlockManagerInfo: Added rdd_15_0 in memory on 127.0.0.1:62620 (size: 48.9 KB, free: 912.2 MB)
19/07/31 12:57:30 INFO CodeGenerator: Code generated in 3.997629 ms
19/07/31 12:57:30 INFO CodeGenerator: Code generated in 19.096697 ms
19/07/31 12:57:30 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2504 bytes result sent to driver
19/07/31 12:57:30 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 238 ms on localhost (executor driver) (1/1)
19/07/31 12:57:30 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/07/31 12:57:30 INFO DAGScheduler: ShuffleMapStage 3 (sql at NativeMethodAccessorImpl.java:0) finished in 0.239 s
19/07/31 12:57:30 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:57:30 INFO DAGScheduler: running: Set()
19/07/31 12:57:30 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/07/31 12:57:30 INFO DAGScheduler: failed: Set()
19/07/31 12:57:30 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:57:30 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 911.3 MB)
19/07/31 12:57:30 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.3 MB)
19/07/31 12:57:30 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:62620 (size: 3.7 KB, free: 912.2 MB)
19/07/31 12:57:30 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:30 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/07/31 12:57:30 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:57:30 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/07/31 12:57:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
19/07/31 12:57:30 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1581 bytes result sent to driver
19/07/31 12:57:30 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 30 ms on localhost (executor driver) (1/1)
19/07/31 12:57:30 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/07/31 12:57:30 INFO DAGScheduler: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0) finished in 0.030 s
19/07/31 12:57:30 INFO DAGScheduler: Job 3 finished: sql at NativeMethodAccessorImpl.java:0, took 0.314759 s
19/07/31 12:57:30 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 12:57:30 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:30 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:30 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:57:30 INFO DAGScheduler: Registering RDD 24 (collect at utils.scala:204)
19/07/31 12:57:30 INFO DAGScheduler: Got job 4 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:57:30 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
19/07/31 12:57:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/07/31 12:57:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/07/31 12:57:30 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:30 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 26.3 KB, free 911.2 MB)
19/07/31 12:57:30 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.9 KB, free 911.2 MB)
19/07/31 12:57:30 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:62620 (size: 11.9 KB, free: 912.1 MB)
19/07/31 12:57:30 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:30 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/07/31 12:57:30 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:57:30 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/07/31 12:57:30 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:57:30 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1780 bytes result sent to driver
19/07/31 12:57:30 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 14 ms on localhost (executor driver) (1/1)
19/07/31 12:57:30 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/07/31 12:57:30 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:204) finished in 0.015 s
19/07/31 12:57:30 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:57:30 INFO DAGScheduler: running: Set()
19/07/31 12:57:30 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/07/31 12:57:30 INFO DAGScheduler: failed: Set()
19/07/31 12:57:30 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:30 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 911.2 MB)
19/07/31 12:57:30 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.2 MB)
19/07/31 12:57:30 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:62620 (size: 3.7 KB, free: 912.1 MB)
19/07/31 12:57:30 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:30 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/07/31 12:57:30 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:57:30 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/07/31 12:57:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:30 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1581 bytes result sent to driver
19/07/31 12:57:30 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 4 ms on localhost (executor driver) (1/1)
19/07/31 12:57:30 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/07/31 12:57:30 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.005 s
19/07/31 12:57:30 INFO DAGScheduler: Job 4 finished: collect at utils.scala:204, took 0.050385 s
19/07/31 12:57:30 INFO CodeGenerator: Code generated in 5.694673 ms
19/07/31 12:57:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz1`
WHERE (0 = 1)
19/07/31 12:57:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_001`) `dbplyr_002`
ORDER BY `date`) `dbplyr_003`) `dbplyr_004`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 12:57:30 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:30 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_005`) `dbplyr_006`
ORDER BY `date`) `dbplyr_007`) `dbplyr_008`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 12:57:31 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:31 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:31 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#442 - cust_prospect_ind.nullCount#441) > 0)
19/07/31 12:57:31 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#447 - visit_device_type.nullCount#446) > 0)
19/07/31 12:57:31 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#440 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#439))
19/07/31 12:57:31 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#445 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#444))
19/07/31 12:57:31 INFO CodeGenerator: Code generated in 17.400959 ms
19/07/31 12:57:31 INFO CodeGenerator: Code generated in 16.082641 ms
19/07/31 12:57:31 INFO CodeGenerator: Code generated in 6.601714 ms
19/07/31 12:57:31 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:57:31 INFO DAGScheduler: Got job 5 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:57:31 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:204)
19/07/31 12:57:31 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:57:31 INFO DAGScheduler: Missing parents: List()
19/07/31 12:57:31 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[32] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:31 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 72.1 KB, free 911.2 MB)
19/07/31 12:57:31 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.1 MB)
19/07/31 12:57:31 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:62620 (size: 30.4 KB, free: 912.1 MB)
19/07/31 12:57:31 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:31 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/07/31 12:57:31 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:57:31 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
19/07/31 12:57:31 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:57:31 INFO CodeGenerator: Code generated in 9.601875 ms
19/07/31 12:57:31 INFO CodeGenerator: Code generated in 13.129736 ms
19/07/31 12:57:31 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 7585 bytes result sent to driver
19/07/31 12:57:31 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 58 ms on localhost (executor driver) (1/1)
19/07/31 12:57:31 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/07/31 12:57:31 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:204) finished in 0.059 s
19/07/31 12:57:31 INFO DAGScheduler: Job 5 finished: collect at utils.scala:204, took 0.068516 s
19/07/31 12:57:31 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:57:31 INFO DAGScheduler: Registering RDD 33 (collect at utils.scala:204)
19/07/31 12:57:31 INFO DAGScheduler: Got job 6 (collect at utils.scala:204) with 4 output partitions
19/07/31 12:57:31 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:204)
19/07/31 12:57:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
19/07/31 12:57:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
19/07/31 12:57:31 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[33] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:31 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 74.6 KB, free 911.1 MB)
19/07/31 12:57:31 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.0 MB)
19/07/31 12:57:31 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:62620 (size: 31.8 KB, free: 912.1 MB)
19/07/31 12:57:31 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[33] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:31 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/07/31 12:57:31 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:57:31 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
19/07/31 12:57:31 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:57:31 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1687 bytes result sent to driver
19/07/31 12:57:31 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 23 ms on localhost (executor driver) (1/1)
19/07/31 12:57:31 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/07/31 12:57:31 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:204) finished in 0.023 s
19/07/31 12:57:31 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:57:31 INFO DAGScheduler: running: Set()
19/07/31 12:57:31 INFO DAGScheduler: waiting: Set(ResultStage 9)
19/07/31 12:57:31 INFO DAGScheduler: failed: Set()
19/07/31 12:57:31 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[36] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:31 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 16.8 KB, free 911.0 MB)
19/07/31 12:57:31 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 8.1 KB, free 911.0 MB)
19/07/31 12:57:31 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:62620 (size: 8.1 KB, free: 912.1 MB)
19/07/31 12:57:31 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:31 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 9 (MapPartitionsRDD[36] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 12:57:31 INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks
19/07/31 12:57:31 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:57:31 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 10, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 12:57:31 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 11, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 12:57:31 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 12, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 12:57:31 INFO Executor: Running task 1.0 in stage 9.0 (TID 10)
19/07/31 12:57:31 INFO Executor: Running task 3.0 in stage 9.0 (TID 12)
19/07/31 12:57:31 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
19/07/31 12:57:31 INFO Executor: Running task 2.0 in stage 9.0 (TID 11)
19/07/31 12:57:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:31 INFO CodeGenerator: Code generated in 9.629289 ms
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 124
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 121
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 181
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 183
19/07/31 12:57:31 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:62620 in memory (size: 8.6 KB, free: 912.1 MB)
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 114
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 186
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 178
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 236
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 179
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 117
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 120
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 122
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 123
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 187
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 185
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 125
19/07/31 12:57:31 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:62620 in memory (size: 11.8 KB, free: 912.1 MB)
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 126
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 116
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 118
19/07/31 12:57:31 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:62620 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 180
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 119
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 182
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 184
19/07/31 12:57:31 INFO Executor: Finished task 1.0 in stage 9.0 (TID 10). 2411 bytes result sent to driver
19/07/31 12:57:31 INFO Executor: Finished task 2.0 in stage 9.0 (TID 11). 2407 bytes result sent to driver
19/07/31 12:57:31 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 10) in 64 ms on localhost (executor driver) (1/4)
19/07/31 12:57:31 INFO ContextCleaner: Cleaned shuffle 0
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 115
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 177
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 176
19/07/31 12:57:31 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 11) in 64 ms on localhost (executor driver) (2/4)
19/07/31 12:57:31 INFO ContextCleaner: Cleaned shuffle 1
19/07/31 12:57:31 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:62620 in memory (size: 31.8 KB, free: 912.1 MB)
19/07/31 12:57:31 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2408 bytes result sent to driver
19/07/31 12:57:31 INFO Executor: Finished task 3.0 in stage 9.0 (TID 12). 2385 bytes result sent to driver
19/07/31 12:57:31 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 66 ms on localhost (executor driver) (3/4)
19/07/31 12:57:31 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:62620 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 12:57:31 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 12) in 66 ms on localhost (executor driver) (4/4)
19/07/31 12:57:31 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/07/31 12:57:31 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:62620 in memory (size: 30.4 KB, free: 912.2 MB)
19/07/31 12:57:31 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:204) finished in 0.068 s
19/07/31 12:57:31 INFO ContextCleaner: Cleaned accumulator 175
19/07/31 12:57:31 INFO DAGScheduler: Job 6 finished: collect at utils.scala:204, took 0.107734 s
19/07/31 12:57:31 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:62620 in memory (size: 11.9 KB, free: 912.2 MB)
19/07/31 12:57:31 INFO CodeGenerator: Code generated in 10.818292 ms
19/07/31 12:57:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_009`) `dbplyr_010`
ORDER BY `date`) `dbplyr_011`) `dbplyr_012`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Mobile Phone"))
19/07/31 12:57:32 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:32 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_013`) `dbplyr_014`
ORDER BY `date`) `dbplyr_015`) `dbplyr_016`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Mobile Phone"))
19/07/31 12:57:32 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:32 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:32 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#540 - cust_prospect_ind.nullCount#539) > 0)
19/07/31 12:57:32 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#545 - visit_device_type.nullCount#544) > 0)
19/07/31 12:57:32 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#538 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#537))
19/07/31 12:57:32 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#543 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#542))
19/07/31 12:57:32 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:57:32 INFO DAGScheduler: Got job 7 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:57:32 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:204)
19/07/31 12:57:32 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:57:32 INFO DAGScheduler: Missing parents: List()
19/07/31 12:57:32 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[41] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:32 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 72.1 KB, free 911.3 MB)
19/07/31 12:57:32 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 30.5 KB, free 911.2 MB)
19/07/31 12:57:32 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:62620 (size: 30.5 KB, free: 912.1 MB)
19/07/31 12:57:32 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[41] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:32 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/07/31 12:57:32 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:57:32 INFO Executor: Running task 0.0 in stage 10.0 (TID 13)
19/07/31 12:57:32 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:57:32 INFO Executor: Finished task 0.0 in stage 10.0 (TID 13). 7022 bytes result sent to driver
19/07/31 12:57:32 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 13) in 12 ms on localhost (executor driver) (1/1)
19/07/31 12:57:32 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/07/31 12:57:32 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:204) finished in 0.012 s
19/07/31 12:57:32 INFO DAGScheduler: Job 7 finished: collect at utils.scala:204, took 0.021950 s
19/07/31 12:57:32 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:57:32 INFO DAGScheduler: Registering RDD 42 (collect at utils.scala:204)
19/07/31 12:57:32 INFO DAGScheduler: Got job 8 (collect at utils.scala:204) with 4 output partitions
19/07/31 12:57:32 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:204)
19/07/31 12:57:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
19/07/31 12:57:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
19/07/31 12:57:32 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[42] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:32 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 74.5 KB, free 911.1 MB)
19/07/31 12:57:32 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.1 MB)
19/07/31 12:57:32 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:62620 (size: 31.8 KB, free: 912.1 MB)
19/07/31 12:57:32 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[42] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:32 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/07/31 12:57:32 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:57:32 INFO Executor: Running task 0.0 in stage 11.0 (TID 14)
19/07/31 12:57:32 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:57:32 INFO Executor: Finished task 0.0 in stage 11.0 (TID 14). 1687 bytes result sent to driver
19/07/31 12:57:32 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 14) in 15 ms on localhost (executor driver) (1/1)
19/07/31 12:57:32 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/07/31 12:57:32 INFO DAGScheduler: ShuffleMapStage 11 (collect at utils.scala:204) finished in 0.016 s
19/07/31 12:57:32 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:57:32 INFO DAGScheduler: running: Set()
19/07/31 12:57:32 INFO DAGScheduler: waiting: Set(ResultStage 12)
19/07/31 12:57:32 INFO DAGScheduler: failed: Set()
19/07/31 12:57:32 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[45] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:32 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 16.8 KB, free 911.1 MB)
19/07/31 12:57:32 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 8.1 KB, free 911.1 MB)
19/07/31 12:57:32 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:62620 (size: 8.1 KB, free: 912.1 MB)
19/07/31 12:57:32 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:32 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 12 (MapPartitionsRDD[45] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 12:57:32 INFO TaskSchedulerImpl: Adding task set 12.0 with 4 tasks
19/07/31 12:57:32 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 15, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:57:32 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 16, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 12:57:32 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 17, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 12:57:32 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 18, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 12:57:32 INFO Executor: Running task 0.0 in stage 12.0 (TID 15)
19/07/31 12:57:32 INFO Executor: Running task 1.0 in stage 12.0 (TID 16)
19/07/31 12:57:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 12:57:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:32 INFO Executor: Running task 2.0 in stage 12.0 (TID 17)
19/07/31 12:57:32 INFO Executor: Running task 3.0 in stage 12.0 (TID 18)
19/07/31 12:57:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:32 INFO Executor: Finished task 1.0 in stage 12.0 (TID 16). 2353 bytes result sent to driver
19/07/31 12:57:32 INFO Executor: Finished task 2.0 in stage 12.0 (TID 17). 2357 bytes result sent to driver
19/07/31 12:57:32 INFO Executor: Finished task 3.0 in stage 12.0 (TID 18). 2341 bytes result sent to driver
19/07/31 12:57:32 INFO Executor: Finished task 0.0 in stage 12.0 (TID 15). 2348 bytes result sent to driver
19/07/31 12:57:32 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 16) in 14 ms on localhost (executor driver) (1/4)
19/07/31 12:57:32 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 17) in 13 ms on localhost (executor driver) (2/4)
19/07/31 12:57:32 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 18) in 14 ms on localhost (executor driver) (3/4)
19/07/31 12:57:32 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 15) in 15 ms on localhost (executor driver) (4/4)
19/07/31 12:57:32 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/07/31 12:57:32 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:204) finished in 0.017 s
19/07/31 12:57:32 INFO DAGScheduler: Job 8 finished: collect at utils.scala:204, took 0.047737 s
19/07/31 12:57:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_017`) `dbplyr_018`
ORDER BY `date`) `dbplyr_019`) `dbplyr_020`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Mobile Phone"))
19/07/31 12:57:33 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:33 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_021`) `dbplyr_022`
ORDER BY `date`) `dbplyr_023`) `dbplyr_024`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Mobile Phone"))
19/07/31 12:57:33 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:33 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:33 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#638 - cust_prospect_ind.nullCount#637) > 0)
19/07/31 12:57:33 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#643 - visit_device_type.nullCount#642) > 0)
19/07/31 12:57:33 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#636 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#635))
19/07/31 12:57:33 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#641 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#640))
19/07/31 12:57:33 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:57:33 INFO DAGScheduler: Got job 9 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:57:33 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:204)
19/07/31 12:57:33 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:57:33 INFO DAGScheduler: Missing parents: List()
19/07/31 12:57:33 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[50] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:33 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 72.1 KB, free 911.0 MB)
19/07/31 12:57:33 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 30.5 KB, free 911.0 MB)
19/07/31 12:57:33 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:62620 (size: 30.5 KB, free: 912.1 MB)
19/07/31 12:57:33 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[50] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:33 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/07/31 12:57:33 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:57:33 INFO Executor: Running task 0.0 in stage 13.0 (TID 19)
19/07/31 12:57:33 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:57:33 INFO Executor: Finished task 0.0 in stage 13.0 (TID 19). 7022 bytes result sent to driver
19/07/31 12:57:33 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 19) in 10 ms on localhost (executor driver) (1/1)
19/07/31 12:57:33 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/07/31 12:57:33 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:204) finished in 0.010 s
19/07/31 12:57:33 INFO DAGScheduler: Job 9 finished: collect at utils.scala:204, took 0.017499 s
19/07/31 12:57:33 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:57:33 INFO DAGScheduler: Registering RDD 51 (collect at utils.scala:204)
19/07/31 12:57:33 INFO DAGScheduler: Got job 10 (collect at utils.scala:204) with 4 output partitions
19/07/31 12:57:33 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:204)
19/07/31 12:57:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
19/07/31 12:57:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
19/07/31 12:57:33 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[51] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:33 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 74.5 KB, free 910.9 MB)
19/07/31 12:57:33 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.9 MB)
19/07/31 12:57:33 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:62620 (size: 31.8 KB, free: 912.0 MB)
19/07/31 12:57:33 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[51] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:33 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/07/31 12:57:33 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:57:33 INFO Executor: Running task 0.0 in stage 14.0 (TID 20)
19/07/31 12:57:33 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:57:33 INFO Executor: Finished task 0.0 in stage 14.0 (TID 20). 1687 bytes result sent to driver
19/07/31 12:57:33 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 20) in 12 ms on localhost (executor driver) (1/1)
19/07/31 12:57:33 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/07/31 12:57:33 INFO DAGScheduler: ShuffleMapStage 14 (collect at utils.scala:204) finished in 0.012 s
19/07/31 12:57:33 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:57:33 INFO DAGScheduler: running: Set()
19/07/31 12:57:33 INFO DAGScheduler: waiting: Set(ResultStage 15)
19/07/31 12:57:33 INFO DAGScheduler: failed: Set()
19/07/31 12:57:33 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[54] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:33 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 16.8 KB, free 910.9 MB)
19/07/31 12:57:33 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 8.1 KB, free 910.9 MB)
19/07/31 12:57:33 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:62620 (size: 8.1 KB, free: 912.0 MB)
19/07/31 12:57:33 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:33 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 12:57:33 INFO TaskSchedulerImpl: Adding task set 15.0 with 4 tasks
19/07/31 12:57:33 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 21, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:57:33 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 22, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 12:57:33 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 23, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 12:57:33 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 24, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 12:57:33 INFO Executor: Running task 0.0 in stage 15.0 (TID 21)
19/07/31 12:57:33 INFO Executor: Running task 3.0 in stage 15.0 (TID 24)
19/07/31 12:57:33 INFO Executor: Running task 1.0 in stage 15.0 (TID 22)
19/07/31 12:57:33 INFO Executor: Running task 2.0 in stage 15.0 (TID 23)
19/07/31 12:57:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:33 INFO Executor: Finished task 1.0 in stage 15.0 (TID 22). 2329 bytes result sent to driver
19/07/31 12:57:33 INFO Executor: Finished task 3.0 in stage 15.0 (TID 24). 2333 bytes result sent to driver
19/07/31 12:57:33 INFO Executor: Finished task 0.0 in stage 15.0 (TID 21). 2348 bytes result sent to driver
19/07/31 12:57:33 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 22) in 7 ms on localhost (executor driver) (1/4)
19/07/31 12:57:33 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 24) in 6 ms on localhost (executor driver) (2/4)
19/07/31 12:57:33 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 21) in 8 ms on localhost (executor driver) (3/4)
19/07/31 12:57:33 INFO Executor: Finished task 2.0 in stage 15.0 (TID 23). 2350 bytes result sent to driver
19/07/31 12:57:33 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 23) in 7 ms on localhost (executor driver) (4/4)
19/07/31 12:57:33 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/07/31 12:57:33 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:204) finished in 0.009 s
19/07/31 12:57:33 INFO DAGScheduler: Job 10 finished: collect at utils.scala:204, took 0.033500 s
19/07/31 12:57:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_025`) `dbplyr_026`
ORDER BY `date`) `dbplyr_027`) `dbplyr_028`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Desktop"))
19/07/31 12:57:34 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_029`) `dbplyr_030`
ORDER BY `date`) `dbplyr_031`) `dbplyr_032`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Desktop"))
19/07/31 12:57:34 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:34 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#736 - cust_prospect_ind.nullCount#735) > 0)
19/07/31 12:57:34 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#741 - visit_device_type.nullCount#740) > 0)
19/07/31 12:57:34 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#734 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#733))
19/07/31 12:57:34 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#739 <= Desktop) && (Desktop <= visit_device_type.upperBound#738))
19/07/31 12:57:34 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:57:34 INFO DAGScheduler: Got job 11 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:57:34 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:204)
19/07/31 12:57:34 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:57:34 INFO DAGScheduler: Missing parents: List()
19/07/31 12:57:34 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[59] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:34 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 72.1 KB, free 910.8 MB)
19/07/31 12:57:34 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.8 MB)
19/07/31 12:57:34 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:62620 (size: 30.4 KB, free: 912.0 MB)
19/07/31 12:57:34 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[59] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:34 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/07/31 12:57:34 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:57:34 INFO Executor: Running task 0.0 in stage 16.0 (TID 25)
19/07/31 12:57:34 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:57:34 INFO Executor: Finished task 0.0 in stage 16.0 (TID 25). 7068 bytes result sent to driver
19/07/31 12:57:34 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 25) in 8 ms on localhost (executor driver) (1/1)
19/07/31 12:57:34 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/07/31 12:57:34 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:204) finished in 0.008 s
19/07/31 12:57:34 INFO DAGScheduler: Job 11 finished: collect at utils.scala:204, took 0.015495 s
19/07/31 12:57:34 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:57:34 INFO DAGScheduler: Registering RDD 60 (collect at utils.scala:204)
19/07/31 12:57:34 INFO DAGScheduler: Got job 12 (collect at utils.scala:204) with 4 output partitions
19/07/31 12:57:34 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:204)
19/07/31 12:57:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
19/07/31 12:57:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
19/07/31 12:57:34 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[60] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:34 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 74.5 KB, free 910.7 MB)
19/07/31 12:57:34 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.7 MB)
19/07/31 12:57:34 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:62620 (size: 31.7 KB, free: 912.0 MB)
19/07/31 12:57:34 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[60] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:34 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
19/07/31 12:57:34 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:57:34 INFO Executor: Running task 0.0 in stage 17.0 (TID 26)
19/07/31 12:57:34 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:57:34 INFO Executor: Finished task 0.0 in stage 17.0 (TID 26). 1687 bytes result sent to driver
19/07/31 12:57:34 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 26) in 15 ms on localhost (executor driver) (1/1)
19/07/31 12:57:34 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/07/31 12:57:34 INFO DAGScheduler: ShuffleMapStage 17 (collect at utils.scala:204) finished in 0.016 s
19/07/31 12:57:34 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:57:34 INFO DAGScheduler: running: Set()
19/07/31 12:57:34 INFO DAGScheduler: waiting: Set(ResultStage 18)
19/07/31 12:57:34 INFO DAGScheduler: failed: Set()
19/07/31 12:57:34 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[63] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:34 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 16.8 KB, free 910.6 MB)
19/07/31 12:57:34 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 8.1 KB, free 910.6 MB)
19/07/31 12:57:34 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:62620 (size: 8.1 KB, free: 912.0 MB)
19/07/31 12:57:34 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:34 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 18 (MapPartitionsRDD[63] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 12:57:34 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks
19/07/31 12:57:34 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 27, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:57:34 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 28, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 12:57:34 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 29, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 12:57:34 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 30, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 12:57:34 INFO Executor: Running task 3.0 in stage 18.0 (TID 30)
19/07/31 12:57:34 INFO Executor: Running task 2.0 in stage 18.0 (TID 29)
19/07/31 12:57:34 INFO Executor: Running task 1.0 in stage 18.0 (TID 28)
19/07/31 12:57:34 INFO Executor: Running task 0.0 in stage 18.0 (TID 27)
19/07/31 12:57:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:34 INFO Executor: Finished task 3.0 in stage 18.0 (TID 30). 2348 bytes result sent to driver
19/07/31 12:57:34 INFO Executor: Finished task 1.0 in stage 18.0 (TID 28). 2369 bytes result sent to driver
19/07/31 12:57:34 INFO Executor: Finished task 2.0 in stage 18.0 (TID 29). 2366 bytes result sent to driver
19/07/31 12:57:34 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 30) in 7 ms on localhost (executor driver) (1/4)
19/07/31 12:57:34 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 28) in 7 ms on localhost (executor driver) (2/4)
19/07/31 12:57:34 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 29) in 7 ms on localhost (executor driver) (3/4)
19/07/31 12:57:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:34 INFO Executor: Finished task 0.0 in stage 18.0 (TID 27). 2373 bytes result sent to driver
19/07/31 12:57:34 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 27) in 10 ms on localhost (executor driver) (4/4)
19/07/31 12:57:34 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/07/31 12:57:34 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:204) finished in 0.011 s
19/07/31 12:57:34 INFO DAGScheduler: Job 12 finished: collect at utils.scala:204, took 0.039524 s
19/07/31 12:57:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_033`) `dbplyr_034`
ORDER BY `date`) `dbplyr_035`) `dbplyr_036`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Desktop"))
19/07/31 12:57:35 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:35 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_037`) `dbplyr_038`
ORDER BY `date`) `dbplyr_039`) `dbplyr_040`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Desktop"))
19/07/31 12:57:35 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:35 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:35 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#834 - cust_prospect_ind.nullCount#833) > 0)
19/07/31 12:57:35 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#839 - visit_device_type.nullCount#838) > 0)
19/07/31 12:57:35 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#832 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#831))
19/07/31 12:57:35 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#837 <= Desktop) && (Desktop <= visit_device_type.upperBound#836))
19/07/31 12:57:35 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:57:35 INFO DAGScheduler: Got job 13 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:57:35 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:204)
19/07/31 12:57:35 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:57:35 INFO DAGScheduler: Missing parents: List()
19/07/31 12:57:35 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[68] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:35 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 72.1 KB, free 910.6 MB)
19/07/31 12:57:35 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.5 MB)
19/07/31 12:57:35 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:62620 (size: 30.5 KB, free: 911.9 MB)
19/07/31 12:57:35 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[68] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:35 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/07/31 12:57:35 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:57:35 INFO Executor: Running task 0.0 in stage 19.0 (TID 31)
19/07/31 12:57:35 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:57:35 INFO Executor: Finished task 0.0 in stage 19.0 (TID 31). 6512 bytes result sent to driver
19/07/31 12:57:35 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 31) in 8 ms on localhost (executor driver) (1/1)
19/07/31 12:57:35 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/07/31 12:57:35 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:204) finished in 0.008 s
19/07/31 12:57:35 INFO DAGScheduler: Job 13 finished: collect at utils.scala:204, took 0.014987 s
19/07/31 12:57:35 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:57:35 INFO DAGScheduler: Registering RDD 69 (collect at utils.scala:204)
19/07/31 12:57:35 INFO DAGScheduler: Got job 14 (collect at utils.scala:204) with 4 output partitions
19/07/31 12:57:35 INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:204)
19/07/31 12:57:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
19/07/31 12:57:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
19/07/31 12:57:35 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[69] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:35 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 74.5 KB, free 910.5 MB)
19/07/31 12:57:35 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.4 MB)
19/07/31 12:57:35 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:62620 (size: 31.8 KB, free: 911.9 MB)
19/07/31 12:57:35 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[69] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:35 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/07/31 12:57:35 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:57:35 INFO Executor: Running task 0.0 in stage 20.0 (TID 32)
19/07/31 12:57:35 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:57:35 INFO Executor: Finished task 0.0 in stage 20.0 (TID 32). 1687 bytes result sent to driver
19/07/31 12:57:35 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 32) in 9 ms on localhost (executor driver) (1/1)
19/07/31 12:57:35 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/07/31 12:57:35 INFO DAGScheduler: ShuffleMapStage 20 (collect at utils.scala:204) finished in 0.010 s
19/07/31 12:57:35 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:57:35 INFO DAGScheduler: running: Set()
19/07/31 12:57:35 INFO DAGScheduler: waiting: Set(ResultStage 21)
19/07/31 12:57:35 INFO DAGScheduler: failed: Set()
19/07/31 12:57:35 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[72] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:35 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 16.8 KB, free 910.4 MB)
19/07/31 12:57:35 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 8.1 KB, free 910.4 MB)
19/07/31 12:57:35 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:62620 (size: 8.1 KB, free: 911.9 MB)
19/07/31 12:57:35 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:35 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 21 (MapPartitionsRDD[72] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 12:57:35 INFO TaskSchedulerImpl: Adding task set 21.0 with 4 tasks
19/07/31 12:57:35 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 33, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:57:35 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 34, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 12:57:35 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 35, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 12:57:35 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 36, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 12:57:35 INFO Executor: Running task 0.0 in stage 21.0 (TID 33)
19/07/31 12:57:35 INFO Executor: Running task 1.0 in stage 21.0 (TID 34)
19/07/31 12:57:35 INFO Executor: Running task 2.0 in stage 21.0 (TID 35)
19/07/31 12:57:35 INFO Executor: Running task 3.0 in stage 21.0 (TID 36)
19/07/31 12:57:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 12:57:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 12:57:35 INFO Executor: Finished task 0.0 in stage 21.0 (TID 33). 2349 bytes result sent to driver
19/07/31 12:57:35 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 33) in 7 ms on localhost (executor driver) (1/4)
19/07/31 12:57:35 INFO Executor: Finished task 1.0 in stage 21.0 (TID 34). 2334 bytes result sent to driver
19/07/31 12:57:35 INFO Executor: Finished task 3.0 in stage 21.0 (TID 36). 2334 bytes result sent to driver
19/07/31 12:57:35 INFO Executor: Finished task 2.0 in stage 21.0 (TID 35). 2352 bytes result sent to driver
19/07/31 12:57:35 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 34) in 6 ms on localhost (executor driver) (2/4)
19/07/31 12:57:35 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 36) in 7 ms on localhost (executor driver) (3/4)
19/07/31 12:57:35 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 35) in 7 ms on localhost (executor driver) (4/4)
19/07/31 12:57:35 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/07/31 12:57:35 INFO DAGScheduler: ResultStage 21 (collect at utils.scala:204) finished in 0.009 s
19/07/31 12:57:35 INFO DAGScheduler: Job 14 finished: collect at utils.scala:204, took 0.030812 s
19/07/31 12:57:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_041`) `dbplyr_042`
ORDER BY `date`) `dbplyr_043`) `dbplyr_044`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Desktop"))
19/07/31 12:57:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_045`) `dbplyr_046`
ORDER BY `date`) `dbplyr_047`) `dbplyr_048`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Desktop"))
19/07/31 12:57:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:36 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#932 - cust_prospect_ind.nullCount#931) > 0)
19/07/31 12:57:36 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#937 - visit_device_type.nullCount#936) > 0)
19/07/31 12:57:36 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#930 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#929))
19/07/31 12:57:36 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#935 <= Desktop) && (Desktop <= visit_device_type.upperBound#934))
19/07/31 12:57:36 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:57:36 INFO DAGScheduler: Got job 15 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:57:36 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:204)
19/07/31 12:57:36 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:57:36 INFO DAGScheduler: Missing parents: List()
19/07/31 12:57:36 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[77] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:36 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 72.1 KB, free 910.3 MB)
19/07/31 12:57:36 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.3 MB)
19/07/31 12:57:36 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:62620 (size: 30.4 KB, free: 911.9 MB)
19/07/31 12:57:36 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[77] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:36 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
19/07/31 12:57:36 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:57:36 INFO Executor: Running task 0.0 in stage 22.0 (TID 37)
19/07/31 12:57:36 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:57:36 INFO Executor: Finished task 0.0 in stage 22.0 (TID 37). 6512 bytes result sent to driver
19/07/31 12:57:36 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 37) in 8 ms on localhost (executor driver) (1/1)
19/07/31 12:57:36 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/07/31 12:57:36 INFO DAGScheduler: ResultStage 22 (collect at utils.scala:204) finished in 0.010 s
19/07/31 12:57:36 INFO DAGScheduler: Job 15 finished: collect at utils.scala:204, took 0.017053 s
19/07/31 12:57:36 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:57:36 INFO DAGScheduler: Registering RDD 78 (collect at utils.scala:204)
19/07/31 12:57:36 INFO DAGScheduler: Got job 16 (collect at utils.scala:204) with 4 output partitions
19/07/31 12:57:36 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:204)
19/07/31 12:57:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
19/07/31 12:57:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 23)
19/07/31 12:57:36 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[78] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:36 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 74.5 KB, free 910.2 MB)
19/07/31 12:57:36 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.2 MB)
19/07/31 12:57:36 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:62620 (size: 31.7 KB, free: 911.8 MB)
19/07/31 12:57:36 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[78] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:36 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
19/07/31 12:57:36 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:57:36 INFO Executor: Running task 0.0 in stage 23.0 (TID 38)
19/07/31 12:57:36 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:57:36 INFO Executor: Finished task 0.0 in stage 23.0 (TID 38). 1730 bytes result sent to driver
19/07/31 12:57:36 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 38) in 11 ms on localhost (executor driver) (1/1)
19/07/31 12:57:36 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
19/07/31 12:57:36 INFO DAGScheduler: ShuffleMapStage 23 (collect at utils.scala:204) finished in 0.011 s
19/07/31 12:57:36 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:57:36 INFO DAGScheduler: running: Set()
19/07/31 12:57:36 INFO DAGScheduler: waiting: Set(ResultStage 24)
19/07/31 12:57:36 INFO DAGScheduler: failed: Set()
19/07/31 12:57:36 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[81] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:36 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 16.8 KB, free 910.2 MB)
19/07/31 12:57:36 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 8.1 KB, free 910.2 MB)
19/07/31 12:57:36 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:62620 (size: 8.1 KB, free: 911.8 MB)
19/07/31 12:57:36 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:36 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[81] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 12:57:36 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks
19/07/31 12:57:36 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 39, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:57:36 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 40, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 12:57:36 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 41, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 12:57:36 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 42, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 12:57:36 INFO Executor: Running task 0.0 in stage 24.0 (TID 39)
19/07/31 12:57:36 INFO Executor: Running task 1.0 in stage 24.0 (TID 40)
19/07/31 12:57:36 INFO Executor: Running task 2.0 in stage 24.0 (TID 41)
19/07/31 12:57:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:36 INFO Executor: Finished task 2.0 in stage 24.0 (TID 41). 2354 bytes result sent to driver
19/07/31 12:57:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:36 INFO Executor: Finished task 0.0 in stage 24.0 (TID 39). 2353 bytes result sent to driver
19/07/31 12:57:36 INFO Executor: Running task 3.0 in stage 24.0 (TID 42)
19/07/31 12:57:36 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 39) in 7 ms on localhost (executor driver) (1/4)
19/07/31 12:57:36 INFO Executor: Finished task 1.0 in stage 24.0 (TID 40). 2338 bytes result sent to driver
19/07/31 12:57:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:36 INFO Executor: Finished task 3.0 in stage 24.0 (TID 42). 2350 bytes result sent to driver
19/07/31 12:57:36 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 41) in 14 ms on localhost (executor driver) (2/4)
19/07/31 12:57:36 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 42) in 14 ms on localhost (executor driver) (3/4)
19/07/31 12:57:36 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 40) in 15 ms on localhost (executor driver) (4/4)
19/07/31 12:57:36 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
19/07/31 12:57:36 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:204) finished in 0.015 s
19/07/31 12:57:36 INFO DAGScheduler: Job 16 finished: collect at utils.scala:204, took 0.039368 s
19/07/31 12:57:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_049`) `dbplyr_050`
ORDER BY `date`) `dbplyr_051`) `dbplyr_052`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Tablet"))
19/07/31 12:57:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_053`) `dbplyr_054`
ORDER BY `date`) `dbplyr_055`) `dbplyr_056`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Tablet"))
19/07/31 12:57:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:37 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1030 - cust_prospect_ind.nullCount#1029) > 0)
19/07/31 12:57:37 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1035 - visit_device_type.nullCount#1034) > 0)
19/07/31 12:57:37 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#1028 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#1027))
19/07/31 12:57:37 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#1033 <= Tablet) && (Tablet <= visit_device_type.upperBound#1032))
19/07/31 12:57:37 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:57:37 INFO DAGScheduler: Got job 17 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:57:37 INFO DAGScheduler: Final stage: ResultStage 25 (collect at utils.scala:204)
19/07/31 12:57:37 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:57:37 INFO DAGScheduler: Missing parents: List()
19/07/31 12:57:37 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[86] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:37 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 72.1 KB, free 910.1 MB)
19/07/31 12:57:37 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.1 MB)
19/07/31 12:57:37 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:62620 (size: 30.5 KB, free: 911.8 MB)
19/07/31 12:57:37 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[86] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:37 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
19/07/31 12:57:37 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:57:37 INFO Executor: Running task 0.0 in stage 25.0 (TID 43)
19/07/31 12:57:37 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:57:37 INFO Executor: Finished task 0.0 in stage 25.0 (TID 43). 7068 bytes result sent to driver
19/07/31 12:57:37 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 43) in 8 ms on localhost (executor driver) (1/1)
19/07/31 12:57:37 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
19/07/31 12:57:37 INFO DAGScheduler: ResultStage 25 (collect at utils.scala:204) finished in 0.008 s
19/07/31 12:57:37 INFO DAGScheduler: Job 17 finished: collect at utils.scala:204, took 0.015160 s
19/07/31 12:57:37 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:57:37 INFO DAGScheduler: Registering RDD 87 (collect at utils.scala:204)
19/07/31 12:57:37 INFO DAGScheduler: Got job 18 (collect at utils.scala:204) with 4 output partitions
19/07/31 12:57:37 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:204)
19/07/31 12:57:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
19/07/31 12:57:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 26)
19/07/31 12:57:37 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[87] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:37 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 74.5 KB, free 910.0 MB)
19/07/31 12:57:37 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.0 MB)
19/07/31 12:57:37 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:62620 (size: 31.8 KB, free: 911.8 MB)
19/07/31 12:57:37 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[87] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:37 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
19/07/31 12:57:37 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:57:37 INFO Executor: Running task 0.0 in stage 26.0 (TID 44)
19/07/31 12:57:37 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:57:37 INFO Executor: Finished task 0.0 in stage 26.0 (TID 44). 1687 bytes result sent to driver
19/07/31 12:57:37 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 44) in 13 ms on localhost (executor driver) (1/1)
19/07/31 12:57:37 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
19/07/31 12:57:37 INFO DAGScheduler: ShuffleMapStage 26 (collect at utils.scala:204) finished in 0.014 s
19/07/31 12:57:37 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:57:37 INFO DAGScheduler: running: Set()
19/07/31 12:57:37 INFO DAGScheduler: waiting: Set(ResultStage 27)
19/07/31 12:57:37 INFO DAGScheduler: failed: Set()
19/07/31 12:57:37 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[90] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:37 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 16.8 KB, free 910.0 MB)
19/07/31 12:57:37 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 8.1 KB, free 910.0 MB)
19/07/31 12:57:37 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:62620 (size: 8.1 KB, free: 911.8 MB)
19/07/31 12:57:37 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:37 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 27 (MapPartitionsRDD[90] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 12:57:37 INFO TaskSchedulerImpl: Adding task set 27.0 with 4 tasks
19/07/31 12:57:37 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 45, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:57:37 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 46, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 12:57:37 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 47, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 12:57:37 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 48, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 12:57:37 INFO Executor: Running task 0.0 in stage 27.0 (TID 45)
19/07/31 12:57:37 INFO Executor: Running task 1.0 in stage 27.0 (TID 46)
19/07/31 12:57:37 INFO Executor: Running task 2.0 in stage 27.0 (TID 47)
19/07/31 12:57:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:37 INFO Executor: Running task 3.0 in stage 27.0 (TID 48)
19/07/31 12:57:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 12:57:37 INFO Executor: Finished task 2.0 in stage 27.0 (TID 47). 2355 bytes result sent to driver
19/07/31 12:57:37 INFO Executor: Finished task 0.0 in stage 27.0 (TID 45). 2354 bytes result sent to driver
19/07/31 12:57:37 INFO Executor: Finished task 3.0 in stage 27.0 (TID 48). 2332 bytes result sent to driver
19/07/31 12:57:37 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 47) in 16 ms on localhost (executor driver) (1/4)
19/07/31 12:57:37 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 45) in 17 ms on localhost (executor driver) (2/4)
19/07/31 12:57:37 INFO Executor: Finished task 1.0 in stage 27.0 (TID 46). 2361 bytes result sent to driver
19/07/31 12:57:37 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 48) in 17 ms on localhost (executor driver) (3/4)
19/07/31 12:57:37 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 46) in 17 ms on localhost (executor driver) (4/4)
19/07/31 12:57:37 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
19/07/31 12:57:37 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:204) finished in 0.019 s
19/07/31 12:57:37 INFO DAGScheduler: Job 18 finished: collect at utils.scala:204, took 0.051313 s
19/07/31 12:57:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_057`) `dbplyr_058`
ORDER BY `date`) `dbplyr_059`) `dbplyr_060`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Tablet"))
19/07/31 12:57:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_061`) `dbplyr_062`
ORDER BY `date`) `dbplyr_063`) `dbplyr_064`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Tablet"))
19/07/31 12:57:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:38 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1128 - cust_prospect_ind.nullCount#1127) > 0)
19/07/31 12:57:38 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1133 - visit_device_type.nullCount#1132) > 0)
19/07/31 12:57:38 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#1126 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#1125))
19/07/31 12:57:38 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#1131 <= Tablet) && (Tablet <= visit_device_type.upperBound#1130))
19/07/31 12:57:38 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:57:38 INFO DAGScheduler: Got job 19 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:57:38 INFO DAGScheduler: Final stage: ResultStage 28 (collect at utils.scala:204)
19/07/31 12:57:38 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:57:38 INFO DAGScheduler: Missing parents: List()
19/07/31 12:57:38 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[95] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:38 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 72.1 KB, free 909.9 MB)
19/07/31 12:57:38 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.9 MB)
19/07/31 12:57:38 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:62620 (size: 30.5 KB, free: 911.7 MB)
19/07/31 12:57:38 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[95] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:38 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
19/07/31 12:57:38 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:57:38 INFO Executor: Running task 0.0 in stage 28.0 (TID 49)
19/07/31 12:57:38 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:57:38 INFO Executor: Finished task 0.0 in stage 28.0 (TID 49). 6512 bytes result sent to driver
19/07/31 12:57:38 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 49) in 8 ms on localhost (executor driver) (1/1)
19/07/31 12:57:38 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
19/07/31 12:57:38 INFO DAGScheduler: ResultStage 28 (collect at utils.scala:204) finished in 0.008 s
19/07/31 12:57:38 INFO DAGScheduler: Job 19 finished: collect at utils.scala:204, took 0.017898 s
19/07/31 12:57:38 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:57:38 INFO DAGScheduler: Registering RDD 96 (collect at utils.scala:204)
19/07/31 12:57:38 INFO DAGScheduler: Got job 20 (collect at utils.scala:204) with 4 output partitions
19/07/31 12:57:38 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:204)
19/07/31 12:57:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
19/07/31 12:57:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 29)
19/07/31 12:57:38 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[96] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:38 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 74.5 KB, free 909.8 MB)
19/07/31 12:57:38 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.7 MB)
19/07/31 12:57:38 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:62620 (size: 31.8 KB, free: 911.7 MB)
19/07/31 12:57:38 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[96] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:38 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
19/07/31 12:57:38 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:57:38 INFO Executor: Running task 0.0 in stage 29.0 (TID 50)
19/07/31 12:57:38 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:57:38 INFO Executor: Finished task 0.0 in stage 29.0 (TID 50). 1687 bytes result sent to driver
19/07/31 12:57:38 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 50) in 12 ms on localhost (executor driver) (1/1)
19/07/31 12:57:38 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
19/07/31 12:57:38 INFO DAGScheduler: ShuffleMapStage 29 (collect at utils.scala:204) finished in 0.012 s
19/07/31 12:57:38 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:57:38 INFO DAGScheduler: running: Set()
19/07/31 12:57:38 INFO DAGScheduler: waiting: Set(ResultStage 30)
19/07/31 12:57:38 INFO DAGScheduler: failed: Set()
19/07/31 12:57:38 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[99] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:38 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 16.8 KB, free 909.7 MB)
19/07/31 12:57:38 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 8.1 KB, free 909.7 MB)
19/07/31 12:57:38 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:62620 (size: 8.1 KB, free: 911.7 MB)
19/07/31 12:57:38 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:38 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 30 (MapPartitionsRDD[99] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 12:57:38 INFO TaskSchedulerImpl: Adding task set 30.0 with 4 tasks
19/07/31 12:57:38 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 51, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:57:38 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 52, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 12:57:38 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 53, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 12:57:38 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 54, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 12:57:38 INFO Executor: Running task 0.0 in stage 30.0 (TID 51)
19/07/31 12:57:38 INFO Executor: Running task 1.0 in stage 30.0 (TID 52)
19/07/31 12:57:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:38 INFO Executor: Running task 3.0 in stage 30.0 (TID 54)
19/07/31 12:57:38 INFO Executor: Finished task 1.0 in stage 30.0 (TID 52). 2313 bytes result sent to driver
19/07/31 12:57:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:38 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 52) in 7 ms on localhost (executor driver) (1/4)
19/07/31 12:57:38 INFO Executor: Running task 2.0 in stage 30.0 (TID 53)
19/07/31 12:57:38 INFO Executor: Finished task 3.0 in stage 30.0 (TID 54). 2311 bytes result sent to driver
19/07/31 12:57:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:38 INFO Executor: Finished task 0.0 in stage 30.0 (TID 51). 2347 bytes result sent to driver
19/07/31 12:57:38 INFO Executor: Finished task 2.0 in stage 30.0 (TID 53). 2338 bytes result sent to driver
19/07/31 12:57:38 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 54) in 11 ms on localhost (executor driver) (2/4)
19/07/31 12:57:38 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 53) in 11 ms on localhost (executor driver) (3/4)
19/07/31 12:57:38 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 51) in 11 ms on localhost (executor driver) (4/4)
19/07/31 12:57:38 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
19/07/31 12:57:38 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:204) finished in 0.013 s
19/07/31 12:57:38 INFO DAGScheduler: Job 20 finished: collect at utils.scala:204, took 0.035889 s
19/07/31 12:57:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_065`) `dbplyr_066`
ORDER BY `date`) `dbplyr_067`) `dbplyr_068`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Tablet"))
19/07/31 12:57:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `orders` / `visitors` AS `rate`, `customer`, `device`, `date`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_069`) `dbplyr_070`
ORDER BY `date`) `dbplyr_071`) `dbplyr_072`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Tablet"))
19/07/31 12:57:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:38 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1226 - cust_prospect_ind.nullCount#1225) > 0)
19/07/31 12:57:38 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1231 - visit_device_type.nullCount#1230) > 0)
19/07/31 12:57:38 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#1224 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#1223))
19/07/31 12:57:38 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#1229 <= Tablet) && (Tablet <= visit_device_type.upperBound#1228))
19/07/31 12:57:39 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:57:39 INFO DAGScheduler: Got job 21 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:57:39 INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:204)
19/07/31 12:57:39 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:57:39 INFO DAGScheduler: Missing parents: List()
19/07/31 12:57:39 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[104] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:39 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 72.1 KB, free 909.7 MB)
19/07/31 12:57:39 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 30.4 KB, free 909.6 MB)
19/07/31 12:57:39 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:62620 (size: 30.4 KB, free: 911.7 MB)
19/07/31 12:57:39 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[104] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:39 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
19/07/31 12:57:39 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 12:57:39 INFO Executor: Running task 0.0 in stage 31.0 (TID 55)
19/07/31 12:57:39 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:57:39 INFO Executor: Finished task 0.0 in stage 31.0 (TID 55). 6512 bytes result sent to driver
19/07/31 12:57:39 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 55) in 8 ms on localhost (executor driver) (1/1)
19/07/31 12:57:39 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
19/07/31 12:57:39 INFO DAGScheduler: ResultStage 31 (collect at utils.scala:204) finished in 0.008 s
19/07/31 12:57:39 INFO DAGScheduler: Job 21 finished: collect at utils.scala:204, took 0.019350 s
19/07/31 12:57:39 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:57:39 INFO DAGScheduler: Registering RDD 105 (collect at utils.scala:204)
19/07/31 12:57:39 INFO DAGScheduler: Got job 22 (collect at utils.scala:204) with 4 output partitions
19/07/31 12:57:39 INFO DAGScheduler: Final stage: ResultStage 33 (collect at utils.scala:204)
19/07/31 12:57:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)
19/07/31 12:57:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 32)
19/07/31 12:57:39 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[105] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:39 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 74.5 KB, free 909.6 MB)
19/07/31 12:57:39 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 31.7 KB, free 909.5 MB)
19/07/31 12:57:39 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:62620 (size: 31.7 KB, free: 911.6 MB)
19/07/31 12:57:39 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[105] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:39 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
19/07/31 12:57:39 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 12:57:39 INFO Executor: Running task 0.0 in stage 32.0 (TID 56)
19/07/31 12:57:39 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 12:57:39 INFO Executor: Finished task 0.0 in stage 32.0 (TID 56). 1687 bytes result sent to driver
19/07/31 12:57:39 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 56) in 11 ms on localhost (executor driver) (1/1)
19/07/31 12:57:39 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
19/07/31 12:57:39 INFO DAGScheduler: ShuffleMapStage 32 (collect at utils.scala:204) finished in 0.012 s
19/07/31 12:57:39 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:57:39 INFO DAGScheduler: running: Set()
19/07/31 12:57:39 INFO DAGScheduler: waiting: Set(ResultStage 33)
19/07/31 12:57:39 INFO DAGScheduler: failed: Set()
19/07/31 12:57:39 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[108] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:39 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 16.8 KB, free 909.5 MB)
19/07/31 12:57:39 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 8.1 KB, free 909.5 MB)
19/07/31 12:57:39 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:62620 (size: 8.1 KB, free: 911.6 MB)
19/07/31 12:57:39 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:39 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 33 (MapPartitionsRDD[108] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 12:57:39 INFO TaskSchedulerImpl: Adding task set 33.0 with 4 tasks
19/07/31 12:57:39 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 57, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:57:39 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 58, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 12:57:39 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 59, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 12:57:39 INFO TaskSetManager: Starting task 3.0 in stage 33.0 (TID 60, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 12:57:39 INFO Executor: Running task 0.0 in stage 33.0 (TID 57)
19/07/31 12:57:39 INFO Executor: Running task 1.0 in stage 33.0 (TID 58)
19/07/31 12:57:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:39 INFO Executor: Running task 2.0 in stage 33.0 (TID 59)
19/07/31 12:57:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:39 INFO Executor: Finished task 0.0 in stage 33.0 (TID 57). 2341 bytes result sent to driver
19/07/31 12:57:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 12:57:39 INFO Executor: Running task 3.0 in stage 33.0 (TID 60)
19/07/31 12:57:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
19/07/31 12:57:39 INFO Executor: Finished task 2.0 in stage 33.0 (TID 59). 2345 bytes result sent to driver
19/07/31 12:57:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:39 INFO Executor: Finished task 1.0 in stage 33.0 (TID 58). 2326 bytes result sent to driver
19/07/31 12:57:39 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 57) in 11 ms on localhost (executor driver) (1/4)
19/07/31 12:57:39 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 59) in 14 ms on localhost (executor driver) (2/4)
19/07/31 12:57:39 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 58) in 14 ms on localhost (executor driver) (3/4)
19/07/31 12:57:39 INFO Executor: Finished task 3.0 in stage 33.0 (TID 60). 2318 bytes result sent to driver
19/07/31 12:57:39 INFO TaskSetManager: Finished task 3.0 in stage 33.0 (TID 60) in 16 ms on localhost (executor driver) (4/4)
19/07/31 12:57:39 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
19/07/31 12:57:39 INFO DAGScheduler: ResultStage 33 (collect at utils.scala:204) finished in 0.021 s
19/07/31 12:57:39 INFO DAGScheduler: Job 22 finished: collect at utils.scala:204, took 0.055850 s
19/07/31 12:57:39 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 12:57:39 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:39 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:39 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 12:57:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 12:57:39 INFO CodeGenerator: Code generated in 6.428706 ms
19/07/31 12:57:39 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 12:57:39 INFO DAGScheduler: Got job 23 (collect at utils.scala:44) with 1 output partitions
19/07/31 12:57:39 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:44)
19/07/31 12:57:39 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:57:39 INFO DAGScheduler: Missing parents: List()
19/07/31 12:57:39 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[113] at map at utils.scala:41), which has no missing parents
19/07/31 12:57:39 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 6.3 KB, free 909.5 MB)
19/07/31 12:57:39 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 3.5 KB, free 909.5 MB)
19/07/31 12:57:39 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:62620 (size: 3.5 KB, free: 911.6 MB)
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 482
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 730
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 403
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 487
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 566
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 648
19/07/31 12:57:39 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[113] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:39 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
19/07/31 12:57:39 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 12:57:39 INFO Executor: Running task 0.0 in stage 34.0 (TID 61)
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:62620 in memory (size: 8.1 KB, free: 911.6 MB)
19/07/31 12:57:39 INFO Executor: Finished task 0.0 in stage 34.0 (TID 61). 964 bytes result sent to driver
19/07/31 12:57:39 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 61) in 3 ms on localhost (executor driver) (1/1)
19/07/31 12:57:39 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 402
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 564
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 645
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 808
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 320
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 568
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 485
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 324
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 325
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 646
19/07/31 12:57:39 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:44) finished in 0.005 s
19/07/31 12:57:39 INFO DAGScheduler: Job 23 finished: collect at utils.scala:44, took 0.018705 s
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:62620 in memory (size: 31.8 KB, free: 911.7 MB)
19/07/31 12:57:39 INFO ContextCleaner: Cleaned shuffle 6
19/07/31 12:57:39 INFO ContextCleaner: Cleaned shuffle 4
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 318
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 803
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 405
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 807
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 811
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 404
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 724
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 400
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 809
19/07/31 12:57:39 INFO ContextCleaner: Cleaned shuffle 3
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 399
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:62620 in memory (size: 30.5 KB, free: 911.7 MB)
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 806
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 322
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 479
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 563
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 643
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:62620 in memory (size: 31.8 KB, free: 911.7 MB)
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:62620 in memory (size: 31.7 KB, free: 911.7 MB)
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:62620 in memory (size: 31.8 KB, free: 911.8 MB)
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:62620 in memory (size: 31.7 KB, free: 911.8 MB)
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:62620 in memory (size: 8.1 KB, free: 911.8 MB)
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 729
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 323
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 321
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 317
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 642
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:62620 in memory (size: 30.4 KB, free: 911.8 MB)
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 728
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 481
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:62620 in memory (size: 30.4 KB, free: 911.9 MB)
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 884
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 722
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 644
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:62620 in memory (size: 30.4 KB, free: 911.9 MB)
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 641
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 805
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 319
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 810
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:62620 in memory (size: 30.5 KB, free: 911.9 MB)
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 649
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 727
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 480
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 486
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:62620 in memory (size: 8.1 KB, free: 911.9 MB)
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:62620 in memory (size: 30.5 KB, free: 912.0 MB)
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 398
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:62620 in memory (size: 8.1 KB, free: 912.0 MB)
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 565
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 401
19/07/31 12:57:39 INFO ContextCleaner: Cleaned shuffle 5
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 723
19/07/31 12:57:39 INFO ContextCleaner: Cleaned shuffle 9
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 725
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 562
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:62620 in memory (size: 8.1 KB, free: 912.0 MB)
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 484
19/07/31 12:57:39 INFO ContextCleaner: Cleaned shuffle 8
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 647
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:62620 in memory (size: 8.1 KB, free: 912.0 MB)
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:62620 in memory (size: 30.5 KB, free: 912.0 MB)
19/07/31 12:57:39 INFO ContextCleaner: Cleaned shuffle 7
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:62620 in memory (size: 31.7 KB, free: 912.1 MB)
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 726
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:62620 in memory (size: 8.1 KB, free: 912.1 MB)
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:62620 in memory (size: 8.1 KB, free: 912.1 MB)
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:62620 in memory (size: 31.8 KB, free: 912.1 MB)
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:62620 in memory (size: 30.5 KB, free: 912.1 MB)
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 483
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 406
19/07/31 12:57:39 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:62620 in memory (size: 31.8 KB, free: 912.2 MB)
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 560
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 567
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 561
19/07/31 12:57:39 INFO ContextCleaner: Cleaned accumulator 804
19/07/31 12:57:39 INFO SparkSqlParser: Parsing command: result
19/07/31 12:57:39 INFO SparkSqlParser: Parsing command: CACHE TABLE `result`
19/07/31 12:57:39 INFO SparkSqlParser: Parsing command: `result`
19/07/31 12:57:39 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 12:57:39 INFO DAGScheduler: Registering RDD 121 (sql at <unknown>:0)
19/07/31 12:57:39 INFO DAGScheduler: Got job 24 (sql at <unknown>:0) with 1 output partitions
19/07/31 12:57:39 INFO DAGScheduler: Final stage: ResultStage 36 (sql at <unknown>:0)
19/07/31 12:57:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
19/07/31 12:57:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 35)
19/07/31 12:57:39 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[121] at sql at <unknown>:0), which has no missing parents
19/07/31 12:57:39 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 28.2 KB, free 911.3 MB)
19/07/31 12:57:39 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 10.9 KB, free 911.3 MB)
19/07/31 12:57:39 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:62620 (size: 10.9 KB, free: 912.2 MB)
19/07/31 12:57:39 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[121] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:39 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
19/07/31 12:57:39 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 46876 bytes)
19/07/31 12:57:39 INFO Executor: Running task 0.0 in stage 35.0 (TID 62)
19/07/31 12:57:39 INFO CodeGenerator: Code generated in 11.936365 ms
19/07/31 12:57:39 INFO CodeGenerator: Code generated in 78.305142 ms
19/07/31 12:57:40 INFO MemoryStore: Block rdd_118_0 stored as values in memory (estimated size 28.5 KB, free 911.2 MB)
19/07/31 12:57:40 INFO BlockManagerInfo: Added rdd_118_0 in memory on 127.0.0.1:62620 (size: 28.5 KB, free: 912.1 MB)
19/07/31 12:57:40 INFO Executor: Finished task 0.0 in stage 35.0 (TID 62). 2285 bytes result sent to driver
19/07/31 12:57:40 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 62) in 158 ms on localhost (executor driver) (1/1)
19/07/31 12:57:40 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
19/07/31 12:57:40 INFO DAGScheduler: ShuffleMapStage 35 (sql at <unknown>:0) finished in 0.158 s
19/07/31 12:57:40 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:57:40 INFO DAGScheduler: running: Set()
19/07/31 12:57:40 INFO DAGScheduler: waiting: Set(ResultStage 36)
19/07/31 12:57:40 INFO DAGScheduler: failed: Set()
19/07/31 12:57:40 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[124] at sql at <unknown>:0), which has no missing parents
19/07/31 12:57:40 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 7.0 KB, free 911.2 MB)
19/07/31 12:57:40 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.2 MB)
19/07/31 12:57:40 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:62620 (size: 3.7 KB, free: 912.1 MB)
19/07/31 12:57:40 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[124] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:40 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
19/07/31 12:57:40 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 63, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:57:40 INFO Executor: Running task 0.0 in stage 36.0 (TID 63)
19/07/31 12:57:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:40 INFO Executor: Finished task 0.0 in stage 36.0 (TID 63). 1581 bytes result sent to driver
19/07/31 12:57:40 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 63) in 4 ms on localhost (executor driver) (1/1)
19/07/31 12:57:40 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
19/07/31 12:57:40 INFO DAGScheduler: ResultStage 36 (sql at <unknown>:0) finished in 0.004 s
19/07/31 12:57:40 INFO DAGScheduler: Job 24 finished: sql at <unknown>:0, took 0.174738 s
19/07/31 12:57:40 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `result`
19/07/31 12:57:40 INFO HiveMetaStore: 0: get_database: default
19/07/31 12:57:40 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 12:57:40 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 12:57:40 INFO DAGScheduler: Registering RDD 127 (collect at utils.scala:204)
19/07/31 12:57:40 INFO DAGScheduler: Got job 25 (collect at utils.scala:204) with 1 output partitions
19/07/31 12:57:40 INFO DAGScheduler: Final stage: ResultStage 38 (collect at utils.scala:204)
19/07/31 12:57:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)
19/07/31 12:57:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 37)
19/07/31 12:57:40 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[127] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:40 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 28.2 KB, free 911.2 MB)
19/07/31 12:57:40 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 11.0 KB, free 911.2 MB)
19/07/31 12:57:40 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:62620 (size: 11.0 KB, free: 912.1 MB)
19/07/31 12:57:40 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[127] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:40 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
19/07/31 12:57:40 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 46876 bytes)
19/07/31 12:57:40 INFO Executor: Running task 0.0 in stage 37.0 (TID 64)
19/07/31 12:57:40 INFO BlockManager: Found block rdd_118_0 locally
19/07/31 12:57:40 INFO Executor: Finished task 0.0 in stage 37.0 (TID 64). 1690 bytes result sent to driver
19/07/31 12:57:40 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 64) in 6 ms on localhost (executor driver) (1/1)
19/07/31 12:57:40 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
19/07/31 12:57:40 INFO DAGScheduler: ShuffleMapStage 37 (collect at utils.scala:204) finished in 0.006 s
19/07/31 12:57:40 INFO DAGScheduler: looking for newly runnable stages
19/07/31 12:57:40 INFO DAGScheduler: running: Set()
19/07/31 12:57:40 INFO DAGScheduler: waiting: Set(ResultStage 38)
19/07/31 12:57:40 INFO DAGScheduler: failed: Set()
19/07/31 12:57:40 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[130] at collect at utils.scala:204), which has no missing parents
19/07/31 12:57:40 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 7.0 KB, free 911.2 MB)
19/07/31 12:57:40 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.2 MB)
19/07/31 12:57:40 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:62620 (size: 3.7 KB, free: 912.1 MB)
19/07/31 12:57:40 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[130] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:40 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
19/07/31 12:57:40 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 65, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 12:57:40 INFO Executor: Running task 0.0 in stage 38.0 (TID 65)
19/07/31 12:57:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 12:57:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 12:57:40 INFO Executor: Finished task 0.0 in stage 38.0 (TID 65). 1538 bytes result sent to driver
19/07/31 12:57:40 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 65) in 2 ms on localhost (executor driver) (1/1)
19/07/31 12:57:40 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
19/07/31 12:57:40 INFO DAGScheduler: ResultStage 38 (collect at utils.scala:204) finished in 0.003 s
19/07/31 12:57:40 INFO DAGScheduler: Job 25 finished: collect at utils.scala:204, took 0.018601 s
19/07/31 12:57:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `result` AS `zzz2`
WHERE (0 = 1)
19/07/31 12:57:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `result`
19/07/31 12:57:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 12:57:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 12:57:40 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 12:57:40 INFO DAGScheduler: Got job 26 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 12:57:40 INFO DAGScheduler: Final stage: ResultStage 39 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 12:57:40 INFO DAGScheduler: Parents of final stage: List()
19/07/31 12:57:40 INFO DAGScheduler: Missing parents: List()
19/07/31 12:57:40 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[131] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 12:57:40 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 99.2 KB, free 911.1 MB)
19/07/31 12:57:40 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 37.2 KB, free 911.1 MB)
19/07/31 12:57:40 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:62620 (size: 37.2 KB, free: 912.1 MB)
19/07/31 12:57:40 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
19/07/31 12:57:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[131] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 12:57:40 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
19/07/31 12:57:40 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 46887 bytes)
19/07/31 12:57:40 INFO Executor: Running task 0.0 in stage 39.0 (TID 66)
19/07/31 12:57:40 INFO BlockManager: Found block rdd_118_0 locally
19/07/31 12:57:40 INFO CodeGenerator: Code generated in 12.740372 ms
19/07/31 12:57:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 12:57:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 12:57:40 INFO FileOutputCommitter: Saved output of task 'attempt_20190731125740_0039_m_000000_0' to file:/Users/6jncnk4f/Desktop/anomaly/result/_temporary/0/task_20190731125740_0039_m_000000
19/07/31 12:57:40 INFO SparkHadoopMapRedUtil: attempt_20190731125740_0039_m_000000_0: Committed
19/07/31 12:57:40 INFO Executor: Finished task 0.0 in stage 39.0 (TID 66). 1619 bytes result sent to driver
19/07/31 12:57:40 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 66) in 131 ms on localhost (executor driver) (1/1)
19/07/31 12:57:40 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
19/07/31 12:57:40 INFO DAGScheduler: ResultStage 39 (csv at NativeMethodAccessorImpl.java:0) finished in 0.131 s
19/07/31 12:57:40 INFO DAGScheduler: Job 26 finished: csv at NativeMethodAccessorImpl.java:0, took 0.154902 s
19/07/31 12:57:40 INFO FileFormatWriter: Job null committed.
19/07/31 12:57:41 INFO SparkContext: Invoking stop() from shutdown hook
19/07/31 12:57:41 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
19/07/31 12:57:41 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/07/31 12:57:41 INFO MemoryStore: MemoryStore cleared
19/07/31 12:57:41 INFO BlockManager: BlockManager stopped
19/07/31 12:57:41 INFO BlockManagerMaster: BlockManagerMaster stopped
19/07/31 12:57:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/07/31 12:57:41 INFO SparkContext: Successfully stopped SparkContext
19/07/31 12:57:41 INFO ShutdownHookManager: Shutdown hook called
19/07/31 12:57:41 INFO ShutdownHookManager: Deleting directory /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-a3b19faf-681e-4802-884a-4c4a32641455
19/07/31 13:00:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_007`) `dbplyr_008`
ORDER BY `date`) `dbplyr_009`) `dbplyr_010`
WHERE ((`customer` = "All Visitors") AND (`device` = "Mobile Phone"))
19/07/31 13:00:14 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:00:14 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:00:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_011`) `dbplyr_012`
ORDER BY `date`) `dbplyr_013`) `dbplyr_014`
WHERE ((`customer` = "All Visitors") AND (`device` = "Mobile Phone"))
19/07/31 13:00:14 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:00:14 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:00:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_015`) `dbplyr_016`
ORDER BY `date`) `dbplyr_017`) `dbplyr_018`
WHERE ((`customer` = "All Visitors") AND (`device` = "Mobile Phone"))
LIMIT 11
19/07/31 13:00:15 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:00:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:00:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_019`) `dbplyr_020`
ORDER BY `date`) `dbplyr_021`) `dbplyr_022`
WHERE ((`customer` = "All Visitors") AND (`device` = "Mobile Phone"))
LIMIT 11
19/07/31 13:00:15 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:00:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:00:15 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#1367) generates partition filter: ((cust_prospect_ind.count#1811 - cust_prospect_ind.nullCount#1810) > 0)
19/07/31 13:00:15 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#1368) generates partition filter: ((visit_device_type.count#1816 - visit_device_type.nullCount#1815) > 0)
19/07/31 13:00:15 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#1367 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#1809 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#1808))
19/07/31 13:00:15 INFO InMemoryTableScanExec: Predicate (visit_device_type#1368 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#1814 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#1813))
19/07/31 13:00:15 INFO CodeGenerator: Code generated in 43.806533 ms
19/07/31 13:00:15 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:00:15 INFO DAGScheduler: Got job 22 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:00:15 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:204)
19/07/31 13:00:15 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:00:15 INFO DAGScheduler: Missing parents: List()
19/07/31 13:00:15 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[122] at collect at utils.scala:204), which has no missing parents
19/07/31 13:00:15 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 72.8 KB, free 909.1 MB)
19/07/31 13:00:15 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 30.8 KB, free 909.1 MB)
19/07/31 13:00:15 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:62226 (size: 30.8 KB, free: 911.9 MB)
19/07/31 13:00:15 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
19/07/31 13:00:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[122] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:00:15 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
19/07/31 13:00:15 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:00:15 INFO Executor: Running task 0.0 in stage 30.0 (TID 30)
19/07/31 13:00:15 INFO BlockManager: Found block rdd_106_0 locally
19/07/31 13:00:15 INFO CodeGenerator: Code generated in 10.40874 ms
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 769
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 558
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 597
19/07/31 13:00:15 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:62226 in memory (size: 3.7 KB, free: 911.9 MB)
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 474
19/07/31 13:00:15 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:62226 in memory (size: 24.0 KB, free: 911.9 MB)
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 662
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 475
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 652
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 869
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 770
19/07/31 13:00:15 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:62226 in memory (size: 11.9 KB, free: 911.9 MB)
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 654
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 771
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 768
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 808
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 739
19/07/31 13:00:15 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:62226 in memory (size: 23.8 KB, free: 912.0 MB)
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 557
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 527
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 737
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 802
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 875
19/07/31 13:00:15 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:62226 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 591
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 874
19/07/31 13:00:15 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:62226 in memory (size: 8.6 KB, free: 912.0 MB)
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 871
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 587
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 873
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 592
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 870
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 767
19/07/31 13:00:15 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:62226 in memory (size: 23.8 KB, free: 912.0 MB)
19/07/31 13:00:15 INFO CodeGenerator: Code generated in 74.391819 ms
19/07/31 13:00:15 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:62226 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 806
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 811
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 526
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 589
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 803
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 598
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 500
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 530
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 872
19/07/31 13:00:15 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:62226 in memory (size: 4.3 KB, free: 912.0 MB)
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 809
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 586
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 812
19/07/31 13:00:15 INFO ContextCleaner: Cleaned shuffle 4
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 810
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 653
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 599
19/07/31 13:00:15 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:62226 in memory (size: 23.8 KB, free: 912.0 MB)
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 741
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 528
19/07/31 13:00:15 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:62226 in memory (size: 8.6 KB, free: 912.0 MB)
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 584
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 660
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 742
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 588
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 656
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 712
19/07/31 13:00:15 INFO ContextCleaner: Cleaned shuffle 6
19/07/31 13:00:15 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:62226 in memory (size: 4.3 KB, free: 912.0 MB)
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 595
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 585
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 867
19/07/31 13:00:15 INFO ContextCleaner: Cleaned shuffle 5
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 596
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 556
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 555
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 529
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 655
19/07/31 13:00:15 INFO Executor: Finished task 0.0 in stage 30.0 (TID 30). 4005 bytes result sent to driver
19/07/31 13:00:15 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:62226 in memory (size: 11.8 KB, free: 912.0 MB)
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 865
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 864
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 559
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 661
19/07/31 13:00:15 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:62226 in memory (size: 3.5 KB, free: 912.0 MB)
19/07/31 13:00:15 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 30) in 119 ms on localhost (executor driver) (1/1)
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 663
19/07/31 13:00:15 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
19/07/31 13:00:15 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:204) finished in 0.122 s
19/07/31 13:00:15 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:62226 in memory (size: 11.9 KB, free: 912.1 MB)
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 807
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 805
19/07/31 13:00:15 INFO DAGScheduler: Job 22 finished: collect at utils.scala:204, took 0.168525 s
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 740
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 813
19/07/31 13:00:15 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:62226 in memory (size: 30.1 KB, free: 912.1 MB)
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 600
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 866
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 868
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 590
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 804
19/07/31 13:00:15 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:62226 in memory (size: 23.8 KB, free: 912.1 MB)
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 738
19/07/31 13:00:15 INFO BlockManager: Removing RDD 78
19/07/31 13:00:15 INFO ContextCleaner: Cleaned RDD 78
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 657
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 814
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 525
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 601
19/07/31 13:00:15 INFO ContextCleaner: Cleaned shuffle 7
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 593
19/07/31 13:00:15 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:62226 in memory (size: 3.5 KB, free: 912.1 MB)
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 594
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 863
19/07/31 13:00:15 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:62226 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 13:00:15 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:62226 in memory (size: 11.9 KB, free: 912.1 MB)
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 658
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 659
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 651
19/07/31 13:00:15 INFO ContextCleaner: Cleaned accumulator 602
19/07/31 13:00:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_023`) `dbplyr_024`
ORDER BY `date`) `dbplyr_025`) `dbplyr_026`
WHERE ((`customer` = "All Visitors") AND (`device` = "Mobile Phone"))
19/07/31 13:00:15 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:00:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:09:51 INFO SparkContext: Running Spark version 2.2.0
19/07/31 13:09:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/07/31 13:09:51 INFO SparkContext: Submitted application: sparklyr
19/07/31 13:09:51 INFO SecurityManager: Changing view acls to: 6jncnk4f
19/07/31 13:09:51 INFO SecurityManager: Changing modify acls to: 6jncnk4f
19/07/31 13:09:51 INFO SecurityManager: Changing view acls groups to: 
19/07/31 13:09:51 INFO SecurityManager: Changing modify acls groups to: 
19/07/31 13:09:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(6jncnk4f); groups with view permissions: Set(); users  with modify permissions: Set(6jncnk4f); groups with modify permissions: Set()
19/07/31 13:09:51 INFO Utils: Successfully started service 'sparkDriver' on port 63053.
19/07/31 13:09:51 INFO SparkEnv: Registering MapOutputTracker
19/07/31 13:09:51 INFO SparkEnv: Registering BlockManagerMaster
19/07/31 13:09:51 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/07/31 13:09:51 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/07/31 13:09:51 INFO DiskBlockManager: Created local directory at /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/blockmgr-b03825e1-54f4-418d-9950-e66dda613dcb
19/07/31 13:09:51 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/07/31 13:09:51 INFO SparkEnv: Registering OutputCommitCoordinator
19/07/31 13:09:52 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/07/31 13:09:52 INFO Utils: Successfully started service 'SparkUI' on port 4041.
19/07/31 13:09:52 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
19/07/31 13:09:52 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:63053/jars/sparklyr-2.0-2.11.jar with timestamp 1564592992090
19/07/31 13:09:52 INFO Executor: Starting executor ID driver on host localhost
19/07/31 13:09:52 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63054.
19/07/31 13:09:52 INFO NettyBlockTransferService: Server created on 127.0.0.1:63054
19/07/31 13:09:52 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/07/31 13:09:52 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 63054, None)
19/07/31 13:09:52 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:63054 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 63054, None)
19/07/31 13:09:52 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 63054, None)
19/07/31 13:09:52 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 63054, None)
19/07/31 13:09:52 INFO SharedState: loading hive config file: file:/Users/6jncnk4f/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/07/31 13:09:52 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse').
19/07/31 13:09:52 INFO SharedState: Warehouse path is 'file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse'.
19/07/31 13:09:53 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/07/31 13:09:53 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/07/31 13:09:53 INFO ObjectStore: ObjectStore, initialize called
19/07/31 13:09:53 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/07/31 13:09:53 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/07/31 13:09:54 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/07/31 13:09:55 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:09:55 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:09:56 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:09:56 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:09:56 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/07/31 13:09:56 INFO ObjectStore: Initialized ObjectStore
19/07/31 13:09:56 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/07/31 13:09:56 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/07/31 13:09:56 INFO HiveMetaStore: Added admin role in metastore
19/07/31 13:09:56 INFO HiveMetaStore: Added public role in metastore
19/07/31 13:09:56 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/07/31 13:09:56 INFO HiveMetaStore: 0: get_all_databases
19/07/31 13:09:56 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_all_databases	
19/07/31 13:09:56 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/07/31 13:09:56 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/07/31 13:09:56 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:09:56 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/eeccc067-7f58-483e-b95e-cf3ab7cfe65f_resources
19/07/31 13:09:56 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/eeccc067-7f58-483e-b95e-cf3ab7cfe65f
19/07/31 13:09:56 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/eeccc067-7f58-483e-b95e-cf3ab7cfe65f
19/07/31 13:09:56 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/eeccc067-7f58-483e-b95e-cf3ab7cfe65f/_tmp_space.db
19/07/31 13:09:56 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 13:09:57 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:09:57 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:09:57 INFO HiveMetaStore: 0: get_database: global_temp
19/07/31 13:09:57 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/07/31 13:09:57 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/07/31 13:09:57 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/dd8256c4-d49b-447a-9f1b-dbf0dc3f9a45_resources
19/07/31 13:09:57 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/dd8256c4-d49b-447a-9f1b-dbf0dc3f9a45
19/07/31 13:09:57 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/dd8256c4-d49b-447a-9f1b-dbf0dc3f9a45
19/07/31 13:09:57 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/dd8256c4-d49b-447a-9f1b-dbf0dc3f9a45/_tmp_space.db
19/07/31 13:09:57 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 13:09:57 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/07/31 13:09:57 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:09:58 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:09:58 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:09:58 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:09:58 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:09:58 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:09:58 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:09:58 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 13:09:58 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/07/31 13:09:58 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/07/31 13:09:58 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:09:58 INFO DAGScheduler: Missing parents: List()
19/07/31 13:09:58 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/07/31 13:09:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/07/31 13:09:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/07/31 13:09:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:63054 (size: 3.4 KB, free: 912.3 MB)
19/07/31 13:09:58 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/07/31 13:09:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 13:09:58 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/07/31 13:09:59 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/07/31 13:09:59 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/07/31 13:09:59 INFO Executor: Fetching spark://127.0.0.1:63053/jars/sparklyr-2.0-2.11.jar with timestamp 1564592992090
19/07/31 13:09:59 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:63053 after 16 ms (0 ms spent in bootstraps)
19/07/31 13:09:59 INFO Utils: Fetching spark://127.0.0.1:63053/jars/sparklyr-2.0-2.11.jar to /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-9ff8838d-8c1e-422a-88f2-05ffca0439e5/userFiles-91301121-5215-43fd-82cb-0b81fba650ce/fetchFileTemp7239280405623425132.tmp
19/07/31 13:09:59 INFO Executor: Adding file:/private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-9ff8838d-8c1e-422a-88f2-05ffca0439e5/userFiles-91301121-5215-43fd-82cb-0b81fba650ce/sparklyr-2.0-2.11.jar to class loader
19/07/31 13:09:59 INFO CodeGenerator: Code generated in 186.588552 ms
19/07/31 13:09:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1056 bytes result sent to driver
19/07/31 13:09:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 503 ms on localhost (executor driver) (1/1)
19/07/31 13:09:59 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/07/31 13:09:59 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.525 s
19/07/31 13:09:59 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0.673646 s
19/07/31 13:09:59 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:09:59 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#10)) > 0)
19/07/31 13:09:59 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 13:09:59 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:10:00 INFO CodeGenerator: Code generated in 15.772342 ms
19/07/31 13:10:00 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 281.2 KB, free 912.0 MB)
19/07/31 13:10:00 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.8 KB, free 912.0 MB)
19/07/31 13:10:00 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:63054 (size: 23.8 KB, free: 912.3 MB)
19/07/31 13:10:00 INFO SparkContext: Created broadcast 1 from csv at NativeMethodAccessorImpl.java:0
19/07/31 13:10:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:10:00 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:10:00 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:10:00 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:10:00 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:10:00 INFO DAGScheduler: Missing parents: List()
19/07/31 13:10:00 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:10:00 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 912.0 MB)
19/07/31 13:10:00 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 912.0 MB)
19/07/31 13:10:00 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:63054 (size: 4.3 KB, free: 912.3 MB)
19/07/31 13:10:00 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:00 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/07/31 13:10:00 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:10:00 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/07/31 13:10:00 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:10:00 INFO CodeGenerator: Code generated in 7.587504 ms
19/07/31 13:10:00 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1480 bytes result sent to driver
19/07/31 13:10:00 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 201 ms on localhost (executor driver) (1/1)
19/07/31 13:10:00 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/07/31 13:10:00 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0.202 s
19/07/31 13:10:00 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0.216652 s
19/07/31 13:10:00 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:63054 in memory (size: 3.4 KB, free: 912.3 MB)
19/07/31 13:10:00 INFO ContextCleaner: Cleaned accumulator 0
19/07/31 13:10:00 INFO CodeGenerator: Code generated in 5.582648 ms
19/07/31 13:10:00 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:10:00 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 13:10:00 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 13:10:00 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:10:00 INFO CodeGenerator: Code generated in 5.625752 ms
19/07/31 13:10:00 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 281.2 KB, free 911.7 MB)
19/07/31 13:10:00 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.7 MB)
19/07/31 13:10:00 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:63054 (size: 23.8 KB, free: 912.2 MB)
19/07/31 13:10:00 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:0
19/07/31 13:10:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:10:00 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:10:00 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:10:00 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:10:00 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:10:00 INFO DAGScheduler: Missing parents: List()
19/07/31 13:10:00 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:10:00 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.8 KB, free 911.7 MB)
19/07/31 13:10:00 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.7 MB)
19/07/31 13:10:00 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:63054 (size: 8.6 KB, free: 912.2 MB)
19/07/31 13:10:00 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:00 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/07/31 13:10:00 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:10:00 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/07/31 13:10:00 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:10:00 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1627 bytes result sent to driver
19/07/31 13:10:00 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 72 ms on localhost (executor driver) (1/1)
19/07/31 13:10:00 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/07/31 13:10:00 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.072 s
19/07/31 13:10:00 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.080398 s
19/07/31 13:10:00 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:10:00 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:00 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:00 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:00 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:00 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:10:00 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:10:00 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 13:10:00 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 13:10:00 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 13:10:00 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:10:00 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 13:10:00 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 13:10:00 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:10:00 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 282.3 KB, free 911.4 MB)
19/07/31 13:10:00 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.4 MB)
19/07/31 13:10:00 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:63054 (size: 24.0 KB, free: 912.2 MB)
19/07/31 13:10:00 INFO SparkContext: Created broadcast 5 from sql at NativeMethodAccessorImpl.java:0
19/07/31 13:10:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:10:00 INFO CodeGenerator: Code generated in 9.017728 ms
19/07/31 13:10:00 INFO CodeGenerator: Code generated in 8.762911 ms
19/07/31 13:10:00 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 13:10:00 INFO DAGScheduler: Registering RDD 18 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 13:10:00 INFO DAGScheduler: Got job 3 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:10:00 INFO DAGScheduler: Final stage: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 13:10:00 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/07/31 13:10:00 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/07/31 13:10:00 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:10:00 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 26.3 KB, free 911.3 MB)
19/07/31 13:10:00 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.8 KB, free 911.3 MB)
19/07/31 13:10:00 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:63054 (size: 11.8 KB, free: 912.2 MB)
19/07/31 13:10:00 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:00 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:00 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/07/31 13:10:00 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:10:00 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/07/31 13:10:00 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:10:00 INFO CodeGenerator: Code generated in 13.454095 ms
19/07/31 13:10:00 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 48.9 KB, free 911.3 MB)
19/07/31 13:10:00 INFO BlockManagerInfo: Added rdd_15_0 in memory on 127.0.0.1:63054 (size: 48.9 KB, free: 912.2 MB)
19/07/31 13:10:00 INFO CodeGenerator: Code generated in 4.884683 ms
19/07/31 13:10:00 INFO CodeGenerator: Code generated in 15.603176 ms
19/07/31 13:10:01 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2504 bytes result sent to driver
19/07/31 13:10:01 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 200 ms on localhost (executor driver) (1/1)
19/07/31 13:10:01 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/07/31 13:10:01 INFO DAGScheduler: ShuffleMapStage 3 (sql at NativeMethodAccessorImpl.java:0) finished in 0.202 s
19/07/31 13:10:01 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:10:01 INFO DAGScheduler: running: Set()
19/07/31 13:10:01 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/07/31 13:10:01 INFO DAGScheduler: failed: Set()
19/07/31 13:10:01 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:10:01 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 911.3 MB)
19/07/31 13:10:01 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.3 MB)
19/07/31 13:10:01 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:63054 (size: 3.7 KB, free: 912.2 MB)
19/07/31 13:10:01 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:01 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/07/31 13:10:01 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:10:01 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/07/31 13:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
19/07/31 13:10:01 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1581 bytes result sent to driver
19/07/31 13:10:01 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 32 ms on localhost (executor driver) (1/1)
19/07/31 13:10:01 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/07/31 13:10:01 INFO DAGScheduler: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0) finished in 0.032 s
19/07/31 13:10:01 INFO DAGScheduler: Job 3 finished: sql at NativeMethodAccessorImpl.java:0, took 0.275875 s
19/07/31 13:10:01 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 13:10:01 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:01 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:10:01 INFO DAGScheduler: Registering RDD 24 (collect at utils.scala:204)
19/07/31 13:10:01 INFO DAGScheduler: Got job 4 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:10:01 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
19/07/31 13:10:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/07/31 13:10:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/07/31 13:10:01 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:01 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 26.3 KB, free 911.2 MB)
19/07/31 13:10:01 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.9 KB, free 911.2 MB)
19/07/31 13:10:01 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:63054 (size: 11.9 KB, free: 912.1 MB)
19/07/31 13:10:01 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:01 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/07/31 13:10:01 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:10:01 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/07/31 13:10:01 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:10:01 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1780 bytes result sent to driver
19/07/31 13:10:01 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 10 ms on localhost (executor driver) (1/1)
19/07/31 13:10:01 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/07/31 13:10:01 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:204) finished in 0.012 s
19/07/31 13:10:01 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:10:01 INFO DAGScheduler: running: Set()
19/07/31 13:10:01 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/07/31 13:10:01 INFO DAGScheduler: failed: Set()
19/07/31 13:10:01 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:01 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 911.2 MB)
19/07/31 13:10:01 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.2 MB)
19/07/31 13:10:01 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:63054 (size: 3.7 KB, free: 912.1 MB)
19/07/31 13:10:01 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:01 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/07/31 13:10:01 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:10:01 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/07/31 13:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:10:01 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1538 bytes result sent to driver
19/07/31 13:10:01 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 5 ms on localhost (executor driver) (1/1)
19/07/31 13:10:01 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/07/31 13:10:01 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.006 s
19/07/31 13:10:01 INFO DAGScheduler: Job 4 finished: collect at utils.scala:204, took 0.037502 s
19/07/31 13:10:01 INFO CodeGenerator: Code generated in 6.237617 ms
19/07/31 13:10:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz1`
WHERE (0 = 1)
19/07/31 13:10:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_001`) `dbplyr_002`
ORDER BY `date`) `dbplyr_003`) `dbplyr_004`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 13:10:01 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_005`) `dbplyr_006`
ORDER BY `date`) `dbplyr_007`) `dbplyr_008`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 13:10:01 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:01 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:01 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#442 - cust_prospect_ind.nullCount#441) > 0)
19/07/31 13:10:01 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#447 - visit_device_type.nullCount#446) > 0)
19/07/31 13:10:01 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#440 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#439))
19/07/31 13:10:01 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#445 <= All Devices) && (All Devices <= visit_device_type.upperBound#444))
19/07/31 13:10:01 INFO CodeGenerator: Code generated in 11.490905 ms
19/07/31 13:10:01 INFO CodeGenerator: Code generated in 15.50679 ms
19/07/31 13:10:01 INFO CodeGenerator: Code generated in 5.837587 ms
19/07/31 13:10:01 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:10:01 INFO DAGScheduler: Got job 5 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:10:01 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:204)
19/07/31 13:10:01 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:10:01 INFO DAGScheduler: Missing parents: List()
19/07/31 13:10:01 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[32] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:01 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 72.1 KB, free 911.2 MB)
19/07/31 13:10:01 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.1 MB)
19/07/31 13:10:01 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:63054 (size: 30.4 KB, free: 912.1 MB)
19/07/31 13:10:01 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:01 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/07/31 13:10:01 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:10:01 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
19/07/31 13:10:01 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:10:01 INFO CodeGenerator: Code generated in 7.784755 ms
19/07/31 13:10:01 INFO CodeGenerator: Code generated in 17.892842 ms
19/07/31 13:10:01 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 7585 bytes result sent to driver
19/07/31 13:10:01 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 59 ms on localhost (executor driver) (1/1)
19/07/31 13:10:01 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/07/31 13:10:01 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:204) finished in 0.059 s
19/07/31 13:10:01 INFO DAGScheduler: Job 5 finished: collect at utils.scala:204, took 0.070240 s
19/07/31 13:10:01 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:10:01 INFO DAGScheduler: Registering RDD 33 (collect at utils.scala:204)
19/07/31 13:10:01 INFO DAGScheduler: Got job 6 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:10:01 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:204)
19/07/31 13:10:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
19/07/31 13:10:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
19/07/31 13:10:01 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[33] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:01 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 74.6 KB, free 911.1 MB)
19/07/31 13:10:01 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 31.7 KB, free 911.0 MB)
19/07/31 13:10:01 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:63054 (size: 31.7 KB, free: 912.1 MB)
19/07/31 13:10:01 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[33] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:01 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/07/31 13:10:01 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:10:01 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
19/07/31 13:10:01 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:10:01 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1687 bytes result sent to driver
19/07/31 13:10:01 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 19 ms on localhost (executor driver) (1/1)
19/07/31 13:10:01 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/07/31 13:10:01 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:204) finished in 0.020 s
19/07/31 13:10:01 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:10:01 INFO DAGScheduler: running: Set()
19/07/31 13:10:01 INFO DAGScheduler: waiting: Set(ResultStage 9)
19/07/31 13:10:01 INFO DAGScheduler: failed: Set()
19/07/31 13:10:01 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[36] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:01 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 16.8 KB, free 911.0 MB)
19/07/31 13:10:01 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.0 MB)
19/07/31 13:10:01 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:63054 (size: 8.0 KB, free: 912.1 MB)
19/07/31 13:10:01 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:01 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 9 (MapPartitionsRDD[36] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:10:01 INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks
19/07/31 13:10:01 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:10:01 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 10, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:10:01 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 11, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:10:01 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 12, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:10:01 INFO Executor: Running task 1.0 in stage 9.0 (TID 10)
19/07/31 13:10:01 INFO Executor: Running task 3.0 in stage 9.0 (TID 12)
19/07/31 13:10:01 INFO Executor: Running task 2.0 in stage 9.0 (TID 11)
19/07/31 13:10:01 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
19/07/31 13:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:10:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:01 INFO CodeGenerator: Code generated in 6.404525 ms
19/07/31 13:10:01 INFO Executor: Finished task 1.0 in stage 9.0 (TID 10). 2403 bytes result sent to driver
19/07/31 13:10:01 INFO Executor: Finished task 3.0 in stage 9.0 (TID 12). 2362 bytes result sent to driver
19/07/31 13:10:01 INFO Executor: Finished task 2.0 in stage 9.0 (TID 11). 2390 bytes result sent to driver
19/07/31 13:10:01 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 10) in 46 ms on localhost (executor driver) (1/4)
19/07/31 13:10:01 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 12) in 46 ms on localhost (executor driver) (2/4)
19/07/31 13:10:01 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 11) in 46 ms on localhost (executor driver) (3/4)
19/07/31 13:10:01 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2382 bytes result sent to driver
19/07/31 13:10:01 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 48 ms on localhost (executor driver) (4/4)
19/07/31 13:10:01 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/07/31 13:10:01 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:204) finished in 0.049 s
19/07/31 13:10:01 INFO DAGScheduler: Job 6 finished: collect at utils.scala:204, took 0.087854 s
19/07/31 13:10:01 INFO CodeGenerator: Code generated in 11.984876 ms
19/07/31 13:10:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_009`) `dbplyr_010`
ORDER BY `date`) `dbplyr_011`) `dbplyr_012`
WHERE ((`customer` = "All Visitors") AND (`device` = "Mobile Phone"))
19/07/31 13:10:03 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:03 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_013`) `dbplyr_014`
ORDER BY `date`) `dbplyr_015`) `dbplyr_016`
WHERE ((`customer` = "All Visitors") AND (`device` = "Mobile Phone"))
19/07/31 13:10:03 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:03 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:03 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#540 - cust_prospect_ind.nullCount#539) > 0)
19/07/31 13:10:03 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#545 - visit_device_type.nullCount#544) > 0)
19/07/31 13:10:03 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#538 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#537))
19/07/31 13:10:03 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#543 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#542))
19/07/31 13:10:03 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:10:03 INFO DAGScheduler: Got job 7 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:10:03 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:204)
19/07/31 13:10:03 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:10:03 INFO DAGScheduler: Missing parents: List()
19/07/31 13:10:03 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[41] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:03 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 72.1 KB, free 910.9 MB)
19/07/31 13:10:03 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.9 MB)
19/07/31 13:10:03 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:63054 (size: 30.5 KB, free: 912.0 MB)
19/07/31 13:10:03 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[41] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:03 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/07/31 13:10:03 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:10:03 INFO Executor: Running task 0.0 in stage 10.0 (TID 13)
19/07/31 13:10:03 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:10:03 INFO Executor: Finished task 0.0 in stage 10.0 (TID 13). 7585 bytes result sent to driver
19/07/31 13:10:03 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 13) in 13 ms on localhost (executor driver) (1/1)
19/07/31 13:10:03 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/07/31 13:10:03 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:204) finished in 0.013 s
19/07/31 13:10:03 INFO DAGScheduler: Job 7 finished: collect at utils.scala:204, took 0.021108 s
19/07/31 13:10:03 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:10:03 INFO DAGScheduler: Registering RDD 42 (collect at utils.scala:204)
19/07/31 13:10:03 INFO DAGScheduler: Got job 8 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:10:03 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:204)
19/07/31 13:10:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
19/07/31 13:10:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
19/07/31 13:10:03 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[42] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:03 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 74.6 KB, free 910.8 MB)
19/07/31 13:10:03 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.8 MB)
19/07/31 13:10:03 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:63054 (size: 31.8 KB, free: 912.0 MB)
19/07/31 13:10:03 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[42] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:03 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/07/31 13:10:03 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:10:03 INFO Executor: Running task 0.0 in stage 11.0 (TID 14)
19/07/31 13:10:03 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:10:03 INFO Executor: Finished task 0.0 in stage 11.0 (TID 14). 1687 bytes result sent to driver
19/07/31 13:10:03 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 14) in 14 ms on localhost (executor driver) (1/1)
19/07/31 13:10:03 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/07/31 13:10:03 INFO DAGScheduler: ShuffleMapStage 11 (collect at utils.scala:204) finished in 0.015 s
19/07/31 13:10:03 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:10:03 INFO DAGScheduler: running: Set()
19/07/31 13:10:03 INFO DAGScheduler: waiting: Set(ResultStage 12)
19/07/31 13:10:03 INFO DAGScheduler: failed: Set()
19/07/31 13:10:03 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[45] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:03 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 16.8 KB, free 910.8 MB)
19/07/31 13:10:03 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.8 MB)
19/07/31 13:10:03 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:63054 (size: 8.0 KB, free: 912.0 MB)
19/07/31 13:10:03 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:03 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 12 (MapPartitionsRDD[45] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:10:03 INFO TaskSchedulerImpl: Adding task set 12.0 with 4 tasks
19/07/31 13:10:03 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 15, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:10:03 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 16, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:10:03 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 17, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:10:03 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 18, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:10:03 INFO Executor: Running task 1.0 in stage 12.0 (TID 16)
19/07/31 13:10:03 INFO Executor: Running task 3.0 in stage 12.0 (TID 18)
19/07/31 13:10:03 INFO Executor: Running task 2.0 in stage 12.0 (TID 17)
19/07/31 13:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:10:03 INFO Executor: Running task 0.0 in stage 12.0 (TID 15)
19/07/31 13:10:03 INFO Executor: Finished task 1.0 in stage 12.0 (TID 16). 2383 bytes result sent to driver
19/07/31 13:10:03 INFO Executor: Finished task 3.0 in stage 12.0 (TID 18). 2358 bytes result sent to driver
19/07/31 13:10:03 INFO Executor: Finished task 2.0 in stage 12.0 (TID 17). 2372 bytes result sent to driver
19/07/31 13:10:03 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 18) in 12 ms on localhost (executor driver) (1/4)
19/07/31 13:10:03 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 16) in 12 ms on localhost (executor driver) (2/4)
19/07/31 13:10:03 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 17) in 12 ms on localhost (executor driver) (3/4)
19/07/31 13:10:03 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:10:03 INFO Executor: Finished task 0.0 in stage 12.0 (TID 15). 2385 bytes result sent to driver
19/07/31 13:10:03 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 15) in 16 ms on localhost (executor driver) (4/4)
19/07/31 13:10:03 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/07/31 13:10:03 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:204) finished in 0.016 s
19/07/31 13:10:03 INFO DAGScheduler: Job 8 finished: collect at utils.scala:204, took 0.046993 s
19/07/31 13:10:05 INFO SparkContext: Invoking stop() from shutdown hook
19/07/31 13:10:05 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
19/07/31 13:10:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/07/31 13:10:05 INFO MemoryStore: MemoryStore cleared
19/07/31 13:10:05 INFO BlockManager: BlockManager stopped
19/07/31 13:10:05 INFO BlockManagerMaster: BlockManagerMaster stopped
19/07/31 13:10:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/07/31 13:10:05 INFO SparkContext: Successfully stopped SparkContext
19/07/31 13:10:05 INFO ShutdownHookManager: Shutdown hook called
19/07/31 13:10:05 INFO ShutdownHookManager: Deleting directory /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-9ff8838d-8c1e-422a-88f2-05ffca0439e5
19/07/31 13:10:30 INFO SparkContext: Running Spark version 2.2.0
19/07/31 13:10:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/07/31 13:10:31 INFO SparkContext: Submitted application: sparklyr
19/07/31 13:10:31 INFO SecurityManager: Changing view acls to: 6jncnk4f
19/07/31 13:10:31 INFO SecurityManager: Changing modify acls to: 6jncnk4f
19/07/31 13:10:31 INFO SecurityManager: Changing view acls groups to: 
19/07/31 13:10:31 INFO SecurityManager: Changing modify acls groups to: 
19/07/31 13:10:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(6jncnk4f); groups with view permissions: Set(); users  with modify permissions: Set(6jncnk4f); groups with modify permissions: Set()
19/07/31 13:10:31 INFO Utils: Successfully started service 'sparkDriver' on port 63076.
19/07/31 13:10:31 INFO SparkEnv: Registering MapOutputTracker
19/07/31 13:10:31 INFO SparkEnv: Registering BlockManagerMaster
19/07/31 13:10:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/07/31 13:10:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/07/31 13:10:31 INFO DiskBlockManager: Created local directory at /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/blockmgr-df14abd5-fca5-40ab-857f-db661eb1ba93
19/07/31 13:10:31 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/07/31 13:10:31 INFO SparkEnv: Registering OutputCommitCoordinator
19/07/31 13:10:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/07/31 13:10:31 INFO Utils: Successfully started service 'SparkUI' on port 4041.
19/07/31 13:10:31 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
19/07/31 13:10:31 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:63076/jars/sparklyr-2.0-2.11.jar with timestamp 1564593031676
19/07/31 13:10:31 INFO Executor: Starting executor ID driver on host localhost
19/07/31 13:10:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63077.
19/07/31 13:10:31 INFO NettyBlockTransferService: Server created on 127.0.0.1:63077
19/07/31 13:10:31 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/07/31 13:10:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 63077, None)
19/07/31 13:10:31 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:63077 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 63077, None)
19/07/31 13:10:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 63077, None)
19/07/31 13:10:31 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 63077, None)
19/07/31 13:10:31 INFO SharedState: loading hive config file: file:/Users/6jncnk4f/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/07/31 13:10:32 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse').
19/07/31 13:10:32 INFO SharedState: Warehouse path is 'file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse'.
19/07/31 13:10:32 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/07/31 13:10:33 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/07/31 13:10:33 INFO ObjectStore: ObjectStore, initialize called
19/07/31 13:10:33 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/07/31 13:10:33 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/07/31 13:10:34 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/07/31 13:10:35 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:10:35 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:10:35 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:10:35 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:10:35 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/07/31 13:10:35 INFO ObjectStore: Initialized ObjectStore
19/07/31 13:10:35 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/07/31 13:10:35 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/07/31 13:10:35 INFO HiveMetaStore: Added admin role in metastore
19/07/31 13:10:35 INFO HiveMetaStore: Added public role in metastore
19/07/31 13:10:36 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/07/31 13:10:36 INFO HiveMetaStore: 0: get_all_databases
19/07/31 13:10:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_all_databases	
19/07/31 13:10:36 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/07/31 13:10:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/07/31 13:10:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:10:36 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/525ee1ca-803e-451b-8f2c-b1ca7a076217_resources
19/07/31 13:10:36 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/525ee1ca-803e-451b-8f2c-b1ca7a076217
19/07/31 13:10:36 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/525ee1ca-803e-451b-8f2c-b1ca7a076217
19/07/31 13:10:36 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/525ee1ca-803e-451b-8f2c-b1ca7a076217/_tmp_space.db
19/07/31 13:10:36 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 13:10:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:36 INFO HiveMetaStore: 0: get_database: global_temp
19/07/31 13:10:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/07/31 13:10:36 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/07/31 13:10:36 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/401e67d8-2ff5-4186-82fb-7cd795376ef0_resources
19/07/31 13:10:36 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/401e67d8-2ff5-4186-82fb-7cd795376ef0
19/07/31 13:10:36 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/401e67d8-2ff5-4186-82fb-7cd795376ef0
19/07/31 13:10:36 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/401e67d8-2ff5-4186-82fb-7cd795376ef0/_tmp_space.db
19/07/31 13:10:36 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 13:10:36 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/07/31 13:10:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:10:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:10:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:10:38 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 13:10:38 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/07/31 13:10:38 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/07/31 13:10:38 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:10:38 INFO DAGScheduler: Missing parents: List()
19/07/31 13:10:38 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/07/31 13:10:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/07/31 13:10:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/07/31 13:10:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:63077 (size: 3.4 KB, free: 912.3 MB)
19/07/31 13:10:38 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/07/31 13:10:38 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/07/31 13:10:38 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/07/31 13:10:38 INFO Executor: Fetching spark://127.0.0.1:63076/jars/sparklyr-2.0-2.11.jar with timestamp 1564593031676
19/07/31 13:10:38 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:63076 after 16 ms (0 ms spent in bootstraps)
19/07/31 13:10:38 INFO Utils: Fetching spark://127.0.0.1:63076/jars/sparklyr-2.0-2.11.jar to /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-c44a3664-da8a-4f39-abe2-a606c3687478/userFiles-51da45dd-3f76-4ffd-9c43-835fa4a6df0d/fetchFileTemp6360058049400313837.tmp
19/07/31 13:10:38 INFO Executor: Adding file:/private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-c44a3664-da8a-4f39-abe2-a606c3687478/userFiles-51da45dd-3f76-4ffd-9c43-835fa4a6df0d/sparklyr-2.0-2.11.jar to class loader
19/07/31 13:10:38 INFO CodeGenerator: Code generated in 174.198155 ms
19/07/31 13:10:38 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
19/07/31 13:10:38 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 433 ms on localhost (executor driver) (1/1)
19/07/31 13:10:38 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/07/31 13:10:38 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.451 s
19/07/31 13:10:38 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0.615324 s
19/07/31 13:10:39 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:10:39 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#10)) > 0)
19/07/31 13:10:39 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 13:10:39 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:10:39 INFO CodeGenerator: Code generated in 13.25098 ms
19/07/31 13:10:39 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 281.2 KB, free 912.0 MB)
19/07/31 13:10:39 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.8 KB, free 912.0 MB)
19/07/31 13:10:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:63077 (size: 23.8 KB, free: 912.3 MB)
19/07/31 13:10:39 INFO SparkContext: Created broadcast 1 from csv at NativeMethodAccessorImpl.java:0
19/07/31 13:10:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:10:39 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:10:39 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:10:39 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:10:39 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:10:39 INFO DAGScheduler: Missing parents: List()
19/07/31 13:10:39 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:10:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 912.0 MB)
19/07/31 13:10:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 912.0 MB)
19/07/31 13:10:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:63077 (size: 4.3 KB, free: 912.3 MB)
19/07/31 13:10:39 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:39 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/07/31 13:10:39 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:10:39 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/07/31 13:10:39 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:10:39 INFO CodeGenerator: Code generated in 7.375094 ms
19/07/31 13:10:39 INFO ContextCleaner: Cleaned accumulator 0
19/07/31 13:10:39 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:63077 in memory (size: 3.4 KB, free: 912.3 MB)
19/07/31 13:10:39 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1480 bytes result sent to driver
19/07/31 13:10:39 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 223 ms on localhost (executor driver) (1/1)
19/07/31 13:10:39 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/07/31 13:10:39 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0.224 s
19/07/31 13:10:39 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0.244278 s
19/07/31 13:10:39 INFO CodeGenerator: Code generated in 6.681058 ms
19/07/31 13:10:39 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:10:39 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 13:10:39 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 13:10:39 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:10:39 INFO CodeGenerator: Code generated in 6.250036 ms
19/07/31 13:10:39 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 281.2 KB, free 911.7 MB)
19/07/31 13:10:39 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.7 MB)
19/07/31 13:10:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:63077 (size: 23.8 KB, free: 912.2 MB)
19/07/31 13:10:39 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:0
19/07/31 13:10:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:10:39 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:10:39 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:10:39 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:10:39 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:10:39 INFO DAGScheduler: Missing parents: List()
19/07/31 13:10:39 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:10:39 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.8 KB, free 911.7 MB)
19/07/31 13:10:39 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.7 MB)
19/07/31 13:10:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:63077 (size: 8.6 KB, free: 912.2 MB)
19/07/31 13:10:39 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:39 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/07/31 13:10:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:10:39 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/07/31 13:10:39 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:10:39 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1627 bytes result sent to driver
19/07/31 13:10:39 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 69 ms on localhost (executor driver) (1/1)
19/07/31 13:10:39 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/07/31 13:10:39 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.070 s
19/07/31 13:10:39 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.077673 s
19/07/31 13:10:39 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:10:39 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:39 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:39 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:10:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:10:39 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 13:10:39 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 13:10:39 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 13:10:39 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:10:39 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 13:10:39 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 13:10:39 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:10:39 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 282.3 KB, free 911.4 MB)
19/07/31 13:10:40 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.4 MB)
19/07/31 13:10:40 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:63077 (size: 24.0 KB, free: 912.2 MB)
19/07/31 13:10:40 INFO SparkContext: Created broadcast 5 from sql at NativeMethodAccessorImpl.java:0
19/07/31 13:10:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:10:40 INFO CodeGenerator: Code generated in 11.184398 ms
19/07/31 13:10:40 INFO CodeGenerator: Code generated in 9.203829 ms
19/07/31 13:10:40 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 13:10:40 INFO DAGScheduler: Registering RDD 18 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 13:10:40 INFO DAGScheduler: Got job 3 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:10:40 INFO DAGScheduler: Final stage: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 13:10:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/07/31 13:10:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/07/31 13:10:40 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:10:40 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 26.3 KB, free 911.3 MB)
19/07/31 13:10:40 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.8 KB, free 911.3 MB)
19/07/31 13:10:40 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:63077 (size: 11.8 KB, free: 912.2 MB)
19/07/31 13:10:40 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:40 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/07/31 13:10:40 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:10:40 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/07/31 13:10:40 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:10:40 INFO CodeGenerator: Code generated in 15.2714 ms
19/07/31 13:10:40 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 48.9 KB, free 911.3 MB)
19/07/31 13:10:40 INFO BlockManagerInfo: Added rdd_15_0 in memory on 127.0.0.1:63077 (size: 48.9 KB, free: 912.2 MB)
19/07/31 13:10:40 INFO CodeGenerator: Code generated in 4.598516 ms
19/07/31 13:10:40 INFO CodeGenerator: Code generated in 15.478801 ms
19/07/31 13:10:40 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2504 bytes result sent to driver
19/07/31 13:10:40 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 216 ms on localhost (executor driver) (1/1)
19/07/31 13:10:40 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/07/31 13:10:40 INFO DAGScheduler: ShuffleMapStage 3 (sql at NativeMethodAccessorImpl.java:0) finished in 0.217 s
19/07/31 13:10:40 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:10:40 INFO DAGScheduler: running: Set()
19/07/31 13:10:40 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/07/31 13:10:40 INFO DAGScheduler: failed: Set()
19/07/31 13:10:40 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:10:40 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 911.3 MB)
19/07/31 13:10:40 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.3 MB)
19/07/31 13:10:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:63077 (size: 3.7 KB, free: 912.2 MB)
19/07/31 13:10:40 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:40 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/07/31 13:10:40 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:10:40 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/07/31 13:10:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
19/07/31 13:10:40 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1581 bytes result sent to driver
19/07/31 13:10:40 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 35 ms on localhost (executor driver) (1/1)
19/07/31 13:10:40 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/07/31 13:10:40 INFO DAGScheduler: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0) finished in 0.036 s
19/07/31 13:10:40 INFO DAGScheduler: Job 3 finished: sql at NativeMethodAccessorImpl.java:0, took 0.299042 s
19/07/31 13:10:40 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 13:10:40 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:40 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:40 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:10:40 INFO DAGScheduler: Registering RDD 24 (collect at utils.scala:204)
19/07/31 13:10:40 INFO DAGScheduler: Got job 4 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:10:40 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
19/07/31 13:10:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/07/31 13:10:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/07/31 13:10:40 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:40 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 26.3 KB, free 911.2 MB)
19/07/31 13:10:40 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.9 KB, free 911.2 MB)
19/07/31 13:10:40 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:63077 (size: 11.9 KB, free: 912.1 MB)
19/07/31 13:10:40 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:40 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/07/31 13:10:40 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:10:40 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/07/31 13:10:40 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:10:40 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1780 bytes result sent to driver
19/07/31 13:10:40 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 18 ms on localhost (executor driver) (1/1)
19/07/31 13:10:40 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/07/31 13:10:40 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:204) finished in 0.018 s
19/07/31 13:10:40 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:10:40 INFO DAGScheduler: running: Set()
19/07/31 13:10:40 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/07/31 13:10:40 INFO DAGScheduler: failed: Set()
19/07/31 13:10:40 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:40 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 911.2 MB)
19/07/31 13:10:40 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.2 MB)
19/07/31 13:10:40 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:63077 (size: 3.7 KB, free: 912.1 MB)
19/07/31 13:10:40 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:40 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/07/31 13:10:40 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:10:40 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/07/31 13:10:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:40 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1581 bytes result sent to driver
19/07/31 13:10:40 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 4 ms on localhost (executor driver) (1/1)
19/07/31 13:10:40 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/07/31 13:10:40 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.006 s
19/07/31 13:10:40 INFO DAGScheduler: Job 4 finished: collect at utils.scala:204, took 0.040124 s
19/07/31 13:10:40 INFO CodeGenerator: Code generated in 5.459469 ms
19/07/31 13:10:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz1`
WHERE (0 = 1)
19/07/31 13:10:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_001`) `dbplyr_002`
ORDER BY `date`) `dbplyr_003`) `dbplyr_004`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 13:10:40 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:40 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_005`) `dbplyr_006`
ORDER BY `date`) `dbplyr_007`) `dbplyr_008`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 13:10:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:41 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#442 - cust_prospect_ind.nullCount#441) > 0)
19/07/31 13:10:41 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#447 - visit_device_type.nullCount#446) > 0)
19/07/31 13:10:41 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#440 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#439))
19/07/31 13:10:41 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#445 <= All Devices) && (All Devices <= visit_device_type.upperBound#444))
19/07/31 13:10:41 INFO CodeGenerator: Code generated in 22.760964 ms
19/07/31 13:10:41 INFO CodeGenerator: Code generated in 17.565209 ms
19/07/31 13:10:41 INFO CodeGenerator: Code generated in 5.876045 ms
19/07/31 13:10:41 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:10:41 INFO DAGScheduler: Got job 5 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:10:41 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:204)
19/07/31 13:10:41 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:10:41 INFO DAGScheduler: Missing parents: List()
19/07/31 13:10:41 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[32] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:41 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 72.1 KB, free 911.2 MB)
19/07/31 13:10:41 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.1 MB)
19/07/31 13:10:41 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:63077 (size: 30.4 KB, free: 912.1 MB)
19/07/31 13:10:41 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:41 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/07/31 13:10:41 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:10:41 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
19/07/31 13:10:41 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:10:41 INFO CodeGenerator: Code generated in 7.342556 ms
19/07/31 13:10:41 INFO CodeGenerator: Code generated in 13.891341 ms
19/07/31 13:10:41 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 7585 bytes result sent to driver
19/07/31 13:10:41 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 54 ms on localhost (executor driver) (1/1)
19/07/31 13:10:41 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/07/31 13:10:41 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:204) finished in 0.054 s
19/07/31 13:10:41 INFO DAGScheduler: Job 5 finished: collect at utils.scala:204, took 0.064864 s
19/07/31 13:10:41 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:10:41 INFO DAGScheduler: Registering RDD 33 (collect at utils.scala:204)
19/07/31 13:10:41 INFO DAGScheduler: Got job 6 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:10:41 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:204)
19/07/31 13:10:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
19/07/31 13:10:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
19/07/31 13:10:41 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[33] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:41 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 74.6 KB, free 911.1 MB)
19/07/31 13:10:41 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 31.7 KB, free 911.0 MB)
19/07/31 13:10:41 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:63077 (size: 31.7 KB, free: 912.1 MB)
19/07/31 13:10:41 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[33] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:41 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/07/31 13:10:41 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:10:41 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
19/07/31 13:10:41 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:10:41 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1687 bytes result sent to driver
19/07/31 13:10:41 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 18 ms on localhost (executor driver) (1/1)
19/07/31 13:10:41 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/07/31 13:10:41 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:204) finished in 0.018 s
19/07/31 13:10:41 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:10:41 INFO DAGScheduler: running: Set()
19/07/31 13:10:41 INFO DAGScheduler: waiting: Set(ResultStage 9)
19/07/31 13:10:41 INFO DAGScheduler: failed: Set()
19/07/31 13:10:41 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[36] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:41 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 16.8 KB, free 911.0 MB)
19/07/31 13:10:41 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.0 MB)
19/07/31 13:10:41 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:63077 (size: 8.0 KB, free: 912.1 MB)
19/07/31 13:10:41 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:41 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 9 (MapPartitionsRDD[36] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:10:41 INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks
19/07/31 13:10:41 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:10:41 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 10, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:10:41 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 11, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:10:41 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 12, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:10:41 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
19/07/31 13:10:41 INFO Executor: Running task 1.0 in stage 9.0 (TID 10)
19/07/31 13:10:41 INFO Executor: Running task 3.0 in stage 9.0 (TID 12)
19/07/31 13:10:41 INFO Executor: Running task 2.0 in stage 9.0 (TID 11)
19/07/31 13:10:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:10:41 INFO CodeGenerator: Code generated in 5.014449 ms
19/07/31 13:10:41 INFO Executor: Finished task 3.0 in stage 9.0 (TID 12). 2362 bytes result sent to driver
19/07/31 13:10:41 INFO Executor: Finished task 1.0 in stage 9.0 (TID 10). 2403 bytes result sent to driver
19/07/31 13:10:41 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 12) in 52 ms on localhost (executor driver) (1/4)
19/07/31 13:10:41 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 10) in 53 ms on localhost (executor driver) (2/4)
19/07/31 13:10:41 INFO Executor: Finished task 2.0 in stage 9.0 (TID 11). 2390 bytes result sent to driver
19/07/31 13:10:41 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2382 bytes result sent to driver
19/07/31 13:10:41 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 11) in 54 ms on localhost (executor driver) (3/4)
19/07/31 13:10:41 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 54 ms on localhost (executor driver) (4/4)
19/07/31 13:10:41 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/07/31 13:10:41 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:204) finished in 0.055 s
19/07/31 13:10:41 INFO DAGScheduler: Job 6 finished: collect at utils.scala:204, took 0.088965 s
19/07/31 13:10:41 INFO CodeGenerator: Code generated in 12.824751 ms
19/07/31 13:10:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_009`) `dbplyr_010`
ORDER BY `date`) `dbplyr_011`) `dbplyr_012`
WHERE ((`customer` = "All Visitors") AND (`device` = "Mobile Phone"))
19/07/31 13:10:42 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:42 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_013`) `dbplyr_014`
ORDER BY `date`) `dbplyr_015`) `dbplyr_016`
WHERE ((`customer` = "All Visitors") AND (`device` = "Mobile Phone"))
19/07/31 13:10:42 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:42 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:42 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#540 - cust_prospect_ind.nullCount#539) > 0)
19/07/31 13:10:42 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#545 - visit_device_type.nullCount#544) > 0)
19/07/31 13:10:42 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#538 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#537))
19/07/31 13:10:42 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#543 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#542))
19/07/31 13:10:42 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:10:42 INFO DAGScheduler: Got job 7 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:10:42 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:204)
19/07/31 13:10:42 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:10:42 INFO DAGScheduler: Missing parents: List()
19/07/31 13:10:42 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[41] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:42 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 72.1 KB, free 910.9 MB)
19/07/31 13:10:42 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.9 MB)
19/07/31 13:10:42 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:63077 (size: 30.5 KB, free: 912.0 MB)
19/07/31 13:10:42 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[41] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:42 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/07/31 13:10:42 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:10:42 INFO Executor: Running task 0.0 in stage 10.0 (TID 13)
19/07/31 13:10:42 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:10:42 INFO Executor: Finished task 0.0 in stage 10.0 (TID 13). 7542 bytes result sent to driver
19/07/31 13:10:42 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 13) in 13 ms on localhost (executor driver) (1/1)
19/07/31 13:10:42 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/07/31 13:10:42 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:204) finished in 0.013 s
19/07/31 13:10:42 INFO DAGScheduler: Job 7 finished: collect at utils.scala:204, took 0.023133 s
19/07/31 13:10:42 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:10:42 INFO DAGScheduler: Registering RDD 42 (collect at utils.scala:204)
19/07/31 13:10:42 INFO DAGScheduler: Got job 8 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:10:42 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:204)
19/07/31 13:10:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
19/07/31 13:10:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
19/07/31 13:10:42 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[42] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:42 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 74.6 KB, free 910.8 MB)
19/07/31 13:10:42 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.8 MB)
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 182
19/07/31 13:10:42 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:63077 (size: 31.8 KB, free: 912.0 MB)
19/07/31 13:10:42 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:42 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:63077 in memory (size: 11.9 KB, free: 912.0 MB)
19/07/31 13:10:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[42] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:42 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 241
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 239
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 178
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 120
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 115
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 117
19/07/31 13:10:42 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:10:42 INFO Executor: Running task 0.0 in stage 11.0 (TID 14)
19/07/31 13:10:42 INFO ContextCleaner: Cleaned shuffle 0
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 176
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 244
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 119
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 186
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 175
19/07/31 13:10:42 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:63077 in memory (size: 11.8 KB, free: 912.0 MB)
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 243
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 124
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 118
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 116
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 240
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 121
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 185
19/07/31 13:10:42 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:63077 in memory (size: 30.4 KB, free: 912.1 MB)
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 237
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 179
19/07/31 13:10:42 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:63077 in memory (size: 8.0 KB, free: 912.1 MB)
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 317
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 238
19/07/31 13:10:42 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:10:42 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:63077 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 236
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 183
19/07/31 13:10:42 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:63077 in memory (size: 31.7 KB, free: 912.1 MB)
19/07/31 13:10:42 INFO ContextCleaner: Cleaned shuffle 1
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 123
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 242
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 181
19/07/31 13:10:42 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:63077 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 13:10:42 INFO ContextCleaner: Cleaned shuffle 2
19/07/31 13:10:42 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:63077 in memory (size: 8.6 KB, free: 912.1 MB)
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 114
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 126
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 122
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 177
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 187
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 125
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 180
19/07/31 13:10:42 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:63077 in memory (size: 30.5 KB, free: 912.1 MB)
19/07/31 13:10:42 INFO ContextCleaner: Cleaned accumulator 184
19/07/31 13:10:42 INFO Executor: Finished task 0.0 in stage 11.0 (TID 14). 1687 bytes result sent to driver
19/07/31 13:10:42 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 14) in 18 ms on localhost (executor driver) (1/1)
19/07/31 13:10:42 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/07/31 13:10:42 INFO DAGScheduler: ShuffleMapStage 11 (collect at utils.scala:204) finished in 0.018 s
19/07/31 13:10:42 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:10:42 INFO DAGScheduler: running: Set()
19/07/31 13:10:42 INFO DAGScheduler: waiting: Set(ResultStage 12)
19/07/31 13:10:42 INFO DAGScheduler: failed: Set()
19/07/31 13:10:42 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[45] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:42 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 16.8 KB, free 911.2 MB)
19/07/31 13:10:42 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.2 MB)
19/07/31 13:10:42 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:63077 (size: 8.0 KB, free: 912.1 MB)
19/07/31 13:10:42 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:42 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 12 (MapPartitionsRDD[45] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:10:42 INFO TaskSchedulerImpl: Adding task set 12.0 with 4 tasks
19/07/31 13:10:42 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 15, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:10:42 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 16, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:10:42 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 17, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:10:42 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 18, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:10:42 INFO Executor: Running task 1.0 in stage 12.0 (TID 16)
19/07/31 13:10:42 INFO Executor: Running task 2.0 in stage 12.0 (TID 17)
19/07/31 13:10:42 INFO Executor: Running task 3.0 in stage 12.0 (TID 18)
19/07/31 13:10:42 INFO Executor: Running task 0.0 in stage 12.0 (TID 15)
19/07/31 13:10:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:42 INFO Executor: Finished task 2.0 in stage 12.0 (TID 17). 2372 bytes result sent to driver
19/07/31 13:10:42 INFO Executor: Finished task 3.0 in stage 12.0 (TID 18). 2358 bytes result sent to driver
19/07/31 13:10:42 INFO Executor: Finished task 1.0 in stage 12.0 (TID 16). 2383 bytes result sent to driver
19/07/31 13:10:42 INFO Executor: Finished task 0.0 in stage 12.0 (TID 15). 2385 bytes result sent to driver
19/07/31 13:10:42 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 17) in 9 ms on localhost (executor driver) (1/4)
19/07/31 13:10:42 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 18) in 9 ms on localhost (executor driver) (2/4)
19/07/31 13:10:42 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 16) in 10 ms on localhost (executor driver) (3/4)
19/07/31 13:10:42 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 15) in 11 ms on localhost (executor driver) (4/4)
19/07/31 13:10:42 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/07/31 13:10:42 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:204) finished in 0.012 s
19/07/31 13:10:42 INFO DAGScheduler: Job 8 finished: collect at utils.scala:204, took 0.058026 s
19/07/31 13:10:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_017`) `dbplyr_018`
ORDER BY `date`) `dbplyr_019`) `dbplyr_020`
WHERE ((`customer` = "All Visitors") AND (`device` = "Desktop"))
19/07/31 13:10:43 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:43 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_021`) `dbplyr_022`
ORDER BY `date`) `dbplyr_023`) `dbplyr_024`
WHERE ((`customer` = "All Visitors") AND (`device` = "Desktop"))
19/07/31 13:10:43 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:43 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:43 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#638 - cust_prospect_ind.nullCount#637) > 0)
19/07/31 13:10:43 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#643 - visit_device_type.nullCount#642) > 0)
19/07/31 13:10:43 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#636 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#635))
19/07/31 13:10:43 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#641 <= Desktop) && (Desktop <= visit_device_type.upperBound#640))
19/07/31 13:10:43 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:10:43 INFO DAGScheduler: Got job 9 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:10:43 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:204)
19/07/31 13:10:43 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:10:43 INFO DAGScheduler: Missing parents: List()
19/07/31 13:10:43 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[50] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:43 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 72.1 KB, free 911.1 MB)
19/07/31 13:10:43 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 30.5 KB, free 911.1 MB)
19/07/31 13:10:43 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:63077 (size: 30.5 KB, free: 912.1 MB)
19/07/31 13:10:43 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[50] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:43 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/07/31 13:10:43 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:10:43 INFO Executor: Running task 0.0 in stage 13.0 (TID 19)
19/07/31 13:10:43 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:10:43 INFO Executor: Finished task 0.0 in stage 13.0 (TID 19). 7068 bytes result sent to driver
19/07/31 13:10:43 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 19) in 10 ms on localhost (executor driver) (1/1)
19/07/31 13:10:43 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/07/31 13:10:43 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:204) finished in 0.011 s
19/07/31 13:10:43 INFO DAGScheduler: Job 9 finished: collect at utils.scala:204, took 0.018849 s
19/07/31 13:10:43 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:10:43 INFO DAGScheduler: Registering RDD 51 (collect at utils.scala:204)
19/07/31 13:10:43 INFO DAGScheduler: Got job 10 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:10:43 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:204)
19/07/31 13:10:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
19/07/31 13:10:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
19/07/31 13:10:43 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[51] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:43 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 74.5 KB, free 911.0 MB)
19/07/31 13:10:43 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.0 MB)
19/07/31 13:10:43 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:63077 (size: 31.8 KB, free: 912.1 MB)
19/07/31 13:10:43 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[51] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:43 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/07/31 13:10:43 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:10:43 INFO Executor: Running task 0.0 in stage 14.0 (TID 20)
19/07/31 13:10:43 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:10:43 INFO Executor: Finished task 0.0 in stage 14.0 (TID 20). 1687 bytes result sent to driver
19/07/31 13:10:43 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 20) in 15 ms on localhost (executor driver) (1/1)
19/07/31 13:10:43 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/07/31 13:10:43 INFO DAGScheduler: ShuffleMapStage 14 (collect at utils.scala:204) finished in 0.015 s
19/07/31 13:10:43 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:10:43 INFO DAGScheduler: running: Set()
19/07/31 13:10:43 INFO DAGScheduler: waiting: Set(ResultStage 15)
19/07/31 13:10:43 INFO DAGScheduler: failed: Set()
19/07/31 13:10:43 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[54] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:43 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 16.8 KB, free 911.0 MB)
19/07/31 13:10:43 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.0 MB)
19/07/31 13:10:43 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:63077 (size: 8.0 KB, free: 912.1 MB)
19/07/31 13:10:43 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:43 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:10:43 INFO TaskSchedulerImpl: Adding task set 15.0 with 4 tasks
19/07/31 13:10:43 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 21, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:10:43 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 22, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:10:43 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 23, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:10:43 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 24, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:10:43 INFO Executor: Running task 0.0 in stage 15.0 (TID 21)
19/07/31 13:10:43 INFO Executor: Running task 2.0 in stage 15.0 (TID 23)
19/07/31 13:10:43 INFO Executor: Running task 3.0 in stage 15.0 (TID 24)
19/07/31 13:10:43 INFO Executor: Running task 1.0 in stage 15.0 (TID 22)
19/07/31 13:10:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:43 INFO Executor: Finished task 3.0 in stage 15.0 (TID 24). 2356 bytes result sent to driver
19/07/31 13:10:43 INFO Executor: Finished task 0.0 in stage 15.0 (TID 21). 2381 bytes result sent to driver
19/07/31 13:10:43 INFO Executor: Finished task 2.0 in stage 15.0 (TID 23). 2380 bytes result sent to driver
19/07/31 13:10:43 INFO Executor: Finished task 1.0 in stage 15.0 (TID 22). 2385 bytes result sent to driver
19/07/31 13:10:43 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 24) in 7 ms on localhost (executor driver) (1/4)
19/07/31 13:10:43 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 23) in 8 ms on localhost (executor driver) (2/4)
19/07/31 13:10:43 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 21) in 9 ms on localhost (executor driver) (3/4)
19/07/31 13:10:43 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 22) in 8 ms on localhost (executor driver) (4/4)
19/07/31 13:10:43 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/07/31 13:10:43 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:204) finished in 0.010 s
19/07/31 13:10:43 INFO DAGScheduler: Job 10 finished: collect at utils.scala:204, took 0.038297 s
19/07/31 13:10:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_025`) `dbplyr_026`
ORDER BY `date`) `dbplyr_027`) `dbplyr_028`
WHERE ((`customer` = "All Visitors") AND (`device` = "Tablet"))
19/07/31 13:10:44 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:44 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_029`) `dbplyr_030`
ORDER BY `date`) `dbplyr_031`) `dbplyr_032`
WHERE ((`customer` = "All Visitors") AND (`device` = "Tablet"))
19/07/31 13:10:44 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:44 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:44 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#736 - cust_prospect_ind.nullCount#735) > 0)
19/07/31 13:10:44 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#741 - visit_device_type.nullCount#740) > 0)
19/07/31 13:10:44 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#734 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#733))
19/07/31 13:10:44 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#739 <= Tablet) && (Tablet <= visit_device_type.upperBound#738))
19/07/31 13:10:44 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:10:44 INFO DAGScheduler: Got job 11 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:10:44 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:204)
19/07/31 13:10:44 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:10:44 INFO DAGScheduler: Missing parents: List()
19/07/31 13:10:44 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[59] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:44 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 72.1 KB, free 910.9 MB)
19/07/31 13:10:44 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.9 MB)
19/07/31 13:10:44 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:63077 (size: 30.4 KB, free: 912.0 MB)
19/07/31 13:10:44 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[59] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:44 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/07/31 13:10:44 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:10:44 INFO Executor: Running task 0.0 in stage 16.0 (TID 25)
19/07/31 13:10:44 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:10:44 INFO Executor: Finished task 0.0 in stage 16.0 (TID 25). 7068 bytes result sent to driver
19/07/31 13:10:44 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 25) in 8 ms on localhost (executor driver) (1/1)
19/07/31 13:10:44 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/07/31 13:10:44 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:204) finished in 0.009 s
19/07/31 13:10:44 INFO DAGScheduler: Job 11 finished: collect at utils.scala:204, took 0.016830 s
19/07/31 13:10:44 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:10:44 INFO DAGScheduler: Registering RDD 60 (collect at utils.scala:204)
19/07/31 13:10:44 INFO DAGScheduler: Got job 12 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:10:44 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:204)
19/07/31 13:10:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
19/07/31 13:10:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
19/07/31 13:10:44 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[60] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:44 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 74.5 KB, free 910.8 MB)
19/07/31 13:10:44 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.8 MB)
19/07/31 13:10:44 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:63077 (size: 31.7 KB, free: 912.0 MB)
19/07/31 13:10:44 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[60] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:44 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
19/07/31 13:10:44 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:10:44 INFO Executor: Running task 0.0 in stage 17.0 (TID 26)
19/07/31 13:10:44 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:10:44 INFO Executor: Finished task 0.0 in stage 17.0 (TID 26). 1687 bytes result sent to driver
19/07/31 13:10:44 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 26) in 13 ms on localhost (executor driver) (1/1)
19/07/31 13:10:44 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/07/31 13:10:44 INFO DAGScheduler: ShuffleMapStage 17 (collect at utils.scala:204) finished in 0.014 s
19/07/31 13:10:44 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:10:44 INFO DAGScheduler: running: Set()
19/07/31 13:10:44 INFO DAGScheduler: waiting: Set(ResultStage 18)
19/07/31 13:10:44 INFO DAGScheduler: failed: Set()
19/07/31 13:10:44 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[63] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:44 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 16.8 KB, free 910.8 MB)
19/07/31 13:10:44 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.8 MB)
19/07/31 13:10:44 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:63077 (size: 8.0 KB, free: 912.0 MB)
19/07/31 13:10:44 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:44 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 18 (MapPartitionsRDD[63] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:10:44 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks
19/07/31 13:10:44 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 27, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:10:44 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 28, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:10:44 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 29, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:10:44 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 30, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:10:44 INFO Executor: Running task 1.0 in stage 18.0 (TID 28)
19/07/31 13:10:44 INFO Executor: Running task 0.0 in stage 18.0 (TID 27)
19/07/31 13:10:44 INFO Executor: Running task 2.0 in stage 18.0 (TID 29)
19/07/31 13:10:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:44 INFO Executor: Running task 3.0 in stage 18.0 (TID 30)
19/07/31 13:10:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/07/31 13:10:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:44 INFO Executor: Finished task 2.0 in stage 18.0 (TID 29). 2362 bytes result sent to driver
19/07/31 13:10:44 INFO Executor: Finished task 1.0 in stage 18.0 (TID 28). 2361 bytes result sent to driver
19/07/31 13:10:44 INFO Executor: Finished task 0.0 in stage 18.0 (TID 27). 2363 bytes result sent to driver
19/07/31 13:10:44 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 28) in 13 ms on localhost (executor driver) (1/4)
19/07/31 13:10:44 INFO Executor: Finished task 3.0 in stage 18.0 (TID 30). 2337 bytes result sent to driver
19/07/31 13:10:44 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 27) in 14 ms on localhost (executor driver) (2/4)
19/07/31 13:10:44 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 29) in 13 ms on localhost (executor driver) (3/4)
19/07/31 13:10:44 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 30) in 14 ms on localhost (executor driver) (4/4)
19/07/31 13:10:44 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/07/31 13:10:44 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:204) finished in 0.016 s
19/07/31 13:10:44 INFO DAGScheduler: Job 12 finished: collect at utils.scala:204, took 0.042663 s
19/07/31 13:10:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_033`) `dbplyr_034`
ORDER BY `date`) `dbplyr_035`) `dbplyr_036`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "All Devices"))
19/07/31 13:10:45 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:45 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_037`) `dbplyr_038`
ORDER BY `date`) `dbplyr_039`) `dbplyr_040`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "All Devices"))
19/07/31 13:10:45 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:45 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:45 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#834 - cust_prospect_ind.nullCount#833) > 0)
19/07/31 13:10:45 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#839 - visit_device_type.nullCount#838) > 0)
19/07/31 13:10:45 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#832 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#831))
19/07/31 13:10:45 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#837 <= All Devices) && (All Devices <= visit_device_type.upperBound#836))
19/07/31 13:10:45 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:10:45 INFO DAGScheduler: Got job 13 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:10:45 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:204)
19/07/31 13:10:45 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:10:45 INFO DAGScheduler: Missing parents: List()
19/07/31 13:10:45 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[68] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:45 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 72.1 KB, free 910.7 MB)
19/07/31 13:10:45 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.7 MB)
19/07/31 13:10:45 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:63077 (size: 30.5 KB, free: 912.0 MB)
19/07/31 13:10:45 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[68] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:45 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/07/31 13:10:45 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:10:45 INFO Executor: Running task 0.0 in stage 19.0 (TID 31)
19/07/31 13:10:45 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:10:45 INFO Executor: Finished task 0.0 in stage 19.0 (TID 31). 6979 bytes result sent to driver
19/07/31 13:10:45 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 31) in 8 ms on localhost (executor driver) (1/1)
19/07/31 13:10:45 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/07/31 13:10:45 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:204) finished in 0.009 s
19/07/31 13:10:45 INFO DAGScheduler: Job 13 finished: collect at utils.scala:204, took 0.015948 s
19/07/31 13:10:45 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:10:45 INFO DAGScheduler: Registering RDD 69 (collect at utils.scala:204)
19/07/31 13:10:45 INFO DAGScheduler: Got job 14 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:10:45 INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:204)
19/07/31 13:10:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
19/07/31 13:10:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
19/07/31 13:10:45 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[69] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:45 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 74.5 KB, free 910.6 MB)
19/07/31 13:10:45 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.6 MB)
19/07/31 13:10:45 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:63077 (size: 31.8 KB, free: 911.9 MB)
19/07/31 13:10:45 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[69] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:45 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/07/31 13:10:45 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:10:45 INFO Executor: Running task 0.0 in stage 20.0 (TID 32)
19/07/31 13:10:45 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:10:45 INFO Executor: Finished task 0.0 in stage 20.0 (TID 32). 1687 bytes result sent to driver
19/07/31 13:10:45 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 32) in 12 ms on localhost (executor driver) (1/1)
19/07/31 13:10:45 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/07/31 13:10:45 INFO DAGScheduler: ShuffleMapStage 20 (collect at utils.scala:204) finished in 0.012 s
19/07/31 13:10:45 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:10:45 INFO DAGScheduler: running: Set()
19/07/31 13:10:45 INFO DAGScheduler: waiting: Set(ResultStage 21)
19/07/31 13:10:45 INFO DAGScheduler: failed: Set()
19/07/31 13:10:45 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[72] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:45 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 16.8 KB, free 910.5 MB)
19/07/31 13:10:45 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.5 MB)
19/07/31 13:10:45 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:63077 (size: 8.0 KB, free: 911.9 MB)
19/07/31 13:10:45 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:45 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 21 (MapPartitionsRDD[72] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:10:45 INFO TaskSchedulerImpl: Adding task set 21.0 with 4 tasks
19/07/31 13:10:45 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 33, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:10:45 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 34, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:10:45 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 35, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:10:45 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 36, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:10:45 INFO Executor: Running task 2.0 in stage 21.0 (TID 35)
19/07/31 13:10:45 INFO Executor: Running task 3.0 in stage 21.0 (TID 36)
19/07/31 13:10:45 INFO Executor: Running task 1.0 in stage 21.0 (TID 34)
19/07/31 13:10:45 INFO Executor: Running task 0.0 in stage 21.0 (TID 33)
19/07/31 13:10:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:45 INFO Executor: Finished task 3.0 in stage 21.0 (TID 36). 2353 bytes result sent to driver
19/07/31 13:10:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:45 INFO Executor: Finished task 1.0 in stage 21.0 (TID 34). 2359 bytes result sent to driver
19/07/31 13:10:45 INFO Executor: Finished task 2.0 in stage 21.0 (TID 35). 2378 bytes result sent to driver
19/07/31 13:10:45 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 36) in 5 ms on localhost (executor driver) (1/4)
19/07/31 13:10:45 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 34) in 7 ms on localhost (executor driver) (2/4)
19/07/31 13:10:45 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 35) in 6 ms on localhost (executor driver) (3/4)
19/07/31 13:10:45 INFO Executor: Finished task 0.0 in stage 21.0 (TID 33). 2377 bytes result sent to driver
19/07/31 13:10:45 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 33) in 9 ms on localhost (executor driver) (4/4)
19/07/31 13:10:45 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/07/31 13:10:45 INFO DAGScheduler: ResultStage 21 (collect at utils.scala:204) finished in 0.009 s
19/07/31 13:10:45 INFO DAGScheduler: Job 14 finished: collect at utils.scala:204, took 0.034516 s
19/07/31 13:10:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_041`) `dbplyr_042`
ORDER BY `date`) `dbplyr_043`) `dbplyr_044`
WHERE ((`customer` = "PROSPECT") AND (`device` = "All Devices"))
19/07/31 13:10:46 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_045`) `dbplyr_046`
ORDER BY `date`) `dbplyr_047`) `dbplyr_048`
WHERE ((`customer` = "PROSPECT") AND (`device` = "All Devices"))
19/07/31 13:10:46 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:10:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:10:46 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#932 - cust_prospect_ind.nullCount#931) > 0)
19/07/31 13:10:46 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#937 - visit_device_type.nullCount#936) > 0)
19/07/31 13:10:46 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#930 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#929))
19/07/31 13:10:46 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#935 <= All Devices) && (All Devices <= visit_device_type.upperBound#934))
19/07/31 13:10:46 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:10:46 INFO DAGScheduler: Got job 15 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:10:46 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:204)
19/07/31 13:10:46 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:10:46 INFO DAGScheduler: Missing parents: List()
19/07/31 13:10:46 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[77] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:46 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 72.1 KB, free 910.5 MB)
19/07/31 13:10:46 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.4 MB)
19/07/31 13:10:46 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:63077 (size: 30.4 KB, free: 911.9 MB)
19/07/31 13:10:46 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[77] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:46 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
19/07/31 13:10:46 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:10:46 INFO Executor: Running task 0.0 in stage 22.0 (TID 37)
19/07/31 13:10:46 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:10:46 INFO Executor: Finished task 0.0 in stage 22.0 (TID 37). 6979 bytes result sent to driver
19/07/31 13:10:46 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 37) in 7 ms on localhost (executor driver) (1/1)
19/07/31 13:10:46 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/07/31 13:10:46 INFO DAGScheduler: ResultStage 22 (collect at utils.scala:204) finished in 0.008 s
19/07/31 13:10:46 INFO DAGScheduler: Job 15 finished: collect at utils.scala:204, took 0.014632 s
19/07/31 13:10:46 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:10:46 INFO DAGScheduler: Registering RDD 78 (collect at utils.scala:204)
19/07/31 13:10:46 INFO DAGScheduler: Got job 16 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:10:46 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:204)
19/07/31 13:10:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
19/07/31 13:10:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 23)
19/07/31 13:10:46 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[78] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:46 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 74.5 KB, free 910.4 MB)
19/07/31 13:10:46 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.3 MB)
19/07/31 13:10:46 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:63077 (size: 31.7 KB, free: 911.9 MB)
19/07/31 13:10:46 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[78] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:10:46 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
19/07/31 13:10:46 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:10:46 INFO Executor: Running task 0.0 in stage 23.0 (TID 38)
19/07/31 13:10:46 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:10:46 INFO Executor: Finished task 0.0 in stage 23.0 (TID 38). 1687 bytes result sent to driver
19/07/31 13:10:46 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 38) in 12 ms on localhost (executor driver) (1/1)
19/07/31 13:10:46 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
19/07/31 13:10:46 INFO DAGScheduler: ShuffleMapStage 23 (collect at utils.scala:204) finished in 0.012 s
19/07/31 13:10:46 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:10:46 INFO DAGScheduler: running: Set()
19/07/31 13:10:46 INFO DAGScheduler: waiting: Set(ResultStage 24)
19/07/31 13:10:46 INFO DAGScheduler: failed: Set()
19/07/31 13:10:46 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[81] at collect at utils.scala:204), which has no missing parents
19/07/31 13:10:46 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 16.8 KB, free 910.3 MB)
19/07/31 13:10:46 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.3 MB)
19/07/31 13:10:46 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:63077 (size: 8.0 KB, free: 911.9 MB)
19/07/31 13:10:46 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
19/07/31 13:10:46 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[81] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:10:46 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks
19/07/31 13:10:46 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 39, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:10:46 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 40, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:10:46 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 41, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:10:46 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 42, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:10:46 INFO Executor: Running task 0.0 in stage 24.0 (TID 39)
19/07/31 13:10:46 INFO Executor: Running task 2.0 in stage 24.0 (TID 41)
19/07/31 13:10:46 INFO Executor: Running task 3.0 in stage 24.0 (TID 42)
19/07/31 13:10:46 INFO Executor: Running task 1.0 in stage 24.0 (TID 40)
19/07/31 13:10:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:10:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:10:46 INFO Executor: Finished task 1.0 in stage 24.0 (TID 40). 2357 bytes result sent to driver
19/07/31 13:10:46 INFO Executor: Finished task 2.0 in stage 24.0 (TID 41). 2391 bytes result sent to driver
19/07/31 13:10:46 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 40) in 6 ms on localhost (executor driver) (1/4)
19/07/31 13:10:46 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 41) in 6 ms on localhost (executor driver) (2/4)
19/07/31 13:10:46 INFO Executor: Finished task 3.0 in stage 24.0 (TID 42). 2369 bytes result sent to driver
19/07/31 13:10:46 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 42) in 6 ms on localhost (executor driver) (3/4)
19/07/31 13:10:46 INFO Executor: Finished task 0.0 in stage 24.0 (TID 39). 2383 bytes result sent to driver
19/07/31 13:10:46 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 39) in 7 ms on localhost (executor driver) (4/4)
19/07/31 13:10:46 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
19/07/31 13:10:46 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:204) finished in 0.007 s
19/07/31 13:10:46 INFO DAGScheduler: Job 16 finished: collect at utils.scala:204, took 0.031240 s
19/07/31 13:10:47 INFO SparkContext: Invoking stop() from shutdown hook
19/07/31 13:10:47 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
19/07/31 13:10:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/07/31 13:10:47 INFO MemoryStore: MemoryStore cleared
19/07/31 13:10:47 INFO BlockManager: BlockManager stopped
19/07/31 13:10:47 INFO BlockManagerMaster: BlockManagerMaster stopped
19/07/31 13:10:47 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/07/31 13:10:47 INFO SparkContext: Successfully stopped SparkContext
19/07/31 13:10:47 INFO ShutdownHookManager: Shutdown hook called
19/07/31 13:10:47 INFO ShutdownHookManager: Deleting directory /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-c44a3664-da8a-4f39-abe2-a606c3687478
19/07/31 13:11:28 INFO SparkContext: Running Spark version 2.2.0
19/07/31 13:11:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/07/31 13:11:28 INFO SparkContext: Submitted application: sparklyr
19/07/31 13:11:28 INFO SecurityManager: Changing view acls to: 6jncnk4f
19/07/31 13:11:28 INFO SecurityManager: Changing modify acls to: 6jncnk4f
19/07/31 13:11:28 INFO SecurityManager: Changing view acls groups to: 
19/07/31 13:11:28 INFO SecurityManager: Changing modify acls groups to: 
19/07/31 13:11:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(6jncnk4f); groups with view permissions: Set(); users  with modify permissions: Set(6jncnk4f); groups with modify permissions: Set()
19/07/31 13:11:28 INFO Utils: Successfully started service 'sparkDriver' on port 63097.
19/07/31 13:11:28 INFO SparkEnv: Registering MapOutputTracker
19/07/31 13:11:28 INFO SparkEnv: Registering BlockManagerMaster
19/07/31 13:11:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/07/31 13:11:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/07/31 13:11:28 INFO DiskBlockManager: Created local directory at /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/blockmgr-8a03e4a8-f4c1-4823-a68c-f0e3502885cd
19/07/31 13:11:28 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/07/31 13:11:28 INFO SparkEnv: Registering OutputCommitCoordinator
19/07/31 13:11:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/07/31 13:11:29 INFO Utils: Successfully started service 'SparkUI' on port 4041.
19/07/31 13:11:29 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
19/07/31 13:11:29 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:63097/jars/sparklyr-2.0-2.11.jar with timestamp 1564593089087
19/07/31 13:11:29 INFO Executor: Starting executor ID driver on host localhost
19/07/31 13:11:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63098.
19/07/31 13:11:29 INFO NettyBlockTransferService: Server created on 127.0.0.1:63098
19/07/31 13:11:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/07/31 13:11:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 63098, None)
19/07/31 13:11:29 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:63098 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 63098, None)
19/07/31 13:11:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 63098, None)
19/07/31 13:11:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 63098, None)
19/07/31 13:11:29 INFO SharedState: loading hive config file: file:/Users/6jncnk4f/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/07/31 13:11:29 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse').
19/07/31 13:11:29 INFO SharedState: Warehouse path is 'file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse'.
19/07/31 13:11:30 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/07/31 13:11:30 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/07/31 13:11:30 INFO ObjectStore: ObjectStore, initialize called
19/07/31 13:11:30 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/07/31 13:11:30 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/07/31 13:11:32 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/07/31 13:11:32 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:11:32 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:11:33 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:11:33 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:11:33 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/07/31 13:11:33 INFO ObjectStore: Initialized ObjectStore
19/07/31 13:11:33 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/07/31 13:11:33 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/07/31 13:11:34 INFO HiveMetaStore: Added admin role in metastore
19/07/31 13:11:34 INFO HiveMetaStore: Added public role in metastore
19/07/31 13:11:34 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/07/31 13:11:34 INFO HiveMetaStore: 0: get_all_databases
19/07/31 13:11:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_all_databases	
19/07/31 13:11:34 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/07/31 13:11:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/07/31 13:11:34 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:11:34 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/b060f5d0-4454-4265-b849-79c1e6bc5957_resources
19/07/31 13:11:34 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/b060f5d0-4454-4265-b849-79c1e6bc5957
19/07/31 13:11:34 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/b060f5d0-4454-4265-b849-79c1e6bc5957
19/07/31 13:11:34 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/b060f5d0-4454-4265-b849-79c1e6bc5957/_tmp_space.db
19/07/31 13:11:34 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 13:11:34 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:34 INFO HiveMetaStore: 0: get_database: global_temp
19/07/31 13:11:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/07/31 13:11:34 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/07/31 13:11:34 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/3622d531-6ca6-4df2-8252-1fdfbb6c00ec_resources
19/07/31 13:11:34 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/3622d531-6ca6-4df2-8252-1fdfbb6c00ec
19/07/31 13:11:34 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/3622d531-6ca6-4df2-8252-1fdfbb6c00ec
19/07/31 13:11:34 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/3622d531-6ca6-4df2-8252-1fdfbb6c00ec/_tmp_space.db
19/07/31 13:11:34 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 13:11:34 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/07/31 13:11:34 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:11:35 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:35 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:35 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:35 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:35 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:11:35 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:11:36 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 13:11:36 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/07/31 13:11:36 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/07/31 13:11:36 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:11:36 INFO DAGScheduler: Missing parents: List()
19/07/31 13:11:36 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/07/31 13:11:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/07/31 13:11:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/07/31 13:11:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:63098 (size: 3.4 KB, free: 912.3 MB)
19/07/31 13:11:36 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:36 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/07/31 13:11:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/07/31 13:11:36 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/07/31 13:11:36 INFO Executor: Fetching spark://127.0.0.1:63097/jars/sparklyr-2.0-2.11.jar with timestamp 1564593089087
19/07/31 13:11:36 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:63097 after 12 ms (0 ms spent in bootstraps)
19/07/31 13:11:36 INFO Utils: Fetching spark://127.0.0.1:63097/jars/sparklyr-2.0-2.11.jar to /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-347e8f7a-db63-4832-af92-10439b9976de/userFiles-e82ee0b5-4094-4b93-9835-5972a225502b/fetchFileTemp2710735668586355545.tmp
19/07/31 13:11:36 INFO Executor: Adding file:/private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-347e8f7a-db63-4832-af92-10439b9976de/userFiles-e82ee0b5-4094-4b93-9835-5972a225502b/sparklyr-2.0-2.11.jar to class loader
19/07/31 13:11:37 INFO CodeGenerator: Code generated in 230.600282 ms
19/07/31 13:11:37 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
19/07/31 13:11:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 566 ms on localhost (executor driver) (1/1)
19/07/31 13:11:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/07/31 13:11:37 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.582 s
19/07/31 13:11:37 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0.706515 s
19/07/31 13:11:37 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:11:37 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#10)) > 0)
19/07/31 13:11:37 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 13:11:37 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:11:37 INFO CodeGenerator: Code generated in 13.86802 ms
19/07/31 13:11:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 281.2 KB, free 912.0 MB)
19/07/31 13:11:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.8 KB, free 912.0 MB)
19/07/31 13:11:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:63098 (size: 23.8 KB, free: 912.3 MB)
19/07/31 13:11:37 INFO SparkContext: Created broadcast 1 from csv at NativeMethodAccessorImpl.java:0
19/07/31 13:11:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:11:37 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:11:37 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:11:37 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:11:37 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:11:37 INFO DAGScheduler: Missing parents: List()
19/07/31 13:11:37 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:11:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 912.0 MB)
19/07/31 13:11:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 912.0 MB)
19/07/31 13:11:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:63098 (size: 4.3 KB, free: 912.3 MB)
19/07/31 13:11:37 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/07/31 13:11:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:11:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/07/31 13:11:37 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:11:37 INFO CodeGenerator: Code generated in 6.767942 ms
19/07/31 13:11:37 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:63098 in memory (size: 3.4 KB, free: 912.3 MB)
19/07/31 13:11:37 INFO ContextCleaner: Cleaned accumulator 0
19/07/31 13:11:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1437 bytes result sent to driver
19/07/31 13:11:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 250 ms on localhost (executor driver) (1/1)
19/07/31 13:11:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/07/31 13:11:37 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0.251 s
19/07/31 13:11:37 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0.262354 s
19/07/31 13:11:37 INFO CodeGenerator: Code generated in 5.577884 ms
19/07/31 13:11:37 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:11:37 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 13:11:37 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 13:11:37 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:11:37 INFO CodeGenerator: Code generated in 4.054408 ms
19/07/31 13:11:38 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 281.2 KB, free 911.7 MB)
19/07/31 13:11:38 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.7 MB)
19/07/31 13:11:38 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:63098 (size: 23.8 KB, free: 912.2 MB)
19/07/31 13:11:38 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:0
19/07/31 13:11:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:11:38 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:11:38 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:11:38 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:11:38 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:11:38 INFO DAGScheduler: Missing parents: List()
19/07/31 13:11:38 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:11:38 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.8 KB, free 911.7 MB)
19/07/31 13:11:38 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.7 MB)
19/07/31 13:11:38 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:63098 (size: 8.6 KB, free: 912.2 MB)
19/07/31 13:11:38 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:38 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/07/31 13:11:38 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:11:38 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/07/31 13:11:38 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:11:38 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1584 bytes result sent to driver
19/07/31 13:11:38 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 72 ms on localhost (executor driver) (1/1)
19/07/31 13:11:38 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/07/31 13:11:38 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.072 s
19/07/31 13:11:38 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.080272 s
19/07/31 13:11:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:11:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:11:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:11:38 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 13:11:38 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 13:11:38 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 13:11:38 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:11:38 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 13:11:38 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 13:11:38 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:11:38 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 282.3 KB, free 911.4 MB)
19/07/31 13:11:38 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.4 MB)
19/07/31 13:11:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:63098 (size: 24.0 KB, free: 912.2 MB)
19/07/31 13:11:38 INFO SparkContext: Created broadcast 5 from sql at NativeMethodAccessorImpl.java:0
19/07/31 13:11:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:11:38 INFO CodeGenerator: Code generated in 7.437724 ms
19/07/31 13:11:38 INFO CodeGenerator: Code generated in 6.547379 ms
19/07/31 13:11:38 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 13:11:38 INFO DAGScheduler: Registering RDD 18 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 13:11:38 INFO DAGScheduler: Got job 3 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:11:38 INFO DAGScheduler: Final stage: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 13:11:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/07/31 13:11:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/07/31 13:11:38 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:11:38 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 26.3 KB, free 911.3 MB)
19/07/31 13:11:38 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.8 KB, free 911.3 MB)
19/07/31 13:11:38 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:63098 (size: 11.8 KB, free: 912.2 MB)
19/07/31 13:11:38 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:38 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/07/31 13:11:38 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:11:38 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/07/31 13:11:38 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:11:38 INFO CodeGenerator: Code generated in 16.804586 ms
19/07/31 13:11:38 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 48.9 KB, free 911.3 MB)
19/07/31 13:11:38 INFO BlockManagerInfo: Added rdd_15_0 in memory on 127.0.0.1:63098 (size: 48.9 KB, free: 912.2 MB)
19/07/31 13:11:38 INFO CodeGenerator: Code generated in 5.944701 ms
19/07/31 13:11:38 INFO CodeGenerator: Code generated in 16.215144 ms
19/07/31 13:11:38 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2504 bytes result sent to driver
19/07/31 13:11:38 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 209 ms on localhost (executor driver) (1/1)
19/07/31 13:11:38 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/07/31 13:11:38 INFO DAGScheduler: ShuffleMapStage 3 (sql at NativeMethodAccessorImpl.java:0) finished in 0.211 s
19/07/31 13:11:38 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:11:38 INFO DAGScheduler: running: Set()
19/07/31 13:11:38 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/07/31 13:11:38 INFO DAGScheduler: failed: Set()
19/07/31 13:11:38 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:11:38 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 911.3 MB)
19/07/31 13:11:38 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.3 MB)
19/07/31 13:11:38 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:63098 (size: 3.7 KB, free: 912.2 MB)
19/07/31 13:11:38 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:38 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/07/31 13:11:38 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:11:38 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/07/31 13:11:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
19/07/31 13:11:38 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1581 bytes result sent to driver
19/07/31 13:11:38 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 31 ms on localhost (executor driver) (1/1)
19/07/31 13:11:38 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/07/31 13:11:38 INFO DAGScheduler: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0) finished in 0.031 s
19/07/31 13:11:38 INFO DAGScheduler: Job 3 finished: sql at NativeMethodAccessorImpl.java:0, took 0.285651 s
19/07/31 13:11:38 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 13:11:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:38 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:38 INFO DAGScheduler: Registering RDD 24 (collect at utils.scala:204)
19/07/31 13:11:38 INFO DAGScheduler: Got job 4 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:11:38 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
19/07/31 13:11:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/07/31 13:11:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/07/31 13:11:38 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:38 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 26.3 KB, free 911.2 MB)
19/07/31 13:11:38 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.9 KB, free 911.2 MB)
19/07/31 13:11:38 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:63098 (size: 11.9 KB, free: 912.1 MB)
19/07/31 13:11:38 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:38 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/07/31 13:11:38 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:11:38 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/07/31 13:11:38 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:38 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1780 bytes result sent to driver
19/07/31 13:11:38 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 10 ms on localhost (executor driver) (1/1)
19/07/31 13:11:38 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/07/31 13:11:38 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:204) finished in 0.011 s
19/07/31 13:11:38 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:11:38 INFO DAGScheduler: running: Set()
19/07/31 13:11:38 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/07/31 13:11:38 INFO DAGScheduler: failed: Set()
19/07/31 13:11:38 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:38 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 911.2 MB)
19/07/31 13:11:38 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.2 MB)
19/07/31 13:11:38 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:63098 (size: 3.7 KB, free: 912.1 MB)
19/07/31 13:11:38 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:38 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/07/31 13:11:38 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:11:38 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/07/31 13:11:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:38 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1581 bytes result sent to driver
19/07/31 13:11:38 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 4 ms on localhost (executor driver) (1/1)
19/07/31 13:11:38 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/07/31 13:11:38 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.005 s
19/07/31 13:11:38 INFO DAGScheduler: Job 4 finished: collect at utils.scala:204, took 0.031899 s
19/07/31 13:11:38 INFO CodeGenerator: Code generated in 6.137197 ms
19/07/31 13:11:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz1`
WHERE (0 = 1)
19/07/31 13:11:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_001`) `dbplyr_002`
ORDER BY `date`) `dbplyr_003`) `dbplyr_004`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 13:11:39 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_005`) `dbplyr_006`
ORDER BY `date`) `dbplyr_007`) `dbplyr_008`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 13:11:39 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:39 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#442 - cust_prospect_ind.nullCount#441) > 0)
19/07/31 13:11:39 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#447 - visit_device_type.nullCount#446) > 0)
19/07/31 13:11:39 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#440 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#439))
19/07/31 13:11:39 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#445 <= All Devices) && (All Devices <= visit_device_type.upperBound#444))
19/07/31 13:11:39 INFO CodeGenerator: Code generated in 15.635127 ms
19/07/31 13:11:39 INFO CodeGenerator: Code generated in 17.854447 ms
19/07/31 13:11:39 INFO CodeGenerator: Code generated in 13.747168 ms
19/07/31 13:11:39 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:39 INFO DAGScheduler: Got job 5 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:11:39 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:204)
19/07/31 13:11:39 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:11:39 INFO DAGScheduler: Missing parents: List()
19/07/31 13:11:39 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[32] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:39 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 72.1 KB, free 911.2 MB)
19/07/31 13:11:39 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.1 MB)
19/07/31 13:11:39 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:63098 (size: 30.4 KB, free: 912.1 MB)
19/07/31 13:11:39 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:39 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/07/31 13:11:39 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:11:39 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
19/07/31 13:11:39 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:39 INFO CodeGenerator: Code generated in 10.021775 ms
19/07/31 13:11:39 INFO CodeGenerator: Code generated in 17.286232 ms
19/07/31 13:11:39 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 7585 bytes result sent to driver
19/07/31 13:11:39 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 73 ms on localhost (executor driver) (1/1)
19/07/31 13:11:39 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/07/31 13:11:39 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:204) finished in 0.074 s
19/07/31 13:11:39 INFO DAGScheduler: Job 5 finished: collect at utils.scala:204, took 0.085324 s
19/07/31 13:11:39 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:39 INFO DAGScheduler: Registering RDD 33 (collect at utils.scala:204)
19/07/31 13:11:39 INFO DAGScheduler: Got job 6 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:11:39 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:204)
19/07/31 13:11:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
19/07/31 13:11:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
19/07/31 13:11:39 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[33] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:39 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 74.5 KB, free 911.1 MB)
19/07/31 13:11:39 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 31.7 KB, free 911.0 MB)
19/07/31 13:11:39 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:63098 (size: 31.7 KB, free: 912.1 MB)
19/07/31 13:11:39 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[33] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:39 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/07/31 13:11:39 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:11:39 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
19/07/31 13:11:39 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:39 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1687 bytes result sent to driver
19/07/31 13:11:39 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 32 ms on localhost (executor driver) (1/1)
19/07/31 13:11:39 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/07/31 13:11:39 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:204) finished in 0.034 s
19/07/31 13:11:39 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:11:39 INFO DAGScheduler: running: Set()
19/07/31 13:11:39 INFO DAGScheduler: waiting: Set(ResultStage 9)
19/07/31 13:11:39 INFO DAGScheduler: failed: Set()
19/07/31 13:11:39 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[36] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:39 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 16.8 KB, free 911.0 MB)
19/07/31 13:11:39 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.0 MB)
19/07/31 13:11:39 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:63098 (size: 8.0 KB, free: 912.1 MB)
19/07/31 13:11:39 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:39 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 9 (MapPartitionsRDD[36] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:11:39 INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks
19/07/31 13:11:39 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:11:39 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 10, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:11:39 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 11, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:11:39 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 12, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:11:39 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
19/07/31 13:11:39 INFO Executor: Running task 1.0 in stage 9.0 (TID 10)
19/07/31 13:11:39 INFO Executor: Running task 3.0 in stage 9.0 (TID 12)
19/07/31 13:11:39 INFO Executor: Running task 2.0 in stage 9.0 (TID 11)
19/07/31 13:11:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/07/31 13:11:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/07/31 13:11:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:11:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:39 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:63098 in memory (size: 11.8 KB, free: 912.1 MB)
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 120
19/07/31 13:11:39 INFO ContextCleaner: Cleaned shuffle 1
19/07/31 13:11:39 INFO CodeGenerator: Code generated in 13.46867 ms
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 236
19/07/31 13:11:39 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:63098 in memory (size: 8.6 KB, free: 912.1 MB)
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 177
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 117
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 123
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 187
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 114
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 125
19/07/31 13:11:39 INFO ContextCleaner: Cleaned shuffle 0
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 121
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 116
19/07/31 13:11:39 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:63098 in memory (size: 31.7 KB, free: 912.1 MB)
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 183
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 122
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 118
19/07/31 13:11:39 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:63098 in memory (size: 30.4 KB, free: 912.2 MB)
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 180
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 115
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 185
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 124
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 119
19/07/31 13:11:39 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:63098 in memory (size: 3.7 KB, free: 912.2 MB)
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 178
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 126
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 179
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 186
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 176
19/07/31 13:11:39 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:63098 in memory (size: 3.7 KB, free: 912.2 MB)
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 182
19/07/31 13:11:39 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:63098 in memory (size: 11.9 KB, free: 912.2 MB)
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 175
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 181
19/07/31 13:11:39 INFO ContextCleaner: Cleaned accumulator 184
19/07/31 13:11:39 INFO Executor: Finished task 3.0 in stage 9.0 (TID 12). 2405 bytes result sent to driver
19/07/31 13:11:39 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 12) in 85 ms on localhost (executor driver) (1/4)
19/07/31 13:11:39 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2425 bytes result sent to driver
19/07/31 13:11:39 INFO Executor: Finished task 2.0 in stage 9.0 (TID 11). 2433 bytes result sent to driver
19/07/31 13:11:39 INFO Executor: Finished task 1.0 in stage 9.0 (TID 10). 2446 bytes result sent to driver
19/07/31 13:11:39 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 86 ms on localhost (executor driver) (2/4)
19/07/31 13:11:39 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 10) in 86 ms on localhost (executor driver) (3/4)
19/07/31 13:11:39 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 11) in 86 ms on localhost (executor driver) (4/4)
19/07/31 13:11:39 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/07/31 13:11:39 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:204) finished in 0.088 s
19/07/31 13:11:39 INFO DAGScheduler: Job 6 finished: collect at utils.scala:204, took 0.147495 s
19/07/31 13:11:39 INFO CodeGenerator: Code generated in 15.474051 ms
19/07/31 13:11:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_009`) `dbplyr_010`
ORDER BY `date`) `dbplyr_011`) `dbplyr_012`
WHERE ((`customer` = "All Visitors") AND (`device` = "Mobile Phone"))
19/07/31 13:11:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_013`) `dbplyr_014`
ORDER BY `date`) `dbplyr_015`) `dbplyr_016`
WHERE ((`customer` = "All Visitors") AND (`device` = "Mobile Phone"))
19/07/31 13:11:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:41 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#540 - cust_prospect_ind.nullCount#539) > 0)
19/07/31 13:11:41 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#545 - visit_device_type.nullCount#544) > 0)
19/07/31 13:11:41 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#538 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#537))
19/07/31 13:11:41 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#543 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#542))
19/07/31 13:11:41 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:41 INFO DAGScheduler: Got job 7 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:11:41 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:204)
19/07/31 13:11:41 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:11:41 INFO DAGScheduler: Missing parents: List()
19/07/31 13:11:41 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[41] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:41 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 72.1 KB, free 911.3 MB)
19/07/31 13:11:41 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 30.5 KB, free 911.2 MB)
19/07/31 13:11:41 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:63098 (size: 30.5 KB, free: 912.1 MB)
19/07/31 13:11:41 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[41] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:41 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/07/31 13:11:41 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:11:41 INFO Executor: Running task 0.0 in stage 10.0 (TID 13)
19/07/31 13:11:41 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:41 INFO Executor: Finished task 0.0 in stage 10.0 (TID 13). 7585 bytes result sent to driver
19/07/31 13:11:41 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 13) in 21 ms on localhost (executor driver) (1/1)
19/07/31 13:11:41 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/07/31 13:11:41 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:204) finished in 0.022 s
19/07/31 13:11:41 INFO DAGScheduler: Job 7 finished: collect at utils.scala:204, took 0.034638 s
19/07/31 13:11:41 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:41 INFO DAGScheduler: Registering RDD 42 (collect at utils.scala:204)
19/07/31 13:11:41 INFO DAGScheduler: Got job 8 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:11:41 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:204)
19/07/31 13:11:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
19/07/31 13:11:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
19/07/31 13:11:41 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[42] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:41 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 74.6 KB, free 911.1 MB)
19/07/31 13:11:41 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.1 MB)
19/07/31 13:11:41 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:63098 (size: 31.8 KB, free: 912.1 MB)
19/07/31 13:11:41 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[42] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:41 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/07/31 13:11:41 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:11:41 INFO Executor: Running task 0.0 in stage 11.0 (TID 14)
19/07/31 13:11:41 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:41 INFO Executor: Finished task 0.0 in stage 11.0 (TID 14). 1687 bytes result sent to driver
19/07/31 13:11:41 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 14) in 23 ms on localhost (executor driver) (1/1)
19/07/31 13:11:41 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/07/31 13:11:41 INFO DAGScheduler: ShuffleMapStage 11 (collect at utils.scala:204) finished in 0.024 s
19/07/31 13:11:41 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:11:41 INFO DAGScheduler: running: Set()
19/07/31 13:11:41 INFO DAGScheduler: waiting: Set(ResultStage 12)
19/07/31 13:11:41 INFO DAGScheduler: failed: Set()
19/07/31 13:11:41 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[45] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:41 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 16.8 KB, free 911.1 MB)
19/07/31 13:11:41 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.1 MB)
19/07/31 13:11:41 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:63098 (size: 8.0 KB, free: 912.1 MB)
19/07/31 13:11:41 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:41 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 12 (MapPartitionsRDD[45] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:11:41 INFO TaskSchedulerImpl: Adding task set 12.0 with 4 tasks
19/07/31 13:11:41 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 15, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:11:41 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 16, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:11:41 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 17, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:11:41 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 18, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:11:41 INFO Executor: Running task 2.0 in stage 12.0 (TID 17)
19/07/31 13:11:41 INFO Executor: Running task 1.0 in stage 12.0 (TID 16)
19/07/31 13:11:41 INFO Executor: Running task 3.0 in stage 12.0 (TID 18)
19/07/31 13:11:41 INFO Executor: Running task 0.0 in stage 12.0 (TID 15)
19/07/31 13:11:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:41 INFO Executor: Finished task 3.0 in stage 12.0 (TID 18). 2358 bytes result sent to driver
19/07/31 13:11:41 INFO Executor: Finished task 2.0 in stage 12.0 (TID 17). 2372 bytes result sent to driver
19/07/31 13:11:41 INFO Executor: Finished task 1.0 in stage 12.0 (TID 16). 2383 bytes result sent to driver
19/07/31 13:11:41 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 18) in 10 ms on localhost (executor driver) (1/4)
19/07/31 13:11:41 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 17) in 10 ms on localhost (executor driver) (2/4)
19/07/31 13:11:41 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 16) in 11 ms on localhost (executor driver) (3/4)
19/07/31 13:11:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:11:41 INFO Executor: Finished task 0.0 in stage 12.0 (TID 15). 2385 bytes result sent to driver
19/07/31 13:11:41 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 15) in 16 ms on localhost (executor driver) (4/4)
19/07/31 13:11:41 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/07/31 13:11:41 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:204) finished in 0.017 s
19/07/31 13:11:41 INFO DAGScheduler: Job 8 finished: collect at utils.scala:204, took 0.064122 s
19/07/31 13:11:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_017`) `dbplyr_018`
ORDER BY `date`) `dbplyr_019`) `dbplyr_020`
WHERE ((`customer` = "All Visitors") AND (`device` = "Desktop"))
19/07/31 13:11:42 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:42 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_021`) `dbplyr_022`
ORDER BY `date`) `dbplyr_023`) `dbplyr_024`
WHERE ((`customer` = "All Visitors") AND (`device` = "Desktop"))
19/07/31 13:11:42 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:42 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:42 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#638 - cust_prospect_ind.nullCount#637) > 0)
19/07/31 13:11:42 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#643 - visit_device_type.nullCount#642) > 0)
19/07/31 13:11:42 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#636 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#635))
19/07/31 13:11:42 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#641 <= Desktop) && (Desktop <= visit_device_type.upperBound#640))
19/07/31 13:11:42 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:42 INFO DAGScheduler: Got job 9 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:11:42 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:204)
19/07/31 13:11:42 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:11:42 INFO DAGScheduler: Missing parents: List()
19/07/31 13:11:42 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[50] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:42 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 72.1 KB, free 911.0 MB)
19/07/31 13:11:42 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 30.5 KB, free 911.0 MB)
19/07/31 13:11:42 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:63098 (size: 30.5 KB, free: 912.1 MB)
19/07/31 13:11:42 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[50] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:42 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/07/31 13:11:42 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:11:42 INFO Executor: Running task 0.0 in stage 13.0 (TID 19)
19/07/31 13:11:42 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:42 INFO Executor: Finished task 0.0 in stage 13.0 (TID 19). 7068 bytes result sent to driver
19/07/31 13:11:42 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 19) in 9 ms on localhost (executor driver) (1/1)
19/07/31 13:11:42 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/07/31 13:11:42 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:204) finished in 0.009 s
19/07/31 13:11:42 INFO DAGScheduler: Job 9 finished: collect at utils.scala:204, took 0.016890 s
19/07/31 13:11:42 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:42 INFO DAGScheduler: Registering RDD 51 (collect at utils.scala:204)
19/07/31 13:11:42 INFO DAGScheduler: Got job 10 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:11:42 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:204)
19/07/31 13:11:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
19/07/31 13:11:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
19/07/31 13:11:42 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[51] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:42 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 74.5 KB, free 910.9 MB)
19/07/31 13:11:42 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.9 MB)
19/07/31 13:11:42 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:63098 (size: 31.8 KB, free: 912.0 MB)
19/07/31 13:11:42 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[51] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:42 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/07/31 13:11:42 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:11:42 INFO Executor: Running task 0.0 in stage 14.0 (TID 20)
19/07/31 13:11:42 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:42 INFO Executor: Finished task 0.0 in stage 14.0 (TID 20). 1687 bytes result sent to driver
19/07/31 13:11:42 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 20) in 13 ms on localhost (executor driver) (1/1)
19/07/31 13:11:42 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/07/31 13:11:42 INFO DAGScheduler: ShuffleMapStage 14 (collect at utils.scala:204) finished in 0.014 s
19/07/31 13:11:42 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:11:42 INFO DAGScheduler: running: Set()
19/07/31 13:11:42 INFO DAGScheduler: waiting: Set(ResultStage 15)
19/07/31 13:11:42 INFO DAGScheduler: failed: Set()
19/07/31 13:11:42 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[54] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:42 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 16.8 KB, free 910.9 MB)
19/07/31 13:11:42 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.9 MB)
19/07/31 13:11:42 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:63098 (size: 8.0 KB, free: 912.0 MB)
19/07/31 13:11:42 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:42 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:11:42 INFO TaskSchedulerImpl: Adding task set 15.0 with 4 tasks
19/07/31 13:11:42 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 21, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:11:42 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 22, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:11:42 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 23, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:11:42 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 24, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:11:42 INFO Executor: Running task 0.0 in stage 15.0 (TID 21)
19/07/31 13:11:42 INFO Executor: Running task 1.0 in stage 15.0 (TID 22)
19/07/31 13:11:42 INFO Executor: Running task 3.0 in stage 15.0 (TID 24)
19/07/31 13:11:42 INFO Executor: Running task 2.0 in stage 15.0 (TID 23)
19/07/31 13:11:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:11:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:11:42 INFO Executor: Finished task 2.0 in stage 15.0 (TID 23). 2380 bytes result sent to driver
19/07/31 13:11:42 INFO Executor: Finished task 0.0 in stage 15.0 (TID 21). 2381 bytes result sent to driver
19/07/31 13:11:42 INFO Executor: Finished task 1.0 in stage 15.0 (TID 22). 2385 bytes result sent to driver
19/07/31 13:11:42 INFO Executor: Finished task 3.0 in stage 15.0 (TID 24). 2356 bytes result sent to driver
19/07/31 13:11:42 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 23) in 7 ms on localhost (executor driver) (1/4)
19/07/31 13:11:42 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 21) in 8 ms on localhost (executor driver) (2/4)
19/07/31 13:11:42 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 24) in 7 ms on localhost (executor driver) (3/4)
19/07/31 13:11:42 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 22) in 8 ms on localhost (executor driver) (4/4)
19/07/31 13:11:42 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/07/31 13:11:42 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:204) finished in 0.009 s
19/07/31 13:11:42 INFO DAGScheduler: Job 10 finished: collect at utils.scala:204, took 0.036183 s
19/07/31 13:11:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_025`) `dbplyr_026`
ORDER BY `date`) `dbplyr_027`) `dbplyr_028`
WHERE ((`customer` = "All Visitors") AND (`device` = "Tablet"))
19/07/31 13:11:43 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:43 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_029`) `dbplyr_030`
ORDER BY `date`) `dbplyr_031`) `dbplyr_032`
WHERE ((`customer` = "All Visitors") AND (`device` = "Tablet"))
19/07/31 13:11:43 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:43 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:43 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#736 - cust_prospect_ind.nullCount#735) > 0)
19/07/31 13:11:43 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#741 - visit_device_type.nullCount#740) > 0)
19/07/31 13:11:43 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#734 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#733))
19/07/31 13:11:43 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#739 <= Tablet) && (Tablet <= visit_device_type.upperBound#738))
19/07/31 13:11:43 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:43 INFO DAGScheduler: Got job 11 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:11:43 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:204)
19/07/31 13:11:43 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:11:43 INFO DAGScheduler: Missing parents: List()
19/07/31 13:11:43 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[59] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:43 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 72.1 KB, free 910.8 MB)
19/07/31 13:11:43 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.8 MB)
19/07/31 13:11:43 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:63098 (size: 30.4 KB, free: 912.0 MB)
19/07/31 13:11:43 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[59] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:43 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/07/31 13:11:43 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:11:43 INFO Executor: Running task 0.0 in stage 16.0 (TID 25)
19/07/31 13:11:43 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:43 INFO Executor: Finished task 0.0 in stage 16.0 (TID 25). 7068 bytes result sent to driver
19/07/31 13:11:43 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 25) in 8 ms on localhost (executor driver) (1/1)
19/07/31 13:11:43 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/07/31 13:11:43 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:204) finished in 0.009 s
19/07/31 13:11:43 INFO DAGScheduler: Job 11 finished: collect at utils.scala:204, took 0.015920 s
19/07/31 13:11:43 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:43 INFO DAGScheduler: Registering RDD 60 (collect at utils.scala:204)
19/07/31 13:11:43 INFO DAGScheduler: Got job 12 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:11:43 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:204)
19/07/31 13:11:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
19/07/31 13:11:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
19/07/31 13:11:43 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[60] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:43 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 74.5 KB, free 910.7 MB)
19/07/31 13:11:43 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.7 MB)
19/07/31 13:11:43 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:63098 (size: 31.7 KB, free: 912.0 MB)
19/07/31 13:11:43 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[60] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:43 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
19/07/31 13:11:43 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:11:43 INFO Executor: Running task 0.0 in stage 17.0 (TID 26)
19/07/31 13:11:43 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:43 INFO Executor: Finished task 0.0 in stage 17.0 (TID 26). 1687 bytes result sent to driver
19/07/31 13:11:43 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 26) in 14 ms on localhost (executor driver) (1/1)
19/07/31 13:11:43 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/07/31 13:11:43 INFO DAGScheduler: ShuffleMapStage 17 (collect at utils.scala:204) finished in 0.014 s
19/07/31 13:11:43 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:11:43 INFO DAGScheduler: running: Set()
19/07/31 13:11:43 INFO DAGScheduler: waiting: Set(ResultStage 18)
19/07/31 13:11:43 INFO DAGScheduler: failed: Set()
19/07/31 13:11:43 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[63] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:43 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 16.8 KB, free 910.6 MB)
19/07/31 13:11:43 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.6 MB)
19/07/31 13:11:43 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:63098 (size: 8.0 KB, free: 912.0 MB)
19/07/31 13:11:43 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:43 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 18 (MapPartitionsRDD[63] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:11:43 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks
19/07/31 13:11:43 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 27, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:11:43 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 28, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:11:43 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 29, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:11:43 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 30, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:11:43 INFO Executor: Running task 1.0 in stage 18.0 (TID 28)
19/07/31 13:11:43 INFO Executor: Running task 0.0 in stage 18.0 (TID 27)
19/07/31 13:11:43 INFO Executor: Running task 3.0 in stage 18.0 (TID 30)
19/07/31 13:11:43 INFO Executor: Running task 2.0 in stage 18.0 (TID 29)
19/07/31 13:11:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:11:43 INFO Executor: Finished task 2.0 in stage 18.0 (TID 29). 2362 bytes result sent to driver
19/07/31 13:11:43 INFO Executor: Finished task 3.0 in stage 18.0 (TID 30). 2337 bytes result sent to driver
19/07/31 13:11:43 INFO Executor: Finished task 1.0 in stage 18.0 (TID 28). 2361 bytes result sent to driver
19/07/31 13:11:43 INFO Executor: Finished task 0.0 in stage 18.0 (TID 27). 2363 bytes result sent to driver
19/07/31 13:11:43 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 29) in 7 ms on localhost (executor driver) (1/4)
19/07/31 13:11:43 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 28) in 7 ms on localhost (executor driver) (2/4)
19/07/31 13:11:43 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 30) in 7 ms on localhost (executor driver) (3/4)
19/07/31 13:11:43 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 27) in 9 ms on localhost (executor driver) (4/4)
19/07/31 13:11:43 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/07/31 13:11:43 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:204) finished in 0.009 s
19/07/31 13:11:43 INFO DAGScheduler: Job 12 finished: collect at utils.scala:204, took 0.035650 s
19/07/31 13:11:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_033`) `dbplyr_034`
ORDER BY `date`) `dbplyr_035`) `dbplyr_036`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "All Devices"))
19/07/31 13:11:44 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:44 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_037`) `dbplyr_038`
ORDER BY `date`) `dbplyr_039`) `dbplyr_040`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "All Devices"))
19/07/31 13:11:44 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:44 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:44 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#834 - cust_prospect_ind.nullCount#833) > 0)
19/07/31 13:11:44 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#839 - visit_device_type.nullCount#838) > 0)
19/07/31 13:11:44 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#832 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#831))
19/07/31 13:11:44 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#837 <= All Devices) && (All Devices <= visit_device_type.upperBound#836))
19/07/31 13:11:44 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:44 INFO DAGScheduler: Got job 13 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:11:44 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:204)
19/07/31 13:11:44 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:11:44 INFO DAGScheduler: Missing parents: List()
19/07/31 13:11:44 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[68] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:44 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 72.1 KB, free 910.6 MB)
19/07/31 13:11:44 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.5 MB)
19/07/31 13:11:44 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:63098 (size: 30.5 KB, free: 911.9 MB)
19/07/31 13:11:44 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[68] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:44 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/07/31 13:11:44 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:11:44 INFO Executor: Running task 0.0 in stage 19.0 (TID 31)
19/07/31 13:11:44 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:44 INFO Executor: Finished task 0.0 in stage 19.0 (TID 31). 7022 bytes result sent to driver
19/07/31 13:11:44 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 31) in 8 ms on localhost (executor driver) (1/1)
19/07/31 13:11:44 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/07/31 13:11:44 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:204) finished in 0.010 s
19/07/31 13:11:44 INFO DAGScheduler: Job 13 finished: collect at utils.scala:204, took 0.016577 s
19/07/31 13:11:44 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:44 INFO DAGScheduler: Registering RDD 69 (collect at utils.scala:204)
19/07/31 13:11:44 INFO DAGScheduler: Got job 14 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:11:44 INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:204)
19/07/31 13:11:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
19/07/31 13:11:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
19/07/31 13:11:44 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[69] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:44 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 74.5 KB, free 910.5 MB)
19/07/31 13:11:44 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.4 MB)
19/07/31 13:11:44 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:63098 (size: 31.8 KB, free: 911.9 MB)
19/07/31 13:11:44 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[69] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:44 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/07/31 13:11:44 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:11:44 INFO Executor: Running task 0.0 in stage 20.0 (TID 32)
19/07/31 13:11:44 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:44 INFO Executor: Finished task 0.0 in stage 20.0 (TID 32). 1687 bytes result sent to driver
19/07/31 13:11:44 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 32) in 12 ms on localhost (executor driver) (1/1)
19/07/31 13:11:44 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/07/31 13:11:44 INFO DAGScheduler: ShuffleMapStage 20 (collect at utils.scala:204) finished in 0.012 s
19/07/31 13:11:44 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:11:44 INFO DAGScheduler: running: Set()
19/07/31 13:11:44 INFO DAGScheduler: waiting: Set(ResultStage 21)
19/07/31 13:11:44 INFO DAGScheduler: failed: Set()
19/07/31 13:11:44 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[72] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:44 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 16.8 KB, free 910.4 MB)
19/07/31 13:11:44 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.4 MB)
19/07/31 13:11:44 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:63098 (size: 8.0 KB, free: 911.9 MB)
19/07/31 13:11:44 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:44 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 21 (MapPartitionsRDD[72] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:11:44 INFO TaskSchedulerImpl: Adding task set 21.0 with 4 tasks
19/07/31 13:11:44 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 33, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:11:44 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 34, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:11:44 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 35, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:11:44 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 36, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:11:44 INFO Executor: Running task 2.0 in stage 21.0 (TID 35)
19/07/31 13:11:44 INFO Executor: Running task 1.0 in stage 21.0 (TID 34)
19/07/31 13:11:44 INFO Executor: Running task 0.0 in stage 21.0 (TID 33)
19/07/31 13:11:44 INFO Executor: Running task 3.0 in stage 21.0 (TID 36)
19/07/31 13:11:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:11:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:44 INFO Executor: Finished task 3.0 in stage 21.0 (TID 36). 2353 bytes result sent to driver
19/07/31 13:11:44 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 36) in 6 ms on localhost (executor driver) (1/4)
19/07/31 13:11:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:44 INFO Executor: Finished task 2.0 in stage 21.0 (TID 35). 2378 bytes result sent to driver
19/07/31 13:11:44 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 35) in 7 ms on localhost (executor driver) (2/4)
19/07/31 13:11:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:11:44 INFO Executor: Finished task 1.0 in stage 21.0 (TID 34). 2359 bytes result sent to driver
19/07/31 13:11:44 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 34) in 9 ms on localhost (executor driver) (3/4)
19/07/31 13:11:44 INFO Executor: Finished task 0.0 in stage 21.0 (TID 33). 2377 bytes result sent to driver
19/07/31 13:11:44 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 33) in 10 ms on localhost (executor driver) (4/4)
19/07/31 13:11:44 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/07/31 13:11:44 INFO DAGScheduler: ResultStage 21 (collect at utils.scala:204) finished in 0.012 s
19/07/31 13:11:44 INFO DAGScheduler: Job 14 finished: collect at utils.scala:204, took 0.034735 s
19/07/31 13:11:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_041`) `dbplyr_042`
ORDER BY `date`) `dbplyr_043`) `dbplyr_044`
WHERE ((`customer` = "PROSPECT") AND (`device` = "All Devices"))
19/07/31 13:11:44 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:44 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_045`) `dbplyr_046`
ORDER BY `date`) `dbplyr_047`) `dbplyr_048`
WHERE ((`customer` = "PROSPECT") AND (`device` = "All Devices"))
19/07/31 13:11:45 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:45 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:45 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#932 - cust_prospect_ind.nullCount#931) > 0)
19/07/31 13:11:45 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#937 - visit_device_type.nullCount#936) > 0)
19/07/31 13:11:45 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#930 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#929))
19/07/31 13:11:45 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#935 <= All Devices) && (All Devices <= visit_device_type.upperBound#934))
19/07/31 13:11:45 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:45 INFO DAGScheduler: Got job 15 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:11:45 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:204)
19/07/31 13:11:45 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:11:45 INFO DAGScheduler: Missing parents: List()
19/07/31 13:11:45 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[77] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:45 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 72.1 KB, free 910.3 MB)
19/07/31 13:11:45 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.3 MB)
19/07/31 13:11:45 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:63098 (size: 30.4 KB, free: 911.9 MB)
19/07/31 13:11:45 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[77] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:45 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
19/07/31 13:11:45 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:11:45 INFO Executor: Running task 0.0 in stage 22.0 (TID 37)
19/07/31 13:11:45 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:45 INFO Executor: Finished task 0.0 in stage 22.0 (TID 37). 6979 bytes result sent to driver
19/07/31 13:11:45 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 37) in 7 ms on localhost (executor driver) (1/1)
19/07/31 13:11:45 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/07/31 13:11:45 INFO DAGScheduler: ResultStage 22 (collect at utils.scala:204) finished in 0.008 s
19/07/31 13:11:45 INFO DAGScheduler: Job 15 finished: collect at utils.scala:204, took 0.015243 s
19/07/31 13:11:45 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:45 INFO DAGScheduler: Registering RDD 78 (collect at utils.scala:204)
19/07/31 13:11:45 INFO DAGScheduler: Got job 16 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:11:45 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:204)
19/07/31 13:11:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
19/07/31 13:11:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 23)
19/07/31 13:11:45 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[78] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:45 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 74.5 KB, free 910.2 MB)
19/07/31 13:11:45 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.2 MB)
19/07/31 13:11:45 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:63098 (size: 31.7 KB, free: 911.8 MB)
19/07/31 13:11:45 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[78] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:45 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
19/07/31 13:11:45 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:11:45 INFO Executor: Running task 0.0 in stage 23.0 (TID 38)
19/07/31 13:11:45 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:45 INFO Executor: Finished task 0.0 in stage 23.0 (TID 38). 1687 bytes result sent to driver
19/07/31 13:11:45 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 38) in 11 ms on localhost (executor driver) (1/1)
19/07/31 13:11:45 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
19/07/31 13:11:45 INFO DAGScheduler: ShuffleMapStage 23 (collect at utils.scala:204) finished in 0.012 s
19/07/31 13:11:45 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:11:45 INFO DAGScheduler: running: Set()
19/07/31 13:11:45 INFO DAGScheduler: waiting: Set(ResultStage 24)
19/07/31 13:11:45 INFO DAGScheduler: failed: Set()
19/07/31 13:11:45 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[81] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:45 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 16.8 KB, free 910.2 MB)
19/07/31 13:11:45 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.2 MB)
19/07/31 13:11:45 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:63098 (size: 8.0 KB, free: 911.8 MB)
19/07/31 13:11:45 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:45 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[81] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:11:45 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks
19/07/31 13:11:45 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 39, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:11:45 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 40, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:11:45 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 41, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:11:45 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 42, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:11:45 INFO Executor: Running task 0.0 in stage 24.0 (TID 39)
19/07/31 13:11:45 INFO Executor: Running task 1.0 in stage 24.0 (TID 40)
19/07/31 13:11:45 INFO Executor: Running task 3.0 in stage 24.0 (TID 42)
19/07/31 13:11:45 INFO Executor: Running task 2.0 in stage 24.0 (TID 41)
19/07/31 13:11:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/07/31 13:11:45 INFO Executor: Finished task 0.0 in stage 24.0 (TID 39). 2383 bytes result sent to driver
19/07/31 13:11:45 INFO Executor: Finished task 1.0 in stage 24.0 (TID 40). 2357 bytes result sent to driver
19/07/31 13:11:45 INFO Executor: Finished task 2.0 in stage 24.0 (TID 41). 2391 bytes result sent to driver
19/07/31 13:11:45 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 39) in 8 ms on localhost (executor driver) (1/4)
19/07/31 13:11:45 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 40) in 8 ms on localhost (executor driver) (2/4)
19/07/31 13:11:45 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 41) in 7 ms on localhost (executor driver) (3/4)
19/07/31 13:11:45 INFO Executor: Finished task 3.0 in stage 24.0 (TID 42). 2369 bytes result sent to driver
19/07/31 13:11:45 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 42) in 8 ms on localhost (executor driver) (4/4)
19/07/31 13:11:45 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
19/07/31 13:11:45 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:204) finished in 0.009 s
19/07/31 13:11:45 INFO DAGScheduler: Job 16 finished: collect at utils.scala:204, took 0.033921 s
19/07/31 13:11:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_049`) `dbplyr_050`
ORDER BY `date`) `dbplyr_051`) `dbplyr_052`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "All Devices"))
19/07/31 13:11:45 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:45 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_053`) `dbplyr_054`
ORDER BY `date`) `dbplyr_055`) `dbplyr_056`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "All Devices"))
19/07/31 13:11:45 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:45 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:45 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1030 - cust_prospect_ind.nullCount#1029) > 0)
19/07/31 13:11:45 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1035 - visit_device_type.nullCount#1034) > 0)
19/07/31 13:11:45 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#1028 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#1027))
19/07/31 13:11:45 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#1033 <= All Devices) && (All Devices <= visit_device_type.upperBound#1032))
19/07/31 13:11:45 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:63098 in memory (size: 8.0 KB, free: 911.8 MB)
19/07/31 13:11:45 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:63098 in memory (size: 8.0 KB, free: 911.8 MB)
19/07/31 13:11:45 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:63098 in memory (size: 30.5 KB, free: 911.9 MB)
19/07/31 13:11:45 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:63098 in memory (size: 8.0 KB, free: 911.9 MB)
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 237
19/07/31 13:11:45 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:63098 in memory (size: 31.8 KB, free: 911.9 MB)
19/07/31 13:11:45 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:63098 in memory (size: 8.0 KB, free: 911.9 MB)
19/07/31 13:11:45 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:63098 in memory (size: 30.5 KB, free: 911.9 MB)
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 568
19/07/31 13:11:45 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:63098 in memory (size: 31.8 KB, free: 912.0 MB)
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 405
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 406
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 485
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 324
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 480
19/07/31 13:11:45 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:63098 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 325
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 566
19/07/31 13:11:45 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:63098 in memory (size: 30.4 KB, free: 912.0 MB)
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 241
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 404
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 641
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 481
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 486
19/07/31 13:11:45 INFO ContextCleaner: Cleaned shuffle 4
19/07/31 13:11:45 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:63098 in memory (size: 30.4 KB, free: 912.0 MB)
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 564
19/07/31 13:11:45 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:63098 in memory (size: 31.7 KB, free: 912.1 MB)
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 483
19/07/31 13:11:45 INFO ContextCleaner: Cleaned shuffle 6
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 563
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 322
19/07/31 13:11:45 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:63098 in memory (size: 31.8 KB, free: 912.1 MB)
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 239
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 400
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 323
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 244
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 402
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 317
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 722
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 560
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 238
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 482
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 398
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 484
19/07/31 13:11:45 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:63098 in memory (size: 8.0 KB, free: 912.1 MB)
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 319
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 240
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 242
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 567
19/07/31 13:11:45 INFO ContextCleaner: Cleaned shuffle 5
19/07/31 13:11:45 INFO ContextCleaner: Cleaned shuffle 3
19/07/31 13:11:45 INFO ContextCleaner: Cleaned shuffle 2
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 403
19/07/31 13:11:45 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:63098 in memory (size: 31.7 KB, free: 912.1 MB)
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 401
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 562
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 243
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 399
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 321
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 318
19/07/31 13:11:45 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:63098 in memory (size: 30.5 KB, free: 912.2 MB)
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 479
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 565
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 320
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 561
19/07/31 13:11:45 INFO ContextCleaner: Cleaned accumulator 487
19/07/31 13:11:45 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:45 INFO DAGScheduler: Got job 17 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:11:45 INFO DAGScheduler: Final stage: ResultStage 25 (collect at utils.scala:204)
19/07/31 13:11:45 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:11:45 INFO DAGScheduler: Missing parents: List()
19/07/31 13:11:45 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[86] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:45 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 72.1 KB, free 911.3 MB)
19/07/31 13:11:45 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 30.5 KB, free 911.2 MB)
19/07/31 13:11:45 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:63098 (size: 30.5 KB, free: 912.1 MB)
19/07/31 13:11:45 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[86] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:45 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
19/07/31 13:11:45 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:11:45 INFO Executor: Running task 0.0 in stage 25.0 (TID 43)
19/07/31 13:11:45 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:45 INFO Executor: Finished task 0.0 in stage 25.0 (TID 43). 7542 bytes result sent to driver
19/07/31 13:11:45 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 43) in 8 ms on localhost (executor driver) (1/1)
19/07/31 13:11:45 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
19/07/31 13:11:45 INFO DAGScheduler: ResultStage 25 (collect at utils.scala:204) finished in 0.008 s
19/07/31 13:11:45 INFO DAGScheduler: Job 17 finished: collect at utils.scala:204, took 0.014827 s
19/07/31 13:11:45 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:45 INFO DAGScheduler: Registering RDD 87 (collect at utils.scala:204)
19/07/31 13:11:45 INFO DAGScheduler: Got job 18 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:11:45 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:204)
19/07/31 13:11:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
19/07/31 13:11:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 26)
19/07/31 13:11:45 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[87] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:45 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 74.5 KB, free 911.2 MB)
19/07/31 13:11:45 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.1 MB)
19/07/31 13:11:45 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:63098 (size: 31.8 KB, free: 912.1 MB)
19/07/31 13:11:45 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[87] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:45 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
19/07/31 13:11:45 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:11:45 INFO Executor: Running task 0.0 in stage 26.0 (TID 44)
19/07/31 13:11:45 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:45 INFO Executor: Finished task 0.0 in stage 26.0 (TID 44). 1687 bytes result sent to driver
19/07/31 13:11:45 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 44) in 10 ms on localhost (executor driver) (1/1)
19/07/31 13:11:45 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
19/07/31 13:11:45 INFO DAGScheduler: ShuffleMapStage 26 (collect at utils.scala:204) finished in 0.011 s
19/07/31 13:11:45 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:11:45 INFO DAGScheduler: running: Set()
19/07/31 13:11:45 INFO DAGScheduler: waiting: Set(ResultStage 27)
19/07/31 13:11:45 INFO DAGScheduler: failed: Set()
19/07/31 13:11:45 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[90] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:45 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 16.8 KB, free 911.1 MB)
19/07/31 13:11:45 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.1 MB)
19/07/31 13:11:45 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:63098 (size: 8.0 KB, free: 912.1 MB)
19/07/31 13:11:45 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:45 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 27 (MapPartitionsRDD[90] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:11:45 INFO TaskSchedulerImpl: Adding task set 27.0 with 4 tasks
19/07/31 13:11:45 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 45, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:11:45 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 46, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:11:45 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 47, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:11:45 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 48, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:11:45 INFO Executor: Running task 2.0 in stage 27.0 (TID 47)
19/07/31 13:11:45 INFO Executor: Running task 3.0 in stage 27.0 (TID 48)
19/07/31 13:11:45 INFO Executor: Running task 1.0 in stage 27.0 (TID 46)
19/07/31 13:11:45 INFO Executor: Running task 0.0 in stage 27.0 (TID 45)
19/07/31 13:11:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:11:45 INFO Executor: Finished task 2.0 in stage 27.0 (TID 47). 2386 bytes result sent to driver
19/07/31 13:11:45 INFO Executor: Finished task 3.0 in stage 27.0 (TID 48). 2374 bytes result sent to driver
19/07/31 13:11:45 INFO Executor: Finished task 1.0 in stage 27.0 (TID 46). 2392 bytes result sent to driver
19/07/31 13:11:45 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 47) in 6 ms on localhost (executor driver) (1/4)
19/07/31 13:11:45 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 48) in 6 ms on localhost (executor driver) (2/4)
19/07/31 13:11:45 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 46) in 7 ms on localhost (executor driver) (3/4)
19/07/31 13:11:45 INFO Executor: Finished task 0.0 in stage 27.0 (TID 45). 2386 bytes result sent to driver
19/07/31 13:11:45 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 45) in 8 ms on localhost (executor driver) (4/4)
19/07/31 13:11:45 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
19/07/31 13:11:45 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:204) finished in 0.009 s
19/07/31 13:11:45 INFO DAGScheduler: Job 18 finished: collect at utils.scala:204, took 0.029890 s
19/07/31 13:11:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_057`) `dbplyr_058`
ORDER BY `date`) `dbplyr_059`) `dbplyr_060`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Mobile Phone"))
19/07/31 13:11:47 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:47 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_061`) `dbplyr_062`
ORDER BY `date`) `dbplyr_063`) `dbplyr_064`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Mobile Phone"))
19/07/31 13:11:47 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:47 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:47 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1128 - cust_prospect_ind.nullCount#1127) > 0)
19/07/31 13:11:47 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1133 - visit_device_type.nullCount#1132) > 0)
19/07/31 13:11:47 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#1126 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#1125))
19/07/31 13:11:47 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#1131 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#1130))
19/07/31 13:11:47 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:47 INFO DAGScheduler: Got job 19 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:11:47 INFO DAGScheduler: Final stage: ResultStage 28 (collect at utils.scala:204)
19/07/31 13:11:47 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:11:47 INFO DAGScheduler: Missing parents: List()
19/07/31 13:11:47 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[95] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:47 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 72.1 KB, free 911.0 MB)
19/07/31 13:11:47 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 30.5 KB, free 911.0 MB)
19/07/31 13:11:47 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:63098 (size: 30.5 KB, free: 912.1 MB)
19/07/31 13:11:47 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[95] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:47 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
19/07/31 13:11:47 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:11:47 INFO Executor: Running task 0.0 in stage 28.0 (TID 49)
19/07/31 13:11:47 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:47 INFO Executor: Finished task 0.0 in stage 28.0 (TID 49). 6979 bytes result sent to driver
19/07/31 13:11:47 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 49) in 6 ms on localhost (executor driver) (1/1)
19/07/31 13:11:47 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
19/07/31 13:11:47 INFO DAGScheduler: ResultStage 28 (collect at utils.scala:204) finished in 0.007 s
19/07/31 13:11:47 INFO DAGScheduler: Job 19 finished: collect at utils.scala:204, took 0.012681 s
19/07/31 13:11:47 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:47 INFO DAGScheduler: Registering RDD 96 (collect at utils.scala:204)
19/07/31 13:11:47 INFO DAGScheduler: Got job 20 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:11:47 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:204)
19/07/31 13:11:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
19/07/31 13:11:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 29)
19/07/31 13:11:47 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[96] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:47 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 74.5 KB, free 910.9 MB)
19/07/31 13:11:47 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.9 MB)
19/07/31 13:11:47 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:63098 (size: 31.8 KB, free: 912.0 MB)
19/07/31 13:11:47 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[96] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:47 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
19/07/31 13:11:47 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:11:47 INFO Executor: Running task 0.0 in stage 29.0 (TID 50)
19/07/31 13:11:47 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:47 INFO Executor: Finished task 0.0 in stage 29.0 (TID 50). 1687 bytes result sent to driver
19/07/31 13:11:47 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 50) in 12 ms on localhost (executor driver) (1/1)
19/07/31 13:11:47 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
19/07/31 13:11:47 INFO DAGScheduler: ShuffleMapStage 29 (collect at utils.scala:204) finished in 0.013 s
19/07/31 13:11:47 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:11:47 INFO DAGScheduler: running: Set()
19/07/31 13:11:47 INFO DAGScheduler: waiting: Set(ResultStage 30)
19/07/31 13:11:47 INFO DAGScheduler: failed: Set()
19/07/31 13:11:47 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[99] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:47 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 16.8 KB, free 910.9 MB)
19/07/31 13:11:47 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.9 MB)
19/07/31 13:11:47 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:63098 (size: 8.0 KB, free: 912.0 MB)
19/07/31 13:11:47 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:47 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 30 (MapPartitionsRDD[99] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:11:47 INFO TaskSchedulerImpl: Adding task set 30.0 with 4 tasks
19/07/31 13:11:47 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 51, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:11:47 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 52, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:11:47 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 53, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:11:47 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 54, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:11:47 INFO Executor: Running task 0.0 in stage 30.0 (TID 51)
19/07/31 13:11:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:47 INFO Executor: Running task 1.0 in stage 30.0 (TID 52)
19/07/31 13:11:47 INFO Executor: Running task 2.0 in stage 30.0 (TID 53)
19/07/31 13:11:47 INFO Executor: Running task 3.0 in stage 30.0 (TID 54)
19/07/31 13:11:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:47 INFO Executor: Finished task 0.0 in stage 30.0 (TID 51). 2366 bytes result sent to driver
19/07/31 13:11:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:47 INFO Executor: Finished task 3.0 in stage 30.0 (TID 54). 2353 bytes result sent to driver
19/07/31 13:11:47 INFO Executor: Finished task 2.0 in stage 30.0 (TID 53). 2371 bytes result sent to driver
19/07/31 13:11:47 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 51) in 10 ms on localhost (executor driver) (1/4)
19/07/31 13:11:47 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 54) in 10 ms on localhost (executor driver) (2/4)
19/07/31 13:11:47 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 53) in 10 ms on localhost (executor driver) (3/4)
19/07/31 13:11:47 INFO Executor: Finished task 1.0 in stage 30.0 (TID 52). 2347 bytes result sent to driver
19/07/31 13:11:47 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 52) in 12 ms on localhost (executor driver) (4/4)
19/07/31 13:11:47 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
19/07/31 13:11:47 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:204) finished in 0.013 s
19/07/31 13:11:47 INFO DAGScheduler: Job 20 finished: collect at utils.scala:204, took 0.037400 s
19/07/31 13:11:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_065`) `dbplyr_066`
ORDER BY `date`) `dbplyr_067`) `dbplyr_068`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Mobile Phone"))
19/07/31 13:11:48 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:48 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_069`) `dbplyr_070`
ORDER BY `date`) `dbplyr_071`) `dbplyr_072`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Mobile Phone"))
19/07/31 13:11:48 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:48 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:48 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1226 - cust_prospect_ind.nullCount#1225) > 0)
19/07/31 13:11:48 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1231 - visit_device_type.nullCount#1230) > 0)
19/07/31 13:11:48 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#1224 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#1223))
19/07/31 13:11:48 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#1229 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#1228))
19/07/31 13:11:48 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:48 INFO DAGScheduler: Got job 21 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:11:48 INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:204)
19/07/31 13:11:48 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:11:48 INFO DAGScheduler: Missing parents: List()
19/07/31 13:11:48 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[104] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:48 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 72.1 KB, free 910.8 MB)
19/07/31 13:11:48 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.8 MB)
19/07/31 13:11:48 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:63098 (size: 30.4 KB, free: 912.0 MB)
19/07/31 13:11:48 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[104] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:48 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
19/07/31 13:11:48 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:11:48 INFO Executor: Running task 0.0 in stage 31.0 (TID 55)
19/07/31 13:11:48 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:48 INFO Executor: Finished task 0.0 in stage 31.0 (TID 55). 6979 bytes result sent to driver
19/07/31 13:11:48 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 55) in 9 ms on localhost (executor driver) (1/1)
19/07/31 13:11:48 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
19/07/31 13:11:48 INFO DAGScheduler: ResultStage 31 (collect at utils.scala:204) finished in 0.010 s
19/07/31 13:11:48 INFO DAGScheduler: Job 21 finished: collect at utils.scala:204, took 0.030177 s
19/07/31 13:11:48 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:48 INFO DAGScheduler: Registering RDD 105 (collect at utils.scala:204)
19/07/31 13:11:48 INFO DAGScheduler: Got job 22 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:11:48 INFO DAGScheduler: Final stage: ResultStage 33 (collect at utils.scala:204)
19/07/31 13:11:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)
19/07/31 13:11:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 32)
19/07/31 13:11:48 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[105] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:48 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 74.5 KB, free 910.7 MB)
19/07/31 13:11:48 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.7 MB)
19/07/31 13:11:48 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:63098 (size: 31.7 KB, free: 912.0 MB)
19/07/31 13:11:48 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[105] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:48 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
19/07/31 13:11:48 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:11:48 INFO Executor: Running task 0.0 in stage 32.0 (TID 56)
19/07/31 13:11:48 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:48 INFO Executor: Finished task 0.0 in stage 32.0 (TID 56). 1687 bytes result sent to driver
19/07/31 13:11:48 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 56) in 18 ms on localhost (executor driver) (1/1)
19/07/31 13:11:48 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
19/07/31 13:11:48 INFO DAGScheduler: ShuffleMapStage 32 (collect at utils.scala:204) finished in 0.018 s
19/07/31 13:11:48 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:11:48 INFO DAGScheduler: running: Set()
19/07/31 13:11:48 INFO DAGScheduler: waiting: Set(ResultStage 33)
19/07/31 13:11:48 INFO DAGScheduler: failed: Set()
19/07/31 13:11:48 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[108] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:48 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 16.8 KB, free 910.7 MB)
19/07/31 13:11:48 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 8.1 KB, free 910.7 MB)
19/07/31 13:11:48 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:63098 (size: 8.1 KB, free: 912.0 MB)
19/07/31 13:11:48 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:48 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 33 (MapPartitionsRDD[108] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:11:48 INFO TaskSchedulerImpl: Adding task set 33.0 with 4 tasks
19/07/31 13:11:48 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 57, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:11:48 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 58, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:11:48 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 59, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:11:48 INFO TaskSetManager: Starting task 3.0 in stage 33.0 (TID 60, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:11:48 INFO Executor: Running task 0.0 in stage 33.0 (TID 57)
19/07/31 13:11:48 INFO Executor: Running task 1.0 in stage 33.0 (TID 58)
19/07/31 13:11:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:11:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:48 INFO Executor: Running task 2.0 in stage 33.0 (TID 59)
19/07/31 13:11:48 INFO Executor: Running task 3.0 in stage 33.0 (TID 60)
19/07/31 13:11:48 INFO Executor: Finished task 0.0 in stage 33.0 (TID 57). 2373 bytes result sent to driver
19/07/31 13:11:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:11:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:48 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 57) in 11 ms on localhost (executor driver) (1/4)
19/07/31 13:11:48 INFO Executor: Finished task 2.0 in stage 33.0 (TID 59). 2384 bytes result sent to driver
19/07/31 13:11:48 INFO Executor: Finished task 1.0 in stage 33.0 (TID 58). 2370 bytes result sent to driver
19/07/31 13:11:48 INFO Executor: Finished task 3.0 in stage 33.0 (TID 60). 2353 bytes result sent to driver
19/07/31 13:11:48 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 59) in 18 ms on localhost (executor driver) (2/4)
19/07/31 13:11:48 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 58) in 18 ms on localhost (executor driver) (3/4)
19/07/31 13:11:48 INFO TaskSetManager: Finished task 3.0 in stage 33.0 (TID 60) in 18 ms on localhost (executor driver) (4/4)
19/07/31 13:11:48 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
19/07/31 13:11:48 INFO DAGScheduler: ResultStage 33 (collect at utils.scala:204) finished in 0.020 s
19/07/31 13:11:48 INFO DAGScheduler: Job 22 finished: collect at utils.scala:204, took 0.068715 s
19/07/31 13:11:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_073`) `dbplyr_074`
ORDER BY `date`) `dbplyr_075`) `dbplyr_076`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 13:11:48 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:48 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_077`) `dbplyr_078`
ORDER BY `date`) `dbplyr_079`) `dbplyr_080`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 13:11:49 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:49 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:49 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1324 - cust_prospect_ind.nullCount#1323) > 0)
19/07/31 13:11:49 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1329 - visit_device_type.nullCount#1328) > 0)
19/07/31 13:11:49 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#1322 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#1321))
19/07/31 13:11:49 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#1327 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#1326))
19/07/31 13:11:49 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:49 INFO DAGScheduler: Got job 23 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:11:49 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:204)
19/07/31 13:11:49 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:11:49 INFO DAGScheduler: Missing parents: List()
19/07/31 13:11:49 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[113] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:49 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 72.1 KB, free 910.6 MB)
19/07/31 13:11:49 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.6 MB)
19/07/31 13:11:49 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:63098 (size: 30.5 KB, free: 911.9 MB)
19/07/31 13:11:49 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[113] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:49 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
19/07/31 13:11:49 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:11:49 INFO Executor: Running task 0.0 in stage 34.0 (TID 61)
19/07/31 13:11:49 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:49 INFO Executor: Finished task 0.0 in stage 34.0 (TID 61). 7542 bytes result sent to driver
19/07/31 13:11:49 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 61) in 6 ms on localhost (executor driver) (1/1)
19/07/31 13:11:49 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
19/07/31 13:11:49 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:204) finished in 0.006 s
19/07/31 13:11:49 INFO DAGScheduler: Job 23 finished: collect at utils.scala:204, took 0.013774 s
19/07/31 13:11:49 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:49 INFO DAGScheduler: Registering RDD 114 (collect at utils.scala:204)
19/07/31 13:11:49 INFO DAGScheduler: Got job 24 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:11:49 INFO DAGScheduler: Final stage: ResultStage 36 (collect at utils.scala:204)
19/07/31 13:11:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
19/07/31 13:11:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 35)
19/07/31 13:11:49 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[114] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:49 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 74.6 KB, free 910.5 MB)
19/07/31 13:11:49 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.5 MB)
19/07/31 13:11:49 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:63098 (size: 31.8 KB, free: 911.9 MB)
19/07/31 13:11:49 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[114] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:49 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
19/07/31 13:11:49 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:11:49 INFO Executor: Running task 0.0 in stage 35.0 (TID 62)
19/07/31 13:11:49 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:49 INFO Executor: Finished task 0.0 in stage 35.0 (TID 62). 1687 bytes result sent to driver
19/07/31 13:11:49 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 62) in 19 ms on localhost (executor driver) (1/1)
19/07/31 13:11:49 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
19/07/31 13:11:49 INFO DAGScheduler: ShuffleMapStage 35 (collect at utils.scala:204) finished in 0.019 s
19/07/31 13:11:49 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:11:49 INFO DAGScheduler: running: Set()
19/07/31 13:11:49 INFO DAGScheduler: waiting: Set(ResultStage 36)
19/07/31 13:11:49 INFO DAGScheduler: failed: Set()
19/07/31 13:11:49 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[117] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:49 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 16.8 KB, free 910.4 MB)
19/07/31 13:11:49 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 8.1 KB, free 910.4 MB)
19/07/31 13:11:49 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:63098 (size: 8.1 KB, free: 911.9 MB)
19/07/31 13:11:49 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:49 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 36 (MapPartitionsRDD[117] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:11:49 INFO TaskSchedulerImpl: Adding task set 36.0 with 4 tasks
19/07/31 13:11:49 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 63, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:11:49 INFO TaskSetManager: Starting task 1.0 in stage 36.0 (TID 64, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:11:49 INFO TaskSetManager: Starting task 2.0 in stage 36.0 (TID 65, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:11:49 INFO TaskSetManager: Starting task 3.0 in stage 36.0 (TID 66, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:11:49 INFO Executor: Running task 1.0 in stage 36.0 (TID 64)
19/07/31 13:11:49 INFO Executor: Running task 0.0 in stage 36.0 (TID 63)
19/07/31 13:11:49 INFO Executor: Running task 3.0 in stage 36.0 (TID 66)
19/07/31 13:11:49 INFO Executor: Running task 2.0 in stage 36.0 (TID 65)
19/07/31 13:11:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:11:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:11:49 INFO Executor: Finished task 3.0 in stage 36.0 (TID 66). 2356 bytes result sent to driver
19/07/31 13:11:49 INFO Executor: Finished task 0.0 in stage 36.0 (TID 63). 2377 bytes result sent to driver
19/07/31 13:11:49 INFO Executor: Finished task 2.0 in stage 36.0 (TID 65). 2377 bytes result sent to driver
19/07/31 13:11:49 INFO Executor: Finished task 1.0 in stage 36.0 (TID 64). 2382 bytes result sent to driver
19/07/31 13:11:49 INFO TaskSetManager: Finished task 3.0 in stage 36.0 (TID 66) in 6 ms on localhost (executor driver) (1/4)
19/07/31 13:11:49 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 63) in 7 ms on localhost (executor driver) (2/4)
19/07/31 13:11:49 INFO TaskSetManager: Finished task 1.0 in stage 36.0 (TID 64) in 7 ms on localhost (executor driver) (3/4)
19/07/31 13:11:49 INFO TaskSetManager: Finished task 2.0 in stage 36.0 (TID 65) in 7 ms on localhost (executor driver) (4/4)
19/07/31 13:11:49 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
19/07/31 13:11:49 INFO DAGScheduler: ResultStage 36 (collect at utils.scala:204) finished in 0.007 s
19/07/31 13:11:49 INFO DAGScheduler: Job 24 finished: collect at utils.scala:204, took 0.038024 s
19/07/31 13:11:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_081`) `dbplyr_082`
ORDER BY `date`) `dbplyr_083`) `dbplyr_084`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Desktop"))
19/07/31 13:11:49 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:49 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_085`) `dbplyr_086`
ORDER BY `date`) `dbplyr_087`) `dbplyr_088`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Desktop"))
19/07/31 13:11:49 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:49 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:49 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1422 - cust_prospect_ind.nullCount#1421) > 0)
19/07/31 13:11:49 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1427 - visit_device_type.nullCount#1426) > 0)
19/07/31 13:11:49 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#1420 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#1419))
19/07/31 13:11:49 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#1425 <= Desktop) && (Desktop <= visit_device_type.upperBound#1424))
19/07/31 13:11:49 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:49 INFO DAGScheduler: Got job 25 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:11:49 INFO DAGScheduler: Final stage: ResultStage 37 (collect at utils.scala:204)
19/07/31 13:11:49 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:11:49 INFO DAGScheduler: Missing parents: List()
19/07/31 13:11:49 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[122] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:49 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 72.1 KB, free 910.4 MB)
19/07/31 13:11:49 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.3 MB)
19/07/31 13:11:49 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:63098 (size: 30.4 KB, free: 911.9 MB)
19/07/31 13:11:49 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[122] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:49 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
19/07/31 13:11:49 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:11:49 INFO Executor: Running task 0.0 in stage 37.0 (TID 67)
19/07/31 13:11:49 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:49 INFO Executor: Finished task 0.0 in stage 37.0 (TID 67). 6512 bytes result sent to driver
19/07/31 13:11:49 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 67) in 6 ms on localhost (executor driver) (1/1)
19/07/31 13:11:49 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
19/07/31 13:11:49 INFO DAGScheduler: ResultStage 37 (collect at utils.scala:204) finished in 0.006 s
19/07/31 13:11:49 INFO DAGScheduler: Job 25 finished: collect at utils.scala:204, took 0.011874 s
19/07/31 13:11:49 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:49 INFO DAGScheduler: Registering RDD 123 (collect at utils.scala:204)
19/07/31 13:11:49 INFO DAGScheduler: Got job 26 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:11:49 INFO DAGScheduler: Final stage: ResultStage 39 (collect at utils.scala:204)
19/07/31 13:11:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)
19/07/31 13:11:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 38)
19/07/31 13:11:49 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[123] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:49 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 74.5 KB, free 910.3 MB)
19/07/31 13:11:49 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.2 MB)
19/07/31 13:11:49 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:63098 (size: 31.8 KB, free: 911.8 MB)
19/07/31 13:11:49 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[123] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:49 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
19/07/31 13:11:49 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:11:49 INFO Executor: Running task 0.0 in stage 38.0 (TID 68)
19/07/31 13:11:49 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:49 INFO Executor: Finished task 0.0 in stage 38.0 (TID 68). 1687 bytes result sent to driver
19/07/31 13:11:49 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 68) in 10 ms on localhost (executor driver) (1/1)
19/07/31 13:11:49 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
19/07/31 13:11:49 INFO DAGScheduler: ShuffleMapStage 38 (collect at utils.scala:204) finished in 0.010 s
19/07/31 13:11:49 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:11:49 INFO DAGScheduler: running: Set()
19/07/31 13:11:49 INFO DAGScheduler: waiting: Set(ResultStage 39)
19/07/31 13:11:49 INFO DAGScheduler: failed: Set()
19/07/31 13:11:49 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[126] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:49 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 16.8 KB, free 910.2 MB)
19/07/31 13:11:49 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.2 MB)
19/07/31 13:11:49 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:63098 (size: 8.0 KB, free: 911.8 MB)
19/07/31 13:11:49 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:49 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 39 (MapPartitionsRDD[126] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:11:49 INFO TaskSchedulerImpl: Adding task set 39.0 with 4 tasks
19/07/31 13:11:49 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 69, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:11:49 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 70, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:11:49 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 71, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:11:49 INFO TaskSetManager: Starting task 3.0 in stage 39.0 (TID 72, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:11:49 INFO Executor: Running task 1.0 in stage 39.0 (TID 70)
19/07/31 13:11:49 INFO Executor: Running task 2.0 in stage 39.0 (TID 71)
19/07/31 13:11:49 INFO Executor: Running task 3.0 in stage 39.0 (TID 72)
19/07/31 13:11:49 INFO Executor: Running task 0.0 in stage 39.0 (TID 69)
19/07/31 13:11:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:11:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:49 INFO Executor: Finished task 2.0 in stage 39.0 (TID 71). 2368 bytes result sent to driver
19/07/31 13:11:49 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 71) in 6 ms on localhost (executor driver) (1/4)
19/07/31 13:11:49 INFO Executor: Finished task 3.0 in stage 39.0 (TID 72). 2357 bytes result sent to driver
19/07/31 13:11:49 INFO Executor: Finished task 1.0 in stage 39.0 (TID 70). 2350 bytes result sent to driver
19/07/31 13:11:49 INFO TaskSetManager: Finished task 3.0 in stage 39.0 (TID 72) in 7 ms on localhost (executor driver) (2/4)
19/07/31 13:11:49 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 70) in 8 ms on localhost (executor driver) (3/4)
19/07/31 13:11:49 INFO Executor: Finished task 0.0 in stage 39.0 (TID 69). 2367 bytes result sent to driver
19/07/31 13:11:49 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 69) in 9 ms on localhost (executor driver) (4/4)
19/07/31 13:11:49 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
19/07/31 13:11:49 INFO DAGScheduler: ResultStage 39 (collect at utils.scala:204) finished in 0.009 s
19/07/31 13:11:49 INFO DAGScheduler: Job 26 finished: collect at utils.scala:204, took 0.028532 s
19/07/31 13:11:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_089`) `dbplyr_090`
ORDER BY `date`) `dbplyr_091`) `dbplyr_092`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Desktop"))
19/07/31 13:11:50 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:50 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_093`) `dbplyr_094`
ORDER BY `date`) `dbplyr_095`) `dbplyr_096`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Desktop"))
19/07/31 13:11:50 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:50 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:50 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1520 - cust_prospect_ind.nullCount#1519) > 0)
19/07/31 13:11:50 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1525 - visit_device_type.nullCount#1524) > 0)
19/07/31 13:11:50 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#1518 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#1517))
19/07/31 13:11:50 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#1523 <= Desktop) && (Desktop <= visit_device_type.upperBound#1522))
19/07/31 13:11:50 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:50 INFO DAGScheduler: Got job 27 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:11:50 INFO DAGScheduler: Final stage: ResultStage 40 (collect at utils.scala:204)
19/07/31 13:11:50 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:11:50 INFO DAGScheduler: Missing parents: List()
19/07/31 13:11:50 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[131] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:50 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 72.1 KB, free 910.1 MB)
19/07/31 13:11:50 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.1 MB)
19/07/31 13:11:50 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:63098 (size: 30.4 KB, free: 911.8 MB)
19/07/31 13:11:50 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[131] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:50 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
19/07/31 13:11:50 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:11:50 INFO Executor: Running task 0.0 in stage 40.0 (TID 73)
19/07/31 13:11:50 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:50 INFO Executor: Finished task 0.0 in stage 40.0 (TID 73). 6512 bytes result sent to driver
19/07/31 13:11:50 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 73) in 5 ms on localhost (executor driver) (1/1)
19/07/31 13:11:50 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
19/07/31 13:11:50 INFO DAGScheduler: ResultStage 40 (collect at utils.scala:204) finished in 0.005 s
19/07/31 13:11:50 INFO DAGScheduler: Job 27 finished: collect at utils.scala:204, took 0.010927 s
19/07/31 13:11:50 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:50 INFO DAGScheduler: Registering RDD 132 (collect at utils.scala:204)
19/07/31 13:11:50 INFO DAGScheduler: Got job 28 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:11:50 INFO DAGScheduler: Final stage: ResultStage 42 (collect at utils.scala:204)
19/07/31 13:11:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
19/07/31 13:11:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
19/07/31 13:11:50 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[132] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:50 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 74.5 KB, free 910.0 MB)
19/07/31 13:11:50 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.0 MB)
19/07/31 13:11:50 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:63098 (size: 31.7 KB, free: 911.8 MB)
19/07/31 13:11:50 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[132] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:50 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
19/07/31 13:11:50 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 74, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:11:50 INFO Executor: Running task 0.0 in stage 41.0 (TID 74)
19/07/31 13:11:50 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:50 INFO Executor: Finished task 0.0 in stage 41.0 (TID 74). 1687 bytes result sent to driver
19/07/31 13:11:50 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 74) in 8 ms on localhost (executor driver) (1/1)
19/07/31 13:11:50 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
19/07/31 13:11:50 INFO DAGScheduler: ShuffleMapStage 41 (collect at utils.scala:204) finished in 0.008 s
19/07/31 13:11:50 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:11:50 INFO DAGScheduler: running: Set()
19/07/31 13:11:50 INFO DAGScheduler: waiting: Set(ResultStage 42)
19/07/31 13:11:50 INFO DAGScheduler: failed: Set()
19/07/31 13:11:50 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[135] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:50 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 16.8 KB, free 910.0 MB)
19/07/31 13:11:50 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.0 MB)
19/07/31 13:11:50 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:63098 (size: 8.0 KB, free: 911.8 MB)
19/07/31 13:11:50 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:50 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 42 (MapPartitionsRDD[135] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:11:50 INFO TaskSchedulerImpl: Adding task set 42.0 with 4 tasks
19/07/31 13:11:50 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 75, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:11:50 INFO TaskSetManager: Starting task 1.0 in stage 42.0 (TID 76, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:11:50 INFO TaskSetManager: Starting task 2.0 in stage 42.0 (TID 77, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:11:50 INFO TaskSetManager: Starting task 3.0 in stage 42.0 (TID 78, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:11:50 INFO Executor: Running task 3.0 in stage 42.0 (TID 78)
19/07/31 13:11:50 INFO Executor: Running task 2.0 in stage 42.0 (TID 77)
19/07/31 13:11:50 INFO Executor: Running task 1.0 in stage 42.0 (TID 76)
19/07/31 13:11:50 INFO Executor: Running task 0.0 in stage 42.0 (TID 75)
19/07/31 13:11:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:50 INFO Executor: Finished task 2.0 in stage 42.0 (TID 77). 2373 bytes result sent to driver
19/07/31 13:11:50 INFO Executor: Finished task 3.0 in stage 42.0 (TID 78). 2359 bytes result sent to driver
19/07/31 13:11:50 INFO Executor: Finished task 1.0 in stage 42.0 (TID 76). 2351 bytes result sent to driver
19/07/31 13:11:50 INFO TaskSetManager: Finished task 2.0 in stage 42.0 (TID 77) in 4 ms on localhost (executor driver) (1/4)
19/07/31 13:11:50 INFO TaskSetManager: Finished task 3.0 in stage 42.0 (TID 78) in 4 ms on localhost (executor driver) (2/4)
19/07/31 13:11:50 INFO TaskSetManager: Finished task 1.0 in stage 42.0 (TID 76) in 4 ms on localhost (executor driver) (3/4)
19/07/31 13:11:50 INFO Executor: Finished task 0.0 in stage 42.0 (TID 75). 2326 bytes result sent to driver
19/07/31 13:11:50 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 75) in 6 ms on localhost (executor driver) (4/4)
19/07/31 13:11:50 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
19/07/31 13:11:50 INFO DAGScheduler: ResultStage 42 (collect at utils.scala:204) finished in 0.007 s
19/07/31 13:11:50 INFO DAGScheduler: Job 28 finished: collect at utils.scala:204, took 0.024359 s
19/07/31 13:11:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_097`) `dbplyr_098`
ORDER BY `date`) `dbplyr_099`) `dbplyr_100`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Desktop"))
19/07/31 13:11:51 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:51 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_101`) `dbplyr_102`
ORDER BY `date`) `dbplyr_103`) `dbplyr_104`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Desktop"))
19/07/31 13:11:51 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:51 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:51 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1618 - cust_prospect_ind.nullCount#1617) > 0)
19/07/31 13:11:51 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1623 - visit_device_type.nullCount#1622) > 0)
19/07/31 13:11:51 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#1616 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#1615))
19/07/31 13:11:51 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#1621 <= Desktop) && (Desktop <= visit_device_type.upperBound#1620))
19/07/31 13:11:51 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:51 INFO DAGScheduler: Got job 29 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:11:51 INFO DAGScheduler: Final stage: ResultStage 43 (collect at utils.scala:204)
19/07/31 13:11:51 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:11:51 INFO DAGScheduler: Missing parents: List()
19/07/31 13:11:51 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[140] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:51 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 72.1 KB, free 909.9 MB)
19/07/31 13:11:51 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.9 MB)
19/07/31 13:11:51 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:63098 (size: 30.5 KB, free: 911.7 MB)
19/07/31 13:11:51 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[140] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:51 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
19/07/31 13:11:51 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 79, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:11:51 INFO Executor: Running task 0.0 in stage 43.0 (TID 79)
19/07/31 13:11:51 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:51 INFO Executor: Finished task 0.0 in stage 43.0 (TID 79). 7068 bytes result sent to driver
19/07/31 13:11:51 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 79) in 9 ms on localhost (executor driver) (1/1)
19/07/31 13:11:51 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
19/07/31 13:11:51 INFO DAGScheduler: ResultStage 43 (collect at utils.scala:204) finished in 0.010 s
19/07/31 13:11:51 INFO DAGScheduler: Job 29 finished: collect at utils.scala:204, took 0.018651 s
19/07/31 13:11:51 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:51 INFO DAGScheduler: Registering RDD 141 (collect at utils.scala:204)
19/07/31 13:11:51 INFO DAGScheduler: Got job 30 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:11:51 INFO DAGScheduler: Final stage: ResultStage 45 (collect at utils.scala:204)
19/07/31 13:11:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
19/07/31 13:11:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 44)
19/07/31 13:11:51 INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[141] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 810
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 890
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 729
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 971
19/07/31 13:11:51 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 74.5 KB, free 909.8 MB)
19/07/31 13:11:51 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:63098 in memory (size: 30.4 KB, free: 911.8 MB)
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 1048
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 803
19/07/31 13:11:51 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.9 MB)
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 1047
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 724
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 1131
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 811
19/07/31 13:11:51 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:63098 (size: 31.8 KB, free: 911.7 MB)
19/07/31 13:11:51 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[141] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:51 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
19/07/31 13:11:51 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:63098 in memory (size: 8.1 KB, free: 911.7 MB)
19/07/31 13:11:51 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 80, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 888
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 969
19/07/31 13:11:51 INFO Executor: Running task 0.0 in stage 44.0 (TID 80)
19/07/31 13:11:51 INFO ContextCleaner: Cleaned shuffle 13
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 1129
19/07/31 13:11:51 INFO ContextCleaner: Cleaned shuffle 7
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 804
19/07/31 13:11:51 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:63098 in memory (size: 31.8 KB, free: 911.8 MB)
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 808
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 887
19/07/31 13:11:51 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:51 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:63098 in memory (size: 30.4 KB, free: 911.8 MB)
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 886
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 1051
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 1052
19/07/31 13:11:51 INFO ContextCleaner: Cleaned shuffle 11
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 1135
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 727
19/07/31 13:11:51 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:63098 in memory (size: 30.5 KB, free: 911.8 MB)
19/07/31 13:11:51 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:63098 in memory (size: 30.5 KB, free: 911.9 MB)
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 1132
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 642
19/07/31 13:11:51 INFO Executor: Finished task 0.0 in stage 44.0 (TID 80). 1687 bytes result sent to driver
19/07/31 13:11:51 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:63098 in memory (size: 30.5 KB, free: 911.9 MB)
19/07/31 13:11:51 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 80) in 10 ms on localhost (executor driver) (1/1)
19/07/31 13:11:51 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
19/07/31 13:11:51 INFO DAGScheduler: ShuffleMapStage 44 (collect at utils.scala:204) finished in 0.010 s
19/07/31 13:11:51 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:11:51 INFO DAGScheduler: running: Set()
19/07/31 13:11:51 INFO DAGScheduler: waiting: Set(ResultStage 45)
19/07/31 13:11:51 INFO DAGScheduler: failed: Set()
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 1053
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 1134
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 1046
19/07/31 13:11:51 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[144] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 644
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 1127
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 1208
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 891
19/07/31 13:11:51 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:63098 in memory (size: 8.1 KB, free: 911.9 MB)
19/07/31 13:11:51 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 16.8 KB, free 910.4 MB)
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 889
19/07/31 13:11:51 INFO ContextCleaner: Cleaned shuffle 12
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 973
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 965
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 884
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 645
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 967
19/07/31 13:11:51 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.4 MB)
19/07/31 13:11:51 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:63098 (size: 8.0 KB, free: 911.9 MB)
19/07/31 13:11:51 INFO ContextCleaner: Cleaned shuffle 10
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 1050
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 970
19/07/31 13:11:51 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:51 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 45 (MapPartitionsRDD[144] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:11:51 INFO TaskSchedulerImpl: Adding task set 45.0 with 4 tasks
19/07/31 13:11:51 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:63098 in memory (size: 31.8 KB, free: 911.9 MB)
19/07/31 13:11:51 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 81, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:11:51 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 82, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:11:51 INFO TaskSetManager: Starting task 2.0 in stage 45.0 (TID 83, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 807
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 1054
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 1133
19/07/31 13:11:51 INFO TaskSetManager: Starting task 3.0 in stage 45.0 (TID 84, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:11:51 INFO Executor: Running task 0.0 in stage 45.0 (TID 81)
19/07/31 13:11:51 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:63098 in memory (size: 8.0 KB, free: 911.9 MB)
19/07/31 13:11:51 INFO Executor: Running task 3.0 in stage 45.0 (TID 84)
19/07/31 13:11:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:51 INFO Executor: Running task 1.0 in stage 45.0 (TID 82)
19/07/31 13:11:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:51 INFO Executor: Finished task 3.0 in stage 45.0 (TID 84). 2371 bytes result sent to driver
19/07/31 13:11:51 INFO Executor: Running task 2.0 in stage 45.0 (TID 83)
19/07/31 13:11:51 INFO Executor: Finished task 0.0 in stage 45.0 (TID 81). 2396 bytes result sent to driver
19/07/31 13:11:51 INFO TaskSetManager: Finished task 3.0 in stage 45.0 (TID 84) in 7 ms on localhost (executor driver) (1/4)
19/07/31 13:11:51 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 81) in 7 ms on localhost (executor driver) (2/4)
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 805
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 892
19/07/31 13:11:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:51 INFO Executor: Finished task 1.0 in stage 45.0 (TID 82). 2389 bytes result sent to driver
19/07/31 13:11:51 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 82) in 8 ms on localhost (executor driver) (3/4)
19/07/31 13:11:51 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:63098 in memory (size: 8.0 KB, free: 911.9 MB)
19/07/31 13:11:51 INFO Executor: Finished task 2.0 in stage 45.0 (TID 83). 2391 bytes result sent to driver
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 885
19/07/31 13:11:51 INFO TaskSetManager: Finished task 2.0 in stage 45.0 (TID 83) in 10 ms on localhost (executor driver) (4/4)
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 648
19/07/31 13:11:51 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
19/07/31 13:11:51 INFO DAGScheduler: ResultStage 45 (collect at utils.scala:204) finished in 0.011 s
19/07/31 13:11:51 INFO DAGScheduler: Job 30 finished: collect at utils.scala:204, took 0.037638 s
19/07/31 13:11:51 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:63098 in memory (size: 30.5 KB, free: 912.0 MB)
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 647
19/07/31 13:11:51 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:63098 in memory (size: 31.8 KB, free: 912.0 MB)
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 1049
19/07/31 13:11:51 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:63098 in memory (size: 31.7 KB, free: 912.0 MB)
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 723
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 966
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 968
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 725
19/07/31 13:11:51 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:63098 in memory (size: 31.8 KB, free: 912.1 MB)
19/07/31 13:11:51 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:63098 in memory (size: 31.7 KB, free: 912.1 MB)
19/07/31 13:11:51 INFO ContextCleaner: Cleaned shuffle 9
19/07/31 13:11:51 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:63098 in memory (size: 8.0 KB, free: 912.1 MB)
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 649
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 806
19/07/31 13:11:51 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:63098 in memory (size: 30.4 KB, free: 912.1 MB)
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 730
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 972
19/07/31 13:11:51 INFO ContextCleaner: Cleaned shuffle 8
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 1130
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 646
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 809
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 728
19/07/31 13:11:51 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:63098 in memory (size: 8.0 KB, free: 912.1 MB)
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 1128
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 643
19/07/31 13:11:51 INFO ContextCleaner: Cleaned accumulator 726
19/07/31 13:11:52 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_105`) `dbplyr_106`
ORDER BY `date`) `dbplyr_107`) `dbplyr_108`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Tablet"))
19/07/31 13:11:52 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:52 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:52 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_109`) `dbplyr_110`
ORDER BY `date`) `dbplyr_111`) `dbplyr_112`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Tablet"))
19/07/31 13:11:52 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:52 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:52 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1716 - cust_prospect_ind.nullCount#1715) > 0)
19/07/31 13:11:52 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1721 - visit_device_type.nullCount#1720) > 0)
19/07/31 13:11:52 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#1714 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#1713))
19/07/31 13:11:52 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#1719 <= Tablet) && (Tablet <= visit_device_type.upperBound#1718))
19/07/31 13:11:52 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:52 INFO DAGScheduler: Got job 31 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:11:52 INFO DAGScheduler: Final stage: ResultStage 46 (collect at utils.scala:204)
19/07/31 13:11:52 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:11:52 INFO DAGScheduler: Missing parents: List()
19/07/31 13:11:52 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[149] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:52 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 72.1 KB, free 911.1 MB)
19/07/31 13:11:52 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.1 MB)
19/07/31 13:11:52 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:63098 (size: 30.4 KB, free: 912.1 MB)
19/07/31 13:11:52 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[149] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:52 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
19/07/31 13:11:52 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:11:52 INFO Executor: Running task 0.0 in stage 46.0 (TID 85)
19/07/31 13:11:52 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:52 INFO Executor: Finished task 0.0 in stage 46.0 (TID 85). 6512 bytes result sent to driver
19/07/31 13:11:52 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 85) in 4 ms on localhost (executor driver) (1/1)
19/07/31 13:11:52 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
19/07/31 13:11:52 INFO DAGScheduler: ResultStage 46 (collect at utils.scala:204) finished in 0.004 s
19/07/31 13:11:52 INFO DAGScheduler: Job 31 finished: collect at utils.scala:204, took 0.010090 s
19/07/31 13:11:52 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:52 INFO DAGScheduler: Registering RDD 150 (collect at utils.scala:204)
19/07/31 13:11:52 INFO DAGScheduler: Got job 32 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:11:52 INFO DAGScheduler: Final stage: ResultStage 48 (collect at utils.scala:204)
19/07/31 13:11:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
19/07/31 13:11:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 47)
19/07/31 13:11:52 INFO DAGScheduler: Submitting ShuffleMapStage 47 (MapPartitionsRDD[150] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:52 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 74.5 KB, free 911.0 MB)
19/07/31 13:11:52 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 31.7 KB, free 911.0 MB)
19/07/31 13:11:52 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:63098 (size: 31.7 KB, free: 912.1 MB)
19/07/31 13:11:52 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[150] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:52 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
19/07/31 13:11:52 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:11:52 INFO Executor: Running task 0.0 in stage 47.0 (TID 86)
19/07/31 13:11:52 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:52 INFO Executor: Finished task 0.0 in stage 47.0 (TID 86). 1687 bytes result sent to driver
19/07/31 13:11:52 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 86) in 10 ms on localhost (executor driver) (1/1)
19/07/31 13:11:52 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
19/07/31 13:11:52 INFO DAGScheduler: ShuffleMapStage 47 (collect at utils.scala:204) finished in 0.012 s
19/07/31 13:11:52 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:11:52 INFO DAGScheduler: running: Set()
19/07/31 13:11:52 INFO DAGScheduler: waiting: Set(ResultStage 48)
19/07/31 13:11:52 INFO DAGScheduler: failed: Set()
19/07/31 13:11:52 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[153] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:52 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 16.8 KB, free 911.0 MB)
19/07/31 13:11:52 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.0 MB)
19/07/31 13:11:52 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:63098 (size: 8.0 KB, free: 912.1 MB)
19/07/31 13:11:52 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:52 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 48 (MapPartitionsRDD[153] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:11:52 INFO TaskSchedulerImpl: Adding task set 48.0 with 4 tasks
19/07/31 13:11:52 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 87, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:11:52 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 88, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:11:52 INFO TaskSetManager: Starting task 2.0 in stage 48.0 (TID 89, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:11:52 INFO TaskSetManager: Starting task 3.0 in stage 48.0 (TID 90, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:11:52 INFO Executor: Running task 0.0 in stage 48.0 (TID 87)
19/07/31 13:11:52 INFO Executor: Running task 1.0 in stage 48.0 (TID 88)
19/07/31 13:11:52 INFO Executor: Running task 2.0 in stage 48.0 (TID 89)
19/07/31 13:11:52 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:52 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:52 INFO Executor: Running task 3.0 in stage 48.0 (TID 90)
19/07/31 13:11:52 INFO Executor: Finished task 0.0 in stage 48.0 (TID 87). 2357 bytes result sent to driver
19/07/31 13:11:52 INFO Executor: Finished task 2.0 in stage 48.0 (TID 89). 2362 bytes result sent to driver
19/07/31 13:11:52 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:52 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 87) in 6 ms on localhost (executor driver) (1/4)
19/07/31 13:11:52 INFO TaskSetManager: Finished task 2.0 in stage 48.0 (TID 89) in 6 ms on localhost (executor driver) (2/4)
19/07/31 13:11:52 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:52 INFO Executor: Finished task 3.0 in stage 48.0 (TID 90). 2336 bytes result sent to driver
19/07/31 13:11:52 INFO TaskSetManager: Finished task 3.0 in stage 48.0 (TID 90) in 7 ms on localhost (executor driver) (3/4)
19/07/31 13:11:52 INFO Executor: Finished task 1.0 in stage 48.0 (TID 88). 2340 bytes result sent to driver
19/07/31 13:11:52 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 88) in 8 ms on localhost (executor driver) (4/4)
19/07/31 13:11:52 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
19/07/31 13:11:52 INFO DAGScheduler: ResultStage 48 (collect at utils.scala:204) finished in 0.010 s
19/07/31 13:11:52 INFO DAGScheduler: Job 32 finished: collect at utils.scala:204, took 0.029932 s
19/07/31 13:11:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_113`) `dbplyr_114`
ORDER BY `date`) `dbplyr_115`) `dbplyr_116`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Tablet"))
19/07/31 13:11:53 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:53 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_117`) `dbplyr_118`
ORDER BY `date`) `dbplyr_119`) `dbplyr_120`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Tablet"))
19/07/31 13:11:53 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:53 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:53 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1814 - cust_prospect_ind.nullCount#1813) > 0)
19/07/31 13:11:53 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1819 - visit_device_type.nullCount#1818) > 0)
19/07/31 13:11:53 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#1812 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#1811))
19/07/31 13:11:53 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#1817 <= Tablet) && (Tablet <= visit_device_type.upperBound#1816))
19/07/31 13:11:53 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:53 INFO DAGScheduler: Got job 33 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:11:53 INFO DAGScheduler: Final stage: ResultStage 49 (collect at utils.scala:204)
19/07/31 13:11:53 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:11:53 INFO DAGScheduler: Missing parents: List()
19/07/31 13:11:53 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[158] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:53 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 72.1 KB, free 910.9 MB)
19/07/31 13:11:53 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.9 MB)
19/07/31 13:11:53 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:63098 (size: 30.4 KB, free: 912.0 MB)
19/07/31 13:11:53 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[158] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:53 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
19/07/31 13:11:53 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 91, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:11:53 INFO Executor: Running task 0.0 in stage 49.0 (TID 91)
19/07/31 13:11:53 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:53 INFO Executor: Finished task 0.0 in stage 49.0 (TID 91). 6512 bytes result sent to driver
19/07/31 13:11:53 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 91) in 4 ms on localhost (executor driver) (1/1)
19/07/31 13:11:53 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
19/07/31 13:11:53 INFO DAGScheduler: ResultStage 49 (collect at utils.scala:204) finished in 0.004 s
19/07/31 13:11:53 INFO DAGScheduler: Job 33 finished: collect at utils.scala:204, took 0.009295 s
19/07/31 13:11:53 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:53 INFO DAGScheduler: Registering RDD 159 (collect at utils.scala:204)
19/07/31 13:11:53 INFO DAGScheduler: Got job 34 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:11:53 INFO DAGScheduler: Final stage: ResultStage 51 (collect at utils.scala:204)
19/07/31 13:11:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
19/07/31 13:11:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 50)
19/07/31 13:11:53 INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[159] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:53 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 74.5 KB, free 910.8 MB)
19/07/31 13:11:53 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.8 MB)
19/07/31 13:11:53 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:63098 (size: 31.7 KB, free: 912.0 MB)
19/07/31 13:11:53 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[159] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:53 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
19/07/31 13:11:53 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:11:53 INFO Executor: Running task 0.0 in stage 50.0 (TID 92)
19/07/31 13:11:53 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:53 INFO Executor: Finished task 0.0 in stage 50.0 (TID 92). 1687 bytes result sent to driver
19/07/31 13:11:53 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 92) in 6 ms on localhost (executor driver) (1/1)
19/07/31 13:11:53 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
19/07/31 13:11:53 INFO DAGScheduler: ShuffleMapStage 50 (collect at utils.scala:204) finished in 0.007 s
19/07/31 13:11:53 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:11:53 INFO DAGScheduler: running: Set()
19/07/31 13:11:53 INFO DAGScheduler: waiting: Set(ResultStage 51)
19/07/31 13:11:53 INFO DAGScheduler: failed: Set()
19/07/31 13:11:53 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[162] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:53 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 16.8 KB, free 910.8 MB)
19/07/31 13:11:53 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.8 MB)
19/07/31 13:11:53 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:63098 (size: 8.0 KB, free: 912.0 MB)
19/07/31 13:11:53 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:53 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 51 (MapPartitionsRDD[162] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:11:53 INFO TaskSchedulerImpl: Adding task set 51.0 with 4 tasks
19/07/31 13:11:53 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 93, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:11:53 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 94, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:11:53 INFO TaskSetManager: Starting task 2.0 in stage 51.0 (TID 95, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:11:53 INFO TaskSetManager: Starting task 3.0 in stage 51.0 (TID 96, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:11:53 INFO Executor: Running task 0.0 in stage 51.0 (TID 93)
19/07/31 13:11:53 INFO Executor: Running task 1.0 in stage 51.0 (TID 94)
19/07/31 13:11:53 INFO Executor: Running task 3.0 in stage 51.0 (TID 96)
19/07/31 13:11:53 INFO Executor: Running task 2.0 in stage 51.0 (TID 95)
19/07/31 13:11:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:11:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:53 INFO Executor: Finished task 3.0 in stage 51.0 (TID 96). 2346 bytes result sent to driver
19/07/31 13:11:53 INFO Executor: Finished task 2.0 in stage 51.0 (TID 95). 2360 bytes result sent to driver
19/07/31 13:11:53 INFO Executor: Finished task 0.0 in stage 51.0 (TID 93). 2385 bytes result sent to driver
19/07/31 13:11:53 INFO TaskSetManager: Finished task 3.0 in stage 51.0 (TID 96) in 5 ms on localhost (executor driver) (1/4)
19/07/31 13:11:53 INFO Executor: Finished task 1.0 in stage 51.0 (TID 94). 2337 bytes result sent to driver
19/07/31 13:11:53 INFO TaskSetManager: Finished task 2.0 in stage 51.0 (TID 95) in 5 ms on localhost (executor driver) (2/4)
19/07/31 13:11:53 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 93) in 5 ms on localhost (executor driver) (3/4)
19/07/31 13:11:53 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 94) in 5 ms on localhost (executor driver) (4/4)
19/07/31 13:11:53 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
19/07/31 13:11:53 INFO DAGScheduler: ResultStage 51 (collect at utils.scala:204) finished in 0.007 s
19/07/31 13:11:53 INFO DAGScheduler: Job 34 finished: collect at utils.scala:204, took 0.021978 s
19/07/31 13:11:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_121`) `dbplyr_122`
ORDER BY `date`) `dbplyr_123`) `dbplyr_124`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Tablet"))
19/07/31 13:11:53 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:53 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:53 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_125`) `dbplyr_126`
ORDER BY `date`) `dbplyr_127`) `dbplyr_128`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Tablet"))
19/07/31 13:11:53 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:53 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:53 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1912 - cust_prospect_ind.nullCount#1911) > 0)
19/07/31 13:11:53 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1917 - visit_device_type.nullCount#1916) > 0)
19/07/31 13:11:53 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#1910 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#1909))
19/07/31 13:11:53 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#1915 <= Tablet) && (Tablet <= visit_device_type.upperBound#1914))
19/07/31 13:11:53 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:53 INFO DAGScheduler: Got job 35 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:11:53 INFO DAGScheduler: Final stage: ResultStage 52 (collect at utils.scala:204)
19/07/31 13:11:53 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:11:53 INFO DAGScheduler: Missing parents: List()
19/07/31 13:11:53 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[167] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:53 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 72.1 KB, free 910.7 MB)
19/07/31 13:11:53 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.7 MB)
19/07/31 13:11:53 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:63098 (size: 30.5 KB, free: 912.0 MB)
19/07/31 13:11:53 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[167] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:53 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
19/07/31 13:11:53 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:11:53 INFO Executor: Running task 0.0 in stage 52.0 (TID 97)
19/07/31 13:11:53 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:53 INFO Executor: Finished task 0.0 in stage 52.0 (TID 97). 7068 bytes result sent to driver
19/07/31 13:11:53 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 97) in 5 ms on localhost (executor driver) (1/1)
19/07/31 13:11:53 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
19/07/31 13:11:53 INFO DAGScheduler: ResultStage 52 (collect at utils.scala:204) finished in 0.006 s
19/07/31 13:11:53 INFO DAGScheduler: Job 35 finished: collect at utils.scala:204, took 0.010713 s
19/07/31 13:11:53 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:53 INFO DAGScheduler: Registering RDD 168 (collect at utils.scala:204)
19/07/31 13:11:53 INFO DAGScheduler: Got job 36 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:11:53 INFO DAGScheduler: Final stage: ResultStage 54 (collect at utils.scala:204)
19/07/31 13:11:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 53)
19/07/31 13:11:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 53)
19/07/31 13:11:53 INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[168] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:53 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 74.5 KB, free 910.6 MB)
19/07/31 13:11:53 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.6 MB)
19/07/31 13:11:53 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:63098 (size: 31.8 KB, free: 911.9 MB)
19/07/31 13:11:53 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[168] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:53 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
19/07/31 13:11:53 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 98, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:11:53 INFO Executor: Running task 0.0 in stage 53.0 (TID 98)
19/07/31 13:11:53 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:11:53 INFO Executor: Finished task 0.0 in stage 53.0 (TID 98). 1687 bytes result sent to driver
19/07/31 13:11:53 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 98) in 8 ms on localhost (executor driver) (1/1)
19/07/31 13:11:53 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
19/07/31 13:11:53 INFO DAGScheduler: ShuffleMapStage 53 (collect at utils.scala:204) finished in 0.008 s
19/07/31 13:11:53 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:11:53 INFO DAGScheduler: running: Set()
19/07/31 13:11:53 INFO DAGScheduler: waiting: Set(ResultStage 54)
19/07/31 13:11:53 INFO DAGScheduler: failed: Set()
19/07/31 13:11:53 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[171] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:53 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 16.8 KB, free 910.5 MB)
19/07/31 13:11:53 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 8.1 KB, free 910.5 MB)
19/07/31 13:11:53 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:63098 (size: 8.1 KB, free: 911.9 MB)
19/07/31 13:11:53 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:53 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 54 (MapPartitionsRDD[171] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:11:53 INFO TaskSchedulerImpl: Adding task set 54.0 with 4 tasks
19/07/31 13:11:53 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 99, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:11:53 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 100, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:11:53 INFO TaskSetManager: Starting task 2.0 in stage 54.0 (TID 101, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:11:53 INFO TaskSetManager: Starting task 3.0 in stage 54.0 (TID 102, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:11:53 INFO Executor: Running task 0.0 in stage 54.0 (TID 99)
19/07/31 13:11:53 INFO Executor: Running task 1.0 in stage 54.0 (TID 100)
19/07/31 13:11:53 INFO Executor: Running task 2.0 in stage 54.0 (TID 101)
19/07/31 13:11:53 INFO Executor: Running task 3.0 in stage 54.0 (TID 102)
19/07/31 13:11:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:53 INFO Executor: Finished task 2.0 in stage 54.0 (TID 101). 2379 bytes result sent to driver
19/07/31 13:11:53 INFO Executor: Finished task 3.0 in stage 54.0 (TID 102). 2357 bytes result sent to driver
19/07/31 13:11:53 INFO TaskSetManager: Finished task 2.0 in stage 54.0 (TID 101) in 4 ms on localhost (executor driver) (1/4)
19/07/31 13:11:53 INFO TaskSetManager: Finished task 3.0 in stage 54.0 (TID 102) in 5 ms on localhost (executor driver) (2/4)
19/07/31 13:11:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:53 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:53 INFO Executor: Finished task 1.0 in stage 54.0 (TID 100). 2381 bytes result sent to driver
19/07/31 13:11:53 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 100) in 10 ms on localhost (executor driver) (3/4)
19/07/31 13:11:53 INFO Executor: Finished task 0.0 in stage 54.0 (TID 99). 2376 bytes result sent to driver
19/07/31 13:11:53 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 99) in 12 ms on localhost (executor driver) (4/4)
19/07/31 13:11:53 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
19/07/31 13:11:53 INFO DAGScheduler: ResultStage 54 (collect at utils.scala:204) finished in 0.012 s
19/07/31 13:11:53 INFO DAGScheduler: Job 36 finished: collect at utils.scala:204, took 0.032436 s
19/07/31 13:11:54 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:11:54 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:54 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:54 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:54 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:54 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:11:54 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:11:54 INFO CodeGenerator: Code generated in 4.907193 ms
19/07/31 13:11:54 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 13:11:54 INFO DAGScheduler: Got job 37 (collect at utils.scala:44) with 1 output partitions
19/07/31 13:11:54 INFO DAGScheduler: Final stage: ResultStage 55 (collect at utils.scala:44)
19/07/31 13:11:54 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:11:54 INFO DAGScheduler: Missing parents: List()
19/07/31 13:11:54 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[176] at map at utils.scala:41), which has no missing parents
19/07/31 13:11:54 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 6.3 KB, free 910.5 MB)
19/07/31 13:11:54 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 3.5 KB, free 910.5 MB)
19/07/31 13:11:54 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:63098 (size: 3.5 KB, free: 911.9 MB)
19/07/31 13:11:54 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[176] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:54 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
19/07/31 13:11:54 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 103, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 13:11:54 INFO Executor: Running task 0.0 in stage 55.0 (TID 103)
19/07/31 13:11:54 INFO Executor: Finished task 0.0 in stage 55.0 (TID 103). 964 bytes result sent to driver
19/07/31 13:11:54 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 103) in 4 ms on localhost (executor driver) (1/1)
19/07/31 13:11:54 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
19/07/31 13:11:54 INFO DAGScheduler: ResultStage 55 (collect at utils.scala:44) finished in 0.004 s
19/07/31 13:11:54 INFO DAGScheduler: Job 37 finished: collect at utils.scala:44, took 0.008194 s
19/07/31 13:11:54 INFO SparkSqlParser: Parsing command: result
19/07/31 13:11:54 INFO SparkSqlParser: Parsing command: CACHE TABLE `result`
19/07/31 13:11:54 INFO SparkSqlParser: Parsing command: `result`
19/07/31 13:11:54 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 13:11:54 INFO DAGScheduler: Registering RDD 184 (sql at <unknown>:0)
19/07/31 13:11:54 INFO DAGScheduler: Got job 38 (sql at <unknown>:0) with 1 output partitions
19/07/31 13:11:54 INFO DAGScheduler: Final stage: ResultStage 57 (sql at <unknown>:0)
19/07/31 13:11:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
19/07/31 13:11:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 56)
19/07/31 13:11:54 INFO DAGScheduler: Submitting ShuffleMapStage 56 (MapPartitionsRDD[184] at sql at <unknown>:0), which has no missing parents
19/07/31 13:11:54 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 28.2 KB, free 910.5 MB)
19/07/31 13:11:54 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 10.9 KB, free 910.5 MB)
19/07/31 13:11:54 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:63098 (size: 10.9 KB, free: 911.9 MB)
19/07/31 13:11:54 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[184] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:54 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
19/07/31 13:11:54 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 104, localhost, executor driver, partition 0, PROCESS_LOCAL, 81622 bytes)
19/07/31 13:11:54 INFO Executor: Running task 0.0 in stage 56.0 (TID 104)
19/07/31 13:11:54 INFO CodeGenerator: Code generated in 11.686495 ms
19/07/31 13:11:54 INFO CodeGenerator: Code generated in 68.590154 ms
19/07/31 13:11:55 INFO MemoryStore: Block rdd_181_0 stored as values in memory (estimated size 48.4 KB, free 910.4 MB)
19/07/31 13:11:55 INFO BlockManagerInfo: Added rdd_181_0 in memory on 127.0.0.1:63098 (size: 48.4 KB, free: 911.9 MB)
19/07/31 13:11:55 INFO Executor: Finished task 0.0 in stage 56.0 (TID 104). 2285 bytes result sent to driver
19/07/31 13:11:55 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 104) in 167 ms on localhost (executor driver) (1/1)
19/07/31 13:11:55 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
19/07/31 13:11:55 INFO DAGScheduler: ShuffleMapStage 56 (sql at <unknown>:0) finished in 0.167 s
19/07/31 13:11:55 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:11:55 INFO DAGScheduler: running: Set()
19/07/31 13:11:55 INFO DAGScheduler: waiting: Set(ResultStage 57)
19/07/31 13:11:55 INFO DAGScheduler: failed: Set()
19/07/31 13:11:55 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[187] at sql at <unknown>:0), which has no missing parents
19/07/31 13:11:55 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 7.0 KB, free 910.4 MB)
19/07/31 13:11:55 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.4 MB)
19/07/31 13:11:55 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:63098 (size: 3.7 KB, free: 911.9 MB)
19/07/31 13:11:55 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[187] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:55 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
19/07/31 13:11:55 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 105, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:11:55 INFO Executor: Running task 0.0 in stage 57.0 (TID 105)
19/07/31 13:11:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:55 INFO Executor: Finished task 0.0 in stage 57.0 (TID 105). 1581 bytes result sent to driver
19/07/31 13:11:55 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 105) in 3 ms on localhost (executor driver) (1/1)
19/07/31 13:11:55 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
19/07/31 13:11:55 INFO DAGScheduler: ResultStage 57 (sql at <unknown>:0) finished in 0.003 s
19/07/31 13:11:55 INFO DAGScheduler: Job 38 finished: sql at <unknown>:0, took 0.182361 s
19/07/31 13:11:55 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `result`
19/07/31 13:11:55 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:11:55 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:11:55 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:11:55 INFO DAGScheduler: Registering RDD 190 (collect at utils.scala:204)
19/07/31 13:11:55 INFO DAGScheduler: Got job 39 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:11:55 INFO DAGScheduler: Final stage: ResultStage 59 (collect at utils.scala:204)
19/07/31 13:11:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58)
19/07/31 13:11:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 58)
19/07/31 13:11:55 INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[190] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:55 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 28.2 KB, free 910.4 MB)
19/07/31 13:11:55 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 10.9 KB, free 910.4 MB)
19/07/31 13:11:55 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:63098 (size: 10.9 KB, free: 911.9 MB)
19/07/31 13:11:55 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[190] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:55 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
19/07/31 13:11:55 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 106, localhost, executor driver, partition 0, PROCESS_LOCAL, 81622 bytes)
19/07/31 13:11:55 INFO Executor: Running task 0.0 in stage 58.0 (TID 106)
19/07/31 13:11:55 INFO BlockManager: Found block rdd_181_0 locally
19/07/31 13:11:55 INFO Executor: Finished task 0.0 in stage 58.0 (TID 106). 1690 bytes result sent to driver
19/07/31 13:11:55 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 106) in 6 ms on localhost (executor driver) (1/1)
19/07/31 13:11:55 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
19/07/31 13:11:55 INFO DAGScheduler: ShuffleMapStage 58 (collect at utils.scala:204) finished in 0.007 s
19/07/31 13:11:55 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:11:55 INFO DAGScheduler: running: Set()
19/07/31 13:11:55 INFO DAGScheduler: waiting: Set(ResultStage 59)
19/07/31 13:11:55 INFO DAGScheduler: failed: Set()
19/07/31 13:11:55 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[193] at collect at utils.scala:204), which has no missing parents
19/07/31 13:11:55 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 7.0 KB, free 910.4 MB)
19/07/31 13:11:55 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.4 MB)
19/07/31 13:11:55 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:63098 (size: 3.7 KB, free: 911.9 MB)
19/07/31 13:11:55 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[193] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:55 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
19/07/31 13:11:55 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 107, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:11:55 INFO Executor: Running task 0.0 in stage 59.0 (TID 107)
19/07/31 13:11:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:11:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:11:55 INFO Executor: Finished task 0.0 in stage 59.0 (TID 107). 1581 bytes result sent to driver
19/07/31 13:11:55 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 107) in 4 ms on localhost (executor driver) (1/1)
19/07/31 13:11:55 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
19/07/31 13:11:55 INFO DAGScheduler: ResultStage 59 (collect at utils.scala:204) finished in 0.004 s
19/07/31 13:11:55 INFO DAGScheduler: Job 39 finished: collect at utils.scala:204, took 0.019480 s
19/07/31 13:11:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `result` AS `zzz2`
WHERE (0 = 1)
19/07/31 13:11:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `result`
19/07/31 13:11:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 13:11:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 13:11:55 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:11:55 INFO DAGScheduler: Got job 40 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:11:55 INFO DAGScheduler: Final stage: ResultStage 60 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:11:55 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:11:55 INFO DAGScheduler: Missing parents: List()
19/07/31 13:11:55 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[194] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:11:55 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 99.2 KB, free 910.3 MB)
19/07/31 13:11:55 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 37.2 KB, free 910.2 MB)
19/07/31 13:11:55 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:63098 (size: 37.2 KB, free: 911.8 MB)
19/07/31 13:11:55 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
19/07/31 13:11:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[194] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:11:55 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
19/07/31 13:11:55 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 108, localhost, executor driver, partition 0, PROCESS_LOCAL, 81633 bytes)
19/07/31 13:11:55 INFO Executor: Running task 0.0 in stage 60.0 (TID 108)
19/07/31 13:11:55 INFO BlockManager: Found block rdd_181_0 locally
19/07/31 13:11:55 INFO CodeGenerator: Code generated in 24.543276 ms
19/07/31 13:11:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 13:11:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 13:11:55 INFO FileOutputCommitter: Saved output of task 'attempt_20190731131155_0060_m_000000_0' to file:/Users/6jncnk4f/Desktop/anomaly/result/_temporary/0/task_20190731131155_0060_m_000000
19/07/31 13:11:55 INFO SparkHadoopMapRedUtil: attempt_20190731131155_0060_m_000000_0: Committed
19/07/31 13:11:55 INFO Executor: Finished task 0.0 in stage 60.0 (TID 108). 1619 bytes result sent to driver
19/07/31 13:11:55 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 108) in 172 ms on localhost (executor driver) (1/1)
19/07/31 13:11:55 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
19/07/31 13:11:55 INFO DAGScheduler: ResultStage 60 (csv at NativeMethodAccessorImpl.java:0) finished in 0.173 s
19/07/31 13:11:55 INFO DAGScheduler: Job 40 finished: csv at NativeMethodAccessorImpl.java:0, took 0.191841 s
19/07/31 13:11:55 INFO FileFormatWriter: Job null committed.
19/07/31 13:11:56 INFO SparkContext: Invoking stop() from shutdown hook
19/07/31 13:11:56 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
19/07/31 13:11:56 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/07/31 13:11:56 INFO MemoryStore: MemoryStore cleared
19/07/31 13:11:56 INFO BlockManager: BlockManager stopped
19/07/31 13:11:56 INFO BlockManagerMaster: BlockManagerMaster stopped
19/07/31 13:11:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/07/31 13:11:56 INFO SparkContext: Successfully stopped SparkContext
19/07/31 13:11:56 INFO ShutdownHookManager: Shutdown hook called
19/07/31 13:11:56 INFO ShutdownHookManager: Deleting directory /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-347e8f7a-db63-4832-af92-10439b9976de
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 391
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 392
19/07/31 13:16:35 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:62226 in memory (size: 30.8 KB, free: 912.2 MB)
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 79
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 52
19/07/31 13:16:35 INFO ContextCleaner: Cleaned shuffle 3
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 396
19/07/31 13:16:35 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:62226 in memory (size: 23.8 KB, free: 912.2 MB)
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 393
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 397
19/07/31 13:16:35 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:62226 in memory (size: 23.8 KB, free: 912.2 MB)
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 51
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 49
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 388
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 395
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 324
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 449
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 323
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 53
19/07/31 13:16:35 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:62226 in memory (size: 24.0 KB, free: 912.2 MB)
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 80
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 398
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 321
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 54
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 448
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 81
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 83
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 325
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 399
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 394
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 50
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 82
19/07/31 13:16:35 INFO BlockManager: Removing RDD 43
19/07/31 13:16:35 INFO ContextCleaner: Cleaned RDD 43
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 389
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 322
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 390
19/07/31 13:16:35 INFO ContextCleaner: Cleaned accumulator 320
19/07/31 13:30:58 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_027`) `dbplyr_028`
ORDER BY `date`) `dbplyr_029`) `dbplyr_030`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 13:30:58 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:30:58 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:30:58 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_031`) `dbplyr_032`
ORDER BY `date`) `dbplyr_033`) `dbplyr_034`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
LIMIT 1000
19/07/31 13:30:58 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:30:58 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:30:59 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#1367) generates partition filter: ((cust_prospect_ind.count#1923 - cust_prospect_ind.nullCount#1922) > 0)
19/07/31 13:30:59 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#1368) generates partition filter: ((visit_device_type.count#1928 - visit_device_type.nullCount#1927) > 0)
19/07/31 13:30:59 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#1367 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#1921 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#1920))
19/07/31 13:30:59 INFO InMemoryTableScanExec: Predicate (visit_device_type#1368 = All Devices) generates partition filter: ((visit_device_type.lowerBound#1926 <= All Devices) && (All Devices <= visit_device_type.upperBound#1925))
19/07/31 13:30:59 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:30:59 INFO DAGScheduler: Got job 23 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:30:59 INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:204)
19/07/31 13:30:59 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:30:59 INFO DAGScheduler: Missing parents: List()
19/07/31 13:30:59 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[126] at collect at utils.scala:204), which has no missing parents
19/07/31 13:30:59 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 72.8 KB, free 911.9 MB)
19/07/31 13:30:59 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 30.9 KB, free 911.9 MB)
19/07/31 13:30:59 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:62226 (size: 30.9 KB, free: 912.2 MB)
19/07/31 13:30:59 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
19/07/31 13:30:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[126] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:30:59 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
19/07/31 13:30:59 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:30:59 INFO Executor: Running task 0.0 in stage 31.0 (TID 31)
19/07/31 13:30:59 INFO BlockManager: Found block rdd_106_0 locally
19/07/31 13:30:59 INFO Executor: Finished task 0.0 in stage 31.0 (TID 31). 8683 bytes result sent to driver
19/07/31 13:30:59 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 31) in 33 ms on localhost (executor driver) (1/1)
19/07/31 13:30:59 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
19/07/31 13:30:59 INFO DAGScheduler: ResultStage 31 (collect at utils.scala:204) finished in 0.037 s
19/07/31 13:30:59 INFO DAGScheduler: Job 23 finished: collect at utils.scala:204, took 0.067389 s
19/07/31 13:37:56 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_035`) `dbplyr_036`
ORDER BY `date`) `dbplyr_037`
19/07/31 13:37:56 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:37:56 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:37:57 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_038`) `dbplyr_039`
ORDER BY `date`) `dbplyr_040`
19/07/31 13:37:57 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:37:57 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:37:57 INFO CodeGenerator: Code generated in 65.450131 ms
19/07/31 13:37:57 INFO CodeGenerator: Code generated in 27.111567 ms
19/07/31 13:37:57 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:37:57 INFO DAGScheduler: Got job 24 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:37:57 INFO DAGScheduler: Final stage: ResultStage 32 (collect at utils.scala:204)
19/07/31 13:37:57 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:37:57 INFO DAGScheduler: Missing parents: List()
19/07/31 13:37:57 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[131] at collect at utils.scala:204), which has no missing parents
19/07/31 13:37:57 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 69.9 KB, free 911.8 MB)
19/07/31 13:37:57 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 29.6 KB, free 911.8 MB)
19/07/31 13:37:57 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:62226 (size: 29.6 KB, free: 912.2 MB)
19/07/31 13:37:57 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
19/07/31 13:37:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[131] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:37:57 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
19/07/31 13:37:57 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:37:57 INFO Executor: Running task 0.0 in stage 32.0 (TID 32)
19/07/31 13:37:57 INFO BlockManager: Found block rdd_106_0 locally
19/07/31 13:37:57 INFO Executor: Finished task 0.0 in stage 32.0 (TID 32). 23374 bytes result sent to driver
19/07/31 13:37:57 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 32) in 53 ms on localhost (executor driver) (1/1)
19/07/31 13:37:57 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
19/07/31 13:37:57 INFO DAGScheduler: ResultStage 32 (collect at utils.scala:204) finished in 0.053 s
19/07/31 13:37:57 INFO DAGScheduler: Job 24 finished: collect at utils.scala:204, took 0.098009 s
19/07/31 13:37:57 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:37:57 INFO DAGScheduler: Registering RDD 132 (collect at utils.scala:204)
19/07/31 13:37:57 INFO DAGScheduler: Got job 25 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:37:57 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:204)
19/07/31 13:37:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
19/07/31 13:37:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
19/07/31 13:37:57 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[132] at collect at utils.scala:204), which has no missing parents
19/07/31 13:37:57 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 72.5 KB, free 911.7 MB)
19/07/31 13:37:57 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 31.1 KB, free 911.7 MB)
19/07/31 13:37:57 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:62226 (size: 31.1 KB, free: 912.1 MB)
19/07/31 13:37:57 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
19/07/31 13:37:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[132] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:37:57 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
19/07/31 13:37:57 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:37:57 INFO Executor: Running task 0.0 in stage 33.0 (TID 33)
19/07/31 13:37:57 INFO BlockManager: Found block rdd_106_0 locally
19/07/31 13:37:57 INFO Executor: Finished task 0.0 in stage 33.0 (TID 33). 1625 bytes result sent to driver
19/07/31 13:37:57 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 33) in 33 ms on localhost (executor driver) (1/1)
19/07/31 13:37:57 INFO DAGScheduler: ShuffleMapStage 33 (collect at utils.scala:204) finished in 0.034 s
19/07/31 13:37:57 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:37:57 INFO DAGScheduler: running: Set()
19/07/31 13:37:57 INFO DAGScheduler: waiting: Set(ResultStage 34)
19/07/31 13:37:57 INFO DAGScheduler: failed: Set()
19/07/31 13:37:57 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[135] at collect at utils.scala:204), which has no missing parents
19/07/31 13:37:57 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
19/07/31 13:37:57 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 15.3 KB, free 911.6 MB)
19/07/31 13:37:57 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 7.4 KB, free 911.6 MB)
19/07/31 13:37:57 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:62226 (size: 7.4 KB, free: 912.1 MB)
19/07/31 13:37:57 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1006
19/07/31 13:37:57 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 34 (MapPartitionsRDD[135] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:37:57 INFO TaskSchedulerImpl: Adding task set 34.0 with 4 tasks
19/07/31 13:37:57 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 34, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:37:57 INFO TaskSetManager: Starting task 1.0 in stage 34.0 (TID 35, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:37:57 INFO TaskSetManager: Starting task 2.0 in stage 34.0 (TID 36, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:37:57 INFO TaskSetManager: Starting task 3.0 in stage 34.0 (TID 37, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:37:57 INFO Executor: Running task 0.0 in stage 34.0 (TID 34)
19/07/31 13:37:57 INFO Executor: Running task 1.0 in stage 34.0 (TID 35)
19/07/31 13:37:57 INFO Executor: Running task 3.0 in stage 34.0 (TID 37)
19/07/31 13:37:57 INFO Executor: Running task 2.0 in stage 34.0 (TID 36)
19/07/31 13:37:57 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:37:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:37:57 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:37:57 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:37:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:37:57 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:37:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:37:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:37:57 INFO CodeGenerator: Code generated in 10.561937 ms
19/07/31 13:37:57 INFO Executor: Finished task 1.0 in stage 34.0 (TID 35). 10962 bytes result sent to driver
19/07/31 13:37:57 INFO Executor: Finished task 3.0 in stage 34.0 (TID 37). 12200 bytes result sent to driver
19/07/31 13:37:57 INFO Executor: Finished task 2.0 in stage 34.0 (TID 36). 11008 bytes result sent to driver
19/07/31 13:37:57 INFO TaskSetManager: Finished task 1.0 in stage 34.0 (TID 35) in 133 ms on localhost (executor driver) (1/4)
19/07/31 13:37:57 INFO TaskSetManager: Finished task 2.0 in stage 34.0 (TID 36) in 129 ms on localhost (executor driver) (2/4)
19/07/31 13:37:57 INFO TaskSetManager: Finished task 3.0 in stage 34.0 (TID 37) in 128 ms on localhost (executor driver) (3/4)
19/07/31 13:37:57 INFO Executor: Finished task 0.0 in stage 34.0 (TID 34). 10723 bytes result sent to driver
19/07/31 13:37:57 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 34) in 140 ms on localhost (executor driver) (4/4)
19/07/31 13:37:57 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
19/07/31 13:37:57 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:204) finished in 0.141 s
19/07/31 13:37:57 INFO DAGScheduler: Job 25 finished: collect at utils.scala:204, took 0.241273 s
19/07/31 13:38:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_041`) `dbplyr_042`
ORDER BY `date`) `dbplyr_043`) `dbplyr_044`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 13:38:02 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:38:02 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:38:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_045`) `dbplyr_046`
ORDER BY `date`) `dbplyr_047`) `dbplyr_048`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 13:38:02 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:38:02 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:38:02 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#1367) generates partition filter: ((cust_prospect_ind.count#2119 - cust_prospect_ind.nullCount#2118) > 0)
19/07/31 13:38:02 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#1368) generates partition filter: ((visit_device_type.count#2124 - visit_device_type.nullCount#2123) > 0)
19/07/31 13:38:02 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#1367 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#2117 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#2116))
19/07/31 13:38:02 INFO InMemoryTableScanExec: Predicate (visit_device_type#1368 = All Devices) generates partition filter: ((visit_device_type.lowerBound#2122 <= All Devices) && (All Devices <= visit_device_type.upperBound#2121))
19/07/31 13:38:02 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:38:02 INFO DAGScheduler: Got job 26 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:38:02 INFO DAGScheduler: Final stage: ResultStage 35 (collect at utils.scala:204)
19/07/31 13:38:02 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:38:02 INFO DAGScheduler: Missing parents: List()
19/07/31 13:38:02 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[140] at collect at utils.scala:204), which has no missing parents
19/07/31 13:38:02 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 72.1 KB, free 911.6 MB)
19/07/31 13:38:02 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 30.5 KB, free 911.5 MB)
19/07/31 13:38:02 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:62226 (size: 30.5 KB, free: 912.1 MB)
19/07/31 13:38:02 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
19/07/31 13:38:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[140] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:38:02 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
19/07/31 13:38:02 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:38:02 INFO Executor: Running task 0.0 in stage 35.0 (TID 38)
19/07/31 13:38:02 INFO BlockManager: Found block rdd_106_0 locally
19/07/31 13:38:02 INFO Executor: Finished task 0.0 in stage 35.0 (TID 38). 7542 bytes result sent to driver
19/07/31 13:38:02 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 38) in 12 ms on localhost (executor driver) (1/1)
19/07/31 13:38:02 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
19/07/31 13:38:02 INFO DAGScheduler: ResultStage 35 (collect at utils.scala:204) finished in 0.014 s
19/07/31 13:38:02 INFO DAGScheduler: Job 26 finished: collect at utils.scala:204, took 0.035079 s
19/07/31 13:38:02 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:38:02 INFO DAGScheduler: Registering RDD 141 (collect at utils.scala:204)
19/07/31 13:38:02 INFO DAGScheduler: Got job 27 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:38:02 INFO DAGScheduler: Final stage: ResultStage 37 (collect at utils.scala:204)
19/07/31 13:38:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)
19/07/31 13:38:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 36)
19/07/31 13:38:02 INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[141] at collect at utils.scala:204), which has no missing parents
19/07/31 13:38:02 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 74.5 KB, free 911.5 MB)
19/07/31 13:38:02 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.4 MB)
19/07/31 13:38:02 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:62226 (size: 31.8 KB, free: 912.1 MB)
19/07/31 13:38:02 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1006
19/07/31 13:38:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[141] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:38:02 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
19/07/31 13:38:02 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:38:02 INFO Executor: Running task 0.0 in stage 36.0 (TID 39)
19/07/31 13:38:02 INFO BlockManager: Found block rdd_106_0 locally
19/07/31 13:38:02 INFO Executor: Finished task 0.0 in stage 36.0 (TID 39). 1687 bytes result sent to driver
19/07/31 13:38:02 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 39) in 30 ms on localhost (executor driver) (1/1)
19/07/31 13:38:02 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
19/07/31 13:38:02 INFO DAGScheduler: ShuffleMapStage 36 (collect at utils.scala:204) finished in 0.031 s
19/07/31 13:38:02 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:38:02 INFO DAGScheduler: running: Set()
19/07/31 13:38:02 INFO DAGScheduler: waiting: Set(ResultStage 37)
19/07/31 13:38:02 INFO DAGScheduler: failed: Set()
19/07/31 13:38:02 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[144] at collect at utils.scala:204), which has no missing parents
19/07/31 13:38:02 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 16.8 KB, free 911.4 MB)
19/07/31 13:38:02 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 8.1 KB, free 911.4 MB)
19/07/31 13:38:02 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:62226 (size: 8.1 KB, free: 912.1 MB)
19/07/31 13:38:02 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
19/07/31 13:38:02 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 37 (MapPartitionsRDD[144] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:38:02 INFO TaskSchedulerImpl: Adding task set 37.0 with 4 tasks
19/07/31 13:38:02 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 40, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:38:02 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 41, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:38:02 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 42, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:38:02 INFO TaskSetManager: Starting task 3.0 in stage 37.0 (TID 43, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:38:02 INFO Executor: Running task 0.0 in stage 37.0 (TID 40)
19/07/31 13:38:02 INFO Executor: Running task 1.0 in stage 37.0 (TID 41)
19/07/31 13:38:02 INFO Executor: Running task 2.0 in stage 37.0 (TID 42)
19/07/31 13:38:02 INFO Executor: Running task 3.0 in stage 37.0 (TID 43)
19/07/31 13:38:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:38:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:38:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:38:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:38:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:38:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:38:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:38:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:38:02 INFO Executor: Finished task 3.0 in stage 37.0 (TID 43). 2362 bytes result sent to driver
19/07/31 13:38:02 INFO Executor: Finished task 2.0 in stage 37.0 (TID 42). 2390 bytes result sent to driver
19/07/31 13:38:02 INFO Executor: Finished task 0.0 in stage 37.0 (TID 40). 2382 bytes result sent to driver
19/07/31 13:38:02 INFO Executor: Finished task 1.0 in stage 37.0 (TID 41). 2403 bytes result sent to driver
19/07/31 13:38:02 INFO TaskSetManager: Finished task 3.0 in stage 37.0 (TID 43) in 11 ms on localhost (executor driver) (1/4)
19/07/31 13:38:02 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 42) in 12 ms on localhost (executor driver) (2/4)
19/07/31 13:38:02 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 41) in 13 ms on localhost (executor driver) (3/4)
19/07/31 13:38:02 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 40) in 13 ms on localhost (executor driver) (4/4)
19/07/31 13:38:02 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
19/07/31 13:38:02 INFO DAGScheduler: ResultStage 37 (collect at utils.scala:204) finished in 0.014 s
19/07/31 13:38:02 INFO DAGScheduler: Job 27 finished: collect at utils.scala:204, took 0.165639 s
19/07/31 13:47:34 INFO SparkContext: Invoking stop() from shutdown hook
19/07/31 13:47:34 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
19/07/31 13:47:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/07/31 13:47:34 INFO MemoryStore: MemoryStore cleared
19/07/31 13:47:34 INFO BlockManager: BlockManager stopped
19/07/31 13:47:34 INFO BlockManagerMaster: BlockManagerMaster stopped
19/07/31 13:47:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/07/31 13:47:34 INFO SparkContext: Successfully stopped SparkContext
19/07/31 13:47:34 INFO ShutdownHookManager: Shutdown hook called
19/07/31 13:47:34 INFO ShutdownHookManager: Deleting directory /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-481bfba8-fe75-4033-9e32-7667ff6e4e17
19/07/31 13:52:09 INFO SparkContext: Running Spark version 2.2.0
19/07/31 13:52:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/07/31 13:52:09 INFO SparkContext: Submitted application: sparklyr
19/07/31 13:52:09 INFO SecurityManager: Changing view acls to: 6jncnk4f
19/07/31 13:52:09 INFO SecurityManager: Changing modify acls to: 6jncnk4f
19/07/31 13:52:09 INFO SecurityManager: Changing view acls groups to: 
19/07/31 13:52:09 INFO SecurityManager: Changing modify acls groups to: 
19/07/31 13:52:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(6jncnk4f); groups with view permissions: Set(); users  with modify permissions: Set(6jncnk4f); groups with modify permissions: Set()
19/07/31 13:52:10 INFO Utils: Successfully started service 'sparkDriver' on port 64019.
19/07/31 13:52:10 INFO SparkEnv: Registering MapOutputTracker
19/07/31 13:52:10 INFO SparkEnv: Registering BlockManagerMaster
19/07/31 13:52:10 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/07/31 13:52:10 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/07/31 13:52:10 INFO DiskBlockManager: Created local directory at /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/blockmgr-bd243577-299e-483f-ad05-579bec48fc18
19/07/31 13:52:10 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/07/31 13:52:10 INFO SparkEnv: Registering OutputCommitCoordinator
19/07/31 13:52:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/07/31 13:52:10 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
19/07/31 13:52:10 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:64019/jars/sparklyr-2.0-2.11.jar with timestamp 1564595530416
19/07/31 13:52:10 INFO Executor: Starting executor ID driver on host localhost
19/07/31 13:52:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64020.
19/07/31 13:52:10 INFO NettyBlockTransferService: Server created on 127.0.0.1:64020
19/07/31 13:52:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/07/31 13:52:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64020, None)
19/07/31 13:52:10 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:64020 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 64020, None)
19/07/31 13:52:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 64020, None)
19/07/31 13:52:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 64020, None)
19/07/31 13:52:10 INFO SharedState: loading hive config file: file:/Users/6jncnk4f/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/07/31 13:52:10 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse').
19/07/31 13:52:10 INFO SharedState: Warehouse path is 'file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse'.
19/07/31 13:52:11 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/07/31 13:52:12 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/07/31 13:52:12 INFO ObjectStore: ObjectStore, initialize called
19/07/31 13:52:12 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/07/31 13:52:12 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/07/31 13:52:13 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/07/31 13:52:14 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:52:14 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:52:14 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:52:14 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:52:14 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/07/31 13:52:14 INFO ObjectStore: Initialized ObjectStore
19/07/31 13:52:15 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/07/31 13:52:15 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/07/31 13:52:15 INFO HiveMetaStore: Added admin role in metastore
19/07/31 13:52:15 INFO HiveMetaStore: Added public role in metastore
19/07/31 13:52:15 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/07/31 13:52:15 INFO HiveMetaStore: 0: get_all_databases
19/07/31 13:52:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_all_databases	
19/07/31 13:52:15 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/07/31 13:52:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/07/31 13:52:15 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:52:15 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/b6bb4535-20a0-4413-9b70-f2a21383e1e1_resources
19/07/31 13:52:15 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/b6bb4535-20a0-4413-9b70-f2a21383e1e1
19/07/31 13:52:15 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/b6bb4535-20a0-4413-9b70-f2a21383e1e1
19/07/31 13:52:15 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/b6bb4535-20a0-4413-9b70-f2a21383e1e1/_tmp_space.db
19/07/31 13:52:15 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 13:52:15 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:52:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:52:15 INFO HiveMetaStore: 0: get_database: global_temp
19/07/31 13:52:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/07/31 13:52:15 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/07/31 13:52:15 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/4df0448b-a4f0-4196-906a-4bbfdf473ecd_resources
19/07/31 13:52:15 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/4df0448b-a4f0-4196-906a-4bbfdf473ecd
19/07/31 13:52:15 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/4df0448b-a4f0-4196-906a-4bbfdf473ecd
19/07/31 13:52:15 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/4df0448b-a4f0-4196-906a-4bbfdf473ecd/_tmp_space.db
19/07/31 13:52:15 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 13:52:16 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/07/31 13:52:16 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:52:17 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:52:17 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:52:17 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:52:17 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:52:17 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:52:17 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:52:18 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:52:18 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:52:18 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:52:18 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:52:18 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:52:18 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:52:18 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:52:19 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 13:52:19 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/07/31 13:52:19 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/07/31 13:52:19 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:52:19 INFO DAGScheduler: Missing parents: List()
19/07/31 13:52:19 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/07/31 13:52:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/07/31 13:52:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/07/31 13:52:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:64020 (size: 3.4 KB, free: 912.3 MB)
19/07/31 13:52:19 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/07/31 13:52:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 13:52:19 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/07/31 13:52:19 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/07/31 13:52:19 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/07/31 13:52:19 INFO Executor: Fetching spark://127.0.0.1:64019/jars/sparklyr-2.0-2.11.jar with timestamp 1564595530416
19/07/31 13:52:19 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:64019 after 15 ms (0 ms spent in bootstraps)
19/07/31 13:52:19 INFO Utils: Fetching spark://127.0.0.1:64019/jars/sparklyr-2.0-2.11.jar to /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-a9144c51-1b1d-460c-9e1f-d78f788b2422/userFiles-978f944b-aa18-4188-abde-ab98fe64349b/fetchFileTemp6487723979018596040.tmp
19/07/31 13:52:19 INFO Executor: Adding file:/private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-a9144c51-1b1d-460c-9e1f-d78f788b2422/userFiles-978f944b-aa18-4188-abde-ab98fe64349b/sparklyr-2.0-2.11.jar to class loader
19/07/31 13:52:20 INFO CodeGenerator: Code generated in 285.085579 ms
19/07/31 13:52:20 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
19/07/31 13:52:20 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 555 ms on localhost (executor driver) (1/1)
19/07/31 13:52:20 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/07/31 13:52:20 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.570 s
19/07/31 13:52:20 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0.708191 s
19/07/31 13:52:20 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:52:20 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#17)) > 0)
19/07/31 13:52:20 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 13:52:20 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:52:20 INFO CodeGenerator: Code generated in 15.457032 ms
19/07/31 13:52:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 281.2 KB, free 912.0 MB)
19/07/31 13:52:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.8 KB, free 912.0 MB)
19/07/31 13:52:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:64020 (size: 23.8 KB, free: 912.3 MB)
19/07/31 13:52:20 INFO SparkContext: Created broadcast 1 from csv at NativeMethodAccessorImpl.java:0
19/07/31 13:52:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:52:20 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:52:20 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:52:20 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:52:20 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:52:20 INFO DAGScheduler: Missing parents: List()
19/07/31 13:52:20 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:52:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 912.0 MB)
19/07/31 13:52:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 912.0 MB)
19/07/31 13:52:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:64020 (size: 4.3 KB, free: 912.3 MB)
19/07/31 13:52:20 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/07/31 13:52:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:52:20 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/07/31 13:52:20 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:52:20 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/07/31 13:52:20 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:52:20 INFO CodeGenerator: Code generated in 14.121853 ms
19/07/31 13:52:21 INFO ContextCleaner: Cleaned accumulator 0
19/07/31 13:52:21 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:64020 in memory (size: 3.4 KB, free: 912.3 MB)
19/07/31 13:52:21 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1437 bytes result sent to driver
19/07/31 13:52:21 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 344 ms on localhost (executor driver) (1/1)
19/07/31 13:52:21 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/07/31 13:52:21 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0.345 s
19/07/31 13:52:21 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0.366788 s
19/07/31 13:52:21 INFO CodeGenerator: Code generated in 9.278723 ms
19/07/31 13:52:21 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:52:21 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 13:52:21 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 13:52:21 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:52:21 INFO CodeGenerator: Code generated in 13.896267 ms
19/07/31 13:52:21 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 281.2 KB, free 911.7 MB)
19/07/31 13:52:21 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.7 MB)
19/07/31 13:52:21 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:64020 (size: 23.8 KB, free: 912.2 MB)
19/07/31 13:52:21 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:0
19/07/31 13:52:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:52:21 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:52:21 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:52:21 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:52:21 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:52:21 INFO DAGScheduler: Missing parents: List()
19/07/31 13:52:21 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:52:21 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.8 KB, free 911.7 MB)
19/07/31 13:52:21 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.7 MB)
19/07/31 13:52:21 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:64020 (size: 8.6 KB, free: 912.2 MB)
19/07/31 13:52:21 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/07/31 13:52:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:52:21 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/07/31 13:52:21 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:52:21 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/07/31 13:52:21 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:52:21 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1627 bytes result sent to driver
19/07/31 13:52:21 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 101 ms on localhost (executor driver) (1/1)
19/07/31 13:52:21 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/07/31 13:52:21 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.104 s
19/07/31 13:52:21 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.112291 s
19/07/31 13:52:21 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:52:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:52:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:52:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:52:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:52:21 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:52:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:52:21 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 13:52:21 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 13:52:21 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 13:52:21 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:52:21 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 13:52:21 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 13:52:21 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:52:21 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 282.3 KB, free 911.4 MB)
19/07/31 13:52:21 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.4 MB)
19/07/31 13:52:21 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:64020 (size: 24.0 KB, free: 912.2 MB)
19/07/31 13:52:21 INFO SparkContext: Created broadcast 5 from sql at NativeMethodAccessorImpl.java:0
19/07/31 13:52:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:52:21 INFO CodeGenerator: Code generated in 8.035573 ms
19/07/31 13:52:21 INFO CodeGenerator: Code generated in 10.220244 ms
19/07/31 13:52:21 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 13:52:21 INFO DAGScheduler: Registering RDD 18 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 13:52:21 INFO DAGScheduler: Got job 3 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:52:21 INFO DAGScheduler: Final stage: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 13:52:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/07/31 13:52:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/07/31 13:52:21 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:52:21 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 26.3 KB, free 911.3 MB)
19/07/31 13:52:21 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.8 KB, free 911.3 MB)
19/07/31 13:52:21 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:64020 (size: 11.8 KB, free: 912.2 MB)
19/07/31 13:52:21 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/07/31 13:52:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:52:21 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/07/31 13:52:21 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:52:21 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/07/31 13:52:21 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:52:21 INFO CodeGenerator: Code generated in 15.476684 ms
19/07/31 13:52:22 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 48.9 KB, free 911.3 MB)
19/07/31 13:52:22 INFO BlockManagerInfo: Added rdd_15_0 in memory on 127.0.0.1:64020 (size: 48.9 KB, free: 912.2 MB)
19/07/31 13:52:22 INFO CodeGenerator: Code generated in 3.810617 ms
19/07/31 13:52:22 INFO CodeGenerator: Code generated in 16.498234 ms
19/07/31 13:52:22 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2504 bytes result sent to driver
19/07/31 13:52:22 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 205 ms on localhost (executor driver) (1/1)
19/07/31 13:52:22 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/07/31 13:52:22 INFO DAGScheduler: ShuffleMapStage 3 (sql at NativeMethodAccessorImpl.java:0) finished in 0.206 s
19/07/31 13:52:22 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:52:22 INFO DAGScheduler: running: Set()
19/07/31 13:52:22 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/07/31 13:52:22 INFO DAGScheduler: failed: Set()
19/07/31 13:52:22 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:52:22 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 911.3 MB)
19/07/31 13:52:22 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.3 MB)
19/07/31 13:52:22 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:64020 (size: 3.7 KB, free: 912.2 MB)
19/07/31 13:52:22 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/07/31 13:52:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:52:22 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/07/31 13:52:22 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:52:22 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/07/31 13:52:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:52:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
19/07/31 13:52:22 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1581 bytes result sent to driver
19/07/31 13:52:22 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 61 ms on localhost (executor driver) (1/1)
19/07/31 13:52:22 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/07/31 13:52:22 INFO DAGScheduler: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0) finished in 0.062 s
19/07/31 13:52:22 INFO DAGScheduler: Job 3 finished: sql at NativeMethodAccessorImpl.java:0, took 0.339371 s
19/07/31 13:52:22 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 13:52:22 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:52:22 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:52:22 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:52:22 INFO DAGScheduler: Registering RDD 24 (collect at utils.scala:204)
19/07/31 13:52:22 INFO DAGScheduler: Got job 4 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:52:22 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
19/07/31 13:52:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/07/31 13:52:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/07/31 13:52:22 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204), which has no missing parents
19/07/31 13:52:22 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 26.3 KB, free 911.2 MB)
19/07/31 13:52:22 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.9 KB, free 911.2 MB)
19/07/31 13:52:22 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:64020 (size: 11.9 KB, free: 912.1 MB)
19/07/31 13:52:22 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/07/31 13:52:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:52:22 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/07/31 13:52:22 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:52:22 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/07/31 13:52:22 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:52:22 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1780 bytes result sent to driver
19/07/31 13:52:22 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 12 ms on localhost (executor driver) (1/1)
19/07/31 13:52:22 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/07/31 13:52:22 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:204) finished in 0.013 s
19/07/31 13:52:22 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:52:22 INFO DAGScheduler: running: Set()
19/07/31 13:52:22 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/07/31 13:52:22 INFO DAGScheduler: failed: Set()
19/07/31 13:52:22 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204), which has no missing parents
19/07/31 13:52:22 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 911.2 MB)
19/07/31 13:52:22 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.2 MB)
19/07/31 13:52:22 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:64020 (size: 3.7 KB, free: 912.1 MB)
19/07/31 13:52:22 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/07/31 13:52:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:52:22 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/07/31 13:52:22 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:52:22 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/07/31 13:52:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:52:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:52:22 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1581 bytes result sent to driver
19/07/31 13:52:22 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 4 ms on localhost (executor driver) (1/1)
19/07/31 13:52:22 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/07/31 13:52:22 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.004 s
19/07/31 13:52:22 INFO DAGScheduler: Job 4 finished: collect at utils.scala:204, took 0.036258 s
19/07/31 13:52:22 INFO CodeGenerator: Code generated in 7.044558 ms
19/07/31 13:52:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz1`
WHERE (0 = 1)
19/07/31 13:52:22 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:52:22 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:52:22 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:52:22 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:52:22 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:52:22 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:52:22 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:52:22 INFO CodeGenerator: Code generated in 5.886064 ms
19/07/31 13:52:22 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 13:52:22 INFO DAGScheduler: Got job 5 (collect at utils.scala:44) with 1 output partitions
19/07/31 13:52:22 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:44)
19/07/31 13:52:22 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:52:22 INFO DAGScheduler: Missing parents: List()
19/07/31 13:52:22 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[32] at map at utils.scala:41), which has no missing parents
19/07/31 13:52:22 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 6.3 KB, free 911.2 MB)
19/07/31 13:52:22 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.5 KB, free 911.2 MB)
19/07/31 13:52:22 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:64020 (size: 3.5 KB, free: 912.1 MB)
19/07/31 13:52:22 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/07/31 13:52:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 13:52:22 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/07/31 13:52:22 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 13:52:22 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
19/07/31 13:52:22 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1007 bytes result sent to driver
19/07/31 13:52:22 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 4 ms on localhost (executor driver) (1/1)
19/07/31 13:52:22 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/07/31 13:52:22 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:44) finished in 0.005 s
19/07/31 13:52:22 INFO DAGScheduler: Job 5 finished: collect at utils.scala:44, took 0.010346 s
19/07/31 13:52:22 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 13:52:22 INFO MapPartitionsRDD: Removing RDD 15 from persistence list
19/07/31 13:52:22 INFO BlockManager: Removing RDD 15
19/07/31 13:52:22 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:52:22 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#389)) > 0)
19/07/31 13:52:22 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 13:52:22 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:52:22 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 281.2 KB, free 911.0 MB)
19/07/31 13:52:22 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.0 MB)
19/07/31 13:52:22 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:64020 (size: 23.8 KB, free: 912.2 MB)
19/07/31 13:52:22 INFO SparkContext: Created broadcast 11 from csv at NativeMethodAccessorImpl.java:0
19/07/31 13:52:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:52:22 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:52:22 INFO DAGScheduler: Got job 6 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:52:22 INFO DAGScheduler: Final stage: ResultStage 8 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:52:22 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:52:22 INFO DAGScheduler: Missing parents: List()
19/07/31 13:52:22 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[35] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:52:22 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.2 KB, free 911.0 MB)
19/07/31 13:52:22 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.3 KB, free 911.0 MB)
19/07/31 13:52:22 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:64020 (size: 4.3 KB, free: 912.2 MB)
19/07/31 13:52:22 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/07/31 13:52:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[35] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:52:22 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/07/31 13:52:22 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:52:22 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
19/07/31 13:52:22 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:52:22 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1394 bytes result sent to driver
19/07/31 13:52:22 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 5 ms on localhost (executor driver) (1/1)
19/07/31 13:52:22 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/07/31 13:52:22 INFO DAGScheduler: ResultStage 8 (csv at NativeMethodAccessorImpl.java:0) finished in 0.006 s
19/07/31 13:52:22 INFO DAGScheduler: Job 6 finished: csv at NativeMethodAccessorImpl.java:0, took 0.011253 s
19/07/31 13:52:22 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:52:22 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 13:52:22 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 13:52:22 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:52:22 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 281.2 KB, free 910.7 MB)
19/07/31 13:52:22 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 23.8 KB, free 910.7 MB)
19/07/31 13:52:22 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:64020 (size: 23.8 KB, free: 912.1 MB)
19/07/31 13:52:22 INFO SparkContext: Created broadcast 13 from csv at NativeMethodAccessorImpl.java:0
19/07/31 13:52:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:52:22 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:52:22 INFO DAGScheduler: Got job 7 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:52:22 INFO DAGScheduler: Final stage: ResultStage 9 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:52:22 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:52:22 INFO DAGScheduler: Missing parents: List()
19/07/31 13:52:22 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[40] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:52:22 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 14.8 KB, free 910.6 MB)
19/07/31 13:52:22 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 8.6 KB, free 910.6 MB)
19/07/31 13:52:22 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:64020 (size: 8.6 KB, free: 912.1 MB)
19/07/31 13:52:22 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/07/31 13:52:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[40] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:52:22 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/07/31 13:52:22 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:52:22 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
19/07/31 13:52:22 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:52:22 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1627 bytes result sent to driver
19/07/31 13:52:22 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 19 ms on localhost (executor driver) (1/1)
19/07/31 13:52:22 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/07/31 13:52:22 INFO DAGScheduler: ResultStage 9 (csv at NativeMethodAccessorImpl.java:0) finished in 0.020 s
19/07/31 13:52:22 INFO DAGScheduler: Job 7 finished: csv at NativeMethodAccessorImpl.java:0, took 0.025212 s
19/07/31 13:52:22 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:52:22 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:52:22 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:52:22 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:52:22 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:52:22 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:52:22 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:52:23 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 13:52:23 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 13:52:23 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 13:52:23 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:52:23 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 13:52:23 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 13:52:23 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:52:23 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 282.3 KB, free 910.4 MB)
19/07/31 13:52:23 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 24.0 KB, free 910.3 MB)
19/07/31 13:52:23 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:64020 (size: 24.0 KB, free: 912.1 MB)
19/07/31 13:52:23 INFO SparkContext: Created broadcast 15 from sql at NativeMethodAccessorImpl.java:0
19/07/31 13:52:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:52:23 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 13:52:23 INFO DAGScheduler: Registering RDD 46 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 13:52:23 INFO DAGScheduler: Got job 8 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:52:23 INFO DAGScheduler: Final stage: ResultStage 11 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 13:52:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
19/07/31 13:52:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
19/07/31 13:52:23 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[46] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:52:23 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 26.3 KB, free 910.3 MB)
19/07/31 13:52:23 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 11.9 KB, free 910.3 MB)
19/07/31 13:52:23 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:64020 (size: 11.9 KB, free: 912.1 MB)
19/07/31 13:52:23 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/07/31 13:52:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[46] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:52:23 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/07/31 13:52:23 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:52:23 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
19/07/31 13:52:23 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:52:23 INFO MemoryStore: Block rdd_43_0 stored as values in memory (estimated size 48.9 KB, free 910.3 MB)
19/07/31 13:52:23 INFO BlockManagerInfo: Added rdd_43_0 in memory on 127.0.0.1:64020 (size: 48.9 KB, free: 912.0 MB)
19/07/31 13:52:23 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2461 bytes result sent to driver
19/07/31 13:52:23 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 48 ms on localhost (executor driver) (1/1)
19/07/31 13:52:23 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/07/31 13:52:23 INFO DAGScheduler: ShuffleMapStage 10 (sql at NativeMethodAccessorImpl.java:0) finished in 0.049 s
19/07/31 13:52:23 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:52:23 INFO DAGScheduler: running: Set()
19/07/31 13:52:23 INFO DAGScheduler: waiting: Set(ResultStage 11)
19/07/31 13:52:23 INFO DAGScheduler: failed: Set()
19/07/31 13:52:23 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[49] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:52:23 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 910.2 MB)
19/07/31 13:52:23 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.2 MB)
19/07/31 13:52:23 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:64020 (size: 3.7 KB, free: 912.0 MB)
19/07/31 13:52:23 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/07/31 13:52:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[49] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:52:23 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/07/31 13:52:23 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:52:23 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
19/07/31 13:52:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:52:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:52:23 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1581 bytes result sent to driver
19/07/31 13:52:23 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 4 ms on localhost (executor driver) (1/1)
19/07/31 13:52:23 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/07/31 13:52:23 INFO DAGScheduler: ResultStage 11 (sql at NativeMethodAccessorImpl.java:0) finished in 0.005 s
19/07/31 13:52:23 INFO DAGScheduler: Job 8 finished: sql at NativeMethodAccessorImpl.java:0, took 0.066935 s
19/07/31 13:52:23 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 13:52:23 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:52:23 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:52:23 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:52:23 INFO DAGScheduler: Registering RDD 52 (collect at utils.scala:204)
19/07/31 13:52:23 INFO DAGScheduler: Got job 9 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:52:23 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:204)
19/07/31 13:52:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
19/07/31 13:52:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
19/07/31 13:52:23 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[52] at collect at utils.scala:204), which has no missing parents
19/07/31 13:52:23 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 26.3 KB, free 910.2 MB)
19/07/31 13:52:23 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 11.8 KB, free 910.2 MB)
19/07/31 13:52:23 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:64020 (size: 11.8 KB, free: 912.0 MB)
19/07/31 13:52:23 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
19/07/31 13:52:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[52] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:52:23 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/07/31 13:52:23 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:52:23 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
19/07/31 13:52:23 INFO BlockManager: Found block rdd_43_0 locally
19/07/31 13:52:23 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1780 bytes result sent to driver
19/07/31 13:52:23 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 7 ms on localhost (executor driver) (1/1)
19/07/31 13:52:23 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/07/31 13:52:23 INFO DAGScheduler: ShuffleMapStage 12 (collect at utils.scala:204) finished in 0.007 s
19/07/31 13:52:23 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:52:23 INFO DAGScheduler: running: Set()
19/07/31 13:52:23 INFO DAGScheduler: waiting: Set(ResultStage 13)
19/07/31 13:52:23 INFO DAGScheduler: failed: Set()
19/07/31 13:52:23 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[55] at collect at utils.scala:204), which has no missing parents
19/07/31 13:52:23 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 7.0 KB, free 910.2 MB)
19/07/31 13:52:23 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.2 MB)
19/07/31 13:52:23 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:64020 (size: 3.7 KB, free: 912.0 MB)
19/07/31 13:52:23 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/07/31 13:52:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[55] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:52:23 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/07/31 13:52:23 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:52:23 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
19/07/31 13:52:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:52:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:52:23 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1581 bytes result sent to driver
19/07/31 13:52:23 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 4 ms on localhost (executor driver) (1/1)
19/07/31 13:52:23 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/07/31 13:52:23 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:204) finished in 0.006 s
19/07/31 13:52:23 INFO DAGScheduler: Job 9 finished: collect at utils.scala:204, took 0.024947 s
19/07/31 13:52:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz2`
WHERE (0 = 1)
19/07/31 13:52:23 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:52:23 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:52:23 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:52:23 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:52:23 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:52:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:52:23 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:52:23 INFO CodeGenerator: Code generated in 7.540179 ms
19/07/31 13:52:23 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:52:23 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:52:23 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:52:23 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:52:23 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:52:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:52:23 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:52:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_001`) `dbplyr_002`
ORDER BY `date`) `dbplyr_003`) `dbplyr_004`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 13:52:50 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:52:50 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:52:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_005`) `dbplyr_006`
ORDER BY `date`) `dbplyr_007`) `dbplyr_008`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 13:52:51 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:52:51 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:52:51 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#412) generates partition filter: ((cust_prospect_ind.count#835 - cust_prospect_ind.nullCount#834) > 0)
19/07/31 13:52:51 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#413) generates partition filter: ((visit_device_type.count#840 - visit_device_type.nullCount#839) > 0)
19/07/31 13:52:51 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#412 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#833 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#832))
19/07/31 13:52:51 INFO InMemoryTableScanExec: Predicate (visit_device_type#413 = All Devices) generates partition filter: ((visit_device_type.lowerBound#838 <= All Devices) && (All Devices <= visit_device_type.upperBound#837))
19/07/31 13:52:51 INFO CodeGenerator: Code generated in 19.457733 ms
19/07/31 13:52:51 INFO CodeGenerator: Code generated in 20.478118 ms
19/07/31 13:52:51 INFO CodeGenerator: Code generated in 10.400631 ms
19/07/31 13:52:51 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:52:51 INFO DAGScheduler: Got job 10 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:52:51 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:204)
19/07/31 13:52:51 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:52:51 INFO DAGScheduler: Missing parents: List()
19/07/31 13:52:51 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[60] at collect at utils.scala:204), which has no missing parents
19/07/31 13:52:51 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 72.1 KB, free 910.1 MB)
19/07/31 13:52:51 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.1 MB)
19/07/31 13:52:51 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:64020 (size: 30.5 KB, free: 912.0 MB)
19/07/31 13:52:51 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
19/07/31 13:52:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[60] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:52:51 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/07/31 13:52:51 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:52:51 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
19/07/31 13:52:51 INFO BlockManager: Found block rdd_43_0 locally
19/07/31 13:52:51 INFO CodeGenerator: Code generated in 6.904646 ms
19/07/31 13:52:51 INFO CodeGenerator: Code generated in 11.914257 ms
19/07/31 13:52:51 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 7585 bytes result sent to driver
19/07/31 13:52:51 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 60 ms on localhost (executor driver) (1/1)
19/07/31 13:52:51 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/07/31 13:52:51 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:204) finished in 0.060 s
19/07/31 13:52:51 INFO DAGScheduler: Job 10 finished: collect at utils.scala:204, took 0.067940 s
19/07/31 13:52:51 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:52:51 INFO DAGScheduler: Registering RDD 61 (collect at utils.scala:204)
19/07/31 13:52:51 INFO DAGScheduler: Got job 11 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:52:51 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:204)
19/07/31 13:52:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
19/07/31 13:52:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
19/07/31 13:52:51 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[61] at collect at utils.scala:204), which has no missing parents
19/07/31 13:52:51 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 74.6 KB, free 910.0 MB)
19/07/31 13:52:51 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.0 MB)
19/07/31 13:52:51 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:64020 (size: 31.8 KB, free: 912.0 MB)
19/07/31 13:52:51 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
19/07/31 13:52:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[61] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:52:51 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
19/07/31 13:52:51 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:52:51 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
19/07/31 13:52:51 INFO BlockManager: Found block rdd_43_0 locally
19/07/31 13:52:51 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1730 bytes result sent to driver
19/07/31 13:52:51 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 26 ms on localhost (executor driver) (1/1)
19/07/31 13:52:51 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/07/31 13:52:51 INFO DAGScheduler: ShuffleMapStage 15 (collect at utils.scala:204) finished in 0.026 s
19/07/31 13:52:51 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:52:51 INFO DAGScheduler: running: Set()
19/07/31 13:52:51 INFO DAGScheduler: waiting: Set(ResultStage 16)
19/07/31 13:52:51 INFO DAGScheduler: failed: Set()
19/07/31 13:52:51 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[64] at collect at utils.scala:204), which has no missing parents
19/07/31 13:52:51 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 16.8 KB, free 910.0 MB)
19/07/31 13:52:51 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.0 MB)
19/07/31 13:52:51 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:64020 (size: 8.0 KB, free: 912.0 MB)
19/07/31 13:52:51 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
19/07/31 13:52:51 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 16 (MapPartitionsRDD[64] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:52:51 INFO TaskSchedulerImpl: Adding task set 16.0 with 4 tasks
19/07/31 13:52:51 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:52:51 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 17, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:52:51 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 18, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:52:51 INFO TaskSetManager: Starting task 3.0 in stage 16.0 (TID 19, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:52:51 INFO Executor: Running task 1.0 in stage 16.0 (TID 17)
19/07/31 13:52:51 INFO Executor: Running task 3.0 in stage 16.0 (TID 19)
19/07/31 13:52:51 INFO Executor: Running task 2.0 in stage 16.0 (TID 18)
19/07/31 13:52:51 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
19/07/31 13:52:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:52:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:52:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:52:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:52:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:52:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:52:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:52:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:52:51 INFO CodeGenerator: Code generated in 5.910834 ms
19/07/31 13:52:51 INFO Executor: Finished task 1.0 in stage 16.0 (TID 17). 2403 bytes result sent to driver
19/07/31 13:52:51 INFO Executor: Finished task 2.0 in stage 16.0 (TID 18). 2390 bytes result sent to driver
19/07/31 13:52:51 INFO Executor: Finished task 3.0 in stage 16.0 (TID 19). 2362 bytes result sent to driver
19/07/31 13:52:51 INFO TaskSetManager: Finished task 3.0 in stage 16.0 (TID 19) in 60 ms on localhost (executor driver) (1/4)
19/07/31 13:52:51 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 18) in 61 ms on localhost (executor driver) (2/4)
19/07/31 13:52:51 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 17) in 62 ms on localhost (executor driver) (3/4)
19/07/31 13:52:51 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 2382 bytes result sent to driver
19/07/31 13:52:51 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 69 ms on localhost (executor driver) (4/4)
19/07/31 13:52:51 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/07/31 13:52:51 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:204) finished in 0.069 s
19/07/31 13:52:51 INFO DAGScheduler: Job 11 finished: collect at utils.scala:204, took 0.118477 s
19/07/31 13:52:51 INFO CodeGenerator: Code generated in 16.835207 ms
19/07/31 13:54:19 INFO SparkContext: Invoking stop() from shutdown hook
19/07/31 13:54:19 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
19/07/31 13:54:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/07/31 13:54:19 INFO MemoryStore: MemoryStore cleared
19/07/31 13:54:19 INFO BlockManager: BlockManager stopped
19/07/31 13:54:19 INFO BlockManagerMaster: BlockManagerMaster stopped
19/07/31 13:54:19 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/07/31 13:54:19 INFO SparkContext: Successfully stopped SparkContext
19/07/31 13:54:19 INFO ShutdownHookManager: Shutdown hook called
19/07/31 13:54:19 INFO ShutdownHookManager: Deleting directory /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-a9144c51-1b1d-460c-9e1f-d78f788b2422
19/07/31 13:54:41 INFO SparkContext: Running Spark version 2.2.0
19/07/31 13:54:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/07/31 13:54:41 INFO SparkContext: Submitted application: sparklyr
19/07/31 13:54:41 INFO SecurityManager: Changing view acls to: 6jncnk4f
19/07/31 13:54:41 INFO SecurityManager: Changing modify acls to: 6jncnk4f
19/07/31 13:54:41 INFO SecurityManager: Changing view acls groups to: 
19/07/31 13:54:41 INFO SecurityManager: Changing modify acls groups to: 
19/07/31 13:54:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(6jncnk4f); groups with view permissions: Set(); users  with modify permissions: Set(6jncnk4f); groups with modify permissions: Set()
19/07/31 13:54:41 INFO Utils: Successfully started service 'sparkDriver' on port 64326.
19/07/31 13:54:41 INFO SparkEnv: Registering MapOutputTracker
19/07/31 13:54:41 INFO SparkEnv: Registering BlockManagerMaster
19/07/31 13:54:41 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/07/31 13:54:41 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/07/31 13:54:41 INFO DiskBlockManager: Created local directory at /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/blockmgr-44391077-3865-4019-b68e-f9439975f39d
19/07/31 13:54:41 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/07/31 13:54:41 INFO SparkEnv: Registering OutputCommitCoordinator
19/07/31 13:54:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/07/31 13:54:41 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
19/07/31 13:54:41 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:64326/jars/sparklyr-2.0-2.11.jar with timestamp 1564595681912
19/07/31 13:54:41 INFO Executor: Starting executor ID driver on host localhost
19/07/31 13:54:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64327.
19/07/31 13:54:41 INFO NettyBlockTransferService: Server created on 127.0.0.1:64327
19/07/31 13:54:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/07/31 13:54:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64327, None)
19/07/31 13:54:41 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:64327 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 64327, None)
19/07/31 13:54:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 64327, None)
19/07/31 13:54:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 64327, None)
19/07/31 13:54:42 INFO SharedState: loading hive config file: file:/Users/6jncnk4f/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/07/31 13:54:42 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse').
19/07/31 13:54:42 INFO SharedState: Warehouse path is 'file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse'.
19/07/31 13:54:42 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/07/31 13:54:43 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/07/31 13:54:43 INFO ObjectStore: ObjectStore, initialize called
19/07/31 13:54:43 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/07/31 13:54:43 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/07/31 13:54:44 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/07/31 13:54:45 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:54:45 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:54:45 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:54:45 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:54:45 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/07/31 13:54:45 INFO ObjectStore: Initialized ObjectStore
19/07/31 13:54:45 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/07/31 13:54:46 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/07/31 13:54:46 INFO HiveMetaStore: Added admin role in metastore
19/07/31 13:54:46 INFO HiveMetaStore: Added public role in metastore
19/07/31 13:54:46 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/07/31 13:54:46 INFO HiveMetaStore: 0: get_all_databases
19/07/31 13:54:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_all_databases	
19/07/31 13:54:46 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/07/31 13:54:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/07/31 13:54:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 13:54:46 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/820232a8-69d5-480b-9e1f-d74a75096487_resources
19/07/31 13:54:46 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/820232a8-69d5-480b-9e1f-d74a75096487
19/07/31 13:54:46 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/820232a8-69d5-480b-9e1f-d74a75096487
19/07/31 13:54:46 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/820232a8-69d5-480b-9e1f-d74a75096487/_tmp_space.db
19/07/31 13:54:46 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 13:54:46 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:46 INFO HiveMetaStore: 0: get_database: global_temp
19/07/31 13:54:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/07/31 13:54:46 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/07/31 13:54:46 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/24c57189-b169-46ac-b4ad-8f1a1e050111_resources
19/07/31 13:54:46 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/24c57189-b169-46ac-b4ad-8f1a1e050111
19/07/31 13:54:46 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/24c57189-b169-46ac-b4ad-8f1a1e050111
19/07/31 13:54:46 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/24c57189-b169-46ac-b4ad-8f1a1e050111/_tmp_space.db
19/07/31 13:54:46 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 13:54:46 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/07/31 13:54:46 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:54:48 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:48 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:48 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:48 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:54:48 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:54:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:54:48 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:48 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:48 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:48 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:54:48 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:54:49 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 13:54:49 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/07/31 13:54:49 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/07/31 13:54:49 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:54:49 INFO DAGScheduler: Missing parents: List()
19/07/31 13:54:49 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/07/31 13:54:49 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/07/31 13:54:49 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/07/31 13:54:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:64327 (size: 3.4 KB, free: 912.3 MB)
19/07/31 13:54:49 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/07/31 13:54:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 13:54:49 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/07/31 13:54:49 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/07/31 13:54:49 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/07/31 13:54:49 INFO Executor: Fetching spark://127.0.0.1:64326/jars/sparklyr-2.0-2.11.jar with timestamp 1564595681912
19/07/31 13:54:49 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:64326 after 11 ms (0 ms spent in bootstraps)
19/07/31 13:54:49 INFO Utils: Fetching spark://127.0.0.1:64326/jars/sparklyr-2.0-2.11.jar to /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-51b847a8-1855-42e9-a904-0b261a3633d8/userFiles-beb22700-c1e1-48e2-876c-09574fce603f/fetchFileTemp1987102284199443607.tmp
19/07/31 13:54:49 INFO Executor: Adding file:/private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-51b847a8-1855-42e9-a904-0b261a3633d8/userFiles-beb22700-c1e1-48e2-876c-09574fce603f/sparklyr-2.0-2.11.jar to class loader
19/07/31 13:54:50 INFO CodeGenerator: Code generated in 288.291788 ms
19/07/31 13:54:50 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
19/07/31 13:54:50 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 555 ms on localhost (executor driver) (1/1)
19/07/31 13:54:50 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/07/31 13:54:50 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.571 s
19/07/31 13:54:50 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0.710409 s
19/07/31 13:54:50 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:54:50 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#17)) > 0)
19/07/31 13:54:50 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 13:54:50 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:54:50 INFO CodeGenerator: Code generated in 17.844752 ms
19/07/31 13:54:50 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 281.2 KB, free 912.0 MB)
19/07/31 13:54:50 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.8 KB, free 912.0 MB)
19/07/31 13:54:50 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:64327 (size: 23.8 KB, free: 912.3 MB)
19/07/31 13:54:50 INFO SparkContext: Created broadcast 1 from csv at NativeMethodAccessorImpl.java:0
19/07/31 13:54:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:54:50 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:54:50 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:54:50 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:54:50 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:54:50 INFO DAGScheduler: Missing parents: List()
19/07/31 13:54:50 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:54:50 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 912.0 MB)
19/07/31 13:54:50 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 912.0 MB)
19/07/31 13:54:50 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:64327 (size: 4.3 KB, free: 912.3 MB)
19/07/31 13:54:50 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/07/31 13:54:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:54:50 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/07/31 13:54:50 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:54:50 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/07/31 13:54:50 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:54:50 INFO CodeGenerator: Code generated in 7.683747 ms
19/07/31 13:54:50 INFO ContextCleaner: Cleaned accumulator 0
19/07/31 13:54:50 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:64327 in memory (size: 3.4 KB, free: 912.3 MB)
19/07/31 13:54:50 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1480 bytes result sent to driver
19/07/31 13:54:50 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 203 ms on localhost (executor driver) (1/1)
19/07/31 13:54:50 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/07/31 13:54:50 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0.204 s
19/07/31 13:54:50 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0.214858 s
19/07/31 13:54:50 INFO CodeGenerator: Code generated in 6.338991 ms
19/07/31 13:54:50 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:54:50 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 13:54:50 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 13:54:50 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:54:50 INFO CodeGenerator: Code generated in 5.320784 ms
19/07/31 13:54:50 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 281.2 KB, free 911.7 MB)
19/07/31 13:54:50 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.7 MB)
19/07/31 13:54:50 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:64327 (size: 23.8 KB, free: 912.2 MB)
19/07/31 13:54:50 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:0
19/07/31 13:54:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:54:50 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:54:50 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:54:50 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:54:50 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:54:50 INFO DAGScheduler: Missing parents: List()
19/07/31 13:54:50 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:54:50 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.8 KB, free 911.7 MB)
19/07/31 13:54:50 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.7 MB)
19/07/31 13:54:50 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:64327 (size: 8.6 KB, free: 912.2 MB)
19/07/31 13:54:50 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/07/31 13:54:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:54:50 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/07/31 13:54:50 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:54:50 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/07/31 13:54:51 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:54:51 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1627 bytes result sent to driver
19/07/31 13:54:51 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 74 ms on localhost (executor driver) (1/1)
19/07/31 13:54:51 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/07/31 13:54:51 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.075 s
19/07/31 13:54:51 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.082795 s
19/07/31 13:54:51 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:54:51 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:51 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:51 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:51 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:51 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:54:51 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:54:51 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 13:54:51 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 13:54:51 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 13:54:51 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:54:51 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 13:54:51 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 13:54:51 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:54:51 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 282.3 KB, free 911.4 MB)
19/07/31 13:54:51 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.4 MB)
19/07/31 13:54:51 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:64327 (size: 24.0 KB, free: 912.2 MB)
19/07/31 13:54:51 INFO SparkContext: Created broadcast 5 from sql at NativeMethodAccessorImpl.java:0
19/07/31 13:54:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:54:51 INFO CodeGenerator: Code generated in 8.183549 ms
19/07/31 13:54:51 INFO CodeGenerator: Code generated in 6.691329 ms
19/07/31 13:54:51 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 13:54:51 INFO DAGScheduler: Registering RDD 18 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 13:54:51 INFO DAGScheduler: Got job 3 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:54:51 INFO DAGScheduler: Final stage: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 13:54:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/07/31 13:54:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/07/31 13:54:51 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:54:51 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 26.3 KB, free 911.3 MB)
19/07/31 13:54:51 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.8 KB, free 911.3 MB)
19/07/31 13:54:51 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:64327 (size: 11.8 KB, free: 912.2 MB)
19/07/31 13:54:51 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/07/31 13:54:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:54:51 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/07/31 13:54:51 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:54:51 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/07/31 13:54:51 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:54:51 INFO CodeGenerator: Code generated in 16.557229 ms
19/07/31 13:54:51 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 48.9 KB, free 911.3 MB)
19/07/31 13:54:51 INFO BlockManagerInfo: Added rdd_15_0 in memory on 127.0.0.1:64327 (size: 48.9 KB, free: 912.2 MB)
19/07/31 13:54:51 INFO CodeGenerator: Code generated in 4.959478 ms
19/07/31 13:54:51 INFO CodeGenerator: Code generated in 19.444854 ms
19/07/31 13:54:51 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2504 bytes result sent to driver
19/07/31 13:54:51 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 249 ms on localhost (executor driver) (1/1)
19/07/31 13:54:51 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/07/31 13:54:51 INFO DAGScheduler: ShuffleMapStage 3 (sql at NativeMethodAccessorImpl.java:0) finished in 0.250 s
19/07/31 13:54:51 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:54:51 INFO DAGScheduler: running: Set()
19/07/31 13:54:51 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/07/31 13:54:51 INFO DAGScheduler: failed: Set()
19/07/31 13:54:51 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:54:51 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 911.3 MB)
19/07/31 13:54:51 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.3 MB)
19/07/31 13:54:51 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:64327 (size: 3.7 KB, free: 912.2 MB)
19/07/31 13:54:51 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/07/31 13:54:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:54:51 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/07/31 13:54:51 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:54:51 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/07/31 13:54:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:54:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
19/07/31 13:54:51 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1581 bytes result sent to driver
19/07/31 13:54:51 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 36 ms on localhost (executor driver) (1/1)
19/07/31 13:54:51 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/07/31 13:54:51 INFO DAGScheduler: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0) finished in 0.038 s
19/07/31 13:54:51 INFO DAGScheduler: Job 3 finished: sql at NativeMethodAccessorImpl.java:0, took 0.332396 s
19/07/31 13:54:51 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 13:54:51 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:51 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:51 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:54:51 INFO DAGScheduler: Registering RDD 24 (collect at utils.scala:204)
19/07/31 13:54:51 INFO DAGScheduler: Got job 4 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:54:51 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
19/07/31 13:54:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/07/31 13:54:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/07/31 13:54:51 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204), which has no missing parents
19/07/31 13:54:51 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 26.3 KB, free 911.2 MB)
19/07/31 13:54:51 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.9 KB, free 911.2 MB)
19/07/31 13:54:51 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:64327 (size: 11.9 KB, free: 912.1 MB)
19/07/31 13:54:51 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/07/31 13:54:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:54:51 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/07/31 13:54:51 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:54:51 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/07/31 13:54:51 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 13:54:51 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1780 bytes result sent to driver
19/07/31 13:54:51 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 10 ms on localhost (executor driver) (1/1)
19/07/31 13:54:51 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/07/31 13:54:51 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:204) finished in 0.011 s
19/07/31 13:54:51 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:54:51 INFO DAGScheduler: running: Set()
19/07/31 13:54:51 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/07/31 13:54:51 INFO DAGScheduler: failed: Set()
19/07/31 13:54:51 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204), which has no missing parents
19/07/31 13:54:51 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 911.2 MB)
19/07/31 13:54:51 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.2 MB)
19/07/31 13:54:51 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:64327 (size: 3.7 KB, free: 912.1 MB)
19/07/31 13:54:51 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/07/31 13:54:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:54:51 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/07/31 13:54:51 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:54:51 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/07/31 13:54:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:54:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:54:51 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1581 bytes result sent to driver
19/07/31 13:54:51 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 4 ms on localhost (executor driver) (1/1)
19/07/31 13:54:51 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/07/31 13:54:51 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.005 s
19/07/31 13:54:51 INFO DAGScheduler: Job 4 finished: collect at utils.scala:204, took 0.032263 s
19/07/31 13:54:51 INFO CodeGenerator: Code generated in 4.973584 ms
19/07/31 13:54:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz1`
WHERE (0 = 1)
19/07/31 13:54:52 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:54:52 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:52 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:52 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:52 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:52 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:54:52 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:54:52 INFO CodeGenerator: Code generated in 8.952772 ms
19/07/31 13:54:53 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:54:53 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:53 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:53 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:53 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:53 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:54:53 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:54:54 INFO CodeGenerator: Code generated in 5.945917 ms
19/07/31 13:54:54 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 13:54:54 INFO DAGScheduler: Got job 5 (collect at utils.scala:44) with 1 output partitions
19/07/31 13:54:54 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:44)
19/07/31 13:54:54 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:54:54 INFO DAGScheduler: Missing parents: List()
19/07/31 13:54:54 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[32] at map at utils.scala:41), which has no missing parents
19/07/31 13:54:54 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 6.3 KB, free 911.2 MB)
19/07/31 13:54:54 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.5 KB, free 911.2 MB)
19/07/31 13:54:54 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:64327 (size: 3.5 KB, free: 912.1 MB)
19/07/31 13:54:54 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/07/31 13:54:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 13:54:54 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/07/31 13:54:54 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 13:54:54 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
19/07/31 13:54:54 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1007 bytes result sent to driver
19/07/31 13:54:54 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 4 ms on localhost (executor driver) (1/1)
19/07/31 13:54:54 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/07/31 13:54:54 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:44) finished in 0.004 s
19/07/31 13:54:54 INFO DAGScheduler: Job 5 finished: collect at utils.scala:44, took 0.010337 s
19/07/31 13:54:54 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 13:54:54 INFO MapPartitionsRDD: Removing RDD 15 from persistence list
19/07/31 13:54:54 INFO BlockManager: Removing RDD 15
19/07/31 13:54:54 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:54:54 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#396)) > 0)
19/07/31 13:54:54 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 13:54:54 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:54:54 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 281.2 KB, free 911.0 MB)
19/07/31 13:54:54 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.0 MB)
19/07/31 13:54:54 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:64327 (size: 23.8 KB, free: 912.2 MB)
19/07/31 13:54:54 INFO SparkContext: Created broadcast 11 from csv at NativeMethodAccessorImpl.java:0
19/07/31 13:54:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:54:54 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:54:54 INFO DAGScheduler: Got job 6 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:54:54 INFO DAGScheduler: Final stage: ResultStage 8 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:54:54 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:54:54 INFO DAGScheduler: Missing parents: List()
19/07/31 13:54:54 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[35] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:54:54 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.2 KB, free 911.0 MB)
19/07/31 13:54:54 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.3 KB, free 911.0 MB)
19/07/31 13:54:54 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:64327 (size: 4.3 KB, free: 912.2 MB)
19/07/31 13:54:54 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/07/31 13:54:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[35] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:54:54 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/07/31 13:54:54 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:54:54 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
19/07/31 13:54:54 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:54:54 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1351 bytes result sent to driver
19/07/31 13:54:54 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 5 ms on localhost (executor driver) (1/1)
19/07/31 13:54:54 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/07/31 13:54:54 INFO DAGScheduler: ResultStage 8 (csv at NativeMethodAccessorImpl.java:0) finished in 0.006 s
19/07/31 13:54:54 INFO DAGScheduler: Job 6 finished: csv at NativeMethodAccessorImpl.java:0, took 0.011668 s
19/07/31 13:54:54 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:54:54 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 13:54:54 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 13:54:54 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:54:54 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 281.2 KB, free 910.7 MB)
19/07/31 13:54:54 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 23.8 KB, free 910.7 MB)
19/07/31 13:54:54 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:64327 (size: 23.8 KB, free: 912.1 MB)
19/07/31 13:54:54 INFO SparkContext: Created broadcast 13 from csv at NativeMethodAccessorImpl.java:0
19/07/31 13:54:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:54:54 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:54:54 INFO DAGScheduler: Got job 7 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:54:54 INFO DAGScheduler: Final stage: ResultStage 9 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:54:54 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:54:54 INFO DAGScheduler: Missing parents: List()
19/07/31 13:54:54 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[40] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:54:54 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 14.8 KB, free 910.6 MB)
19/07/31 13:54:54 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 8.6 KB, free 910.6 MB)
19/07/31 13:54:54 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:64327 (size: 8.6 KB, free: 912.1 MB)
19/07/31 13:54:54 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/07/31 13:54:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[40] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:54:54 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
19/07/31 13:54:54 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:54:54 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
19/07/31 13:54:54 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:54:54 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1627 bytes result sent to driver
19/07/31 13:54:54 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 22 ms on localhost (executor driver) (1/1)
19/07/31 13:54:54 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/07/31 13:54:54 INFO DAGScheduler: ResultStage 9 (csv at NativeMethodAccessorImpl.java:0) finished in 0.022 s
19/07/31 13:54:54 INFO DAGScheduler: Job 7 finished: csv at NativeMethodAccessorImpl.java:0, took 0.029187 s
19/07/31 13:54:54 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:54:54 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:54 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:54 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:54 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:54 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:54:54 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:54:54 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 13:54:54 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 13:54:54 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 13:54:54 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:54:54 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 13:54:54 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 13:54:54 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:54:54 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 282.3 KB, free 910.4 MB)
19/07/31 13:54:54 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 24.0 KB, free 910.3 MB)
19/07/31 13:54:54 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:64327 (size: 24.0 KB, free: 912.1 MB)
19/07/31 13:54:54 INFO SparkContext: Created broadcast 15 from sql at NativeMethodAccessorImpl.java:0
19/07/31 13:54:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:54:54 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 13:54:54 INFO DAGScheduler: Registering RDD 46 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 13:54:54 INFO DAGScheduler: Got job 8 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:54:54 INFO DAGScheduler: Final stage: ResultStage 11 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 13:54:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
19/07/31 13:54:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
19/07/31 13:54:54 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[46] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:54:54 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 26.3 KB, free 910.3 MB)
19/07/31 13:54:54 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 11.9 KB, free 910.3 MB)
19/07/31 13:54:54 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:64327 (size: 11.9 KB, free: 912.1 MB)
19/07/31 13:54:54 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/07/31 13:54:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[46] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:54:54 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/07/31 13:54:54 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:54:54 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
19/07/31 13:54:54 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:54:54 INFO MemoryStore: Block rdd_43_0 stored as values in memory (estimated size 48.9 KB, free 910.3 MB)
19/07/31 13:54:54 INFO BlockManagerInfo: Added rdd_43_0 in memory on 127.0.0.1:64327 (size: 48.9 KB, free: 912.0 MB)
19/07/31 13:54:54 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2461 bytes result sent to driver
19/07/31 13:54:54 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 49 ms on localhost (executor driver) (1/1)
19/07/31 13:54:54 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/07/31 13:54:54 INFO DAGScheduler: ShuffleMapStage 10 (sql at NativeMethodAccessorImpl.java:0) finished in 0.050 s
19/07/31 13:54:54 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:54:54 INFO DAGScheduler: running: Set()
19/07/31 13:54:54 INFO DAGScheduler: waiting: Set(ResultStage 11)
19/07/31 13:54:54 INFO DAGScheduler: failed: Set()
19/07/31 13:54:54 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[49] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:54:54 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 910.2 MB)
19/07/31 13:54:54 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.2 MB)
19/07/31 13:54:54 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:64327 (size: 3.7 KB, free: 912.0 MB)
19/07/31 13:54:54 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/07/31 13:54:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[49] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:54:54 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/07/31 13:54:54 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:54:54 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
19/07/31 13:54:54 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:54:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:54:54 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1581 bytes result sent to driver
19/07/31 13:54:54 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 4 ms on localhost (executor driver) (1/1)
19/07/31 13:54:54 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/07/31 13:54:54 INFO DAGScheduler: ResultStage 11 (sql at NativeMethodAccessorImpl.java:0) finished in 0.005 s
19/07/31 13:54:54 INFO DAGScheduler: Job 8 finished: sql at NativeMethodAccessorImpl.java:0, took 0.068045 s
19/07/31 13:54:54 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 13:54:54 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:54 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:54 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:54:54 INFO DAGScheduler: Registering RDD 52 (collect at utils.scala:204)
19/07/31 13:54:54 INFO DAGScheduler: Got job 9 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:54:54 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:204)
19/07/31 13:54:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
19/07/31 13:54:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
19/07/31 13:54:54 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[52] at collect at utils.scala:204), which has no missing parents
19/07/31 13:54:54 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 26.3 KB, free 910.2 MB)
19/07/31 13:54:54 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 11.8 KB, free 910.2 MB)
19/07/31 13:54:54 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:64327 (size: 11.8 KB, free: 912.0 MB)
19/07/31 13:54:54 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
19/07/31 13:54:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[52] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:54:54 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
19/07/31 13:54:54 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:54:54 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
19/07/31 13:54:54 INFO BlockManager: Found block rdd_43_0 locally
19/07/31 13:54:54 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1780 bytes result sent to driver
19/07/31 13:54:54 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 7 ms on localhost (executor driver) (1/1)
19/07/31 13:54:54 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/07/31 13:54:54 INFO DAGScheduler: ShuffleMapStage 12 (collect at utils.scala:204) finished in 0.008 s
19/07/31 13:54:54 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:54:54 INFO DAGScheduler: running: Set()
19/07/31 13:54:54 INFO DAGScheduler: waiting: Set(ResultStage 13)
19/07/31 13:54:54 INFO DAGScheduler: failed: Set()
19/07/31 13:54:54 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[55] at collect at utils.scala:204), which has no missing parents
19/07/31 13:54:54 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 7.0 KB, free 910.2 MB)
19/07/31 13:54:54 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.2 MB)
19/07/31 13:54:54 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:64327 (size: 3.7 KB, free: 912.0 MB)
19/07/31 13:54:54 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/07/31 13:54:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[55] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:54:54 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/07/31 13:54:54 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:54:54 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
19/07/31 13:54:54 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:54:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:54:54 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1581 bytes result sent to driver
19/07/31 13:54:54 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 5 ms on localhost (executor driver) (1/1)
19/07/31 13:54:54 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/07/31 13:54:54 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:204) finished in 0.006 s
19/07/31 13:54:54 INFO DAGScheduler: Job 9 finished: collect at utils.scala:204, took 0.028446 s
19/07/31 13:54:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz2`
WHERE (0 = 1)
19/07/31 13:54:54 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:54:54 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:54 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:54 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:54 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:54 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:54:54 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:54:54 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 13:54:54 INFO DAGScheduler: Got job 10 (collect at utils.scala:44) with 1 output partitions
19/07/31 13:54:54 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:44)
19/07/31 13:54:54 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:54:54 INFO DAGScheduler: Missing parents: List()
19/07/31 13:54:54 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[60] at map at utils.scala:41), which has no missing parents
19/07/31 13:54:54 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 6.3 KB, free 910.2 MB)
19/07/31 13:54:54 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.5 KB, free 910.2 MB)
19/07/31 13:54:54 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:64327 (size: 3.5 KB, free: 912.0 MB)
19/07/31 13:54:54 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
19/07/31 13:54:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[60] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 13:54:54 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/07/31 13:54:54 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 13:54:54 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
19/07/31 13:54:54 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1007 bytes result sent to driver
19/07/31 13:54:54 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 4 ms on localhost (executor driver) (1/1)
19/07/31 13:54:54 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/07/31 13:54:54 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:44) finished in 0.004 s
19/07/31 13:54:54 INFO DAGScheduler: Job 10 finished: collect at utils.scala:44, took 0.009937 s
19/07/31 13:54:54 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 13:54:54 INFO MapPartitionsRDD: Removing RDD 43 from persistence list
19/07/31 13:54:54 INFO BlockManager: Removing RDD 43
19/07/31 13:54:55 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:54:55 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#768)) > 0)
19/07/31 13:54:55 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 13:54:55 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:54:55 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 281.2 KB, free 910.0 MB)
19/07/31 13:54:55 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 23.8 KB, free 909.9 MB)
19/07/31 13:54:55 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:64327 (size: 23.8 KB, free: 912.0 MB)
19/07/31 13:54:55 INFO SparkContext: Created broadcast 21 from csv at NativeMethodAccessorImpl.java:0
19/07/31 13:54:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:54:55 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:54:55 INFO DAGScheduler: Got job 11 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:54:55 INFO DAGScheduler: Final stage: ResultStage 15 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:54:55 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:54:55 INFO DAGScheduler: Missing parents: List()
19/07/31 13:54:55 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[63] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:54:55 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 8.2 KB, free 909.9 MB)
19/07/31 13:54:55 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 4.3 KB, free 909.9 MB)
19/07/31 13:54:55 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:64327 (size: 4.3 KB, free: 912.0 MB)
19/07/31 13:54:55 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
19/07/31 13:54:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[63] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:54:55 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
19/07/31 13:54:55 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:54:55 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
19/07/31 13:54:55 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:54:55 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1394 bytes result sent to driver
19/07/31 13:54:55 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 5 ms on localhost (executor driver) (1/1)
19/07/31 13:54:55 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/07/31 13:54:55 INFO DAGScheduler: ResultStage 15 (csv at NativeMethodAccessorImpl.java:0) finished in 0.006 s
19/07/31 13:54:55 INFO DAGScheduler: Job 11 finished: csv at NativeMethodAccessorImpl.java:0, took 0.011131 s
19/07/31 13:54:55 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:54:55 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 13:54:55 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 13:54:55 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:54:55 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 281.2 KB, free 909.6 MB)
19/07/31 13:54:55 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 23.8 KB, free 909.6 MB)
19/07/31 13:54:55 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:64327 (size: 23.8 KB, free: 912.0 MB)
19/07/31 13:54:55 INFO SparkContext: Created broadcast 23 from csv at NativeMethodAccessorImpl.java:0
19/07/31 13:54:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:54:55 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:54:55 INFO DAGScheduler: Got job 12 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:54:55 INFO DAGScheduler: Final stage: ResultStage 16 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:54:55 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:54:55 INFO DAGScheduler: Missing parents: List()
19/07/31 13:54:55 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[68] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:54:55 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 14.8 KB, free 909.6 MB)
19/07/31 13:54:55 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 8.6 KB, free 909.6 MB)
19/07/31 13:54:55 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:64327 (size: 8.6 KB, free: 912.0 MB)
19/07/31 13:54:55 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
19/07/31 13:54:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[68] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:54:55 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/07/31 13:54:55 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:54:55 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
19/07/31 13:54:55 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:54:55 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1584 bytes result sent to driver
19/07/31 13:54:55 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 21 ms on localhost (executor driver) (1/1)
19/07/31 13:54:55 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/07/31 13:54:55 INFO DAGScheduler: ResultStage 16 (csv at NativeMethodAccessorImpl.java:0) finished in 0.021 s
19/07/31 13:54:55 INFO DAGScheduler: Job 12 finished: csv at NativeMethodAccessorImpl.java:0, took 0.030530 s
19/07/31 13:54:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:54:55 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:55 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:55 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:55 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:54:55 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:54:55 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 13:54:55 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 13:54:55 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 13:54:55 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:54:55 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 13:54:55 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 13:54:55 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:54:55 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 282.3 KB, free 909.3 MB)
19/07/31 13:54:55 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 24.0 KB, free 909.3 MB)
19/07/31 13:54:55 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:64327 (size: 24.0 KB, free: 912.0 MB)
19/07/31 13:54:55 INFO SparkContext: Created broadcast 25 from sql at <unknown>:0
19/07/31 13:54:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 178
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 185
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 326
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 120
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 328
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 264
19/07/31 13:54:55 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:64327 in memory (size: 23.8 KB, free: 912.0 MB)
19/07/31 13:54:55 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 109
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 111
19/07/31 13:54:55 INFO DAGScheduler: Registering RDD 74 (sql at <unknown>:0)
19/07/31 13:54:55 INFO DAGScheduler: Got job 13 (sql at <unknown>:0) with 1 output partitions
19/07/31 13:54:55 INFO DAGScheduler: Final stage: ResultStage 18 (sql at <unknown>:0)
19/07/31 13:54:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
19/07/31 13:54:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
19/07/31 13:54:55 INFO BlockManager: Removing RDD 15
19/07/31 13:54:55 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[74] at sql at <unknown>:0), which has no missing parents
19/07/31 13:54:55 INFO ContextCleaner: Cleaned RDD 15
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 475
19/07/31 13:54:55 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 26.3 KB, free 909.6 MB)
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 335
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 448
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 118
19/07/31 13:54:55 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:64327 in memory (size: 8.6 KB, free: 912.0 MB)
19/07/31 13:54:55 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 11.8 KB, free 909.6 MB)
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 124
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 187
19/07/31 13:54:55 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:64327 (size: 11.8 KB, free: 912.0 MB)
19/07/31 13:54:55 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
19/07/31 13:54:55 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:64327 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 13:54:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[74] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:54:55 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 175
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 182
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 332
19/07/31 13:54:55 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:54:55 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
19/07/31 13:54:55 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:64327 in memory (size: 11.9 KB, free: 912.0 MB)
19/07/31 13:54:55 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:64327 in memory (size: 11.8 KB, free: 912.0 MB)
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 506
19/07/31 13:54:55 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:64327 in memory (size: 4.3 KB, free: 912.0 MB)
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 108
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 180
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 183
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 327
19/07/31 13:54:55 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:64327 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 538
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 294
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 126
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 121
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 179
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 265
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 114
19/07/31 13:54:55 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:54:55 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:64327 in memory (size: 8.6 KB, free: 912.0 MB)
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 337
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 336
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 263
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 291
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 474
19/07/31 13:54:55 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:64327 in memory (size: 23.8 KB, free: 912.1 MB)
19/07/31 13:54:55 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:64327 in memory (size: 11.8 KB, free: 912.1 MB)
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 295
19/07/31 13:54:55 INFO ContextCleaner: Cleaned shuffle 0
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 504
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 329
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 331
19/07/31 13:54:55 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:64327 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 478
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 334
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 505
19/07/31 13:54:55 INFO ContextCleaner: Cleaned shuffle 2
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 119
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 181
19/07/31 13:54:55 INFO ContextCleaner: Cleaned shuffle 1
19/07/31 13:54:55 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:64327 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 117
19/07/31 13:54:55 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:64327 in memory (size: 24.0 KB, free: 912.1 MB)
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 236
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 116
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 122
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 113
19/07/31 13:54:55 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:64327 in memory (size: 3.5 KB, free: 912.1 MB)
19/07/31 13:54:55 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:64327 in memory (size: 3.5 KB, free: 912.1 MB)
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 387
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 115
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 293
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 125
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 123
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 176
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 338
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 184
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 477
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 110
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 177
19/07/31 13:54:55 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:64327 in memory (size: 23.8 KB, free: 912.1 MB)
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 186
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 261
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 330
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 266
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 262
19/07/31 13:54:55 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:64327 in memory (size: 4.3 KB, free: 912.1 MB)
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 476
19/07/31 13:54:55 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:64327 in memory (size: 23.8 KB, free: 912.2 MB)
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 473
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 333
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 503
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 112
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 292
19/07/31 13:54:55 INFO ContextCleaner: Cleaned accumulator 507
19/07/31 13:54:55 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:64327 in memory (size: 8.6 KB, free: 912.2 MB)
19/07/31 13:54:55 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:64327 in memory (size: 11.9 KB, free: 912.2 MB)
19/07/31 13:54:55 INFO MemoryStore: Block rdd_71_0 stored as values in memory (estimated size 48.9 KB, free 911.0 MB)
19/07/31 13:54:55 INFO BlockManagerInfo: Added rdd_71_0 in memory on 127.0.0.1:64327 (size: 48.9 KB, free: 912.1 MB)
19/07/31 13:54:55 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 2461 bytes result sent to driver
19/07/31 13:54:55 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 54 ms on localhost (executor driver) (1/1)
19/07/31 13:54:55 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/07/31 13:54:55 INFO DAGScheduler: ShuffleMapStage 17 (sql at <unknown>:0) finished in 0.054 s
19/07/31 13:54:55 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:54:55 INFO DAGScheduler: running: Set()
19/07/31 13:54:55 INFO DAGScheduler: waiting: Set(ResultStage 18)
19/07/31 13:54:55 INFO DAGScheduler: failed: Set()
19/07/31 13:54:55 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[77] at sql at <unknown>:0), which has no missing parents
19/07/31 13:54:55 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 7.0 KB, free 911.0 MB)
19/07/31 13:54:55 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.0 MB)
19/07/31 13:54:55 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:64327 (size: 3.7 KB, free: 912.1 MB)
19/07/31 13:54:55 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
19/07/31 13:54:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[77] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:54:55 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
19/07/31 13:54:55 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:54:55 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
19/07/31 13:54:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:54:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:54:55 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 1581 bytes result sent to driver
19/07/31 13:54:55 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 4 ms on localhost (executor driver) (1/1)
19/07/31 13:54:55 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/07/31 13:54:55 INFO DAGScheduler: ResultStage 18 (sql at <unknown>:0) finished in 0.004 s
19/07/31 13:54:55 INFO DAGScheduler: Job 13 finished: sql at <unknown>:0, took 0.070374 s
19/07/31 13:54:55 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 13:54:55 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:55 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:55 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:54:55 INFO DAGScheduler: Registering RDD 80 (collect at utils.scala:204)
19/07/31 13:54:55 INFO DAGScheduler: Got job 14 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:54:55 INFO DAGScheduler: Final stage: ResultStage 20 (collect at utils.scala:204)
19/07/31 13:54:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
19/07/31 13:54:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 19)
19/07/31 13:54:55 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[80] at collect at utils.scala:204), which has no missing parents
19/07/31 13:54:55 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 26.3 KB, free 911.0 MB)
19/07/31 13:54:55 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 11.9 KB, free 911.0 MB)
19/07/31 13:54:55 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:64327 (size: 11.9 KB, free: 912.1 MB)
19/07/31 13:54:55 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
19/07/31 13:54:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[80] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:54:55 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/07/31 13:54:55 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:54:55 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
19/07/31 13:54:55 INFO BlockManager: Found block rdd_71_0 locally
19/07/31 13:54:55 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1780 bytes result sent to driver
19/07/31 13:54:55 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 7 ms on localhost (executor driver) (1/1)
19/07/31 13:54:55 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/07/31 13:54:55 INFO DAGScheduler: ShuffleMapStage 19 (collect at utils.scala:204) finished in 0.008 s
19/07/31 13:54:55 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:54:55 INFO DAGScheduler: running: Set()
19/07/31 13:54:55 INFO DAGScheduler: waiting: Set(ResultStage 20)
19/07/31 13:54:55 INFO DAGScheduler: failed: Set()
19/07/31 13:54:55 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[83] at collect at utils.scala:204), which has no missing parents
19/07/31 13:54:55 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 7.0 KB, free 911.0 MB)
19/07/31 13:54:55 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.0 MB)
19/07/31 13:54:55 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:64327 (size: 3.7 KB, free: 912.1 MB)
19/07/31 13:54:55 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
19/07/31 13:54:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[83] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:54:55 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/07/31 13:54:55 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:54:55 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
19/07/31 13:54:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:54:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:54:55 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1581 bytes result sent to driver
19/07/31 13:54:55 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 3 ms on localhost (executor driver) (1/1)
19/07/31 13:54:55 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/07/31 13:54:55 INFO DAGScheduler: ResultStage 20 (collect at utils.scala:204) finished in 0.004 s
19/07/31 13:54:55 INFO DAGScheduler: Job 14 finished: collect at utils.scala:204, took 0.028810 s
19/07/31 13:54:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz3`
WHERE (0 = 1)
19/07/31 13:54:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:54:55 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:55 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:55 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:55 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:54:55 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:54:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:54:55 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:55 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:55 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:54:55 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:54:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:54:55 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:57:12 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_001`) `dbplyr_002`) `dbplyr_003`
ORDER BY `date`) `dbplyr_004`
19/07/31 13:57:12 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:57:12 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:57:12 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:57:12 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:57:13 INFO SparkSqlParser: Parsing command: SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_005`) `dbplyr_006`) `dbplyr_007`
ORDER BY `date`) `dbplyr_008`
19/07/31 13:57:13 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:57:13 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:57:13 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:57:13 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:57:13 INFO CodeGenerator: Code generated in 37.389332 ms
19/07/31 13:57:13 INFO CodeGenerator: Code generated in 20.495926 ms
19/07/31 13:57:13 INFO CodeGenerator: Code generated in 8.344276 ms
19/07/31 13:57:13 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:57:13 INFO DAGScheduler: Got job 15 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:57:13 INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:204)
19/07/31 13:57:13 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:57:13 INFO DAGScheduler: Missing parents: List()
19/07/31 13:57:13 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[88] at collect at utils.scala:204), which has no missing parents
19/07/31 13:57:13 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 70.5 KB, free 910.9 MB)
19/07/31 13:57:13 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 29.7 KB, free 910.9 MB)
19/07/31 13:57:13 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:64327 (size: 29.7 KB, free: 912.1 MB)
19/07/31 13:57:13 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
19/07/31 13:57:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[88] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:57:13 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
19/07/31 13:57:13 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:57:13 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
19/07/31 13:57:13 INFO BlockManager: Found block rdd_71_0 locally
19/07/31 13:57:13 INFO CodeGenerator: Code generated in 15.902262 ms
19/07/31 13:57:13 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 23350 bytes result sent to driver
19/07/31 13:57:13 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 99 ms on localhost (executor driver) (1/1)
19/07/31 13:57:13 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/07/31 13:57:13 INFO DAGScheduler: ResultStage 21 (collect at utils.scala:204) finished in 0.099 s
19/07/31 13:57:13 INFO DAGScheduler: Job 15 finished: collect at utils.scala:204, took 0.110661 s
19/07/31 13:57:13 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:57:13 INFO DAGScheduler: Registering RDD 89 (collect at utils.scala:204)
19/07/31 13:57:13 INFO DAGScheduler: Got job 16 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:57:13 INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:204)
19/07/31 13:57:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
19/07/31 13:57:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
19/07/31 13:57:13 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[89] at collect at utils.scala:204), which has no missing parents
19/07/31 13:57:13 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 73.1 KB, free 910.8 MB)
19/07/31 13:57:13 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 31.2 KB, free 910.8 MB)
19/07/31 13:57:13 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:64327 (size: 31.2 KB, free: 912.1 MB)
19/07/31 13:57:13 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
19/07/31 13:57:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[89] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:57:13 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
19/07/31 13:57:13 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:57:13 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
19/07/31 13:57:13 INFO BlockManager: Found block rdd_71_0 locally
19/07/31 13:57:13 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1625 bytes result sent to driver
19/07/31 13:57:13 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 39 ms on localhost (executor driver) (1/1)
19/07/31 13:57:13 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/07/31 13:57:13 INFO DAGScheduler: ShuffleMapStage 22 (collect at utils.scala:204) finished in 0.039 s
19/07/31 13:57:13 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:57:13 INFO DAGScheduler: running: Set()
19/07/31 13:57:13 INFO DAGScheduler: waiting: Set(ResultStage 23)
19/07/31 13:57:13 INFO DAGScheduler: failed: Set()
19/07/31 13:57:13 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[92] at collect at utils.scala:204), which has no missing parents
19/07/31 13:57:13 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 15.4 KB, free 910.7 MB)
19/07/31 13:57:13 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 7.4 KB, free 910.7 MB)
19/07/31 13:57:13 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:64327 (size: 7.4 KB, free: 912.1 MB)
19/07/31 13:57:13 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
19/07/31 13:57:13 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 23 (MapPartitionsRDD[92] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:57:13 INFO TaskSchedulerImpl: Adding task set 23.0 with 4 tasks
19/07/31 13:57:13 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:57:13 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 24, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:57:13 INFO TaskSetManager: Starting task 2.0 in stage 23.0 (TID 25, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:57:13 INFO TaskSetManager: Starting task 3.0 in stage 23.0 (TID 26, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:57:13 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
19/07/31 13:57:13 INFO Executor: Running task 1.0 in stage 23.0 (TID 24)
19/07/31 13:57:13 INFO Executor: Running task 3.0 in stage 23.0 (TID 26)
19/07/31 13:57:13 INFO Executor: Running task 2.0 in stage 23.0 (TID 25)
19/07/31 13:57:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:57:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:57:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:57:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:57:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:57:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:57:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:57:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:57:13 INFO CodeGenerator: Code generated in 5.541855 ms
19/07/31 13:57:13 INFO Executor: Finished task 3.0 in stage 23.0 (TID 26). 11521 bytes result sent to driver
19/07/31 13:57:13 INFO TaskSetManager: Finished task 3.0 in stage 23.0 (TID 26) in 51 ms on localhost (executor driver) (1/4)
19/07/31 13:57:13 INFO Executor: Finished task 1.0 in stage 23.0 (TID 24). 11547 bytes result sent to driver
19/07/31 13:57:13 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 11347 bytes result sent to driver
19/07/31 13:57:13 INFO Executor: Finished task 2.0 in stage 23.0 (TID 25). 10352 bytes result sent to driver
19/07/31 13:57:13 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 24) in 51 ms on localhost (executor driver) (2/4)
19/07/31 13:57:13 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 53 ms on localhost (executor driver) (3/4)
19/07/31 13:57:13 INFO TaskSetManager: Finished task 2.0 in stage 23.0 (TID 25) in 52 ms on localhost (executor driver) (4/4)
19/07/31 13:57:13 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
19/07/31 13:57:13 INFO DAGScheduler: ResultStage 23 (collect at utils.scala:204) finished in 0.053 s
19/07/31 13:57:13 INFO DAGScheduler: Job 16 finished: collect at utils.scala:204, took 0.109003 s
19/07/31 13:57:13 INFO CodeGenerator: Code generated in 9.950808 ms
19/07/31 13:57:40 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:57:40 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:57:40 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:57:40 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:57:40 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:57:40 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:57:40 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:57:40 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 13:57:40 INFO DAGScheduler: Got job 17 (collect at utils.scala:44) with 1 output partitions
19/07/31 13:57:40 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:44)
19/07/31 13:57:40 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:57:40 INFO DAGScheduler: Missing parents: List()
19/07/31 13:57:40 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[97] at map at utils.scala:41), which has no missing parents
19/07/31 13:57:40 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 6.3 KB, free 910.7 MB)
19/07/31 13:57:40 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.5 KB, free 910.7 MB)
19/07/31 13:57:40 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:64327 (size: 3.5 KB, free: 912.1 MB)
19/07/31 13:57:40 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
19/07/31 13:57:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[97] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 13:57:40 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
19/07/31 13:57:40 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 13:57:40 INFO Executor: Running task 0.0 in stage 24.0 (TID 27)
19/07/31 13:57:40 INFO Executor: Finished task 0.0 in stage 24.0 (TID 27). 1007 bytes result sent to driver
19/07/31 13:57:40 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 27) in 3 ms on localhost (executor driver) (1/1)
19/07/31 13:57:40 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
19/07/31 13:57:40 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:44) finished in 0.004 s
19/07/31 13:57:40 INFO DAGScheduler: Job 17 finished: collect at utils.scala:44, took 0.009416 s
19/07/31 13:57:40 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 13:57:40 INFO MapPartitionsRDD: Removing RDD 71 from persistence list
19/07/31 13:57:40 INFO BlockManager: Removing RDD 71
19/07/31 13:57:40 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:57:40 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1254)) > 0)
19/07/31 13:57:40 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 13:57:40 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:57:40 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 281.2 KB, free 910.5 MB)
19/07/31 13:57:40 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 23.8 KB, free 910.5 MB)
19/07/31 13:57:40 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:64327 (size: 23.8 KB, free: 912.1 MB)
19/07/31 13:57:40 INFO SparkContext: Created broadcast 34 from csv at NativeMethodAccessorImpl.java:0
19/07/31 13:57:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:57:40 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:57:40 INFO DAGScheduler: Got job 18 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:57:40 INFO DAGScheduler: Final stage: ResultStage 25 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:57:40 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:57:40 INFO DAGScheduler: Missing parents: List()
19/07/31 13:57:40 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[100] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:57:40 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 8.2 KB, free 910.5 MB)
19/07/31 13:57:40 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 4.3 KB, free 910.5 MB)
19/07/31 13:57:40 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:64327 (size: 4.3 KB, free: 912.1 MB)
19/07/31 13:57:40 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
19/07/31 13:57:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[100] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:57:40 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
19/07/31 13:57:40 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:57:40 INFO Executor: Running task 0.0 in stage 25.0 (TID 28)
19/07/31 13:57:40 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:57:40 INFO Executor: Finished task 0.0 in stage 25.0 (TID 28). 1394 bytes result sent to driver
19/07/31 13:57:40 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 28) in 7 ms on localhost (executor driver) (1/1)
19/07/31 13:57:40 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
19/07/31 13:57:40 INFO DAGScheduler: ResultStage 25 (csv at NativeMethodAccessorImpl.java:0) finished in 0.007 s
19/07/31 13:57:40 INFO DAGScheduler: Job 18 finished: csv at NativeMethodAccessorImpl.java:0, took 0.011513 s
19/07/31 13:57:40 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:57:40 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 13:57:40 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 13:57:40 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:57:40 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 281.2 KB, free 910.2 MB)
19/07/31 13:57:40 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 23.8 KB, free 910.2 MB)
19/07/31 13:57:40 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:64327 (size: 23.8 KB, free: 912.1 MB)
19/07/31 13:57:40 INFO SparkContext: Created broadcast 36 from csv at NativeMethodAccessorImpl.java:0
19/07/31 13:57:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:57:40 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:57:40 INFO DAGScheduler: Got job 19 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:57:40 INFO DAGScheduler: Final stage: ResultStage 26 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:57:40 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:57:40 INFO DAGScheduler: Missing parents: List()
19/07/31 13:57:40 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[105] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:57:40 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 14.8 KB, free 910.1 MB)
19/07/31 13:57:40 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 8.6 KB, free 910.1 MB)
19/07/31 13:57:40 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:64327 (size: 8.6 KB, free: 912.0 MB)
19/07/31 13:57:40 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
19/07/31 13:57:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[105] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:57:40 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
19/07/31 13:57:40 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:57:40 INFO Executor: Running task 0.0 in stage 26.0 (TID 29)
19/07/31 13:57:40 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:57:40 INFO Executor: Finished task 0.0 in stage 26.0 (TID 29). 1584 bytes result sent to driver
19/07/31 13:57:40 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 29) in 20 ms on localhost (executor driver) (1/1)
19/07/31 13:57:40 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
19/07/31 13:57:40 INFO DAGScheduler: ResultStage 26 (csv at NativeMethodAccessorImpl.java:0) finished in 0.020 s
19/07/31 13:57:40 INFO DAGScheduler: Job 19 finished: csv at NativeMethodAccessorImpl.java:0, took 0.027124 s
19/07/31 13:57:40 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:57:40 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:57:40 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:57:40 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:57:40 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:57:40 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:57:40 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:57:40 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 13:57:40 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 13:57:40 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 13:57:40 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:57:40 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 13:57:40 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 13:57:40 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:57:40 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 282.3 KB, free 909.9 MB)
19/07/31 13:57:40 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 24.0 KB, free 909.8 MB)
19/07/31 13:57:40 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:64327 (size: 24.0 KB, free: 912.0 MB)
19/07/31 13:57:40 INFO SparkContext: Created broadcast 38 from sql at <unknown>:0
19/07/31 13:57:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:57:41 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 13:57:41 INFO DAGScheduler: Registering RDD 111 (sql at <unknown>:0)
19/07/31 13:57:41 INFO DAGScheduler: Got job 20 (sql at <unknown>:0) with 1 output partitions
19/07/31 13:57:41 INFO DAGScheduler: Final stage: ResultStage 28 (sql at <unknown>:0)
19/07/31 13:57:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)
19/07/31 13:57:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 27)
19/07/31 13:57:41 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[111] at sql at <unknown>:0), which has no missing parents
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 26.3 KB, free 909.8 MB)
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 11.8 KB, free 909.8 MB)
19/07/31 13:57:41 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:64327 (size: 11.8 KB, free: 912.0 MB)
19/07/31 13:57:41 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
19/07/31 13:57:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[111] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:57:41 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
19/07/31 13:57:41 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:57:41 INFO Executor: Running task 0.0 in stage 27.0 (TID 30)
19/07/31 13:57:41 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:57:41 INFO MemoryStore: Block rdd_108_0 stored as values in memory (estimated size 48.9 KB, free 909.8 MB)
19/07/31 13:57:41 INFO BlockManagerInfo: Added rdd_108_0 in memory on 127.0.0.1:64327 (size: 48.9 KB, free: 912.0 MB)
19/07/31 13:57:41 INFO Executor: Finished task 0.0 in stage 27.0 (TID 30). 2461 bytes result sent to driver
19/07/31 13:57:41 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 30) in 35 ms on localhost (executor driver) (1/1)
19/07/31 13:57:41 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
19/07/31 13:57:41 INFO DAGScheduler: ShuffleMapStage 27 (sql at <unknown>:0) finished in 0.035 s
19/07/31 13:57:41 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:57:41 INFO DAGScheduler: running: Set()
19/07/31 13:57:41 INFO DAGScheduler: waiting: Set(ResultStage 28)
19/07/31 13:57:41 INFO DAGScheduler: failed: Set()
19/07/31 13:57:41 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[114] at sql at <unknown>:0), which has no missing parents
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 7.0 KB, free 909.7 MB)
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 3.7 KB, free 909.7 MB)
19/07/31 13:57:41 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:64327 (size: 3.7 KB, free: 912.0 MB)
19/07/31 13:57:41 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
19/07/31 13:57:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[114] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:57:41 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
19/07/31 13:57:41 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 31, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:57:41 INFO Executor: Running task 0.0 in stage 28.0 (TID 31)
19/07/31 13:57:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:57:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:57:41 INFO Executor: Finished task 0.0 in stage 28.0 (TID 31). 1538 bytes result sent to driver
19/07/31 13:57:41 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 31) in 3 ms on localhost (executor driver) (1/1)
19/07/31 13:57:41 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
19/07/31 13:57:41 INFO DAGScheduler: ResultStage 28 (sql at <unknown>:0) finished in 0.003 s
19/07/31 13:57:41 INFO DAGScheduler: Job 20 finished: sql at <unknown>:0, took 0.053071 s
19/07/31 13:57:41 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 13:57:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:57:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:57:41 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:57:41 INFO DAGScheduler: Registering RDD 117 (collect at utils.scala:204)
19/07/31 13:57:41 INFO DAGScheduler: Got job 21 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:57:41 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:204)
19/07/31 13:57:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
19/07/31 13:57:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 29)
19/07/31 13:57:41 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[117] at collect at utils.scala:204), which has no missing parents
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 26.3 KB, free 909.7 MB)
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 11.9 KB, free 909.7 MB)
19/07/31 13:57:41 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:64327 (size: 11.9 KB, free: 911.9 MB)
19/07/31 13:57:41 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
19/07/31 13:57:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[117] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:57:41 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
19/07/31 13:57:41 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:57:41 INFO Executor: Running task 0.0 in stage 29.0 (TID 32)
19/07/31 13:57:41 INFO BlockManager: Found block rdd_108_0 locally
19/07/31 13:57:41 INFO Executor: Finished task 0.0 in stage 29.0 (TID 32). 1780 bytes result sent to driver
19/07/31 13:57:41 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 32) in 10 ms on localhost (executor driver) (1/1)
19/07/31 13:57:41 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
19/07/31 13:57:41 INFO DAGScheduler: ShuffleMapStage 29 (collect at utils.scala:204) finished in 0.011 s
19/07/31 13:57:41 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:57:41 INFO DAGScheduler: running: Set()
19/07/31 13:57:41 INFO DAGScheduler: waiting: Set(ResultStage 30)
19/07/31 13:57:41 INFO DAGScheduler: failed: Set()
19/07/31 13:57:41 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[120] at collect at utils.scala:204), which has no missing parents
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 7.0 KB, free 909.7 MB)
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 3.7 KB, free 909.7 MB)
19/07/31 13:57:41 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:64327 (size: 3.7 KB, free: 911.9 MB)
19/07/31 13:57:41 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
19/07/31 13:57:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[120] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:57:41 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
19/07/31 13:57:41 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 33, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:57:41 INFO Executor: Running task 0.0 in stage 30.0 (TID 33)
19/07/31 13:57:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:57:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:57:41 INFO Executor: Finished task 0.0 in stage 30.0 (TID 33). 1581 bytes result sent to driver
19/07/31 13:57:41 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 33) in 4 ms on localhost (executor driver) (1/1)
19/07/31 13:57:41 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
19/07/31 13:57:41 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:204) finished in 0.004 s
19/07/31 13:57:41 INFO DAGScheduler: Job 21 finished: collect at utils.scala:204, took 0.034759 s
19/07/31 13:57:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz4`
WHERE (0 = 1)
19/07/31 13:57:41 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:57:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:57:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:57:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:57:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:57:41 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:57:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:57:41 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 13:57:41 INFO DAGScheduler: Got job 22 (collect at utils.scala:44) with 1 output partitions
19/07/31 13:57:41 INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:44)
19/07/31 13:57:41 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:57:41 INFO DAGScheduler: Missing parents: List()
19/07/31 13:57:41 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[125] at map at utils.scala:41), which has no missing parents
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 6.3 KB, free 909.7 MB)
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.5 KB, free 909.7 MB)
19/07/31 13:57:41 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:64327 (size: 3.5 KB, free: 911.9 MB)
19/07/31 13:57:41 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
19/07/31 13:57:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[125] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 13:57:41 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
19/07/31 13:57:41 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 13:57:41 INFO Executor: Running task 0.0 in stage 31.0 (TID 34)
19/07/31 13:57:41 INFO Executor: Finished task 0.0 in stage 31.0 (TID 34). 964 bytes result sent to driver
19/07/31 13:57:41 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 34) in 3 ms on localhost (executor driver) (1/1)
19/07/31 13:57:41 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
19/07/31 13:57:41 INFO DAGScheduler: ResultStage 31 (collect at utils.scala:44) finished in 0.003 s
19/07/31 13:57:41 INFO DAGScheduler: Job 22 finished: collect at utils.scala:44, took 0.007965 s
19/07/31 13:57:41 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 13:57:41 INFO MapPartitionsRDD: Removing RDD 108 from persistence list
19/07/31 13:57:41 INFO BlockManager: Removing RDD 108
19/07/31 13:57:41 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:57:41 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#1626)) > 0)
19/07/31 13:57:41 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 13:57:41 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 281.2 KB, free 909.5 MB)
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 23.8 KB, free 909.4 MB)
19/07/31 13:57:41 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:64327 (size: 23.8 KB, free: 912.0 MB)
19/07/31 13:57:41 INFO SparkContext: Created broadcast 44 from csv at NativeMethodAccessorImpl.java:0
19/07/31 13:57:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:57:41 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:57:41 INFO DAGScheduler: Got job 23 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:57:41 INFO DAGScheduler: Final stage: ResultStage 32 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:57:41 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:57:41 INFO DAGScheduler: Missing parents: List()
19/07/31 13:57:41 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[128] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 8.2 KB, free 909.4 MB)
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 4.3 KB, free 909.4 MB)
19/07/31 13:57:41 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:64327 (size: 4.3 KB, free: 912.0 MB)
19/07/31 13:57:41 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
19/07/31 13:57:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[128] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:57:41 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
19/07/31 13:57:41 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:57:41 INFO Executor: Running task 0.0 in stage 32.0 (TID 35)
19/07/31 13:57:41 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:57:41 INFO Executor: Finished task 0.0 in stage 32.0 (TID 35). 1394 bytes result sent to driver
19/07/31 13:57:41 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 35) in 5 ms on localhost (executor driver) (1/1)
19/07/31 13:57:41 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
19/07/31 13:57:41 INFO DAGScheduler: ResultStage 32 (csv at NativeMethodAccessorImpl.java:0) finished in 0.005 s
19/07/31 13:57:41 INFO DAGScheduler: Job 23 finished: csv at NativeMethodAccessorImpl.java:0, took 0.009124 s
19/07/31 13:57:41 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:57:41 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 13:57:41 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 13:57:41 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 281.2 KB, free 909.1 MB)
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 23.8 KB, free 909.1 MB)
19/07/31 13:57:41 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:64327 (size: 23.8 KB, free: 911.9 MB)
19/07/31 13:57:41 INFO SparkContext: Created broadcast 46 from csv at NativeMethodAccessorImpl.java:0
19/07/31 13:57:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:57:41 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:57:41 INFO DAGScheduler: Got job 24 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:57:41 INFO DAGScheduler: Final stage: ResultStage 33 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:57:41 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:57:41 INFO DAGScheduler: Missing parents: List()
19/07/31 13:57:41 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[133] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 14.8 KB, free 909.1 MB)
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 8.6 KB, free 909.1 MB)
19/07/31 13:57:41 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:64327 (size: 8.6 KB, free: 911.9 MB)
19/07/31 13:57:41 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
19/07/31 13:57:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[133] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:57:41 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
19/07/31 13:57:41 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:57:41 INFO Executor: Running task 0.0 in stage 33.0 (TID 36)
19/07/31 13:57:41 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:57:41 INFO Executor: Finished task 0.0 in stage 33.0 (TID 36). 1584 bytes result sent to driver
19/07/31 13:57:41 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 36) in 18 ms on localhost (executor driver) (1/1)
19/07/31 13:57:41 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
19/07/31 13:57:41 INFO DAGScheduler: ResultStage 33 (csv at NativeMethodAccessorImpl.java:0) finished in 0.018 s
19/07/31 13:57:41 INFO DAGScheduler: Job 24 finished: csv at NativeMethodAccessorImpl.java:0, took 0.027381 s
19/07/31 13:57:41 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:57:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:57:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:57:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:57:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:57:41 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:57:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:57:41 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 13:57:41 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 13:57:41 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 13:57:41 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:57:41 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 13:57:41 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 13:57:41 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 282.3 KB, free 908.8 MB)
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 24.0 KB, free 908.8 MB)
19/07/31 13:57:41 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:64327 (size: 24.0 KB, free: 911.9 MB)
19/07/31 13:57:41 INFO SparkContext: Created broadcast 48 from sql at <unknown>:0
19/07/31 13:57:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 539
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 534
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 541
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 665
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 840
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 740
19/07/31 13:57:41 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:64327 in memory (size: 23.8 KB, free: 911.9 MB)
19/07/31 13:57:41 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:64327 in memory (size: 3.7 KB, free: 911.9 MB)
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 979
19/07/31 13:57:41 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 13:57:41 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:64327 in memory (size: 3.5 KB, free: 911.9 MB)
19/07/31 13:57:41 INFO DAGScheduler: Registering RDD 139 (sql at <unknown>:0)
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 601
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 796
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 769
19/07/31 13:57:41 INFO DAGScheduler: Got job 25 (sql at <unknown>:0) with 1 output partitions
19/07/31 13:57:41 INFO DAGScheduler: Final stage: ResultStage 35 (sql at <unknown>:0)
19/07/31 13:57:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
19/07/31 13:57:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 34)
19/07/31 13:57:41 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:64327 in memory (size: 4.3 KB, free: 911.9 MB)
19/07/31 13:57:41 INFO DAGScheduler: Submitting ShuffleMapStage 34 (MapPartitionsRDD[139] at sql at <unknown>:0), which has no missing parents
19/07/31 13:57:41 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:64327 in memory (size: 29.7 KB, free: 912.0 MB)
19/07/31 13:57:41 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:64327 in memory (size: 24.0 KB, free: 912.0 MB)
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 548
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 547
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 797
19/07/31 13:57:41 INFO ContextCleaner: Cleaned shuffle 7
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 26.3 KB, free 909.5 MB)
19/07/31 13:57:41 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:64327 in memory (size: 23.8 KB, free: 912.0 MB)
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 550
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 798
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 11.9 KB, free 909.8 MB)
19/07/31 13:57:41 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:64327 in memory (size: 7.4 KB, free: 912.0 MB)
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 537
19/07/31 13:57:41 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:64327 (size: 11.9 KB, free: 912.0 MB)
19/07/31 13:57:41 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
19/07/31 13:57:41 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:64327 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 13:57:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[139] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:57:41 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 981
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 542
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 549
19/07/31 13:57:41 INFO BlockManager: Removing RDD 71
19/07/31 13:57:41 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:57:41 INFO ContextCleaner: Cleaned RDD 71
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 536
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 606
19/07/31 13:57:41 INFO Executor: Running task 0.0 in stage 34.0 (TID 37)
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 841
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 831
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 977
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 1007
19/07/31 13:57:41 INFO ContextCleaner: Cleaned shuffle 5
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 1008
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 832
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 767
19/07/31 13:57:41 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:64327 in memory (size: 8.6 KB, free: 912.0 MB)
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 666
19/07/31 13:57:41 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:64327 in memory (size: 23.8 KB, free: 912.0 MB)
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 603
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 543
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 544
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 768
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 600
19/07/31 13:57:41 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:64327 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 660
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 980
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 602
19/07/31 13:57:41 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:64327 in memory (size: 11.9 KB, free: 912.1 MB)
19/07/31 13:57:41 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:57:41 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:64327 in memory (size: 4.3 KB, free: 912.1 MB)
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 770
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 610
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 661
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 795
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 611
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 891
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 607
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 835
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 1009
19/07/31 13:57:41 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:64327 in memory (size: 8.6 KB, free: 912.1 MB)
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 609
19/07/31 13:57:41 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:64327 in memory (size: 23.8 KB, free: 912.1 MB)
19/07/31 13:57:41 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:64327 in memory (size: 3.5 KB, free: 912.1 MB)
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 662
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 608
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 664
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 1010
19/07/31 13:57:41 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:64327 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 13:57:41 INFO ContextCleaner: Cleaned shuffle 4
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 830
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 842
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 837
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 605
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 545
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 604
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 978
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 765
19/07/31 13:57:41 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:64327 in memory (size: 31.2 KB, free: 912.1 MB)
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 535
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 839
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 952
19/07/31 13:57:41 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:64327 in memory (size: 11.9 KB, free: 912.1 MB)
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 1011
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 834
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 1042
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 540
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 663
19/07/31 13:57:41 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:64327 in memory (size: 11.8 KB, free: 912.2 MB)
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 838
19/07/31 13:57:41 INFO ContextCleaner: Cleaned shuffle 6
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 546
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 982
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 833
19/07/31 13:57:41 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:64327 in memory (size: 11.8 KB, free: 912.2 MB)
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 836
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 532
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 599
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 799
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 533
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 667
19/07/31 13:57:41 INFO ContextCleaner: Cleaned accumulator 766
19/07/31 13:57:41 INFO MemoryStore: Block rdd_136_0 stored as values in memory (estimated size 48.9 KB, free 910.7 MB)
19/07/31 13:57:41 INFO BlockManagerInfo: Added rdd_136_0 in memory on 127.0.0.1:64327 (size: 48.9 KB, free: 912.1 MB)
19/07/31 13:57:41 INFO Executor: Finished task 0.0 in stage 34.0 (TID 37). 2461 bytes result sent to driver
19/07/31 13:57:41 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 37) in 32 ms on localhost (executor driver) (1/1)
19/07/31 13:57:41 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
19/07/31 13:57:41 INFO DAGScheduler: ShuffleMapStage 34 (sql at <unknown>:0) finished in 0.032 s
19/07/31 13:57:41 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:57:41 INFO DAGScheduler: running: Set()
19/07/31 13:57:41 INFO DAGScheduler: waiting: Set(ResultStage 35)
19/07/31 13:57:41 INFO DAGScheduler: failed: Set()
19/07/31 13:57:41 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[142] at sql at <unknown>:0), which has no missing parents
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 7.0 KB, free 910.7 MB)
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.7 MB)
19/07/31 13:57:41 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:64327 (size: 3.7 KB, free: 912.1 MB)
19/07/31 13:57:41 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
19/07/31 13:57:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[142] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:57:41 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
19/07/31 13:57:41 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 38, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:57:41 INFO Executor: Running task 0.0 in stage 35.0 (TID 38)
19/07/31 13:57:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:57:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:57:41 INFO Executor: Finished task 0.0 in stage 35.0 (TID 38). 1581 bytes result sent to driver
19/07/31 13:57:41 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 38) in 5 ms on localhost (executor driver) (1/1)
19/07/31 13:57:41 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
19/07/31 13:57:41 INFO DAGScheduler: ResultStage 35 (sql at <unknown>:0) finished in 0.005 s
19/07/31 13:57:41 INFO DAGScheduler: Job 25 finished: sql at <unknown>:0, took 0.051138 s
19/07/31 13:57:41 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 13:57:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:57:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:57:41 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:57:41 INFO DAGScheduler: Registering RDD 145 (collect at utils.scala:204)
19/07/31 13:57:41 INFO DAGScheduler: Got job 26 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:57:41 INFO DAGScheduler: Final stage: ResultStage 37 (collect at utils.scala:204)
19/07/31 13:57:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)
19/07/31 13:57:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 36)
19/07/31 13:57:41 INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[145] at collect at utils.scala:204), which has no missing parents
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 26.3 KB, free 910.7 MB)
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 11.9 KB, free 910.7 MB)
19/07/31 13:57:41 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:64327 (size: 11.9 KB, free: 912.1 MB)
19/07/31 13:57:41 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
19/07/31 13:57:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[145] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:57:41 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
19/07/31 13:57:41 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:57:41 INFO Executor: Running task 0.0 in stage 36.0 (TID 39)
19/07/31 13:57:41 INFO BlockManager: Found block rdd_136_0 locally
19/07/31 13:57:41 INFO Executor: Finished task 0.0 in stage 36.0 (TID 39). 1780 bytes result sent to driver
19/07/31 13:57:41 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 39) in 7 ms on localhost (executor driver) (1/1)
19/07/31 13:57:41 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
19/07/31 13:57:41 INFO DAGScheduler: ShuffleMapStage 36 (collect at utils.scala:204) finished in 0.007 s
19/07/31 13:57:41 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:57:41 INFO DAGScheduler: running: Set()
19/07/31 13:57:41 INFO DAGScheduler: waiting: Set(ResultStage 37)
19/07/31 13:57:41 INFO DAGScheduler: failed: Set()
19/07/31 13:57:41 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[148] at collect at utils.scala:204), which has no missing parents
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 7.0 KB, free 910.7 MB)
19/07/31 13:57:41 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.7 MB)
19/07/31 13:57:41 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:64327 (size: 3.7 KB, free: 912.1 MB)
19/07/31 13:57:41 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1006
19/07/31 13:57:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[148] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:57:41 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
19/07/31 13:57:41 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 40, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:57:41 INFO Executor: Running task 0.0 in stage 37.0 (TID 40)
19/07/31 13:57:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:57:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:57:41 INFO Executor: Finished task 0.0 in stage 37.0 (TID 40). 1581 bytes result sent to driver
19/07/31 13:57:41 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 40) in 3 ms on localhost (executor driver) (1/1)
19/07/31 13:57:41 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
19/07/31 13:57:41 INFO DAGScheduler: ResultStage 37 (collect at utils.scala:204) finished in 0.004 s
19/07/31 13:57:41 INFO DAGScheduler: Job 26 finished: collect at utils.scala:204, took 0.020695 s
19/07/31 13:57:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz5`
WHERE (0 = 1)
19/07/31 13:57:41 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:57:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:57:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:57:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:57:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:57:41 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:57:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:57:41 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:57:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:57:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:57:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:57:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:57:41 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:57:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:59:25 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:59:25 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:59:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:59:25 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:59:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:59:25 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:59:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:59:25 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 13:59:25 INFO DAGScheduler: Got job 27 (collect at utils.scala:44) with 1 output partitions
19/07/31 13:59:25 INFO DAGScheduler: Final stage: ResultStage 38 (collect at utils.scala:44)
19/07/31 13:59:25 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:59:25 INFO DAGScheduler: Missing parents: List()
19/07/31 13:59:25 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[153] at map at utils.scala:41), which has no missing parents
19/07/31 13:59:25 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 6.3 KB, free 910.6 MB)
19/07/31 13:59:25 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 3.5 KB, free 910.6 MB)
19/07/31 13:59:25 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:64327 (size: 3.5 KB, free: 912.1 MB)
19/07/31 13:59:25 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
19/07/31 13:59:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[153] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 13:59:25 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
19/07/31 13:59:25 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 13:59:25 INFO Executor: Running task 0.0 in stage 38.0 (TID 41)
19/07/31 13:59:25 INFO Executor: Finished task 0.0 in stage 38.0 (TID 41). 1007 bytes result sent to driver
19/07/31 13:59:25 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 41) in 5 ms on localhost (executor driver) (1/1)
19/07/31 13:59:25 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
19/07/31 13:59:25 INFO DAGScheduler: ResultStage 38 (collect at utils.scala:44) finished in 0.006 s
19/07/31 13:59:25 INFO DAGScheduler: Job 27 finished: collect at utils.scala:44, took 0.018332 s
19/07/31 13:59:25 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 13:59:25 INFO MapPartitionsRDD: Removing RDD 136 from persistence list
19/07/31 13:59:25 INFO BlockManager: Removing RDD 136
19/07/31 13:59:25 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:59:25 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#2012)) > 0)
19/07/31 13:59:25 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 13:59:25 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:59:25 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 281.2 KB, free 910.4 MB)
19/07/31 13:59:25 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 23.8 KB, free 910.4 MB)
19/07/31 13:59:25 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:64327 (size: 23.8 KB, free: 912.1 MB)
19/07/31 13:59:25 INFO SparkContext: Created broadcast 54 from csv at NativeMethodAccessorImpl.java:0
19/07/31 13:59:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:59:25 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:59:25 INFO DAGScheduler: Got job 28 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:59:25 INFO DAGScheduler: Final stage: ResultStage 39 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:59:25 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:59:25 INFO DAGScheduler: Missing parents: List()
19/07/31 13:59:25 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[156] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:59:25 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 8.2 KB, free 910.4 MB)
19/07/31 13:59:25 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 4.3 KB, free 910.4 MB)
19/07/31 13:59:25 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:64327 (size: 4.3 KB, free: 912.1 MB)
19/07/31 13:59:25 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
19/07/31 13:59:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[156] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:59:25 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
19/07/31 13:59:25 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 42, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:59:25 INFO Executor: Running task 0.0 in stage 39.0 (TID 42)
19/07/31 13:59:25 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:59:25 INFO Executor: Finished task 0.0 in stage 39.0 (TID 42). 1394 bytes result sent to driver
19/07/31 13:59:25 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 42) in 24 ms on localhost (executor driver) (1/1)
19/07/31 13:59:25 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
19/07/31 13:59:25 INFO DAGScheduler: ResultStage 39 (csv at NativeMethodAccessorImpl.java:0) finished in 0.024 s
19/07/31 13:59:25 INFO DAGScheduler: Job 28 finished: csv at NativeMethodAccessorImpl.java:0, took 0.028934 s
19/07/31 13:59:25 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:59:25 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 13:59:25 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 13:59:25 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:59:25 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 281.2 KB, free 910.1 MB)
19/07/31 13:59:25 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 23.8 KB, free 910.1 MB)
19/07/31 13:59:25 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:64327 (size: 23.8 KB, free: 912.1 MB)
19/07/31 13:59:25 INFO SparkContext: Created broadcast 56 from csv at NativeMethodAccessorImpl.java:0
19/07/31 13:59:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:59:25 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 13:59:25 INFO DAGScheduler: Got job 29 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 13:59:25 INFO DAGScheduler: Final stage: ResultStage 40 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 13:59:25 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:59:25 INFO DAGScheduler: Missing parents: List()
19/07/31 13:59:25 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[161] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 13:59:25 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 14.8 KB, free 910.1 MB)
19/07/31 13:59:25 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 8.6 KB, free 910.1 MB)
19/07/31 13:59:25 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:64327 (size: 8.6 KB, free: 912.1 MB)
19/07/31 13:59:25 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
19/07/31 13:59:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[161] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:59:25 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
19/07/31 13:59:25 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:59:25 INFO Executor: Running task 0.0 in stage 40.0 (TID 43)
19/07/31 13:59:25 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:59:25 INFO Executor: Finished task 0.0 in stage 40.0 (TID 43). 1584 bytes result sent to driver
19/07/31 13:59:25 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 43) in 12 ms on localhost (executor driver) (1/1)
19/07/31 13:59:25 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
19/07/31 13:59:25 INFO DAGScheduler: ResultStage 40 (csv at NativeMethodAccessorImpl.java:0) finished in 0.012 s
19/07/31 13:59:25 INFO DAGScheduler: Job 29 finished: csv at NativeMethodAccessorImpl.java:0, took 0.016578 s
19/07/31 13:59:25 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:59:25 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:59:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:59:25 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:59:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:59:25 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:59:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:59:26 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 13:59:26 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 13:59:26 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 13:59:26 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 13:59:26 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 13:59:26 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 13:59:26 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 13:59:26 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 282.3 KB, free 909.8 MB)
19/07/31 13:59:26 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 24.0 KB, free 909.8 MB)
19/07/31 13:59:26 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:64327 (size: 24.0 KB, free: 912.1 MB)
19/07/31 13:59:26 INFO SparkContext: Created broadcast 58 from sql at <unknown>:0
19/07/31 13:59:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 13:59:26 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 13:59:26 INFO DAGScheduler: Registering RDD 167 (sql at <unknown>:0)
19/07/31 13:59:26 INFO DAGScheduler: Got job 30 (sql at <unknown>:0) with 1 output partitions
19/07/31 13:59:26 INFO DAGScheduler: Final stage: ResultStage 42 (sql at <unknown>:0)
19/07/31 13:59:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
19/07/31 13:59:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
19/07/31 13:59:26 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[167] at sql at <unknown>:0), which has no missing parents
19/07/31 13:59:26 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 26.3 KB, free 909.7 MB)
19/07/31 13:59:26 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 11.8 KB, free 909.7 MB)
19/07/31 13:59:26 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:64327 (size: 11.8 KB, free: 912.1 MB)
19/07/31 13:59:26 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
19/07/31 13:59:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[167] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:59:26 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
19/07/31 13:59:26 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:59:26 INFO Executor: Running task 0.0 in stage 41.0 (TID 44)
19/07/31 13:59:26 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 13:59:26 INFO MemoryStore: Block rdd_164_0 stored as values in memory (estimated size 48.9 KB, free 909.7 MB)
19/07/31 13:59:26 INFO BlockManagerInfo: Added rdd_164_0 in memory on 127.0.0.1:64327 (size: 48.9 KB, free: 912.0 MB)
19/07/31 13:59:26 INFO Executor: Finished task 0.0 in stage 41.0 (TID 44). 2461 bytes result sent to driver
19/07/31 13:59:26 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 44) in 23 ms on localhost (executor driver) (1/1)
19/07/31 13:59:26 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
19/07/31 13:59:26 INFO DAGScheduler: ShuffleMapStage 41 (sql at <unknown>:0) finished in 0.023 s
19/07/31 13:59:26 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:59:26 INFO DAGScheduler: running: Set()
19/07/31 13:59:26 INFO DAGScheduler: waiting: Set(ResultStage 42)
19/07/31 13:59:26 INFO DAGScheduler: failed: Set()
19/07/31 13:59:26 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[170] at sql at <unknown>:0), which has no missing parents
19/07/31 13:59:26 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 7.0 KB, free 909.7 MB)
19/07/31 13:59:26 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 3.7 KB, free 909.7 MB)
19/07/31 13:59:26 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:64327 (size: 3.7 KB, free: 912.0 MB)
19/07/31 13:59:26 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
19/07/31 13:59:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[170] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 13:59:26 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
19/07/31 13:59:26 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 45, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:59:26 INFO Executor: Running task 0.0 in stage 42.0 (TID 45)
19/07/31 13:59:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:59:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:59:26 INFO Executor: Finished task 0.0 in stage 42.0 (TID 45). 1538 bytes result sent to driver
19/07/31 13:59:26 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 45) in 3 ms on localhost (executor driver) (1/1)
19/07/31 13:59:26 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
19/07/31 13:59:26 INFO DAGScheduler: ResultStage 42 (sql at <unknown>:0) finished in 0.003 s
19/07/31 13:59:26 INFO DAGScheduler: Job 30 finished: sql at <unknown>:0, took 0.038385 s
19/07/31 13:59:26 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 13:59:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:59:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:59:26 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:59:26 INFO DAGScheduler: Registering RDD 173 (collect at utils.scala:204)
19/07/31 13:59:26 INFO DAGScheduler: Got job 31 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:59:26 INFO DAGScheduler: Final stage: ResultStage 44 (collect at utils.scala:204)
19/07/31 13:59:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 43)
19/07/31 13:59:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 43)
19/07/31 13:59:26 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[173] at collect at utils.scala:204), which has no missing parents
19/07/31 13:59:26 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 26.3 KB, free 909.6 MB)
19/07/31 13:59:26 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 11.9 KB, free 909.6 MB)
19/07/31 13:59:26 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:64327 (size: 11.9 KB, free: 912.0 MB)
19/07/31 13:59:26 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
19/07/31 13:59:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[173] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:59:26 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
19/07/31 13:59:26 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:59:26 INFO Executor: Running task 0.0 in stage 43.0 (TID 46)
19/07/31 13:59:26 INFO BlockManager: Found block rdd_164_0 locally
19/07/31 13:59:26 INFO Executor: Finished task 0.0 in stage 43.0 (TID 46). 1780 bytes result sent to driver
19/07/31 13:59:26 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 46) in 6 ms on localhost (executor driver) (1/1)
19/07/31 13:59:26 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
19/07/31 13:59:26 INFO DAGScheduler: ShuffleMapStage 43 (collect at utils.scala:204) finished in 0.006 s
19/07/31 13:59:26 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:59:26 INFO DAGScheduler: running: Set()
19/07/31 13:59:26 INFO DAGScheduler: waiting: Set(ResultStage 44)
19/07/31 13:59:26 INFO DAGScheduler: failed: Set()
19/07/31 13:59:26 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[176] at collect at utils.scala:204), which has no missing parents
19/07/31 13:59:26 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 7.0 KB, free 909.6 MB)
19/07/31 13:59:26 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 3.7 KB, free 909.6 MB)
19/07/31 13:59:26 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:64327 (size: 3.7 KB, free: 912.0 MB)
19/07/31 13:59:26 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
19/07/31 13:59:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[176] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:59:26 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
19/07/31 13:59:26 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 47, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:59:26 INFO Executor: Running task 0.0 in stage 44.0 (TID 47)
19/07/31 13:59:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:59:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:59:26 INFO Executor: Finished task 0.0 in stage 44.0 (TID 47). 1581 bytes result sent to driver
19/07/31 13:59:26 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 47) in 3 ms on localhost (executor driver) (1/1)
19/07/31 13:59:26 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
19/07/31 13:59:26 INFO DAGScheduler: ResultStage 44 (collect at utils.scala:204) finished in 0.004 s
19/07/31 13:59:26 INFO DAGScheduler: Job 31 finished: collect at utils.scala:204, took 0.017395 s
19/07/31 13:59:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz6`
WHERE (0 = 1)
19/07/31 13:59:26 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 13:59:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:59:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:59:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:59:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:59:26 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 13:59:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 13:59:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_009`) `dbplyr_010`
ORDER BY `date`) `dbplyr_011`) `dbplyr_012`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 13:59:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:59:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:59:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_013`) `dbplyr_014`
ORDER BY `date`) `dbplyr_015`) `dbplyr_016`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 13:59:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 13:59:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 13:59:41 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#2035) generates partition filter: ((cust_prospect_ind.count#2451 - cust_prospect_ind.nullCount#2450) > 0)
19/07/31 13:59:41 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#2036) generates partition filter: ((visit_device_type.count#2456 - visit_device_type.nullCount#2455) > 0)
19/07/31 13:59:41 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#2035 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#2449 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#2448))
19/07/31 13:59:41 INFO InMemoryTableScanExec: Predicate (visit_device_type#2036 = All Devices) generates partition filter: ((visit_device_type.lowerBound#2454 <= All Devices) && (All Devices <= visit_device_type.upperBound#2453))
19/07/31 13:59:41 INFO CodeGenerator: Code generated in 14.552344 ms
19/07/31 13:59:41 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:59:41 INFO DAGScheduler: Got job 32 (collect at utils.scala:204) with 1 output partitions
19/07/31 13:59:41 INFO DAGScheduler: Final stage: ResultStage 45 (collect at utils.scala:204)
19/07/31 13:59:41 INFO DAGScheduler: Parents of final stage: List()
19/07/31 13:59:41 INFO DAGScheduler: Missing parents: List()
19/07/31 13:59:41 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[181] at collect at utils.scala:204), which has no missing parents
19/07/31 13:59:41 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 72.1 KB, free 909.5 MB)
19/07/31 13:59:41 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.5 MB)
19/07/31 13:59:41 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:64327 (size: 30.5 KB, free: 912.0 MB)
19/07/31 13:59:41 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
19/07/31 13:59:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[181] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:59:41 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
19/07/31 13:59:41 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 13:59:41 INFO Executor: Running task 0.0 in stage 45.0 (TID 48)
19/07/31 13:59:41 INFO BlockManager: Found block rdd_164_0 locally
19/07/31 13:59:41 INFO CodeGenerator: Code generated in 7.172761 ms
19/07/31 13:59:41 INFO CodeGenerator: Code generated in 11.868539 ms
19/07/31 13:59:41 INFO Executor: Finished task 0.0 in stage 45.0 (TID 48). 7542 bytes result sent to driver
19/07/31 13:59:41 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 48) in 33 ms on localhost (executor driver) (1/1)
19/07/31 13:59:41 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
19/07/31 13:59:41 INFO DAGScheduler: ResultStage 45 (collect at utils.scala:204) finished in 0.033 s
19/07/31 13:59:41 INFO DAGScheduler: Job 32 finished: collect at utils.scala:204, took 0.040775 s
19/07/31 13:59:41 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 13:59:41 INFO DAGScheduler: Registering RDD 182 (collect at utils.scala:204)
19/07/31 13:59:41 INFO DAGScheduler: Got job 33 (collect at utils.scala:204) with 4 output partitions
19/07/31 13:59:41 INFO DAGScheduler: Final stage: ResultStage 47 (collect at utils.scala:204)
19/07/31 13:59:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
19/07/31 13:59:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 46)
19/07/31 13:59:41 INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[182] at collect at utils.scala:204), which has no missing parents
19/07/31 13:59:41 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 74.5 KB, free 909.4 MB)
19/07/31 13:59:41 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.4 MB)
19/07/31 13:59:41 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:64327 (size: 31.8 KB, free: 911.9 MB)
19/07/31 13:59:41 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1006
19/07/31 13:59:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[182] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 13:59:41 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
19/07/31 13:59:41 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 13:59:41 INFO Executor: Running task 0.0 in stage 46.0 (TID 49)
19/07/31 13:59:41 INFO BlockManager: Found block rdd_164_0 locally
19/07/31 13:59:41 INFO Executor: Finished task 0.0 in stage 46.0 (TID 49). 1687 bytes result sent to driver
19/07/31 13:59:41 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 49) in 16 ms on localhost (executor driver) (1/1)
19/07/31 13:59:41 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
19/07/31 13:59:41 INFO DAGScheduler: ShuffleMapStage 46 (collect at utils.scala:204) finished in 0.017 s
19/07/31 13:59:41 INFO DAGScheduler: looking for newly runnable stages
19/07/31 13:59:41 INFO DAGScheduler: running: Set()
19/07/31 13:59:41 INFO DAGScheduler: waiting: Set(ResultStage 47)
19/07/31 13:59:41 INFO DAGScheduler: failed: Set()
19/07/31 13:59:41 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[185] at collect at utils.scala:204), which has no missing parents
19/07/31 13:59:41 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 16.8 KB, free 909.4 MB)
19/07/31 13:59:41 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.4 MB)
19/07/31 13:59:41 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:64327 (size: 8.0 KB, free: 911.9 MB)
19/07/31 13:59:41 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1006
19/07/31 13:59:41 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 47 (MapPartitionsRDD[185] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 13:59:41 INFO TaskSchedulerImpl: Adding task set 47.0 with 4 tasks
19/07/31 13:59:41 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 50, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 13:59:41 INFO TaskSetManager: Starting task 1.0 in stage 47.0 (TID 51, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 13:59:41 INFO TaskSetManager: Starting task 2.0 in stage 47.0 (TID 52, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 13:59:41 INFO TaskSetManager: Starting task 3.0 in stage 47.0 (TID 53, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 13:59:41 INFO Executor: Running task 0.0 in stage 47.0 (TID 50)
19/07/31 13:59:41 INFO Executor: Running task 1.0 in stage 47.0 (TID 51)
19/07/31 13:59:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:59:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:59:41 INFO Executor: Running task 2.0 in stage 47.0 (TID 52)
19/07/31 13:59:41 INFO Executor: Running task 3.0 in stage 47.0 (TID 53)
19/07/31 13:59:41 INFO Executor: Finished task 0.0 in stage 47.0 (TID 50). 2382 bytes result sent to driver
19/07/31 13:59:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:59:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:59:41 INFO Executor: Finished task 3.0 in stage 47.0 (TID 53). 2362 bytes result sent to driver
19/07/31 13:59:41 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 50) in 14 ms on localhost (executor driver) (1/4)
19/07/31 13:59:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:59:41 INFO TaskSetManager: Finished task 3.0 in stage 47.0 (TID 53) in 15 ms on localhost (executor driver) (2/4)
19/07/31 13:59:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 13:59:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 13:59:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 13:59:41 INFO Executor: Finished task 2.0 in stage 47.0 (TID 52). 2390 bytes result sent to driver
19/07/31 13:59:41 INFO Executor: Finished task 1.0 in stage 47.0 (TID 51). 2403 bytes result sent to driver
19/07/31 13:59:41 INFO TaskSetManager: Finished task 2.0 in stage 47.0 (TID 52) in 18 ms on localhost (executor driver) (3/4)
19/07/31 13:59:41 INFO TaskSetManager: Finished task 1.0 in stage 47.0 (TID 51) in 19 ms on localhost (executor driver) (4/4)
19/07/31 13:59:41 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
19/07/31 13:59:41 INFO DAGScheduler: ResultStage 47 (collect at utils.scala:204) finished in 0.020 s
19/07/31 13:59:41 INFO DAGScheduler: Job 33 finished: collect at utils.scala:204, took 0.050187 s
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 49
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1110
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1112
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 394
19/07/31 14:24:42 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:64327 in memory (size: 11.8 KB, free: 911.9 MB)
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1044
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1111
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1189
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1323
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1046
19/07/31 14:24:42 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:64327 in memory (size: 11.9 KB, free: 911.9 MB)
19/07/31 14:24:42 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:64327 in memory (size: 24.0 KB, free: 912.0 MB)
19/07/31 14:24:42 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:64327 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1040
19/07/31 14:24:42 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:64327 in memory (size: 4.3 KB, free: 912.0 MB)
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 901
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1264
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1104
19/07/31 14:24:42 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:64327 in memory (size: 11.9 KB, free: 912.0 MB)
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 393
19/07/31 14:24:42 INFO ContextCleaner: Cleaned shuffle 8
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 828
19/07/31 14:24:42 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:64327 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 14:24:42 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:64327 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 897
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1113
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 395
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1219
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1105
19/07/31 14:24:42 INFO BlockManager: Removing RDD 136
19/07/31 14:24:42 INFO ContextCleaner: Cleaned RDD 136
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 893
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1036
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1266
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1327
19/07/31 14:24:42 INFO BlockManager: Removing RDD 43
19/07/31 14:24:42 INFO ContextCleaner: Cleaned RDD 43
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1037
19/07/31 14:24:42 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:64327 in memory (size: 11.9 KB, free: 912.0 MB)
19/07/31 14:24:42 INFO ContextCleaner: Cleaned shuffle 9
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 896
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1223
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 894
19/07/31 14:24:42 INFO ContextCleaner: Cleaned shuffle 11
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1115
19/07/31 14:24:42 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:64327 in memory (size: 24.0 KB, free: 912.0 MB)
19/07/31 14:24:42 INFO ContextCleaner: Cleaned shuffle 12
19/07/31 14:24:42 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:64327 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1320
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 325
19/07/31 14:24:42 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:64327 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 14:24:42 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:64327 in memory (size: 8.6 KB, free: 912.0 MB)
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 322
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 389
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1325
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1326
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 825
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1043
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1038
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 826
19/07/31 14:24:42 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:64327 in memory (size: 23.8 KB, free: 912.1 MB)
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 323
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1045
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1114
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 324
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1049
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1103
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1316
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 320
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1222
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1191
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 902
19/07/31 14:24:42 INFO BlockManager: Removing RDD 108
19/07/31 14:24:42 INFO ContextCleaner: Cleaned RDD 108
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1265
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 388
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 895
19/07/31 14:24:42 INFO ContextCleaner: Cleaned shuffle 10
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1260
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1315
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1039
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1109
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1107
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1053
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1321
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1262
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1318
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 397
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 824
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 321
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1255
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1193
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 899
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1106
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1051
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1190
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1054
19/07/31 14:24:42 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:64327 in memory (size: 31.8 KB, free: 912.1 MB)
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 892
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 903
19/07/31 14:24:42 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:64327 in memory (size: 23.8 KB, free: 912.1 MB)
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1221
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1324
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1050
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1047
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1164
19/07/31 14:24:42 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:64327 in memory (size: 24.0 KB, free: 912.1 MB)
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1376
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1052
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 399
19/07/31 14:24:42 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:64327 in memory (size: 3.5 KB, free: 912.1 MB)
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1048
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1220
19/07/31 14:24:42 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:64327 in memory (size: 30.5 KB, free: 912.2 MB)
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1319
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1041
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1259
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1258
19/07/31 14:24:42 INFO ContextCleaner: Cleaned shuffle 3
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 392
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1261
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1257
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1263
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 391
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 396
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1192
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 390
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1317
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1108
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 827
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1322
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 398
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1256
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 829
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 898
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1254
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 1194
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 900
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 53
19/07/31 14:24:42 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:64327 in memory (size: 23.8 KB, free: 912.2 MB)
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 79
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 54
19/07/31 14:24:42 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:64327 in memory (size: 4.3 KB, free: 912.2 MB)
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 82
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 83
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 50
19/07/31 14:24:42 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:64327 in memory (size: 23.8 KB, free: 912.2 MB)
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 80
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 51
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 52
19/07/31 14:24:42 INFO ContextCleaner: Cleaned accumulator 81
19/07/31 14:55:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 14:55:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 14:55:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 14:55:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 14:55:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 14:55:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 14:55:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 14:55:36 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 14:55:36 INFO DAGScheduler: Got job 34 (collect at utils.scala:44) with 1 output partitions
19/07/31 14:55:36 INFO DAGScheduler: Final stage: ResultStage 48 (collect at utils.scala:44)
19/07/31 14:55:36 INFO DAGScheduler: Parents of final stage: List()
19/07/31 14:55:36 INFO DAGScheduler: Missing parents: List()
19/07/31 14:55:36 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[190] at map at utils.scala:41), which has no missing parents
19/07/31 14:55:36 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 6.3 KB, free 911.9 MB)
19/07/31 14:55:36 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 3.5 KB, free 911.9 MB)
19/07/31 14:55:36 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:64327 (size: 3.5 KB, free: 912.2 MB)
19/07/31 14:55:36 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1006
19/07/31 14:55:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[190] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 14:55:36 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
19/07/31 14:55:36 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 14:55:36 INFO Executor: Running task 0.0 in stage 48.0 (TID 54)
19/07/31 14:55:36 INFO Executor: Finished task 0.0 in stage 48.0 (TID 54). 1007 bytes result sent to driver
19/07/31 14:55:36 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 54) in 17 ms on localhost (executor driver) (1/1)
19/07/31 14:55:36 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
19/07/31 14:55:36 INFO DAGScheduler: ResultStage 48 (collect at utils.scala:44) finished in 0.019 s
19/07/31 14:55:36 INFO DAGScheduler: Job 34 finished: collect at utils.scala:44, took 0.058657 s
19/07/31 14:55:36 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 14:55:36 INFO MapPartitionsRDD: Removing RDD 164 from persistence list
19/07/31 14:55:36 INFO BlockManager: Removing RDD 164
19/07/31 14:55:36 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 14:55:36 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#2489)) > 0)
19/07/31 14:55:36 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 14:55:36 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 14:55:36 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 281.2 KB, free 911.7 MB)
19/07/31 14:55:36 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.7 MB)
19/07/31 14:55:36 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:64327 (size: 23.8 KB, free: 912.2 MB)
19/07/31 14:55:36 INFO SparkContext: Created broadcast 67 from csv at NativeMethodAccessorImpl.java:0
19/07/31 14:55:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 14:55:36 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 14:55:36 INFO DAGScheduler: Got job 35 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 14:55:36 INFO DAGScheduler: Final stage: ResultStage 49 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 14:55:36 INFO DAGScheduler: Parents of final stage: List()
19/07/31 14:55:36 INFO DAGScheduler: Missing parents: List()
19/07/31 14:55:36 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[193] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 14:55:36 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 8.2 KB, free 911.7 MB)
19/07/31 14:55:36 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 4.3 KB, free 911.7 MB)
19/07/31 14:55:36 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:64327 (size: 4.3 KB, free: 912.2 MB)
19/07/31 14:55:36 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1006
19/07/31 14:55:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[193] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 14:55:36 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
19/07/31 14:55:36 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 14:55:36 INFO Executor: Running task 0.0 in stage 49.0 (TID 55)
19/07/31 14:55:36 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 14:55:36 INFO Executor: Finished task 0.0 in stage 49.0 (TID 55). 1394 bytes result sent to driver
19/07/31 14:55:36 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 55) in 25 ms on localhost (executor driver) (1/1)
19/07/31 14:55:36 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
19/07/31 14:55:36 INFO DAGScheduler: ResultStage 49 (csv at NativeMethodAccessorImpl.java:0) finished in 0.025 s
19/07/31 14:55:36 INFO DAGScheduler: Job 35 finished: csv at NativeMethodAccessorImpl.java:0, took 0.034107 s
19/07/31 14:55:36 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 14:55:36 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 14:55:36 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 14:55:36 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 14:55:36 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 281.2 KB, free 911.4 MB)
19/07/31 14:55:36 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.4 MB)
19/07/31 14:55:36 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:64327 (size: 23.8 KB, free: 912.2 MB)
19/07/31 14:55:36 INFO SparkContext: Created broadcast 69 from csv at NativeMethodAccessorImpl.java:0
19/07/31 14:55:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 14:55:36 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 14:55:36 INFO DAGScheduler: Got job 36 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 14:55:36 INFO DAGScheduler: Final stage: ResultStage 50 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 14:55:36 INFO DAGScheduler: Parents of final stage: List()
19/07/31 14:55:36 INFO DAGScheduler: Missing parents: List()
19/07/31 14:55:36 INFO DAGScheduler: Submitting ResultStage 50 (MapPartitionsRDD[198] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 14:55:36 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 14.8 KB, free 911.4 MB)
19/07/31 14:55:36 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.4 MB)
19/07/31 14:55:36 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:64327 (size: 8.6 KB, free: 912.2 MB)
19/07/31 14:55:36 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1006
19/07/31 14:55:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (MapPartitionsRDD[198] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 14:55:36 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
19/07/31 14:55:36 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 14:55:36 INFO Executor: Running task 0.0 in stage 50.0 (TID 56)
19/07/31 14:55:36 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 14:55:36 INFO Executor: Finished task 0.0 in stage 50.0 (TID 56). 1584 bytes result sent to driver
19/07/31 14:55:36 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 56) in 27 ms on localhost (executor driver) (1/1)
19/07/31 14:55:36 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
19/07/31 14:55:36 INFO DAGScheduler: ResultStage 50 (csv at NativeMethodAccessorImpl.java:0) finished in 0.027 s
19/07/31 14:55:36 INFO DAGScheduler: Job 36 finished: csv at NativeMethodAccessorImpl.java:0, took 0.037773 s
19/07/31 14:55:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 14:55:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 14:55:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 14:55:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 14:55:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 14:55:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 14:55:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 14:55:36 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 14:55:36 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 14:55:36 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 14:55:36 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 14:55:36 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 14:55:36 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 14:55:36 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 14:55:36 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 282.3 KB, free 911.1 MB)
19/07/31 14:55:36 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.1 MB)
19/07/31 14:55:36 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:64327 (size: 24.0 KB, free: 912.2 MB)
19/07/31 14:55:36 INFO SparkContext: Created broadcast 71 from sql at <unknown>:0
19/07/31 14:55:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 14:55:36 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 14:55:36 INFO DAGScheduler: Registering RDD 204 (sql at <unknown>:0)
19/07/31 14:55:36 INFO DAGScheduler: Got job 37 (sql at <unknown>:0) with 1 output partitions
19/07/31 14:55:36 INFO DAGScheduler: Final stage: ResultStage 52 (sql at <unknown>:0)
19/07/31 14:55:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 51)
19/07/31 14:55:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 51)
19/07/31 14:55:36 INFO DAGScheduler: Submitting ShuffleMapStage 51 (MapPartitionsRDD[204] at sql at <unknown>:0), which has no missing parents
19/07/31 14:55:36 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 26.3 KB, free 911.0 MB)
19/07/31 14:55:36 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 11.8 KB, free 911.0 MB)
19/07/31 14:55:36 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:64327 (size: 11.8 KB, free: 912.2 MB)
19/07/31 14:55:36 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1006
19/07/31 14:55:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[204] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 14:55:36 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
19/07/31 14:55:36 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 14:55:36 INFO Executor: Running task 0.0 in stage 51.0 (TID 57)
19/07/31 14:55:36 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 14:55:37 INFO MemoryStore: Block rdd_201_0 stored as values in memory (estimated size 48.9 KB, free 911.0 MB)
19/07/31 14:55:37 INFO BlockManagerInfo: Added rdd_201_0 in memory on 127.0.0.1:64327 (size: 48.9 KB, free: 912.1 MB)
19/07/31 14:55:37 INFO Executor: Finished task 0.0 in stage 51.0 (TID 57). 2461 bytes result sent to driver
19/07/31 14:55:37 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 57) in 68 ms on localhost (executor driver) (1/1)
19/07/31 14:55:37 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
19/07/31 14:55:37 INFO DAGScheduler: ShuffleMapStage 51 (sql at <unknown>:0) finished in 0.069 s
19/07/31 14:55:37 INFO DAGScheduler: looking for newly runnable stages
19/07/31 14:55:37 INFO DAGScheduler: running: Set()
19/07/31 14:55:37 INFO DAGScheduler: waiting: Set(ResultStage 52)
19/07/31 14:55:37 INFO DAGScheduler: failed: Set()
19/07/31 14:55:37 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[207] at sql at <unknown>:0), which has no missing parents
19/07/31 14:55:37 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 7.0 KB, free 911.0 MB)
19/07/31 14:55:37 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.0 MB)
19/07/31 14:55:37 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:64327 (size: 3.7 KB, free: 912.1 MB)
19/07/31 14:55:37 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1006
19/07/31 14:55:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[207] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 14:55:37 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
19/07/31 14:55:37 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 58, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 14:55:37 INFO Executor: Running task 0.0 in stage 52.0 (TID 58)
19/07/31 14:55:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 14:55:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 14:55:37 INFO Executor: Finished task 0.0 in stage 52.0 (TID 58). 1581 bytes result sent to driver
19/07/31 14:55:37 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 58) in 7 ms on localhost (executor driver) (1/1)
19/07/31 14:55:37 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
19/07/31 14:55:37 INFO DAGScheduler: ResultStage 52 (sql at <unknown>:0) finished in 0.008 s
19/07/31 14:55:37 INFO DAGScheduler: Job 37 finished: sql at <unknown>:0, took 0.121894 s
19/07/31 14:55:37 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 14:55:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 14:55:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 14:55:37 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 14:55:37 INFO DAGScheduler: Registering RDD 210 (collect at utils.scala:204)
19/07/31 14:55:37 INFO DAGScheduler: Got job 38 (collect at utils.scala:204) with 1 output partitions
19/07/31 14:55:37 INFO DAGScheduler: Final stage: ResultStage 54 (collect at utils.scala:204)
19/07/31 14:55:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 53)
19/07/31 14:55:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 53)
19/07/31 14:55:37 INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[210] at collect at utils.scala:204), which has no missing parents
19/07/31 14:55:37 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 26.3 KB, free 910.9 MB)
19/07/31 14:55:37 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 11.9 KB, free 910.9 MB)
19/07/31 14:55:37 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:64327 (size: 11.9 KB, free: 912.1 MB)
19/07/31 14:55:37 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1006
19/07/31 14:55:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[210] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 14:55:37 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
19/07/31 14:55:37 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 59, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 14:55:37 INFO Executor: Running task 0.0 in stage 53.0 (TID 59)
19/07/31 14:55:37 INFO BlockManager: Found block rdd_201_0 locally
19/07/31 14:55:37 INFO Executor: Finished task 0.0 in stage 53.0 (TID 59). 1780 bytes result sent to driver
19/07/31 14:55:37 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 59) in 8 ms on localhost (executor driver) (1/1)
19/07/31 14:55:37 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
19/07/31 14:55:37 INFO DAGScheduler: ShuffleMapStage 53 (collect at utils.scala:204) finished in 0.008 s
19/07/31 14:55:37 INFO DAGScheduler: looking for newly runnable stages
19/07/31 14:55:37 INFO DAGScheduler: running: Set()
19/07/31 14:55:37 INFO DAGScheduler: waiting: Set(ResultStage 54)
19/07/31 14:55:37 INFO DAGScheduler: failed: Set()
19/07/31 14:55:37 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[213] at collect at utils.scala:204), which has no missing parents
19/07/31 14:55:37 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 7.0 KB, free 910.9 MB)
19/07/31 14:55:37 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.9 MB)
19/07/31 14:55:37 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:64327 (size: 3.7 KB, free: 912.1 MB)
19/07/31 14:55:37 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1006
19/07/31 14:55:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[213] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 14:55:37 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
19/07/31 14:55:37 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 60, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 14:55:37 INFO Executor: Running task 0.0 in stage 54.0 (TID 60)
19/07/31 14:55:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 14:55:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 14:55:37 INFO Executor: Finished task 0.0 in stage 54.0 (TID 60). 1581 bytes result sent to driver
19/07/31 14:55:37 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 60) in 4 ms on localhost (executor driver) (1/1)
19/07/31 14:55:37 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
19/07/31 14:55:37 INFO DAGScheduler: ResultStage 54 (collect at utils.scala:204) finished in 0.005 s
19/07/31 14:55:37 INFO DAGScheduler: Job 38 finished: collect at utils.scala:204, took 0.061385 s
19/07/31 14:55:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz7`
WHERE (0 = 1)
19/07/31 14:55:37 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 14:55:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 14:55:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 14:55:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 14:55:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 14:55:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 14:55:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1252
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1487
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1553
19/07/31 14:56:47 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:64327 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 14:56:47 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:64327 in memory (size: 11.8 KB, free: 912.1 MB)
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1485
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1552
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1556
19/07/31 14:56:47 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:64327 in memory (size: 3.5 KB, free: 912.1 MB)
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1484
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1513
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1550
19/07/31 14:56:47 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:64327 in memory (size: 4.3 KB, free: 912.1 MB)
19/07/31 14:56:47 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:64327 in memory (size: 11.9 KB, free: 912.1 MB)
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1559
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1516
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1486
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1557
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1551
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1515
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1457
19/07/31 14:56:47 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:64327 in memory (size: 8.6 KB, free: 912.2 MB)
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1554
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1483
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1482
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1558
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1555
19/07/31 14:56:47 INFO ContextCleaner: Cleaned shuffle 14
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1548
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1547
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1512
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1608
19/07/31 14:56:47 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:64327 in memory (size: 23.8 KB, free: 912.2 MB)
19/07/31 14:56:47 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:64327 in memory (size: 23.8 KB, free: 912.2 MB)
19/07/31 14:56:47 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:64327 in memory (size: 3.7 KB, free: 912.2 MB)
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1514
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1549
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1383
19/07/31 14:56:47 INFO BlockManager: Removing RDD 164
19/07/31 14:56:47 INFO ContextCleaner: Cleaned RDD 164
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1249
19/07/31 14:56:47 INFO ContextCleaner: Cleaned shuffle 13
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1250
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1378
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1379
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1381
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1384
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1253
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1251
19/07/31 14:56:47 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:64327 in memory (size: 24.0 KB, free: 912.2 MB)
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1377
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1248
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1380
19/07/31 14:56:47 INFO ContextCleaner: Cleaned accumulator 1382
19/07/31 15:05:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_017`) `dbplyr_018`
ORDER BY `date`) `dbplyr_019`) `dbplyr_020`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:05:46 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:05:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:05:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_021`) `dbplyr_022`
ORDER BY `date`) `dbplyr_023`) `dbplyr_024`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:05:46 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:05:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:05:46 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#2512) generates partition filter: ((cust_prospect_ind.count#2928 - cust_prospect_ind.nullCount#2927) > 0)
19/07/31 15:05:46 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#2513) generates partition filter: ((visit_device_type.count#2933 - visit_device_type.nullCount#2932) > 0)
19/07/31 15:05:46 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#2512 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#2926 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#2925))
19/07/31 15:05:46 INFO InMemoryTableScanExec: Predicate (visit_device_type#2513 = All Devices) generates partition filter: ((visit_device_type.lowerBound#2931 <= All Devices) && (All Devices <= visit_device_type.upperBound#2930))
19/07/31 15:05:46 INFO CodeGenerator: Code generated in 44.504065 ms
19/07/31 15:05:46 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:05:46 INFO DAGScheduler: Got job 39 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:05:46 INFO DAGScheduler: Final stage: ResultStage 55 (collect at utils.scala:204)
19/07/31 15:05:46 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:05:46 INFO DAGScheduler: Missing parents: List()
19/07/31 15:05:46 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[218] at collect at utils.scala:204), which has no missing parents
19/07/31 15:05:46 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 72.1 KB, free 911.9 MB)
19/07/31 15:05:46 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 30.5 KB, free 911.9 MB)
19/07/31 15:05:46 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:64327 (size: 30.5 KB, free: 912.2 MB)
19/07/31 15:05:46 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1006
19/07/31 15:05:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[218] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:05:46 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
19/07/31 15:05:46 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:05:46 INFO Executor: Running task 0.0 in stage 55.0 (TID 61)
19/07/31 15:05:46 INFO BlockManager: Found block rdd_201_0 locally
19/07/31 15:05:46 INFO CodeGenerator: Code generated in 37.059885 ms
19/07/31 15:05:46 INFO Executor: Finished task 0.0 in stage 55.0 (TID 61). 7585 bytes result sent to driver
19/07/31 15:05:46 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 61) in 64 ms on localhost (executor driver) (1/1)
19/07/31 15:05:46 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
19/07/31 15:05:46 INFO DAGScheduler: ResultStage 55 (collect at utils.scala:204) finished in 0.066 s
19/07/31 15:05:46 INFO DAGScheduler: Job 39 finished: collect at utils.scala:204, took 0.092935 s
19/07/31 15:05:46 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:05:46 INFO DAGScheduler: Registering RDD 219 (collect at utils.scala:204)
19/07/31 15:05:46 INFO DAGScheduler: Got job 40 (collect at utils.scala:204) with 4 output partitions
19/07/31 15:05:46 INFO DAGScheduler: Final stage: ResultStage 57 (collect at utils.scala:204)
19/07/31 15:05:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
19/07/31 15:05:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 56)
19/07/31 15:05:46 INFO DAGScheduler: Submitting ShuffleMapStage 56 (MapPartitionsRDD[219] at collect at utils.scala:204), which has no missing parents
19/07/31 15:05:46 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 74.5 KB, free 911.8 MB)
19/07/31 15:05:46 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.7 MB)
19/07/31 15:05:46 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:64327 (size: 31.8 KB, free: 912.2 MB)
19/07/31 15:05:46 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1006
19/07/31 15:05:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[219] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:05:46 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
19/07/31 15:05:46 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 15:05:46 INFO Executor: Running task 0.0 in stage 56.0 (TID 62)
19/07/31 15:05:46 INFO BlockManager: Found block rdd_201_0 locally
19/07/31 15:05:46 INFO Executor: Finished task 0.0 in stage 56.0 (TID 62). 1687 bytes result sent to driver
19/07/31 15:05:46 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 62) in 14 ms on localhost (executor driver) (1/1)
19/07/31 15:05:46 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
19/07/31 15:05:46 INFO DAGScheduler: ShuffleMapStage 56 (collect at utils.scala:204) finished in 0.014 s
19/07/31 15:05:46 INFO DAGScheduler: looking for newly runnable stages
19/07/31 15:05:46 INFO DAGScheduler: running: Set()
19/07/31 15:05:46 INFO DAGScheduler: waiting: Set(ResultStage 57)
19/07/31 15:05:46 INFO DAGScheduler: failed: Set()
19/07/31 15:05:46 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[222] at collect at utils.scala:204), which has no missing parents
19/07/31 15:05:46 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 16.8 KB, free 911.7 MB)
19/07/31 15:05:46 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.7 MB)
19/07/31 15:05:46 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:64327 (size: 8.0 KB, free: 912.2 MB)
19/07/31 15:05:46 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1006
19/07/31 15:05:46 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 57 (MapPartitionsRDD[222] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 15:05:46 INFO TaskSchedulerImpl: Adding task set 57.0 with 4 tasks
19/07/31 15:05:46 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 63, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 15:05:46 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 64, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 15:05:46 INFO TaskSetManager: Starting task 2.0 in stage 57.0 (TID 65, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 15:05:46 INFO TaskSetManager: Starting task 3.0 in stage 57.0 (TID 66, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 15:05:46 INFO Executor: Running task 0.0 in stage 57.0 (TID 63)
19/07/31 15:05:46 INFO Executor: Running task 1.0 in stage 57.0 (TID 64)
19/07/31 15:05:46 INFO Executor: Running task 2.0 in stage 57.0 (TID 65)
19/07/31 15:05:46 INFO Executor: Running task 3.0 in stage 57.0 (TID 66)
19/07/31 15:05:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:05:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:05:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:05:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:05:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:05:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:05:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:05:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:05:46 INFO Executor: Finished task 3.0 in stage 57.0 (TID 66). 2362 bytes result sent to driver
19/07/31 15:05:46 INFO Executor: Finished task 1.0 in stage 57.0 (TID 64). 2403 bytes result sent to driver
19/07/31 15:05:46 INFO Executor: Finished task 2.0 in stage 57.0 (TID 65). 2390 bytes result sent to driver
19/07/31 15:05:46 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 64) in 16 ms on localhost (executor driver) (1/4)
19/07/31 15:05:46 INFO TaskSetManager: Finished task 3.0 in stage 57.0 (TID 66) in 16 ms on localhost (executor driver) (2/4)
19/07/31 15:05:46 INFO TaskSetManager: Finished task 2.0 in stage 57.0 (TID 65) in 16 ms on localhost (executor driver) (3/4)
19/07/31 15:05:46 INFO Executor: Finished task 0.0 in stage 57.0 (TID 63). 2382 bytes result sent to driver
19/07/31 15:05:46 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 63) in 19 ms on localhost (executor driver) (4/4)
19/07/31 15:05:46 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
19/07/31 15:05:46 INFO DAGScheduler: ResultStage 57 (collect at utils.scala:204) finished in 0.021 s
19/07/31 15:05:46 INFO DAGScheduler: Job 40 finished: collect at utils.scala:204, took 0.057478 s
19/07/31 15:05:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_025`) `dbplyr_026`
ORDER BY `date`) `dbplyr_027`) `dbplyr_028`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:05:57 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:05:57 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:05:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_029`) `dbplyr_030`
ORDER BY `date`) `dbplyr_031`) `dbplyr_032`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:05:57 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:05:57 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:05:57 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_033`) `dbplyr_034`
ORDER BY `date`) `dbplyr_035`) `dbplyr_036`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
LIMIT 11
19/07/31 15:05:57 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:05:57 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:05:58 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_037`) `dbplyr_038`
ORDER BY `date`) `dbplyr_039`) `dbplyr_040`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
LIMIT 11
19/07/31 15:05:58 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:05:58 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:05:58 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#2512) generates partition filter: ((cust_prospect_ind.count#3054 - cust_prospect_ind.nullCount#3053) > 0)
19/07/31 15:05:58 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#2513) generates partition filter: ((visit_device_type.count#3059 - visit_device_type.nullCount#3058) > 0)
19/07/31 15:05:58 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#2512 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#3052 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#3051))
19/07/31 15:05:58 INFO InMemoryTableScanExec: Predicate (visit_device_type#2513 = All Devices) generates partition filter: ((visit_device_type.lowerBound#3057 <= All Devices) && (All Devices <= visit_device_type.upperBound#3056))
19/07/31 15:05:58 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:05:58 INFO DAGScheduler: Got job 41 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:05:58 INFO DAGScheduler: Final stage: ResultStage 58 (collect at utils.scala:204)
19/07/31 15:05:58 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:05:58 INFO DAGScheduler: Missing parents: List()
19/07/31 15:05:58 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[226] at collect at utils.scala:204), which has no missing parents
19/07/31 15:05:58 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 72.8 KB, free 911.7 MB)
19/07/31 15:05:58 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 30.8 KB, free 911.6 MB)
19/07/31 15:05:58 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:64327 (size: 30.8 KB, free: 912.1 MB)
19/07/31 15:05:58 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1006
19/07/31 15:05:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[226] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:05:58 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
19/07/31 15:05:58 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:05:58 INFO Executor: Running task 0.0 in stage 58.0 (TID 67)
19/07/31 15:05:58 INFO BlockManager: Found block rdd_201_0 locally
19/07/31 15:05:58 INFO Executor: Finished task 0.0 in stage 58.0 (TID 67). 4005 bytes result sent to driver
19/07/31 15:05:58 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 67) in 26 ms on localhost (executor driver) (1/1)
19/07/31 15:05:58 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
19/07/31 15:05:58 INFO DAGScheduler: ResultStage 58 (collect at utils.scala:204) finished in 0.029 s
19/07/31 15:05:58 INFO DAGScheduler: Job 41 finished: collect at utils.scala:204, took 0.040157 s
19/07/31 15:05:58 INFO CodeGenerator: Code generated in 18.339016 ms
19/07/31 15:05:58 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_041`) `dbplyr_042`
ORDER BY `date`) `dbplyr_043`) `dbplyr_044`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:05:58 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:05:58 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:07:06 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 15:07:06 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:07:06 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:07:06 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:07:06 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:07:06 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 15:07:06 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 15:07:06 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 15:07:06 INFO DAGScheduler: Got job 42 (collect at utils.scala:44) with 1 output partitions
19/07/31 15:07:06 INFO DAGScheduler: Final stage: ResultStage 59 (collect at utils.scala:44)
19/07/31 15:07:06 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:07:06 INFO DAGScheduler: Missing parents: List()
19/07/31 15:07:06 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[231] at map at utils.scala:41), which has no missing parents
19/07/31 15:07:06 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 6.3 KB, free 911.6 MB)
19/07/31 15:07:06 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 3.5 KB, free 911.6 MB)
19/07/31 15:07:06 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:64327 (size: 3.5 KB, free: 912.1 MB)
19/07/31 15:07:06 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1006
19/07/31 15:07:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[231] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 15:07:06 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
19/07/31 15:07:06 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 15:07:06 INFO Executor: Running task 0.0 in stage 59.0 (TID 68)
19/07/31 15:07:06 INFO Executor: Finished task 0.0 in stage 59.0 (TID 68). 1007 bytes result sent to driver
19/07/31 15:07:06 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 68) in 3 ms on localhost (executor driver) (1/1)
19/07/31 15:07:06 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
19/07/31 15:07:06 INFO DAGScheduler: ResultStage 59 (collect at utils.scala:44) finished in 0.005 s
19/07/31 15:07:06 INFO DAGScheduler: Job 42 finished: collect at utils.scala:44, took 0.010926 s
19/07/31 15:07:06 INFO SparkSqlParser: Parsing command: DROP TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 15:07:06 INFO MapPartitionsRDD: Removing RDD 201 from persistence list
19/07/31 15:07:06 INFO BlockManager: Removing RDD 201
19/07/31 15:07:06 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 15:07:06 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#3106)) > 0)
19/07/31 15:07:06 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 15:07:06 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 15:07:06 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 281.2 KB, free 911.4 MB)
19/07/31 15:07:06 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.4 MB)
19/07/31 15:07:06 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:64327 (size: 23.8 KB, free: 912.2 MB)
19/07/31 15:07:06 INFO SparkContext: Created broadcast 81 from csv at NativeMethodAccessorImpl.java:0
19/07/31 15:07:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 15:07:06 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 15:07:06 INFO DAGScheduler: Got job 43 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 15:07:06 INFO DAGScheduler: Final stage: ResultStage 60 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 15:07:06 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:07:06 INFO DAGScheduler: Missing parents: List()
19/07/31 15:07:06 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[234] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 15:07:06 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 8.2 KB, free 911.4 MB)
19/07/31 15:07:06 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 4.3 KB, free 911.4 MB)
19/07/31 15:07:06 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:64327 (size: 4.3 KB, free: 912.1 MB)
19/07/31 15:07:06 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1006
19/07/31 15:07:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[234] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 15:07:06 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
19/07/31 15:07:06 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 69, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:07:06 INFO Executor: Running task 0.0 in stage 60.0 (TID 69)
19/07/31 15:07:06 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 15:07:06 INFO Executor: Finished task 0.0 in stage 60.0 (TID 69). 1351 bytes result sent to driver
19/07/31 15:07:06 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 69) in 5 ms on localhost (executor driver) (1/1)
19/07/31 15:07:06 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
19/07/31 15:07:06 INFO DAGScheduler: ResultStage 60 (csv at NativeMethodAccessorImpl.java:0) finished in 0.006 s
19/07/31 15:07:06 INFO DAGScheduler: Job 43 finished: csv at NativeMethodAccessorImpl.java:0, took 0.022958 s
19/07/31 15:07:06 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 15:07:06 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 15:07:06 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 15:07:06 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 15:07:06 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 281.2 KB, free 911.1 MB)
19/07/31 15:07:07 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.1 MB)
19/07/31 15:07:07 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:64327 (size: 23.8 KB, free: 912.1 MB)
19/07/31 15:07:07 INFO SparkContext: Created broadcast 83 from csv at NativeMethodAccessorImpl.java:0
19/07/31 15:07:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 15:07:07 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 15:07:07 INFO DAGScheduler: Got job 44 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 15:07:07 INFO DAGScheduler: Final stage: ResultStage 61 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 15:07:07 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:07:07 INFO DAGScheduler: Missing parents: List()
19/07/31 15:07:07 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[239] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 15:07:07 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 14.8 KB, free 911.0 MB)
19/07/31 15:07:07 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.0 MB)
19/07/31 15:07:07 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:64327 (size: 8.6 KB, free: 912.1 MB)
19/07/31 15:07:07 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1006
19/07/31 15:07:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[239] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 15:07:07 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
19/07/31 15:07:07 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 70, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:07:07 INFO Executor: Running task 0.0 in stage 61.0 (TID 70)
19/07/31 15:07:07 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 15:07:07 INFO Executor: Finished task 0.0 in stage 61.0 (TID 70). 1584 bytes result sent to driver
19/07/31 15:07:07 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 70) in 21 ms on localhost (executor driver) (1/1)
19/07/31 15:07:07 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
19/07/31 15:07:07 INFO DAGScheduler: ResultStage 61 (csv at NativeMethodAccessorImpl.java:0) finished in 0.021 s
19/07/31 15:07:07 INFO DAGScheduler: Job 44 finished: csv at NativeMethodAccessorImpl.java:0, took 0.042812 s
19/07/31 15:07:07 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 15:07:07 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:07:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:07:07 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:07:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:07:07 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 15:07:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 15:07:07 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 15:07:07 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 15:07:07 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 15:07:07 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 15:07:07 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 15:07:07 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 15:07:07 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 15:07:07 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 282.3 KB, free 910.8 MB)
19/07/31 15:07:07 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 24.0 KB, free 910.7 MB)
19/07/31 15:07:07 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:64327 (size: 24.0 KB, free: 912.1 MB)
19/07/31 15:07:07 INFO SparkContext: Created broadcast 85 from sql at <unknown>:0
19/07/31 15:07:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 15:07:07 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 15:07:07 INFO DAGScheduler: Registering RDD 245 (sql at <unknown>:0)
19/07/31 15:07:07 INFO DAGScheduler: Got job 45 (sql at <unknown>:0) with 1 output partitions
19/07/31 15:07:07 INFO DAGScheduler: Final stage: ResultStage 63 (sql at <unknown>:0)
19/07/31 15:07:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
19/07/31 15:07:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 62)
19/07/31 15:07:07 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[245] at sql at <unknown>:0), which has no missing parents
19/07/31 15:07:07 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 26.3 KB, free 910.7 MB)
19/07/31 15:07:07 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 11.8 KB, free 910.7 MB)
19/07/31 15:07:07 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:64327 (size: 11.8 KB, free: 912.1 MB)
19/07/31 15:07:07 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1006
19/07/31 15:07:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[245] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 15:07:07 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
19/07/31 15:07:07 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 71, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 15:07:07 INFO Executor: Running task 0.0 in stage 62.0 (TID 71)
19/07/31 15:07:07 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 15:07:07 INFO MemoryStore: Block rdd_242_0 stored as values in memory (estimated size 48.9 KB, free 910.6 MB)
19/07/31 15:07:07 INFO BlockManagerInfo: Added rdd_242_0 in memory on 127.0.0.1:64327 (size: 48.9 KB, free: 912.0 MB)
19/07/31 15:07:07 INFO Executor: Finished task 0.0 in stage 62.0 (TID 71). 2461 bytes result sent to driver
19/07/31 15:07:07 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 71) in 31 ms on localhost (executor driver) (1/1)
19/07/31 15:07:07 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
19/07/31 15:07:07 INFO DAGScheduler: ShuffleMapStage 62 (sql at <unknown>:0) finished in 0.032 s
19/07/31 15:07:07 INFO DAGScheduler: looking for newly runnable stages
19/07/31 15:07:07 INFO DAGScheduler: running: Set()
19/07/31 15:07:07 INFO DAGScheduler: waiting: Set(ResultStage 63)
19/07/31 15:07:07 INFO DAGScheduler: failed: Set()
19/07/31 15:07:07 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[248] at sql at <unknown>:0), which has no missing parents
19/07/31 15:07:07 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 7.0 KB, free 910.6 MB)
19/07/31 15:07:07 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.6 MB)
19/07/31 15:07:07 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:64327 (size: 3.7 KB, free: 912.0 MB)
19/07/31 15:07:07 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1006
19/07/31 15:07:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[248] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 15:07:07 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
19/07/31 15:07:07 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 72, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 15:07:07 INFO Executor: Running task 0.0 in stage 63.0 (TID 72)
19/07/31 15:07:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:07:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:07:07 INFO Executor: Finished task 0.0 in stage 63.0 (TID 72). 1581 bytes result sent to driver
19/07/31 15:07:07 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 72) in 4 ms on localhost (executor driver) (1/1)
19/07/31 15:07:07 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
19/07/31 15:07:07 INFO DAGScheduler: ResultStage 63 (sql at <unknown>:0) finished in 0.004 s
19/07/31 15:07:07 INFO DAGScheduler: Job 45 finished: sql at <unknown>:0, took 0.058110 s
19/07/31 15:07:07 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 15:07:07 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:07:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:07:07 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:07:07 INFO DAGScheduler: Registering RDD 251 (collect at utils.scala:204)
19/07/31 15:07:07 INFO DAGScheduler: Got job 46 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:07:07 INFO DAGScheduler: Final stage: ResultStage 65 (collect at utils.scala:204)
19/07/31 15:07:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)
19/07/31 15:07:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 64)
19/07/31 15:07:07 INFO DAGScheduler: Submitting ShuffleMapStage 64 (MapPartitionsRDD[251] at collect at utils.scala:204), which has no missing parents
19/07/31 15:07:07 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 26.3 KB, free 910.6 MB)
19/07/31 15:07:07 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 11.9 KB, free 910.6 MB)
19/07/31 15:07:07 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:64327 (size: 11.9 KB, free: 912.0 MB)
19/07/31 15:07:07 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1006
19/07/31 15:07:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[251] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:07:07 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
19/07/31 15:07:07 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 15:07:07 INFO Executor: Running task 0.0 in stage 64.0 (TID 73)
19/07/31 15:07:07 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:07:07 INFO Executor: Finished task 0.0 in stage 64.0 (TID 73). 1780 bytes result sent to driver
19/07/31 15:07:07 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 73) in 7 ms on localhost (executor driver) (1/1)
19/07/31 15:07:07 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
19/07/31 15:07:07 INFO DAGScheduler: ShuffleMapStage 64 (collect at utils.scala:204) finished in 0.008 s
19/07/31 15:07:07 INFO DAGScheduler: looking for newly runnable stages
19/07/31 15:07:07 INFO DAGScheduler: running: Set()
19/07/31 15:07:07 INFO DAGScheduler: waiting: Set(ResultStage 65)
19/07/31 15:07:07 INFO DAGScheduler: failed: Set()
19/07/31 15:07:07 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[254] at collect at utils.scala:204), which has no missing parents
19/07/31 15:07:07 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 7.0 KB, free 910.6 MB)
19/07/31 15:07:07 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.6 MB)
19/07/31 15:07:07 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:64327 (size: 3.7 KB, free: 912.0 MB)
19/07/31 15:07:07 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1006
19/07/31 15:07:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[254] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:07:07 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
19/07/31 15:07:07 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 74, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 15:07:07 INFO Executor: Running task 0.0 in stage 65.0 (TID 74)
19/07/31 15:07:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:07:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 15:07:07 INFO Executor: Finished task 0.0 in stage 65.0 (TID 74). 1581 bytes result sent to driver
19/07/31 15:07:07 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 74) in 5 ms on localhost (executor driver) (1/1)
19/07/31 15:07:07 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
19/07/31 15:07:07 INFO DAGScheduler: ResultStage 65 (collect at utils.scala:204) finished in 0.005 s
19/07/31 15:07:07 INFO DAGScheduler: Job 46 finished: collect at utils.scala:204, took 0.050850 s
19/07/31 15:07:07 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz8`
WHERE (0 = 1)
19/07/31 15:07:07 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 15:07:07 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:07:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:07:07 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:07:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:07:07 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 15:07:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 15:07:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_045`) `dbplyr_046`
ORDER BY `date`) `dbplyr_047`) `dbplyr_048`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:07:15 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:07:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:07:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_049`) `dbplyr_050`
ORDER BY `date`) `dbplyr_051`) `dbplyr_052`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:07:15 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:07:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:07:15 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#3129) generates partition filter: ((cust_prospect_ind.count#3545 - cust_prospect_ind.nullCount#3544) > 0)
19/07/31 15:07:15 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#3130) generates partition filter: ((visit_device_type.count#3550 - visit_device_type.nullCount#3549) > 0)
19/07/31 15:07:15 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#3129 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#3543 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#3542))
19/07/31 15:07:15 INFO InMemoryTableScanExec: Predicate (visit_device_type#3130 = All Devices) generates partition filter: ((visit_device_type.lowerBound#3548 <= All Devices) && (All Devices <= visit_device_type.upperBound#3547))
19/07/31 15:07:15 INFO CodeGenerator: Code generated in 18.050161 ms
19/07/31 15:07:15 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:07:15 INFO DAGScheduler: Got job 47 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:07:15 INFO DAGScheduler: Final stage: ResultStage 66 (collect at utils.scala:204)
19/07/31 15:07:15 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:07:15 INFO DAGScheduler: Missing parents: List()
19/07/31 15:07:15 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[259] at collect at utils.scala:204), which has no missing parents
19/07/31 15:07:15 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 72.1 KB, free 910.5 MB)
19/07/31 15:07:15 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.5 MB)
19/07/31 15:07:15 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:64327 (size: 30.4 KB, free: 912.0 MB)
19/07/31 15:07:15 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1006
19/07/31 15:07:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[259] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:07:15 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
19/07/31 15:07:15 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 75, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:07:15 INFO Executor: Running task 0.0 in stage 66.0 (TID 75)
19/07/31 15:07:15 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:07:15 INFO Executor: Finished task 0.0 in stage 66.0 (TID 75). 7542 bytes result sent to driver
19/07/31 15:07:15 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 75) in 11 ms on localhost (executor driver) (1/1)
19/07/31 15:07:15 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
19/07/31 15:07:15 INFO DAGScheduler: ResultStage 66 (collect at utils.scala:204) finished in 0.011 s
19/07/31 15:07:15 INFO DAGScheduler: Job 47 finished: collect at utils.scala:204, took 0.024784 s
19/07/31 15:07:15 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:07:15 INFO DAGScheduler: Registering RDD 260 (collect at utils.scala:204)
19/07/31 15:07:15 INFO DAGScheduler: Got job 48 (collect at utils.scala:204) with 4 output partitions
19/07/31 15:07:15 INFO DAGScheduler: Final stage: ResultStage 68 (collect at utils.scala:204)
19/07/31 15:07:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 67)
19/07/31 15:07:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 67)
19/07/31 15:07:15 INFO DAGScheduler: Submitting ShuffleMapStage 67 (MapPartitionsRDD[260] at collect at utils.scala:204), which has no missing parents
19/07/31 15:07:15 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 74.6 KB, free 910.4 MB)
19/07/31 15:07:15 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.4 MB)
19/07/31 15:07:15 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:64327 (size: 31.7 KB, free: 912.0 MB)
19/07/31 15:07:15 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1006
19/07/31 15:07:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 67 (MapPartitionsRDD[260] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:07:15 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks
19/07/31 15:07:15 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 76, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 15:07:15 INFO Executor: Running task 0.0 in stage 67.0 (TID 76)
19/07/31 15:07:15 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:07:15 INFO Executor: Finished task 0.0 in stage 67.0 (TID 76). 1687 bytes result sent to driver
19/07/31 15:07:15 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 76) in 20 ms on localhost (executor driver) (1/1)
19/07/31 15:07:15 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
19/07/31 15:07:15 INFO DAGScheduler: ShuffleMapStage 67 (collect at utils.scala:204) finished in 0.022 s
19/07/31 15:07:15 INFO DAGScheduler: looking for newly runnable stages
19/07/31 15:07:15 INFO DAGScheduler: running: Set()
19/07/31 15:07:15 INFO DAGScheduler: waiting: Set(ResultStage 68)
19/07/31 15:07:15 INFO DAGScheduler: failed: Set()
19/07/31 15:07:15 INFO DAGScheduler: Submitting ResultStage 68 (MapPartitionsRDD[263] at collect at utils.scala:204), which has no missing parents
19/07/31 15:07:15 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 16.8 KB, free 910.4 MB)
19/07/31 15:07:15 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.4 MB)
19/07/31 15:07:15 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 127.0.0.1:64327 (size: 8.0 KB, free: 911.9 MB)
19/07/31 15:07:15 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1006
19/07/31 15:07:15 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 68 (MapPartitionsRDD[263] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 15:07:15 INFO TaskSchedulerImpl: Adding task set 68.0 with 4 tasks
19/07/31 15:07:15 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 77, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 15:07:15 INFO TaskSetManager: Starting task 1.0 in stage 68.0 (TID 78, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 15:07:15 INFO TaskSetManager: Starting task 2.0 in stage 68.0 (TID 79, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 15:07:15 INFO TaskSetManager: Starting task 3.0 in stage 68.0 (TID 80, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 15:07:15 INFO Executor: Running task 0.0 in stage 68.0 (TID 77)
19/07/31 15:07:15 INFO Executor: Running task 2.0 in stage 68.0 (TID 79)
19/07/31 15:07:15 INFO Executor: Running task 1.0 in stage 68.0 (TID 78)
19/07/31 15:07:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:07:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:07:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:07:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:07:15 INFO Executor: Running task 3.0 in stage 68.0 (TID 80)
19/07/31 15:07:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:07:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:07:15 INFO Executor: Finished task 2.0 in stage 68.0 (TID 79). 2390 bytes result sent to driver
19/07/31 15:07:15 INFO TaskSetManager: Finished task 2.0 in stage 68.0 (TID 79) in 13 ms on localhost (executor driver) (1/4)
19/07/31 15:07:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:07:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:07:15 INFO Executor: Finished task 3.0 in stage 68.0 (TID 80). 2362 bytes result sent to driver
19/07/31 15:07:15 INFO Executor: Finished task 0.0 in stage 68.0 (TID 77). 2382 bytes result sent to driver
19/07/31 15:07:15 INFO TaskSetManager: Finished task 3.0 in stage 68.0 (TID 80) in 16 ms on localhost (executor driver) (2/4)
19/07/31 15:07:15 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 77) in 16 ms on localhost (executor driver) (3/4)
19/07/31 15:07:15 INFO Executor: Finished task 1.0 in stage 68.0 (TID 78). 2403 bytes result sent to driver
19/07/31 15:07:15 INFO TaskSetManager: Finished task 1.0 in stage 68.0 (TID 78) in 17 ms on localhost (executor driver) (4/4)
19/07/31 15:07:15 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
19/07/31 15:07:15 INFO DAGScheduler: ResultStage 68 (collect at utils.scala:204) finished in 0.018 s
19/07/31 15:07:15 INFO DAGScheduler: Job 48 finished: collect at utils.scala:204, took 0.078014 s
19/07/31 15:07:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_053`) `dbplyr_054`
ORDER BY `date`) `dbplyr_055`) `dbplyr_056`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:07:25 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:07:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:07:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_057`) `dbplyr_058`
ORDER BY `date`) `dbplyr_059`) `dbplyr_060`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:07:25 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:07:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:07:25 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#3129) generates partition filter: ((cust_prospect_ind.count#3643 - cust_prospect_ind.nullCount#3642) > 0)
19/07/31 15:07:25 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#3130) generates partition filter: ((visit_device_type.count#3648 - visit_device_type.nullCount#3647) > 0)
19/07/31 15:07:25 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#3129 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#3641 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#3640))
19/07/31 15:07:25 INFO InMemoryTableScanExec: Predicate (visit_device_type#3130 = All Devices) generates partition filter: ((visit_device_type.lowerBound#3646 <= All Devices) && (All Devices <= visit_device_type.upperBound#3645))
19/07/31 15:07:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:07:25 INFO DAGScheduler: Got job 49 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:07:25 INFO DAGScheduler: Final stage: ResultStage 69 (collect at utils.scala:204)
19/07/31 15:07:25 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:07:25 INFO DAGScheduler: Missing parents: List()
19/07/31 15:07:25 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[268] at collect at utils.scala:204), which has no missing parents
19/07/31 15:07:25 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 72.1 KB, free 910.3 MB)
19/07/31 15:07:25 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.3 MB)
19/07/31 15:07:25 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 127.0.0.1:64327 (size: 30.5 KB, free: 911.9 MB)
19/07/31 15:07:25 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1006
19/07/31 15:07:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[268] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:07:25 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks
19/07/31 15:07:25 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 81, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:07:25 INFO Executor: Running task 0.0 in stage 69.0 (TID 81)
19/07/31 15:07:25 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:07:25 INFO Executor: Finished task 0.0 in stage 69.0 (TID 81). 7542 bytes result sent to driver
19/07/31 15:07:25 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 81) in 10 ms on localhost (executor driver) (1/1)
19/07/31 15:07:25 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
19/07/31 15:07:25 INFO DAGScheduler: ResultStage 69 (collect at utils.scala:204) finished in 0.011 s
19/07/31 15:07:25 INFO DAGScheduler: Job 49 finished: collect at utils.scala:204, took 0.027875 s
19/07/31 15:07:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:07:25 INFO DAGScheduler: Registering RDD 269 (collect at utils.scala:204)
19/07/31 15:07:25 INFO DAGScheduler: Got job 50 (collect at utils.scala:204) with 4 output partitions
19/07/31 15:07:25 INFO DAGScheduler: Final stage: ResultStage 71 (collect at utils.scala:204)
19/07/31 15:07:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)
19/07/31 15:07:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 70)
19/07/31 15:07:25 INFO DAGScheduler: Submitting ShuffleMapStage 70 (MapPartitionsRDD[269] at collect at utils.scala:204), which has no missing parents
19/07/31 15:07:25 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 74.6 KB, free 910.2 MB)
19/07/31 15:07:25 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.2 MB)
19/07/31 15:07:25 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 127.0.0.1:64327 (size: 31.8 KB, free: 911.9 MB)
19/07/31 15:07:25 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1006
19/07/31 15:07:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[269] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:07:25 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks
19/07/31 15:07:25 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 82, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 15:07:25 INFO Executor: Running task 0.0 in stage 70.0 (TID 82)
19/07/31 15:07:25 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:07:25 INFO Executor: Finished task 0.0 in stage 70.0 (TID 82). 1687 bytes result sent to driver
19/07/31 15:07:25 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 82) in 18 ms on localhost (executor driver) (1/1)
19/07/31 15:07:25 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
19/07/31 15:07:25 INFO DAGScheduler: ShuffleMapStage 70 (collect at utils.scala:204) finished in 0.019 s
19/07/31 15:07:25 INFO DAGScheduler: looking for newly runnable stages
19/07/31 15:07:25 INFO DAGScheduler: running: Set()
19/07/31 15:07:25 INFO DAGScheduler: waiting: Set(ResultStage 71)
19/07/31 15:07:25 INFO DAGScheduler: failed: Set()
19/07/31 15:07:25 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[272] at collect at utils.scala:204), which has no missing parents
19/07/31 15:07:25 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 16.8 KB, free 910.1 MB)
19/07/31 15:07:25 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.1 MB)
19/07/31 15:07:25 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 127.0.0.1:64327 (size: 8.0 KB, free: 911.9 MB)
19/07/31 15:07:25 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1006
19/07/31 15:07:25 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 71 (MapPartitionsRDD[272] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 15:07:25 INFO TaskSchedulerImpl: Adding task set 71.0 with 4 tasks
19/07/31 15:07:25 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 83, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 15:07:25 INFO TaskSetManager: Starting task 1.0 in stage 71.0 (TID 84, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 15:07:25 INFO TaskSetManager: Starting task 2.0 in stage 71.0 (TID 85, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 15:07:25 INFO TaskSetManager: Starting task 3.0 in stage 71.0 (TID 86, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 15:07:25 INFO Executor: Running task 0.0 in stage 71.0 (TID 83)
19/07/31 15:07:25 INFO Executor: Running task 1.0 in stage 71.0 (TID 84)
19/07/31 15:07:25 INFO Executor: Running task 3.0 in stage 71.0 (TID 86)
19/07/31 15:07:25 INFO Executor: Running task 2.0 in stage 71.0 (TID 85)
19/07/31 15:07:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:07:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:07:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:07:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 15:07:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:07:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 15:07:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:07:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:07:25 INFO Executor: Finished task 2.0 in stage 71.0 (TID 85). 2390 bytes result sent to driver
19/07/31 15:07:25 INFO Executor: Finished task 3.0 in stage 71.0 (TID 86). 2362 bytes result sent to driver
19/07/31 15:07:25 INFO Executor: Finished task 0.0 in stage 71.0 (TID 83). 2382 bytes result sent to driver
19/07/31 15:07:25 INFO TaskSetManager: Finished task 3.0 in stage 71.0 (TID 86) in 7 ms on localhost (executor driver) (1/4)
19/07/31 15:07:25 INFO Executor: Finished task 1.0 in stage 71.0 (TID 84). 2403 bytes result sent to driver
19/07/31 15:07:25 INFO TaskSetManager: Finished task 2.0 in stage 71.0 (TID 85) in 7 ms on localhost (executor driver) (2/4)
19/07/31 15:07:25 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 83) in 8 ms on localhost (executor driver) (3/4)
19/07/31 15:07:25 INFO TaskSetManager: Finished task 1.0 in stage 71.0 (TID 84) in 8 ms on localhost (executor driver) (4/4)
19/07/31 15:07:25 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
19/07/31 15:07:25 INFO DAGScheduler: ResultStage 71 (collect at utils.scala:204) finished in 0.009 s
19/07/31 15:07:25 INFO DAGScheduler: Job 50 finished: collect at utils.scala:204, took 0.049485 s
19/07/31 15:10:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_061`) `dbplyr_062`
ORDER BY `date`) `dbplyr_063`) `dbplyr_064`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:10:32 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:10:32 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:10:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_065`) `dbplyr_066`
ORDER BY `date`) `dbplyr_067`) `dbplyr_068`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:10:32 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:10:32 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:10:33 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#3129) generates partition filter: ((cust_prospect_ind.count#3741 - cust_prospect_ind.nullCount#3740) > 0)
19/07/31 15:10:33 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#3130) generates partition filter: ((visit_device_type.count#3746 - visit_device_type.nullCount#3745) > 0)
19/07/31 15:10:33 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#3129 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#3739 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#3738))
19/07/31 15:10:33 INFO InMemoryTableScanExec: Predicate (visit_device_type#3130 = All Devices) generates partition filter: ((visit_device_type.lowerBound#3744 <= All Devices) && (All Devices <= visit_device_type.upperBound#3743))
19/07/31 15:10:33 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:10:33 INFO DAGScheduler: Got job 51 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:10:33 INFO DAGScheduler: Final stage: ResultStage 72 (collect at utils.scala:204)
19/07/31 15:10:33 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:10:33 INFO DAGScheduler: Missing parents: List()
19/07/31 15:10:33 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[277] at collect at utils.scala:204), which has no missing parents
19/07/31 15:10:33 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 72.1 KB, free 910.1 MB)
19/07/31 15:10:33 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.0 MB)
19/07/31 15:10:33 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 127.0.0.1:64327 (size: 30.5 KB, free: 911.8 MB)
19/07/31 15:10:33 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1006
19/07/31 15:10:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[277] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:10:33 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks
19/07/31 15:10:33 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 87, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:10:33 INFO Executor: Running task 0.0 in stage 72.0 (TID 87)
19/07/31 15:10:33 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:10:33 INFO Executor: Finished task 0.0 in stage 72.0 (TID 87). 7542 bytes result sent to driver
19/07/31 15:10:33 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 87) in 12 ms on localhost (executor driver) (1/1)
19/07/31 15:10:33 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
19/07/31 15:10:33 INFO DAGScheduler: ResultStage 72 (collect at utils.scala:204) finished in 0.014 s
19/07/31 15:10:33 INFO DAGScheduler: Job 51 finished: collect at utils.scala:204, took 0.046417 s
19/07/31 15:10:33 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:10:33 INFO DAGScheduler: Registering RDD 278 (collect at utils.scala:204)
19/07/31 15:10:33 INFO DAGScheduler: Got job 52 (collect at utils.scala:204) with 4 output partitions
19/07/31 15:10:33 INFO DAGScheduler: Final stage: ResultStage 74 (collect at utils.scala:204)
19/07/31 15:10:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)
19/07/31 15:10:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 73)
19/07/31 15:10:33 INFO DAGScheduler: Submitting ShuffleMapStage 73 (MapPartitionsRDD[278] at collect at utils.scala:204), which has no missing parents
19/07/31 15:10:33 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 74.6 KB, free 910.0 MB)
19/07/31 15:10:33 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 31.7 KB, free 909.9 MB)
19/07/31 15:10:33 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 127.0.0.1:64327 (size: 31.7 KB, free: 911.8 MB)
19/07/31 15:10:33 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1006
19/07/31 15:10:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 73 (MapPartitionsRDD[278] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:10:33 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks
19/07/31 15:10:33 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 88, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 15:10:33 INFO Executor: Running task 0.0 in stage 73.0 (TID 88)
19/07/31 15:10:33 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:10:33 INFO Executor: Finished task 0.0 in stage 73.0 (TID 88). 1687 bytes result sent to driver
19/07/31 15:10:33 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 88) in 28 ms on localhost (executor driver) (1/1)
19/07/31 15:10:33 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
19/07/31 15:10:33 INFO DAGScheduler: ShuffleMapStage 73 (collect at utils.scala:204) finished in 0.030 s
19/07/31 15:10:33 INFO DAGScheduler: looking for newly runnable stages
19/07/31 15:10:33 INFO DAGScheduler: running: Set()
19/07/31 15:10:33 INFO DAGScheduler: waiting: Set(ResultStage 74)
19/07/31 15:10:33 INFO DAGScheduler: failed: Set()
19/07/31 15:10:33 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[281] at collect at utils.scala:204), which has no missing parents
19/07/31 15:10:33 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 16.8 KB, free 909.9 MB)
19/07/31 15:10:33 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.9 MB)
19/07/31 15:10:33 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 127.0.0.1:64327 (size: 8.0 KB, free: 911.8 MB)
19/07/31 15:10:33 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1006
19/07/31 15:10:33 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 74 (MapPartitionsRDD[281] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 15:10:33 INFO TaskSchedulerImpl: Adding task set 74.0 with 4 tasks
19/07/31 15:10:33 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 89, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 15:10:33 INFO TaskSetManager: Starting task 1.0 in stage 74.0 (TID 90, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 15:10:33 INFO TaskSetManager: Starting task 2.0 in stage 74.0 (TID 91, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 15:10:33 INFO TaskSetManager: Starting task 3.0 in stage 74.0 (TID 92, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 15:10:33 INFO Executor: Running task 0.0 in stage 74.0 (TID 89)
19/07/31 15:10:33 INFO Executor: Running task 1.0 in stage 74.0 (TID 90)
19/07/31 15:10:33 INFO Executor: Running task 2.0 in stage 74.0 (TID 91)
19/07/31 15:10:33 INFO Executor: Running task 3.0 in stage 74.0 (TID 92)
19/07/31 15:10:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:10:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:10:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:10:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:10:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:10:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:10:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:10:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:10:33 INFO Executor: Finished task 1.0 in stage 74.0 (TID 90). 2403 bytes result sent to driver
19/07/31 15:10:33 INFO Executor: Finished task 0.0 in stage 74.0 (TID 89). 2382 bytes result sent to driver
19/07/31 15:10:33 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 89) in 39 ms on localhost (executor driver) (1/4)
19/07/31 15:10:33 INFO Executor: Finished task 2.0 in stage 74.0 (TID 91). 2390 bytes result sent to driver
19/07/31 15:10:33 INFO Executor: Finished task 3.0 in stage 74.0 (TID 92). 2362 bytes result sent to driver
19/07/31 15:10:33 INFO TaskSetManager: Finished task 1.0 in stage 74.0 (TID 90) in 39 ms on localhost (executor driver) (2/4)
19/07/31 15:10:33 INFO TaskSetManager: Finished task 2.0 in stage 74.0 (TID 91) in 39 ms on localhost (executor driver) (3/4)
19/07/31 15:10:33 INFO TaskSetManager: Finished task 3.0 in stage 74.0 (TID 92) in 39 ms on localhost (executor driver) (4/4)
19/07/31 15:10:33 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
19/07/31 15:10:33 INFO DAGScheduler: ResultStage 74 (collect at utils.scala:204) finished in 0.041 s
19/07/31 15:10:33 INFO DAGScheduler: Job 52 finished: collect at utils.scala:204, took 0.124084 s
19/07/31 15:23:07 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_069`) `dbplyr_070`
ORDER BY `date`) `dbplyr_071`) `dbplyr_072`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:23:07 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:23:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:23:07 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_073`) `dbplyr_074`
ORDER BY `date`) `dbplyr_075`) `dbplyr_076`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:23:07 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:23:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:23:07 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#3129) generates partition filter: ((cust_prospect_ind.count#3839 - cust_prospect_ind.nullCount#3838) > 0)
19/07/31 15:23:07 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#3130) generates partition filter: ((visit_device_type.count#3844 - visit_device_type.nullCount#3843) > 0)
19/07/31 15:23:07 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#3129 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#3837 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#3836))
19/07/31 15:23:07 INFO InMemoryTableScanExec: Predicate (visit_device_type#3130 = All Devices) generates partition filter: ((visit_device_type.lowerBound#3842 <= All Devices) && (All Devices <= visit_device_type.upperBound#3841))
19/07/31 15:23:07 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:23:07 INFO DAGScheduler: Got job 53 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:23:07 INFO DAGScheduler: Final stage: ResultStage 75 (collect at utils.scala:204)
19/07/31 15:23:07 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:23:07 INFO DAGScheduler: Missing parents: List()
19/07/31 15:23:07 INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[286] at collect at utils.scala:204), which has no missing parents
19/07/31 15:23:07 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 72.1 KB, free 909.8 MB)
19/07/31 15:23:07 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 30.4 KB, free 909.8 MB)
19/07/31 15:23:07 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 127.0.0.1:64327 (size: 30.4 KB, free: 911.8 MB)
19/07/31 15:23:07 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1006
19/07/31 15:23:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[286] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:23:07 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks
19/07/31 15:23:07 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 93, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:23:07 INFO Executor: Running task 0.0 in stage 75.0 (TID 93)
19/07/31 15:23:07 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:23:07 INFO Executor: Finished task 0.0 in stage 75.0 (TID 93). 7542 bytes result sent to driver
19/07/31 15:23:07 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 93) in 13 ms on localhost (executor driver) (1/1)
19/07/31 15:23:07 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
19/07/31 15:23:07 INFO DAGScheduler: ResultStage 75 (collect at utils.scala:204) finished in 0.014 s
19/07/31 15:23:07 INFO DAGScheduler: Job 53 finished: collect at utils.scala:204, took 0.031254 s
19/07/31 15:23:07 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:23:07 INFO DAGScheduler: Registering RDD 287 (collect at utils.scala:204)
19/07/31 15:23:07 INFO DAGScheduler: Got job 54 (collect at utils.scala:204) with 4 output partitions
19/07/31 15:23:07 INFO DAGScheduler: Final stage: ResultStage 77 (collect at utils.scala:204)
19/07/31 15:23:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 76)
19/07/31 15:23:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 76)
19/07/31 15:23:07 INFO DAGScheduler: Submitting ShuffleMapStage 76 (MapPartitionsRDD[287] at collect at utils.scala:204), which has no missing parents
19/07/31 15:23:07 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 74.6 KB, free 909.7 MB)
19/07/31 15:23:07 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 31.7 KB, free 909.7 MB)
19/07/31 15:23:07 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 127.0.0.1:64327 (size: 31.7 KB, free: 911.7 MB)
19/07/31 15:23:07 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1006
19/07/31 15:23:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 76 (MapPartitionsRDD[287] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:23:07 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks
19/07/31 15:23:07 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 94, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 15:23:07 INFO Executor: Running task 0.0 in stage 76.0 (TID 94)
19/07/31 15:23:07 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:23:07 INFO Executor: Finished task 0.0 in stage 76.0 (TID 94). 1687 bytes result sent to driver
19/07/31 15:23:07 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 94) in 11 ms on localhost (executor driver) (1/1)
19/07/31 15:23:07 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
19/07/31 15:23:07 INFO DAGScheduler: ShuffleMapStage 76 (collect at utils.scala:204) finished in 0.011 s
19/07/31 15:23:07 INFO DAGScheduler: looking for newly runnable stages
19/07/31 15:23:07 INFO DAGScheduler: running: Set()
19/07/31 15:23:07 INFO DAGScheduler: waiting: Set(ResultStage 77)
19/07/31 15:23:07 INFO DAGScheduler: failed: Set()
19/07/31 15:23:07 INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[290] at collect at utils.scala:204), which has no missing parents
19/07/31 15:23:07 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 16.8 KB, free 909.7 MB)
19/07/31 15:23:07 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.7 MB)
19/07/31 15:23:07 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 127.0.0.1:64327 (size: 8.0 KB, free: 911.7 MB)
19/07/31 15:23:07 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1006
19/07/31 15:23:07 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 77 (MapPartitionsRDD[290] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 15:23:07 INFO TaskSchedulerImpl: Adding task set 77.0 with 4 tasks
19/07/31 15:23:07 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 95, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 15:23:07 INFO TaskSetManager: Starting task 1.0 in stage 77.0 (TID 96, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 15:23:07 INFO TaskSetManager: Starting task 2.0 in stage 77.0 (TID 97, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 15:23:07 INFO TaskSetManager: Starting task 3.0 in stage 77.0 (TID 98, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 15:23:07 INFO Executor: Running task 0.0 in stage 77.0 (TID 95)
19/07/31 15:23:07 INFO Executor: Running task 1.0 in stage 77.0 (TID 96)
19/07/31 15:23:07 INFO Executor: Running task 2.0 in stage 77.0 (TID 97)
19/07/31 15:23:07 INFO Executor: Running task 3.0 in stage 77.0 (TID 98)
19/07/31 15:23:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:23:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:23:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:23:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:23:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:23:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:23:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:23:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:23:07 INFO Executor: Finished task 2.0 in stage 77.0 (TID 97). 2390 bytes result sent to driver
19/07/31 15:23:07 INFO Executor: Finished task 3.0 in stage 77.0 (TID 98). 2362 bytes result sent to driver
19/07/31 15:23:07 INFO Executor: Finished task 1.0 in stage 77.0 (TID 96). 2403 bytes result sent to driver
19/07/31 15:23:07 INFO Executor: Finished task 0.0 in stage 77.0 (TID 95). 2382 bytes result sent to driver
19/07/31 15:23:07 INFO TaskSetManager: Finished task 3.0 in stage 77.0 (TID 98) in 7 ms on localhost (executor driver) (1/4)
19/07/31 15:23:07 INFO TaskSetManager: Finished task 2.0 in stage 77.0 (TID 97) in 7 ms on localhost (executor driver) (2/4)
19/07/31 15:23:07 INFO TaskSetManager: Finished task 1.0 in stage 77.0 (TID 96) in 8 ms on localhost (executor driver) (3/4)
19/07/31 15:23:07 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 95) in 8 ms on localhost (executor driver) (4/4)
19/07/31 15:23:07 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
19/07/31 15:23:07 INFO DAGScheduler: ResultStage 77 (collect at utils.scala:204) finished in 0.009 s
19/07/31 15:23:07 INFO DAGScheduler: Job 54 finished: collect at utils.scala:204, took 0.040274 s
19/07/31 15:24:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_077`) `dbplyr_078`
ORDER BY `date`) `dbplyr_079`) `dbplyr_080`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:24:08 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:24:08 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:24:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_081`) `dbplyr_082`
ORDER BY `date`) `dbplyr_083`) `dbplyr_084`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:24:08 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:24:08 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:24:08 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#3129) generates partition filter: ((cust_prospect_ind.count#3937 - cust_prospect_ind.nullCount#3936) > 0)
19/07/31 15:24:08 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#3130) generates partition filter: ((visit_device_type.count#3942 - visit_device_type.nullCount#3941) > 0)
19/07/31 15:24:08 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#3129 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#3935 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#3934))
19/07/31 15:24:08 INFO InMemoryTableScanExec: Predicate (visit_device_type#3130 = All Devices) generates partition filter: ((visit_device_type.lowerBound#3940 <= All Devices) && (All Devices <= visit_device_type.upperBound#3939))
19/07/31 15:24:08 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:24:08 INFO DAGScheduler: Got job 55 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:24:08 INFO DAGScheduler: Final stage: ResultStage 78 (collect at utils.scala:204)
19/07/31 15:24:08 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:24:08 INFO DAGScheduler: Missing parents: List()
19/07/31 15:24:08 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[295] at collect at utils.scala:204), which has no missing parents
19/07/31 15:24:08 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 72.1 KB, free 909.6 MB)
19/07/31 15:24:08 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.6 MB)
19/07/31 15:24:08 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 127.0.0.1:64327 (size: 30.5 KB, free: 911.7 MB)
19/07/31 15:24:08 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1006
19/07/31 15:24:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[295] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:24:08 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks
19/07/31 15:24:08 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 99, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:24:08 INFO Executor: Running task 0.0 in stage 78.0 (TID 99)
19/07/31 15:24:08 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:24:08 INFO Executor: Finished task 0.0 in stage 78.0 (TID 99). 7542 bytes result sent to driver
19/07/31 15:24:08 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 99) in 5 ms on localhost (executor driver) (1/1)
19/07/31 15:24:08 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
19/07/31 15:24:08 INFO DAGScheduler: ResultStage 78 (collect at utils.scala:204) finished in 0.006 s
19/07/31 15:24:08 INFO DAGScheduler: Job 55 finished: collect at utils.scala:204, took 0.012736 s
19/07/31 15:24:08 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:24:08 INFO DAGScheduler: Registering RDD 296 (collect at utils.scala:204)
19/07/31 15:24:08 INFO DAGScheduler: Got job 56 (collect at utils.scala:204) with 4 output partitions
19/07/31 15:24:08 INFO DAGScheduler: Final stage: ResultStage 80 (collect at utils.scala:204)
19/07/31 15:24:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 79)
19/07/31 15:24:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 79)
19/07/31 15:24:08 INFO DAGScheduler: Submitting ShuffleMapStage 79 (MapPartitionsRDD[296] at collect at utils.scala:204), which has no missing parents
19/07/31 15:24:08 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 74.6 KB, free 909.5 MB)
19/07/31 15:24:08 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.5 MB)
19/07/31 15:24:08 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 127.0.0.1:64327 (size: 31.8 KB, free: 911.7 MB)
19/07/31 15:24:08 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1006
19/07/31 15:24:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 79 (MapPartitionsRDD[296] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:24:08 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks
19/07/31 15:24:08 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 100, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 15:24:08 INFO Executor: Running task 0.0 in stage 79.0 (TID 100)
19/07/31 15:24:08 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:24:08 INFO Executor: Finished task 0.0 in stage 79.0 (TID 100). 1687 bytes result sent to driver
19/07/31 15:24:08 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 100) in 9 ms on localhost (executor driver) (1/1)
19/07/31 15:24:08 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
19/07/31 15:24:08 INFO DAGScheduler: ShuffleMapStage 79 (collect at utils.scala:204) finished in 0.010 s
19/07/31 15:24:08 INFO DAGScheduler: looking for newly runnable stages
19/07/31 15:24:08 INFO DAGScheduler: running: Set()
19/07/31 15:24:08 INFO DAGScheduler: waiting: Set(ResultStage 80)
19/07/31 15:24:08 INFO DAGScheduler: failed: Set()
19/07/31 15:24:08 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[299] at collect at utils.scala:204), which has no missing parents
19/07/31 15:24:08 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 16.8 KB, free 909.5 MB)
19/07/31 15:24:08 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.4 MB)
19/07/31 15:24:08 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 127.0.0.1:64327 (size: 8.0 KB, free: 911.7 MB)
19/07/31 15:24:08 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1006
19/07/31 15:24:08 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 80 (MapPartitionsRDD[299] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 15:24:08 INFO TaskSchedulerImpl: Adding task set 80.0 with 4 tasks
19/07/31 15:24:08 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 101, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 15:24:08 INFO TaskSetManager: Starting task 1.0 in stage 80.0 (TID 102, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 15:24:08 INFO TaskSetManager: Starting task 2.0 in stage 80.0 (TID 103, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 15:24:08 INFO TaskSetManager: Starting task 3.0 in stage 80.0 (TID 104, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 15:24:08 INFO Executor: Running task 0.0 in stage 80.0 (TID 101)
19/07/31 15:24:08 INFO Executor: Running task 3.0 in stage 80.0 (TID 104)
19/07/31 15:24:08 INFO Executor: Running task 1.0 in stage 80.0 (TID 102)
19/07/31 15:24:08 INFO Executor: Running task 2.0 in stage 80.0 (TID 103)
19/07/31 15:24:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:24:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:24:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:24:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:24:08 INFO ContextCleaner: Cleaned accumulator 1879
19/07/31 15:24:08 INFO ContextCleaner: Cleaned accumulator 1934
19/07/31 15:24:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:24:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:24:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:24:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 15:24:08 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 127.0.0.1:64327 in memory (size: 8.0 KB, free: 911.7 MB)
19/07/31 15:24:08 INFO ContextCleaner: Cleaned accumulator 1802
19/07/31 15:24:08 INFO ContextCleaner: Cleaned accumulator 2070
19/07/31 15:24:08 INFO ContextCleaner: Cleaned accumulator 1994
19/07/31 15:24:08 INFO ContextCleaner: Cleaned accumulator 2077
19/07/31 15:24:08 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 127.0.0.1:64327 in memory (size: 30.4 KB, free: 911.7 MB)
19/07/31 15:24:08 INFO ContextCleaner: Cleaned accumulator 2232
19/07/31 15:24:08 INFO ContextCleaner: Cleaned accumulator 1836
19/07/31 15:24:08 INFO ContextCleaner: Cleaned accumulator 1935
19/07/31 15:24:08 INFO ContextCleaner: Cleaned accumulator 1805
19/07/31 15:24:08 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 127.0.0.1:64327 in memory (size: 30.5 KB, free: 911.7 MB)
19/07/31 15:24:08 INFO ContextCleaner: Cleaned accumulator 2151
19/07/31 15:24:08 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 127.0.0.1:64327 in memory (size: 8.0 KB, free: 911.7 MB)
19/07/31 15:24:08 INFO ContextCleaner: Cleaned accumulator 1993
19/07/31 15:24:08 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 127.0.0.1:64327 in memory (size: 11.8 KB, free: 911.8 MB)
19/07/31 15:24:08 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 127.0.0.1:64327 in memory (size: 30.4 KB, free: 911.8 MB)
19/07/31 15:24:08 INFO ContextCleaner: Cleaned accumulator 2073
19/07/31 15:24:08 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:64327 in memory (size: 31.8 KB, free: 911.8 MB)
19/07/31 15:24:08 INFO ContextCleaner: Cleaned accumulator 1876
19/07/31 15:24:08 INFO ContextCleaner: Cleaned accumulator 1996
19/07/31 15:24:08 INFO ContextCleaner: Cleaned accumulator 2313
19/07/31 15:24:08 INFO ContextCleaner: Cleaned accumulator 1752
19/07/31 15:24:08 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 127.0.0.1:64327 in memory (size: 3.7 KB, free: 911.8 MB)
19/07/31 15:24:08 INFO ContextCleaner: Cleaned accumulator 1832
19/07/31 15:24:08 INFO ContextCleaner: Cleaned accumulator 2074
19/07/31 15:24:08 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:64327 in memory (size: 8.6 KB, free: 911.8 MB)
19/07/31 15:24:08 INFO ContextCleaner: Cleaned shuffle 22
19/07/31 15:24:08 INFO ContextCleaner: Cleaned accumulator 1677
19/07/31 15:24:08 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 127.0.0.1:64327 in memory (size: 8.0 KB, free: 911.8 MB)
19/07/31 15:24:08 INFO ContextCleaner: Cleaned accumulator 1669
19/07/31 15:24:08 INFO ContextCleaner: Cleaned accumulator 1671
19/07/31 15:24:09 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 127.0.0.1:64327 in memory (size: 31.8 KB, free: 911.9 MB)
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1932
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1833
19/07/31 15:24:09 INFO ContextCleaner: Cleaned shuffle 16
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1873
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1673
19/07/31 15:24:09 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:64327 in memory (size: 8.0 KB, free: 911.9 MB)
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1675
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1867
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 2078
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1938
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1868
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1751
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1672
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1936
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 2239
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1874
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1990
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1933
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1875
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1931
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 2072
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 2071
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1937
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1804
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1878
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1997
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1674
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1750
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1877
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1676
19/07/31 15:24:09 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:64327 in memory (size: 4.3 KB, free: 911.9 MB)
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 2235
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1777
19/07/31 15:24:09 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 127.0.0.1:64327 in memory (size: 30.5 KB, free: 911.9 MB)
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 2234
19/07/31 15:24:09 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 127.0.0.1:64327 in memory (size: 31.8 KB, free: 911.9 MB)
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1871
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 2075
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1939
19/07/31 15:24:09 INFO ContextCleaner: Cleaned shuffle 20
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1807
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1835
19/07/31 15:24:09 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 127.0.0.1:64327 in memory (size: 31.7 KB, free: 912.0 MB)
19/07/31 15:24:09 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:64327 in memory (size: 23.8 KB, free: 912.0 MB)
19/07/31 15:24:09 INFO ContextCleaner: Cleaned shuffle 17
19/07/31 15:24:09 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 127.0.0.1:64327 in memory (size: 31.7 KB, free: 912.0 MB)
19/07/31 15:24:09 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:64327 in memory (size: 30.8 KB, free: 912.1 MB)
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1670
19/07/31 15:24:09 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 127.0.0.1:64327 in memory (size: 31.7 KB, free: 912.1 MB)
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1940
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1803
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1834
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 2076
19/07/31 15:24:09 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 127.0.0.1:64327 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1869
19/07/31 15:24:09 INFO ContextCleaner: Cleaned shuffle 18
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 2238
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 2233
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1992
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1929
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1870
19/07/31 15:24:09 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 127.0.0.1:64327 in memory (size: 11.9 KB, free: 912.1 MB)
19/07/31 15:24:09 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:64327 in memory (size: 23.8 KB, free: 912.1 MB)
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1989
19/07/31 15:24:09 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:64327 in memory (size: 3.5 KB, free: 912.1 MB)
19/07/31 15:24:09 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 127.0.0.1:64327 in memory (size: 30.5 KB, free: 912.2 MB)
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1806
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 2236
19/07/31 15:24:09 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 127.0.0.1:64327 in memory (size: 8.0 KB, free: 912.2 MB)
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1872
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1995
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1928
19/07/31 15:24:09 INFO ContextCleaner: Cleaned shuffle 19
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 2237
19/07/31 15:24:09 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:64327 in memory (size: 30.5 KB, free: 912.2 MB)
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1991
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 1930
19/07/31 15:24:09 INFO ContextCleaner: Cleaned accumulator 2240
19/07/31 15:24:09 INFO Executor: Finished task 1.0 in stage 80.0 (TID 102). 2446 bytes result sent to driver
19/07/31 15:24:09 INFO TaskSetManager: Finished task 1.0 in stage 80.0 (TID 102) in 82 ms on localhost (executor driver) (1/4)
19/07/31 15:24:09 INFO Executor: Finished task 2.0 in stage 80.0 (TID 103). 2433 bytes result sent to driver
19/07/31 15:24:09 INFO TaskSetManager: Finished task 2.0 in stage 80.0 (TID 103) in 84 ms on localhost (executor driver) (2/4)
19/07/31 15:24:09 INFO Executor: Finished task 3.0 in stage 80.0 (TID 104). 2405 bytes result sent to driver
19/07/31 15:24:09 INFO TaskSetManager: Finished task 3.0 in stage 80.0 (TID 104) in 88 ms on localhost (executor driver) (3/4)
19/07/31 15:24:09 INFO Executor: Finished task 0.0 in stage 80.0 (TID 101). 2425 bytes result sent to driver
19/07/31 15:24:09 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 101) in 141 ms on localhost (executor driver) (4/4)
19/07/31 15:24:09 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
19/07/31 15:24:09 INFO DAGScheduler: ResultStage 80 (collect at utils.scala:204) finished in 0.142 s
19/07/31 15:24:09 INFO DAGScheduler: Job 56 finished: collect at utils.scala:204, took 0.163840 s
19/07/31 15:32:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_085`) `dbplyr_086`
ORDER BY `date`) `dbplyr_087`) `dbplyr_088`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:32:48 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:32:48 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:32:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_089`) `dbplyr_090`
ORDER BY `date`) `dbplyr_091`) `dbplyr_092`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:32:48 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:32:48 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:32:48 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#3129) generates partition filter: ((cust_prospect_ind.count#4035 - cust_prospect_ind.nullCount#4034) > 0)
19/07/31 15:32:48 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#3130) generates partition filter: ((visit_device_type.count#4040 - visit_device_type.nullCount#4039) > 0)
19/07/31 15:32:48 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#3129 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4033 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4032))
19/07/31 15:32:48 INFO InMemoryTableScanExec: Predicate (visit_device_type#3130 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4038 <= All Devices) && (All Devices <= visit_device_type.upperBound#4037))
19/07/31 15:32:48 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:32:48 INFO DAGScheduler: Got job 57 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:32:48 INFO DAGScheduler: Final stage: ResultStage 81 (collect at utils.scala:204)
19/07/31 15:32:48 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:32:48 INFO DAGScheduler: Missing parents: List()
19/07/31 15:32:48 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[304] at collect at utils.scala:204), which has no missing parents
19/07/31 15:32:48 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 72.1 KB, free 911.6 MB)
19/07/31 15:32:48 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.5 MB)
19/07/31 15:32:48 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 127.0.0.1:64327 (size: 30.4 KB, free: 912.2 MB)
19/07/31 15:32:48 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1006
19/07/31 15:32:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[304] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:32:48 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks
19/07/31 15:32:48 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 105, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:32:48 INFO Executor: Running task 0.0 in stage 81.0 (TID 105)
19/07/31 15:32:48 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:32:48 INFO Executor: Finished task 0.0 in stage 81.0 (TID 105). 7542 bytes result sent to driver
19/07/31 15:32:48 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 105) in 9 ms on localhost (executor driver) (1/1)
19/07/31 15:32:48 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
19/07/31 15:32:48 INFO DAGScheduler: ResultStage 81 (collect at utils.scala:204) finished in 0.010 s
19/07/31 15:32:48 INFO DAGScheduler: Job 57 finished: collect at utils.scala:204, took 0.023291 s
19/07/31 15:32:48 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:32:48 INFO DAGScheduler: Registering RDD 305 (collect at utils.scala:204)
19/07/31 15:32:48 INFO DAGScheduler: Got job 58 (collect at utils.scala:204) with 4 output partitions
19/07/31 15:32:48 INFO DAGScheduler: Final stage: ResultStage 83 (collect at utils.scala:204)
19/07/31 15:32:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 82)
19/07/31 15:32:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 82)
19/07/31 15:32:48 INFO DAGScheduler: Submitting ShuffleMapStage 82 (MapPartitionsRDD[305] at collect at utils.scala:204), which has no missing parents
19/07/31 15:32:48 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 74.6 KB, free 911.5 MB)
19/07/31 15:32:48 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 31.7 KB, free 911.4 MB)
19/07/31 15:32:48 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 127.0.0.1:64327 (size: 31.7 KB, free: 912.1 MB)
19/07/31 15:32:48 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1006
19/07/31 15:32:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 82 (MapPartitionsRDD[305] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:32:48 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks
19/07/31 15:32:48 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 106, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 15:32:48 INFO Executor: Running task 0.0 in stage 82.0 (TID 106)
19/07/31 15:32:48 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:32:48 INFO Executor: Finished task 0.0 in stage 82.0 (TID 106). 1687 bytes result sent to driver
19/07/31 15:32:48 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 106) in 26 ms on localhost (executor driver) (1/1)
19/07/31 15:32:48 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
19/07/31 15:32:48 INFO DAGScheduler: ShuffleMapStage 82 (collect at utils.scala:204) finished in 0.027 s
19/07/31 15:32:48 INFO DAGScheduler: looking for newly runnable stages
19/07/31 15:32:48 INFO DAGScheduler: running: Set()
19/07/31 15:32:48 INFO DAGScheduler: waiting: Set(ResultStage 83)
19/07/31 15:32:48 INFO DAGScheduler: failed: Set()
19/07/31 15:32:48 INFO DAGScheduler: Submitting ResultStage 83 (MapPartitionsRDD[308] at collect at utils.scala:204), which has no missing parents
19/07/31 15:32:48 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 16.8 KB, free 911.4 MB)
19/07/31 15:32:48 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.4 MB)
19/07/31 15:32:48 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 127.0.0.1:64327 (size: 8.0 KB, free: 912.1 MB)
19/07/31 15:32:48 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1006
19/07/31 15:32:48 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 83 (MapPartitionsRDD[308] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 15:32:48 INFO TaskSchedulerImpl: Adding task set 83.0 with 4 tasks
19/07/31 15:32:48 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 107, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 15:32:48 INFO TaskSetManager: Starting task 1.0 in stage 83.0 (TID 108, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 15:32:48 INFO TaskSetManager: Starting task 2.0 in stage 83.0 (TID 109, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 15:32:48 INFO TaskSetManager: Starting task 3.0 in stage 83.0 (TID 110, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 15:32:48 INFO Executor: Running task 0.0 in stage 83.0 (TID 107)
19/07/31 15:32:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:32:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:32:48 INFO Executor: Running task 1.0 in stage 83.0 (TID 108)
19/07/31 15:32:48 INFO Executor: Finished task 0.0 in stage 83.0 (TID 107). 2382 bytes result sent to driver
19/07/31 15:32:48 INFO Executor: Running task 2.0 in stage 83.0 (TID 109)
19/07/31 15:32:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:32:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:32:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:32:48 INFO Executor: Running task 3.0 in stage 83.0 (TID 110)
19/07/31 15:32:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:32:48 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 107) in 12 ms on localhost (executor driver) (1/4)
19/07/31 15:32:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:32:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:32:48 INFO Executor: Finished task 2.0 in stage 83.0 (TID 109). 2390 bytes result sent to driver
19/07/31 15:32:48 INFO TaskSetManager: Finished task 2.0 in stage 83.0 (TID 109) in 15 ms on localhost (executor driver) (2/4)
19/07/31 15:32:48 INFO Executor: Finished task 1.0 in stage 83.0 (TID 108). 2403 bytes result sent to driver
19/07/31 15:32:48 INFO Executor: Finished task 3.0 in stage 83.0 (TID 110). 2362 bytes result sent to driver
19/07/31 15:32:48 INFO TaskSetManager: Finished task 1.0 in stage 83.0 (TID 108) in 16 ms on localhost (executor driver) (3/4)
19/07/31 15:32:48 INFO TaskSetManager: Finished task 3.0 in stage 83.0 (TID 110) in 16 ms on localhost (executor driver) (4/4)
19/07/31 15:32:48 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
19/07/31 15:32:48 INFO DAGScheduler: ResultStage 83 (collect at utils.scala:204) finished in 0.017 s
19/07/31 15:32:48 INFO DAGScheduler: Job 58 finished: collect at utils.scala:204, took 0.069535 s
19/07/31 15:33:06 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_093`) `dbplyr_094`
ORDER BY `date`) `dbplyr_095`) `dbplyr_096`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:33:06 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:33:06 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:33:06 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_097`) `dbplyr_098`
ORDER BY `date`) `dbplyr_099`) `dbplyr_100`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:33:06 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:33:06 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:33:06 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#3129) generates partition filter: ((cust_prospect_ind.count#4133 - cust_prospect_ind.nullCount#4132) > 0)
19/07/31 15:33:06 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#3130) generates partition filter: ((visit_device_type.count#4138 - visit_device_type.nullCount#4137) > 0)
19/07/31 15:33:06 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#3129 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4131 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4130))
19/07/31 15:33:06 INFO InMemoryTableScanExec: Predicate (visit_device_type#3130 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4136 <= All Devices) && (All Devices <= visit_device_type.upperBound#4135))
19/07/31 15:33:06 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:33:06 INFO DAGScheduler: Got job 59 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:33:06 INFO DAGScheduler: Final stage: ResultStage 84 (collect at utils.scala:204)
19/07/31 15:33:06 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:33:06 INFO DAGScheduler: Missing parents: List()
19/07/31 15:33:06 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[313] at collect at utils.scala:204), which has no missing parents
19/07/31 15:33:06 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 72.1 KB, free 911.3 MB)
19/07/31 15:33:06 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 30.5 KB, free 911.3 MB)
19/07/31 15:33:06 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 127.0.0.1:64327 (size: 30.5 KB, free: 912.1 MB)
19/07/31 15:33:06 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1006
19/07/31 15:33:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[313] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:33:06 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks
19/07/31 15:33:06 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 111, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:33:06 INFO Executor: Running task 0.0 in stage 84.0 (TID 111)
19/07/31 15:33:06 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:33:06 INFO Executor: Finished task 0.0 in stage 84.0 (TID 111). 7542 bytes result sent to driver
19/07/31 15:33:06 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 111) in 8 ms on localhost (executor driver) (1/1)
19/07/31 15:33:06 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
19/07/31 15:33:06 INFO DAGScheduler: ResultStage 84 (collect at utils.scala:204) finished in 0.009 s
19/07/31 15:33:06 INFO DAGScheduler: Job 59 finished: collect at utils.scala:204, took 0.019917 s
19/07/31 15:33:06 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:33:06 INFO DAGScheduler: Registering RDD 314 (collect at utils.scala:204)
19/07/31 15:33:06 INFO DAGScheduler: Got job 60 (collect at utils.scala:204) with 4 output partitions
19/07/31 15:33:06 INFO DAGScheduler: Final stage: ResultStage 86 (collect at utils.scala:204)
19/07/31 15:33:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 85)
19/07/31 15:33:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 85)
19/07/31 15:33:06 INFO DAGScheduler: Submitting ShuffleMapStage 85 (MapPartitionsRDD[314] at collect at utils.scala:204), which has no missing parents
19/07/31 15:33:06 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 74.6 KB, free 911.2 MB)
19/07/31 15:33:06 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.2 MB)
19/07/31 15:33:06 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 127.0.0.1:64327 (size: 31.8 KB, free: 912.1 MB)
19/07/31 15:33:06 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1006
19/07/31 15:33:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 85 (MapPartitionsRDD[314] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:33:06 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks
19/07/31 15:33:06 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 112, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 15:33:06 INFO Executor: Running task 0.0 in stage 85.0 (TID 112)
19/07/31 15:33:06 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:33:06 INFO Executor: Finished task 0.0 in stage 85.0 (TID 112). 1687 bytes result sent to driver
19/07/31 15:33:06 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 112) in 9 ms on localhost (executor driver) (1/1)
19/07/31 15:33:06 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
19/07/31 15:33:06 INFO DAGScheduler: ShuffleMapStage 85 (collect at utils.scala:204) finished in 0.011 s
19/07/31 15:33:06 INFO DAGScheduler: looking for newly runnable stages
19/07/31 15:33:06 INFO DAGScheduler: running: Set()
19/07/31 15:33:06 INFO DAGScheduler: waiting: Set(ResultStage 86)
19/07/31 15:33:06 INFO DAGScheduler: failed: Set()
19/07/31 15:33:06 INFO DAGScheduler: Submitting ResultStage 86 (MapPartitionsRDD[317] at collect at utils.scala:204), which has no missing parents
19/07/31 15:33:06 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 16.8 KB, free 911.2 MB)
19/07/31 15:33:06 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.2 MB)
19/07/31 15:33:06 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 127.0.0.1:64327 (size: 8.0 KB, free: 912.1 MB)
19/07/31 15:33:06 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1006
19/07/31 15:33:06 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 86 (MapPartitionsRDD[317] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 15:33:06 INFO TaskSchedulerImpl: Adding task set 86.0 with 4 tasks
19/07/31 15:33:06 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 113, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 15:33:06 INFO TaskSetManager: Starting task 1.0 in stage 86.0 (TID 114, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 15:33:06 INFO TaskSetManager: Starting task 2.0 in stage 86.0 (TID 115, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 15:33:06 INFO TaskSetManager: Starting task 3.0 in stage 86.0 (TID 116, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 15:33:06 INFO Executor: Running task 1.0 in stage 86.0 (TID 114)
19/07/31 15:33:06 INFO Executor: Running task 0.0 in stage 86.0 (TID 113)
19/07/31 15:33:06 INFO Executor: Running task 3.0 in stage 86.0 (TID 116)
19/07/31 15:33:06 INFO Executor: Running task 2.0 in stage 86.0 (TID 115)
19/07/31 15:33:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:33:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:33:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:33:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:33:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:33:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:33:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:33:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:33:06 INFO Executor: Finished task 0.0 in stage 86.0 (TID 113). 2382 bytes result sent to driver
19/07/31 15:33:06 INFO Executor: Finished task 3.0 in stage 86.0 (TID 116). 2362 bytes result sent to driver
19/07/31 15:33:06 INFO Executor: Finished task 2.0 in stage 86.0 (TID 115). 2390 bytes result sent to driver
19/07/31 15:33:06 INFO Executor: Finished task 1.0 in stage 86.0 (TID 114). 2446 bytes result sent to driver
19/07/31 15:33:06 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 113) in 10 ms on localhost (executor driver) (1/4)
19/07/31 15:33:06 INFO TaskSetManager: Finished task 2.0 in stage 86.0 (TID 115) in 10 ms on localhost (executor driver) (2/4)
19/07/31 15:33:06 INFO TaskSetManager: Finished task 3.0 in stage 86.0 (TID 116) in 10 ms on localhost (executor driver) (3/4)
19/07/31 15:33:06 INFO TaskSetManager: Finished task 1.0 in stage 86.0 (TID 114) in 10 ms on localhost (executor driver) (4/4)
19/07/31 15:33:06 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
19/07/31 15:33:06 INFO DAGScheduler: ResultStage 86 (collect at utils.scala:204) finished in 0.011 s
19/07/31 15:33:06 INFO DAGScheduler: Job 60 finished: collect at utils.scala:204, took 0.039061 s
19/07/31 15:33:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_101`) `dbplyr_102`
ORDER BY `date`) `dbplyr_103`) `dbplyr_104`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:33:35 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:33:35 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:33:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_105`) `dbplyr_106`
ORDER BY `date`) `dbplyr_107`) `dbplyr_108`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:33:35 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:33:35 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:33:36 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#3129) generates partition filter: ((cust_prospect_ind.count#4231 - cust_prospect_ind.nullCount#4230) > 0)
19/07/31 15:33:36 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#3130) generates partition filter: ((visit_device_type.count#4236 - visit_device_type.nullCount#4235) > 0)
19/07/31 15:33:36 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#3129 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4229 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4228))
19/07/31 15:33:36 INFO InMemoryTableScanExec: Predicate (visit_device_type#3130 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4234 <= All Devices) && (All Devices <= visit_device_type.upperBound#4233))
19/07/31 15:33:36 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:33:36 INFO DAGScheduler: Got job 61 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:33:36 INFO DAGScheduler: Final stage: ResultStage 87 (collect at utils.scala:204)
19/07/31 15:33:36 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:33:36 INFO DAGScheduler: Missing parents: List()
19/07/31 15:33:36 INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[322] at collect at utils.scala:204), which has no missing parents
19/07/31 15:33:36 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 72.1 KB, free 911.1 MB)
19/07/31 15:33:36 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 30.5 KB, free 911.1 MB)
19/07/31 15:33:36 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 127.0.0.1:64327 (size: 30.5 KB, free: 912.0 MB)
19/07/31 15:33:36 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1006
19/07/31 15:33:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[322] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:33:36 INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks
19/07/31 15:33:36 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 117, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:33:36 INFO Executor: Running task 0.0 in stage 87.0 (TID 117)
19/07/31 15:33:36 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:33:36 INFO Executor: Finished task 0.0 in stage 87.0 (TID 117). 7542 bytes result sent to driver
19/07/31 15:33:36 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 117) in 6 ms on localhost (executor driver) (1/1)
19/07/31 15:33:36 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
19/07/31 15:33:36 INFO DAGScheduler: ResultStage 87 (collect at utils.scala:204) finished in 0.006 s
19/07/31 15:33:36 INFO DAGScheduler: Job 61 finished: collect at utils.scala:204, took 0.014305 s
19/07/31 15:33:36 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:33:36 INFO DAGScheduler: Registering RDD 323 (collect at utils.scala:204)
19/07/31 15:33:36 INFO DAGScheduler: Got job 62 (collect at utils.scala:204) with 4 output partitions
19/07/31 15:33:36 INFO DAGScheduler: Final stage: ResultStage 89 (collect at utils.scala:204)
19/07/31 15:33:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 88)
19/07/31 15:33:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 88)
19/07/31 15:33:36 INFO DAGScheduler: Submitting ShuffleMapStage 88 (MapPartitionsRDD[323] at collect at utils.scala:204), which has no missing parents
19/07/31 15:33:36 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 74.6 KB, free 911.0 MB)
19/07/31 15:33:36 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.0 MB)
19/07/31 15:33:36 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 127.0.0.1:64327 (size: 31.8 KB, free: 912.0 MB)
19/07/31 15:33:36 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1006
19/07/31 15:33:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 88 (MapPartitionsRDD[323] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:33:36 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks
19/07/31 15:33:36 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 118, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 15:33:36 INFO Executor: Running task 0.0 in stage 88.0 (TID 118)
19/07/31 15:33:36 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:33:36 INFO Executor: Finished task 0.0 in stage 88.0 (TID 118). 1687 bytes result sent to driver
19/07/31 15:33:36 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 118) in 12 ms on localhost (executor driver) (1/1)
19/07/31 15:33:36 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
19/07/31 15:33:36 INFO DAGScheduler: ShuffleMapStage 88 (collect at utils.scala:204) finished in 0.012 s
19/07/31 15:33:36 INFO DAGScheduler: looking for newly runnable stages
19/07/31 15:33:36 INFO DAGScheduler: running: Set()
19/07/31 15:33:36 INFO DAGScheduler: waiting: Set(ResultStage 89)
19/07/31 15:33:36 INFO DAGScheduler: failed: Set()
19/07/31 15:33:36 INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[326] at collect at utils.scala:204), which has no missing parents
19/07/31 15:33:36 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 16.8 KB, free 911.0 MB)
19/07/31 15:33:36 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.9 MB)
19/07/31 15:33:36 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 127.0.0.1:64327 (size: 8.0 KB, free: 912.0 MB)
19/07/31 15:33:36 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1006
19/07/31 15:33:36 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 89 (MapPartitionsRDD[326] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 15:33:36 INFO TaskSchedulerImpl: Adding task set 89.0 with 4 tasks
19/07/31 15:33:36 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 119, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 15:33:36 INFO TaskSetManager: Starting task 1.0 in stage 89.0 (TID 120, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 15:33:36 INFO TaskSetManager: Starting task 2.0 in stage 89.0 (TID 121, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 15:33:36 INFO TaskSetManager: Starting task 3.0 in stage 89.0 (TID 122, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 15:33:36 INFO Executor: Running task 3.0 in stage 89.0 (TID 122)
19/07/31 15:33:36 INFO Executor: Running task 1.0 in stage 89.0 (TID 120)
19/07/31 15:33:36 INFO Executor: Running task 2.0 in stage 89.0 (TID 121)
19/07/31 15:33:36 INFO Executor: Running task 0.0 in stage 89.0 (TID 119)
19/07/31 15:33:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:33:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:33:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:33:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:33:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:33:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:33:36 INFO Executor: Finished task 3.0 in stage 89.0 (TID 122). 2362 bytes result sent to driver
19/07/31 15:33:36 INFO TaskSetManager: Finished task 3.0 in stage 89.0 (TID 122) in 6 ms on localhost (executor driver) (1/4)
19/07/31 15:33:36 INFO Executor: Finished task 1.0 in stage 89.0 (TID 120). 2403 bytes result sent to driver
19/07/31 15:33:36 INFO Executor: Finished task 2.0 in stage 89.0 (TID 121). 2390 bytes result sent to driver
19/07/31 15:33:36 INFO TaskSetManager: Finished task 1.0 in stage 89.0 (TID 120) in 8 ms on localhost (executor driver) (2/4)
19/07/31 15:33:36 INFO TaskSetManager: Finished task 2.0 in stage 89.0 (TID 121) in 8 ms on localhost (executor driver) (3/4)
19/07/31 15:33:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:33:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:33:36 INFO Executor: Finished task 0.0 in stage 89.0 (TID 119). 2382 bytes result sent to driver
19/07/31 15:33:36 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 119) in 12 ms on localhost (executor driver) (4/4)
19/07/31 15:33:36 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
19/07/31 15:33:36 INFO DAGScheduler: ResultStage 89 (collect at utils.scala:204) finished in 0.013 s
19/07/31 15:33:36 INFO DAGScheduler: Job 62 finished: collect at utils.scala:204, took 0.039322 s
19/07/31 15:33:52 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_109`) `dbplyr_110`
ORDER BY `date`) `dbplyr_111`) `dbplyr_112`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:33:52 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:33:52 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:33:52 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_113`) `dbplyr_114`
ORDER BY `date`) `dbplyr_115`) `dbplyr_116`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:33:52 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:33:52 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:33:52 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#3129) generates partition filter: ((cust_prospect_ind.count#4329 - cust_prospect_ind.nullCount#4328) > 0)
19/07/31 15:33:52 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#3130) generates partition filter: ((visit_device_type.count#4334 - visit_device_type.nullCount#4333) > 0)
19/07/31 15:33:52 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#3129 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4327 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4326))
19/07/31 15:33:52 INFO InMemoryTableScanExec: Predicate (visit_device_type#3130 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4332 <= All Devices) && (All Devices <= visit_device_type.upperBound#4331))
19/07/31 15:33:52 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:33:52 INFO DAGScheduler: Got job 63 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:33:52 INFO DAGScheduler: Final stage: ResultStage 90 (collect at utils.scala:204)
19/07/31 15:33:52 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:33:52 INFO DAGScheduler: Missing parents: List()
19/07/31 15:33:52 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[331] at collect at utils.scala:204), which has no missing parents
19/07/31 15:33:52 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 72.1 KB, free 910.9 MB)
19/07/31 15:33:52 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.8 MB)
19/07/31 15:33:52 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 127.0.0.1:64327 (size: 30.4 KB, free: 912.0 MB)
19/07/31 15:33:52 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1006
19/07/31 15:33:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[331] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:33:52 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks
19/07/31 15:33:52 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 123, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:33:52 INFO Executor: Running task 0.0 in stage 90.0 (TID 123)
19/07/31 15:33:52 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:33:52 INFO Executor: Finished task 0.0 in stage 90.0 (TID 123). 7542 bytes result sent to driver
19/07/31 15:33:52 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 123) in 5 ms on localhost (executor driver) (1/1)
19/07/31 15:33:52 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
19/07/31 15:33:52 INFO DAGScheduler: ResultStage 90 (collect at utils.scala:204) finished in 0.006 s
19/07/31 15:33:52 INFO DAGScheduler: Job 63 finished: collect at utils.scala:204, took 0.015471 s
19/07/31 15:33:52 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:33:52 INFO DAGScheduler: Registering RDD 332 (collect at utils.scala:204)
19/07/31 15:33:52 INFO DAGScheduler: Got job 64 (collect at utils.scala:204) with 4 output partitions
19/07/31 15:33:52 INFO DAGScheduler: Final stage: ResultStage 92 (collect at utils.scala:204)
19/07/31 15:33:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 91)
19/07/31 15:33:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 91)
19/07/31 15:33:52 INFO DAGScheduler: Submitting ShuffleMapStage 91 (MapPartitionsRDD[332] at collect at utils.scala:204), which has no missing parents
19/07/31 15:33:52 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 74.6 KB, free 910.8 MB)
19/07/31 15:33:52 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.7 MB)
19/07/31 15:33:52 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 127.0.0.1:64327 (size: 31.7 KB, free: 911.9 MB)
19/07/31 15:33:52 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1006
19/07/31 15:33:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 91 (MapPartitionsRDD[332] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:33:52 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks
19/07/31 15:33:52 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 124, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 15:33:52 INFO Executor: Running task 0.0 in stage 91.0 (TID 124)
19/07/31 15:33:52 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:33:52 INFO Executor: Finished task 0.0 in stage 91.0 (TID 124). 1687 bytes result sent to driver
19/07/31 15:33:52 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 124) in 12 ms on localhost (executor driver) (1/1)
19/07/31 15:33:52 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
19/07/31 15:33:52 INFO DAGScheduler: ShuffleMapStage 91 (collect at utils.scala:204) finished in 0.013 s
19/07/31 15:33:52 INFO DAGScheduler: looking for newly runnable stages
19/07/31 15:33:52 INFO DAGScheduler: running: Set()
19/07/31 15:33:52 INFO DAGScheduler: waiting: Set(ResultStage 92)
19/07/31 15:33:52 INFO DAGScheduler: failed: Set()
19/07/31 15:33:52 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[335] at collect at utils.scala:204), which has no missing parents
19/07/31 15:33:52 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 16.8 KB, free 910.7 MB)
19/07/31 15:33:52 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.7 MB)
19/07/31 15:33:52 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 127.0.0.1:64327 (size: 8.0 KB, free: 911.9 MB)
19/07/31 15:33:52 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1006
19/07/31 15:33:52 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 92 (MapPartitionsRDD[335] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 15:33:52 INFO TaskSchedulerImpl: Adding task set 92.0 with 4 tasks
19/07/31 15:33:52 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 125, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 15:33:52 INFO TaskSetManager: Starting task 1.0 in stage 92.0 (TID 126, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 15:33:52 INFO TaskSetManager: Starting task 2.0 in stage 92.0 (TID 127, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 15:33:52 INFO TaskSetManager: Starting task 3.0 in stage 92.0 (TID 128, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 15:33:52 INFO Executor: Running task 0.0 in stage 92.0 (TID 125)
19/07/31 15:33:52 INFO Executor: Running task 1.0 in stage 92.0 (TID 126)
19/07/31 15:33:52 INFO Executor: Running task 3.0 in stage 92.0 (TID 128)
19/07/31 15:33:52 INFO Executor: Running task 2.0 in stage 92.0 (TID 127)
19/07/31 15:33:52 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:33:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:33:52 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:33:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:33:52 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:33:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:33:52 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:33:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:33:52 INFO Executor: Finished task 1.0 in stage 92.0 (TID 126). 2403 bytes result sent to driver
19/07/31 15:33:52 INFO Executor: Finished task 3.0 in stage 92.0 (TID 128). 2362 bytes result sent to driver
19/07/31 15:33:52 INFO Executor: Finished task 0.0 in stage 92.0 (TID 125). 2382 bytes result sent to driver
19/07/31 15:33:52 INFO TaskSetManager: Finished task 1.0 in stage 92.0 (TID 126) in 10 ms on localhost (executor driver) (1/4)
19/07/31 15:33:52 INFO Executor: Finished task 2.0 in stage 92.0 (TID 127). 2390 bytes result sent to driver
19/07/31 15:33:52 INFO TaskSetManager: Finished task 3.0 in stage 92.0 (TID 128) in 11 ms on localhost (executor driver) (2/4)
19/07/31 15:33:52 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 125) in 12 ms on localhost (executor driver) (3/4)
19/07/31 15:33:52 INFO TaskSetManager: Finished task 2.0 in stage 92.0 (TID 127) in 11 ms on localhost (executor driver) (4/4)
19/07/31 15:33:52 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
19/07/31 15:33:52 INFO DAGScheduler: ResultStage 92 (collect at utils.scala:204) finished in 0.012 s
19/07/31 15:33:52 INFO DAGScheduler: Job 64 finished: collect at utils.scala:204, took 0.042862 s
19/07/31 15:34:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_117`) `dbplyr_118`
ORDER BY `date`) `dbplyr_119`) `dbplyr_120`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:34:20 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:34:20 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:34:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_121`) `dbplyr_122`
ORDER BY `date`) `dbplyr_123`) `dbplyr_124`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:34:20 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:34:20 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:34:20 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#3129) generates partition filter: ((cust_prospect_ind.count#4427 - cust_prospect_ind.nullCount#4426) > 0)
19/07/31 15:34:20 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#3130) generates partition filter: ((visit_device_type.count#4432 - visit_device_type.nullCount#4431) > 0)
19/07/31 15:34:20 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#3129 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4425 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4424))
19/07/31 15:34:20 INFO InMemoryTableScanExec: Predicate (visit_device_type#3130 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4430 <= All Devices) && (All Devices <= visit_device_type.upperBound#4429))
19/07/31 15:34:20 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:34:20 INFO DAGScheduler: Got job 65 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:34:20 INFO DAGScheduler: Final stage: ResultStage 93 (collect at utils.scala:204)
19/07/31 15:34:20 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:34:20 INFO DAGScheduler: Missing parents: List()
19/07/31 15:34:20 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[340] at collect at utils.scala:204), which has no missing parents
19/07/31 15:34:20 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 72.1 KB, free 910.6 MB)
19/07/31 15:34:20 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.6 MB)
19/07/31 15:34:20 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 127.0.0.1:64327 (size: 30.5 KB, free: 911.9 MB)
19/07/31 15:34:20 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1006
19/07/31 15:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[340] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:34:20 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks
19/07/31 15:34:20 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 129, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:34:20 INFO Executor: Running task 0.0 in stage 93.0 (TID 129)
19/07/31 15:34:20 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:34:20 INFO Executor: Finished task 0.0 in stage 93.0 (TID 129). 7542 bytes result sent to driver
19/07/31 15:34:20 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 129) in 6 ms on localhost (executor driver) (1/1)
19/07/31 15:34:20 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
19/07/31 15:34:20 INFO DAGScheduler: ResultStage 93 (collect at utils.scala:204) finished in 0.006 s
19/07/31 15:34:20 INFO DAGScheduler: Job 65 finished: collect at utils.scala:204, took 0.015039 s
19/07/31 15:34:20 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:34:20 INFO DAGScheduler: Registering RDD 341 (collect at utils.scala:204)
19/07/31 15:34:20 INFO DAGScheduler: Got job 66 (collect at utils.scala:204) with 4 output partitions
19/07/31 15:34:20 INFO DAGScheduler: Final stage: ResultStage 95 (collect at utils.scala:204)
19/07/31 15:34:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 94)
19/07/31 15:34:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 94)
19/07/31 15:34:20 INFO DAGScheduler: Submitting ShuffleMapStage 94 (MapPartitionsRDD[341] at collect at utils.scala:204), which has no missing parents
19/07/31 15:34:20 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 74.6 KB, free 910.5 MB)
19/07/31 15:34:20 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.5 MB)
19/07/31 15:34:20 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 127.0.0.1:64327 (size: 31.8 KB, free: 911.9 MB)
19/07/31 15:34:20 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1006
19/07/31 15:34:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 94 (MapPartitionsRDD[341] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:34:20 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks
19/07/31 15:34:20 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 130, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 15:34:20 INFO Executor: Running task 0.0 in stage 94.0 (TID 130)
19/07/31 15:34:20 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:34:20 INFO Executor: Finished task 0.0 in stage 94.0 (TID 130). 1687 bytes result sent to driver
19/07/31 15:34:20 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 130) in 13 ms on localhost (executor driver) (1/1)
19/07/31 15:34:20 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
19/07/31 15:34:20 INFO DAGScheduler: ShuffleMapStage 94 (collect at utils.scala:204) finished in 0.013 s
19/07/31 15:34:20 INFO DAGScheduler: looking for newly runnable stages
19/07/31 15:34:20 INFO DAGScheduler: running: Set()
19/07/31 15:34:20 INFO DAGScheduler: waiting: Set(ResultStage 95)
19/07/31 15:34:20 INFO DAGScheduler: failed: Set()
19/07/31 15:34:20 INFO DAGScheduler: Submitting ResultStage 95 (MapPartitionsRDD[344] at collect at utils.scala:204), which has no missing parents
19/07/31 15:34:20 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 16.8 KB, free 910.5 MB)
19/07/31 15:34:20 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.5 MB)
19/07/31 15:34:20 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 127.0.0.1:64327 (size: 8.0 KB, free: 911.9 MB)
19/07/31 15:34:20 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1006
19/07/31 15:34:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 95 (MapPartitionsRDD[344] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 15:34:20 INFO TaskSchedulerImpl: Adding task set 95.0 with 4 tasks
19/07/31 15:34:20 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 131, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 15:34:20 INFO TaskSetManager: Starting task 1.0 in stage 95.0 (TID 132, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 15:34:20 INFO TaskSetManager: Starting task 2.0 in stage 95.0 (TID 133, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 15:34:20 INFO TaskSetManager: Starting task 3.0 in stage 95.0 (TID 134, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 15:34:20 INFO Executor: Running task 2.0 in stage 95.0 (TID 133)
19/07/31 15:34:20 INFO Executor: Running task 1.0 in stage 95.0 (TID 132)
19/07/31 15:34:20 INFO Executor: Running task 3.0 in stage 95.0 (TID 134)
19/07/31 15:34:20 INFO Executor: Running task 0.0 in stage 95.0 (TID 131)
19/07/31 15:34:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:34:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:34:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:34:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:34:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:34:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:34:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:34:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:34:20 INFO Executor: Finished task 1.0 in stage 95.0 (TID 132). 2403 bytes result sent to driver
19/07/31 15:34:20 INFO Executor: Finished task 3.0 in stage 95.0 (TID 134). 2362 bytes result sent to driver
19/07/31 15:34:20 INFO TaskSetManager: Finished task 1.0 in stage 95.0 (TID 132) in 7 ms on localhost (executor driver) (1/4)
19/07/31 15:34:20 INFO Executor: Finished task 2.0 in stage 95.0 (TID 133). 2390 bytes result sent to driver
19/07/31 15:34:20 INFO TaskSetManager: Finished task 3.0 in stage 95.0 (TID 134) in 8 ms on localhost (executor driver) (2/4)
19/07/31 15:34:20 INFO TaskSetManager: Finished task 2.0 in stage 95.0 (TID 133) in 8 ms on localhost (executor driver) (3/4)
19/07/31 15:34:20 INFO Executor: Finished task 0.0 in stage 95.0 (TID 131). 2382 bytes result sent to driver
19/07/31 15:34:20 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 131) in 9 ms on localhost (executor driver) (4/4)
19/07/31 15:34:20 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
19/07/31 15:34:20 INFO DAGScheduler: ResultStage 95 (collect at utils.scala:204) finished in 0.009 s
19/07/31 15:34:20 INFO DAGScheduler: Job 66 finished: collect at utils.scala:204, took 0.042919 s
19/07/31 15:34:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_125`) `dbplyr_126`
ORDER BY `date`) `dbplyr_127`) `dbplyr_128`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:34:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:34:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:34:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_129`) `dbplyr_130`
ORDER BY `date`) `dbplyr_131`) `dbplyr_132`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:34:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:34:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:34:26 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#3129) generates partition filter: ((cust_prospect_ind.count#4525 - cust_prospect_ind.nullCount#4524) > 0)
19/07/31 15:34:26 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#3130) generates partition filter: ((visit_device_type.count#4530 - visit_device_type.nullCount#4529) > 0)
19/07/31 15:34:26 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#3129 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4523 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4522))
19/07/31 15:34:26 INFO InMemoryTableScanExec: Predicate (visit_device_type#3130 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4528 <= All Devices) && (All Devices <= visit_device_type.upperBound#4527))
19/07/31 15:34:26 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:34:26 INFO DAGScheduler: Got job 67 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:34:26 INFO DAGScheduler: Final stage: ResultStage 96 (collect at utils.scala:204)
19/07/31 15:34:26 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:34:26 INFO DAGScheduler: Missing parents: List()
19/07/31 15:34:26 INFO DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[349] at collect at utils.scala:204), which has no missing parents
19/07/31 15:34:26 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 72.1 KB, free 910.4 MB)
19/07/31 15:34:26 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.4 MB)
19/07/31 15:34:26 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 127.0.0.1:64327 (size: 30.4 KB, free: 911.8 MB)
19/07/31 15:34:26 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1006
19/07/31 15:34:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[349] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:34:26 INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks
19/07/31 15:34:26 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 135, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:34:26 INFO Executor: Running task 0.0 in stage 96.0 (TID 135)
19/07/31 15:34:26 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:34:26 INFO Executor: Finished task 0.0 in stage 96.0 (TID 135). 7542 bytes result sent to driver
19/07/31 15:34:26 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 135) in 5 ms on localhost (executor driver) (1/1)
19/07/31 15:34:26 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
19/07/31 15:34:26 INFO DAGScheduler: ResultStage 96 (collect at utils.scala:204) finished in 0.006 s
19/07/31 15:34:26 INFO DAGScheduler: Job 67 finished: collect at utils.scala:204, took 0.014441 s
19/07/31 15:34:26 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:34:26 INFO DAGScheduler: Registering RDD 350 (collect at utils.scala:204)
19/07/31 15:34:26 INFO DAGScheduler: Got job 68 (collect at utils.scala:204) with 4 output partitions
19/07/31 15:34:26 INFO DAGScheduler: Final stage: ResultStage 98 (collect at utils.scala:204)
19/07/31 15:34:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 97)
19/07/31 15:34:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 97)
19/07/31 15:34:26 INFO DAGScheduler: Submitting ShuffleMapStage 97 (MapPartitionsRDD[350] at collect at utils.scala:204), which has no missing parents
19/07/31 15:34:26 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 74.6 KB, free 910.3 MB)
19/07/31 15:34:26 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.3 MB)
19/07/31 15:34:26 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 127.0.0.1:64327 (size: 31.8 KB, free: 911.8 MB)
19/07/31 15:34:26 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1006
19/07/31 15:34:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 97 (MapPartitionsRDD[350] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:34:26 INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks
19/07/31 15:34:26 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 136, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 15:34:26 INFO Executor: Running task 0.0 in stage 97.0 (TID 136)
19/07/31 15:34:26 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:34:26 INFO Executor: Finished task 0.0 in stage 97.0 (TID 136). 1687 bytes result sent to driver
19/07/31 15:34:26 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 136) in 10 ms on localhost (executor driver) (1/1)
19/07/31 15:34:26 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
19/07/31 15:34:26 INFO DAGScheduler: ShuffleMapStage 97 (collect at utils.scala:204) finished in 0.010 s
19/07/31 15:34:26 INFO DAGScheduler: looking for newly runnable stages
19/07/31 15:34:26 INFO DAGScheduler: running: Set()
19/07/31 15:34:26 INFO DAGScheduler: waiting: Set(ResultStage 98)
19/07/31 15:34:26 INFO DAGScheduler: failed: Set()
19/07/31 15:34:26 INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[353] at collect at utils.scala:204), which has no missing parents
19/07/31 15:34:26 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 16.8 KB, free 910.3 MB)
19/07/31 15:34:26 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.3 MB)
19/07/31 15:34:26 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 127.0.0.1:64327 (size: 8.0 KB, free: 911.8 MB)
19/07/31 15:34:26 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1006
19/07/31 15:34:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 98 (MapPartitionsRDD[353] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 15:34:26 INFO TaskSchedulerImpl: Adding task set 98.0 with 4 tasks
19/07/31 15:34:26 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 137, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 15:34:26 INFO TaskSetManager: Starting task 1.0 in stage 98.0 (TID 138, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 15:34:26 INFO TaskSetManager: Starting task 2.0 in stage 98.0 (TID 139, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 15:34:26 INFO TaskSetManager: Starting task 3.0 in stage 98.0 (TID 140, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 15:34:26 INFO Executor: Running task 2.0 in stage 98.0 (TID 139)
19/07/31 15:34:26 INFO Executor: Running task 0.0 in stage 98.0 (TID 137)
19/07/31 15:34:26 INFO Executor: Running task 3.0 in stage 98.0 (TID 140)
19/07/31 15:34:26 INFO Executor: Running task 1.0 in stage 98.0 (TID 138)
19/07/31 15:34:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:34:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:34:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:34:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:34:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:34:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:34:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:34:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:34:26 INFO Executor: Finished task 3.0 in stage 98.0 (TID 140). 2362 bytes result sent to driver
19/07/31 15:34:26 INFO Executor: Finished task 1.0 in stage 98.0 (TID 138). 2403 bytes result sent to driver
19/07/31 15:34:26 INFO Executor: Finished task 2.0 in stage 98.0 (TID 139). 2390 bytes result sent to driver
19/07/31 15:34:26 INFO TaskSetManager: Finished task 3.0 in stage 98.0 (TID 140) in 9 ms on localhost (executor driver) (1/4)
19/07/31 15:34:26 INFO Executor: Finished task 0.0 in stage 98.0 (TID 137). 2382 bytes result sent to driver
19/07/31 15:34:26 INFO TaskSetManager: Finished task 1.0 in stage 98.0 (TID 138) in 11 ms on localhost (executor driver) (2/4)
19/07/31 15:34:26 INFO TaskSetManager: Finished task 2.0 in stage 98.0 (TID 139) in 10 ms on localhost (executor driver) (3/4)
19/07/31 15:34:26 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 137) in 11 ms on localhost (executor driver) (4/4)
19/07/31 15:34:26 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
19/07/31 15:34:26 INFO DAGScheduler: ResultStage 98 (collect at utils.scala:204) finished in 0.012 s
19/07/31 15:34:26 INFO DAGScheduler: Job 68 finished: collect at utils.scala:204, took 0.040388 s
19/07/31 15:34:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_133`) `dbplyr_134`
ORDER BY `date`) `dbplyr_135`) `dbplyr_136`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:34:46 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:34:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:34:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_137`) `dbplyr_138`
ORDER BY `date`) `dbplyr_139`) `dbplyr_140`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:34:46 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:34:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:34:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_141`) `dbplyr_142`
ORDER BY `date`) `dbplyr_143`) `dbplyr_144`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
LIMIT 11
19/07/31 15:34:46 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:34:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:34:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_145`) `dbplyr_146`
ORDER BY `date`) `dbplyr_147`) `dbplyr_148`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
LIMIT 11
19/07/31 15:34:46 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:34:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:34:46 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#3129) generates partition filter: ((cust_prospect_ind.count#4651 - cust_prospect_ind.nullCount#4650) > 0)
19/07/31 15:34:46 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#3130) generates partition filter: ((visit_device_type.count#4656 - visit_device_type.nullCount#4655) > 0)
19/07/31 15:34:46 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#3129 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4649 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4648))
19/07/31 15:34:46 INFO InMemoryTableScanExec: Predicate (visit_device_type#3130 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4654 <= All Devices) && (All Devices <= visit_device_type.upperBound#4653))
19/07/31 15:34:46 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:34:46 INFO DAGScheduler: Got job 69 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:34:46 INFO DAGScheduler: Final stage: ResultStage 99 (collect at utils.scala:204)
19/07/31 15:34:46 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:34:46 INFO DAGScheduler: Missing parents: List()
19/07/31 15:34:46 INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[357] at collect at utils.scala:204), which has no missing parents
19/07/31 15:34:46 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 72.8 KB, free 910.2 MB)
19/07/31 15:34:46 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 30.9 KB, free 910.2 MB)
19/07/31 15:34:46 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 127.0.0.1:64327 (size: 30.9 KB, free: 911.8 MB)
19/07/31 15:34:46 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1006
19/07/31 15:34:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[357] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:34:46 INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks
19/07/31 15:34:46 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 141, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:34:46 INFO Executor: Running task 0.0 in stage 99.0 (TID 141)
19/07/31 15:34:46 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:34:46 INFO Executor: Finished task 0.0 in stage 99.0 (TID 141). 3962 bytes result sent to driver
19/07/31 15:34:46 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 141) in 12 ms on localhost (executor driver) (1/1)
19/07/31 15:34:46 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
19/07/31 15:34:46 INFO DAGScheduler: ResultStage 99 (collect at utils.scala:204) finished in 0.012 s
19/07/31 15:34:46 INFO DAGScheduler: Job 69 finished: collect at utils.scala:204, took 0.023723 s
19/07/31 15:34:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_149`) `dbplyr_150`
ORDER BY `date`) `dbplyr_151`) `dbplyr_152`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:34:46 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:34:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:35:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_153`) `dbplyr_154`
ORDER BY `date`) `dbplyr_155`) `dbplyr_156`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:35:09 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:35:09 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:35:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_157`) `dbplyr_158`
ORDER BY `date`) `dbplyr_159`) `dbplyr_160`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:35:09 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:35:09 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:35:09 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#3129) generates partition filter: ((cust_prospect_ind.count#4763 - cust_prospect_ind.nullCount#4762) > 0)
19/07/31 15:35:09 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#3130) generates partition filter: ((visit_device_type.count#4768 - visit_device_type.nullCount#4767) > 0)
19/07/31 15:35:09 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#3129 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4761 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4760))
19/07/31 15:35:09 INFO InMemoryTableScanExec: Predicate (visit_device_type#3130 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4766 <= All Devices) && (All Devices <= visit_device_type.upperBound#4765))
19/07/31 15:35:09 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:35:09 INFO DAGScheduler: Got job 70 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:35:09 INFO DAGScheduler: Final stage: ResultStage 100 (collect at utils.scala:204)
19/07/31 15:35:09 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:35:09 INFO DAGScheduler: Missing parents: List()
19/07/31 15:35:09 INFO DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[362] at collect at utils.scala:204), which has no missing parents
19/07/31 15:35:09 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 72.1 KB, free 910.1 MB)
19/07/31 15:35:09 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.1 MB)
19/07/31 15:35:09 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 127.0.0.1:64327 (size: 30.5 KB, free: 911.7 MB)
19/07/31 15:35:09 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1006
19/07/31 15:35:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[362] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:35:09 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks
19/07/31 15:35:09 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 142, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:35:09 INFO Executor: Running task 0.0 in stage 100.0 (TID 142)
19/07/31 15:35:09 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:35:09 INFO Executor: Finished task 0.0 in stage 100.0 (TID 142). 7542 bytes result sent to driver
19/07/31 15:35:09 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 142) in 6 ms on localhost (executor driver) (1/1)
19/07/31 15:35:09 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
19/07/31 15:35:09 INFO DAGScheduler: ResultStage 100 (collect at utils.scala:204) finished in 0.006 s
19/07/31 15:35:09 INFO DAGScheduler: Job 70 finished: collect at utils.scala:204, took 0.018617 s
19/07/31 15:35:09 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:35:09 INFO DAGScheduler: Registering RDD 363 (collect at utils.scala:204)
19/07/31 15:35:09 INFO DAGScheduler: Got job 71 (collect at utils.scala:204) with 4 output partitions
19/07/31 15:35:09 INFO DAGScheduler: Final stage: ResultStage 102 (collect at utils.scala:204)
19/07/31 15:35:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 101)
19/07/31 15:35:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 101)
19/07/31 15:35:09 INFO DAGScheduler: Submitting ShuffleMapStage 101 (MapPartitionsRDD[363] at collect at utils.scala:204), which has no missing parents
19/07/31 15:35:09 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 74.6 KB, free 910.0 MB)
19/07/31 15:35:09 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.0 MB)
19/07/31 15:35:09 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 127.0.0.1:64327 (size: 31.8 KB, free: 911.7 MB)
19/07/31 15:35:09 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1006
19/07/31 15:35:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 101 (MapPartitionsRDD[363] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:35:09 INFO TaskSchedulerImpl: Adding task set 101.0 with 1 tasks
19/07/31 15:35:09 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 143, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 15:35:09 INFO Executor: Running task 0.0 in stage 101.0 (TID 143)
19/07/31 15:35:09 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:35:09 INFO Executor: Finished task 0.0 in stage 101.0 (TID 143). 1687 bytes result sent to driver
19/07/31 15:35:09 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 143) in 10 ms on localhost (executor driver) (1/1)
19/07/31 15:35:09 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
19/07/31 15:35:09 INFO DAGScheduler: ShuffleMapStage 101 (collect at utils.scala:204) finished in 0.010 s
19/07/31 15:35:09 INFO DAGScheduler: looking for newly runnable stages
19/07/31 15:35:09 INFO DAGScheduler: running: Set()
19/07/31 15:35:09 INFO DAGScheduler: waiting: Set(ResultStage 102)
19/07/31 15:35:09 INFO DAGScheduler: failed: Set()
19/07/31 15:35:09 INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[366] at collect at utils.scala:204), which has no missing parents
19/07/31 15:35:09 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 16.8 KB, free 909.9 MB)
19/07/31 15:35:09 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.9 MB)
19/07/31 15:35:09 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 127.0.0.1:64327 (size: 8.0 KB, free: 911.7 MB)
19/07/31 15:35:09 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1006
19/07/31 15:35:09 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 102 (MapPartitionsRDD[366] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 15:35:09 INFO TaskSchedulerImpl: Adding task set 102.0 with 4 tasks
19/07/31 15:35:09 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 144, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 15:35:09 INFO TaskSetManager: Starting task 1.0 in stage 102.0 (TID 145, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 15:35:09 INFO TaskSetManager: Starting task 2.0 in stage 102.0 (TID 146, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 15:35:09 INFO TaskSetManager: Starting task 3.0 in stage 102.0 (TID 147, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 15:35:09 INFO Executor: Running task 2.0 in stage 102.0 (TID 146)
19/07/31 15:35:09 INFO Executor: Running task 3.0 in stage 102.0 (TID 147)
19/07/31 15:35:09 INFO Executor: Running task 0.0 in stage 102.0 (TID 144)
19/07/31 15:35:09 INFO Executor: Running task 1.0 in stage 102.0 (TID 145)
19/07/31 15:35:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:35:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:35:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:35:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:35:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:35:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:35:09 INFO Executor: Finished task 3.0 in stage 102.0 (TID 147). 2362 bytes result sent to driver
19/07/31 15:35:09 INFO Executor: Finished task 2.0 in stage 102.0 (TID 146). 2390 bytes result sent to driver
19/07/31 15:35:09 INFO TaskSetManager: Finished task 2.0 in stage 102.0 (TID 146) in 8 ms on localhost (executor driver) (1/4)
19/07/31 15:35:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:35:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:35:09 INFO Executor: Finished task 0.0 in stage 102.0 (TID 144). 2382 bytes result sent to driver
19/07/31 15:35:09 INFO TaskSetManager: Finished task 3.0 in stage 102.0 (TID 147) in 8 ms on localhost (executor driver) (2/4)
19/07/31 15:35:09 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 144) in 10 ms on localhost (executor driver) (3/4)
19/07/31 15:35:09 INFO Executor: Finished task 1.0 in stage 102.0 (TID 145). 2403 bytes result sent to driver
19/07/31 15:35:09 INFO TaskSetManager: Finished task 1.0 in stage 102.0 (TID 145) in 11 ms on localhost (executor driver) (4/4)
19/07/31 15:35:09 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
19/07/31 15:35:09 INFO DAGScheduler: ResultStage 102 (collect at utils.scala:204) finished in 0.012 s
19/07/31 15:35:09 INFO DAGScheduler: Job 71 finished: collect at utils.scala:204, took 0.039905 s
19/07/31 15:36:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_161`) `dbplyr_162`
ORDER BY `date`) `dbplyr_163`) `dbplyr_164`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:36:02 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:36:02 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:36:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_165`) `dbplyr_166`
ORDER BY `date`) `dbplyr_167`) `dbplyr_168`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:36:02 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:36:02 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:36:02 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#3129) generates partition filter: ((cust_prospect_ind.count#4861 - cust_prospect_ind.nullCount#4860) > 0)
19/07/31 15:36:02 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#3130) generates partition filter: ((visit_device_type.count#4866 - visit_device_type.nullCount#4865) > 0)
19/07/31 15:36:02 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#3129 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4859 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4858))
19/07/31 15:36:02 INFO InMemoryTableScanExec: Predicate (visit_device_type#3130 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4864 <= All Devices) && (All Devices <= visit_device_type.upperBound#4863))
19/07/31 15:36:02 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:36:02 INFO DAGScheduler: Got job 72 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:36:02 INFO DAGScheduler: Final stage: ResultStage 103 (collect at utils.scala:204)
19/07/31 15:36:02 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:36:02 INFO DAGScheduler: Missing parents: List()
19/07/31 15:36:02 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[371] at collect at utils.scala:204), which has no missing parents
19/07/31 15:36:02 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 72.1 KB, free 909.9 MB)
19/07/31 15:36:02 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 30.4 KB, free 909.8 MB)
19/07/31 15:36:02 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 127.0.0.1:64327 (size: 30.4 KB, free: 911.7 MB)
19/07/31 15:36:02 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1006
19/07/31 15:36:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[371] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:36:02 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks
19/07/31 15:36:02 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 148, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:36:02 INFO Executor: Running task 0.0 in stage 103.0 (TID 148)
19/07/31 15:36:02 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:36:02 INFO Executor: Finished task 0.0 in stage 103.0 (TID 148). 7542 bytes result sent to driver
19/07/31 15:36:02 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 148) in 6 ms on localhost (executor driver) (1/1)
19/07/31 15:36:02 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
19/07/31 15:36:02 INFO DAGScheduler: ResultStage 103 (collect at utils.scala:204) finished in 0.006 s
19/07/31 15:36:02 INFO DAGScheduler: Job 72 finished: collect at utils.scala:204, took 0.015528 s
19/07/31 15:36:02 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:36:02 INFO DAGScheduler: Registering RDD 372 (collect at utils.scala:204)
19/07/31 15:36:02 INFO DAGScheduler: Got job 73 (collect at utils.scala:204) with 4 output partitions
19/07/31 15:36:02 INFO DAGScheduler: Final stage: ResultStage 105 (collect at utils.scala:204)
19/07/31 15:36:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 104)
19/07/31 15:36:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 104)
19/07/31 15:36:02 INFO DAGScheduler: Submitting ShuffleMapStage 104 (MapPartitionsRDD[372] at collect at utils.scala:204), which has no missing parents
19/07/31 15:36:02 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 74.6 KB, free 909.8 MB)
19/07/31 15:36:02 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 31.7 KB, free 909.7 MB)
19/07/31 15:36:02 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 127.0.0.1:64327 (size: 31.7 KB, free: 911.6 MB)
19/07/31 15:36:02 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1006
19/07/31 15:36:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 104 (MapPartitionsRDD[372] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:36:02 INFO TaskSchedulerImpl: Adding task set 104.0 with 1 tasks
19/07/31 15:36:02 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 149, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 15:36:02 INFO Executor: Running task 0.0 in stage 104.0 (TID 149)
19/07/31 15:36:02 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:36:02 INFO Executor: Finished task 0.0 in stage 104.0 (TID 149). 1687 bytes result sent to driver
19/07/31 15:36:02 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 149) in 14 ms on localhost (executor driver) (1/1)
19/07/31 15:36:02 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
19/07/31 15:36:02 INFO DAGScheduler: ShuffleMapStage 104 (collect at utils.scala:204) finished in 0.014 s
19/07/31 15:36:02 INFO DAGScheduler: looking for newly runnable stages
19/07/31 15:36:02 INFO DAGScheduler: running: Set()
19/07/31 15:36:02 INFO DAGScheduler: waiting: Set(ResultStage 105)
19/07/31 15:36:02 INFO DAGScheduler: failed: Set()
19/07/31 15:36:02 INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[375] at collect at utils.scala:204), which has no missing parents
19/07/31 15:36:02 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 16.8 KB, free 909.7 MB)
19/07/31 15:36:02 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.7 MB)
19/07/31 15:36:02 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 127.0.0.1:64327 (size: 8.0 KB, free: 911.6 MB)
19/07/31 15:36:02 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1006
19/07/31 15:36:02 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 105 (MapPartitionsRDD[375] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 15:36:02 INFO TaskSchedulerImpl: Adding task set 105.0 with 4 tasks
19/07/31 15:36:02 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 150, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 15:36:02 INFO TaskSetManager: Starting task 1.0 in stage 105.0 (TID 151, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 15:36:02 INFO TaskSetManager: Starting task 2.0 in stage 105.0 (TID 152, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 15:36:02 INFO TaskSetManager: Starting task 3.0 in stage 105.0 (TID 153, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 15:36:02 INFO Executor: Running task 1.0 in stage 105.0 (TID 151)
19/07/31 15:36:02 INFO Executor: Running task 3.0 in stage 105.0 (TID 153)
19/07/31 15:36:02 INFO Executor: Running task 2.0 in stage 105.0 (TID 152)
19/07/31 15:36:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:36:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 15:36:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:36:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 15:36:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:36:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 15:36:02 INFO Executor: Running task 0.0 in stage 105.0 (TID 150)
19/07/31 15:36:02 INFO Executor: Finished task 1.0 in stage 105.0 (TID 151). 2403 bytes result sent to driver
19/07/31 15:36:02 INFO Executor: Finished task 2.0 in stage 105.0 (TID 152). 2390 bytes result sent to driver
19/07/31 15:36:02 INFO Executor: Finished task 3.0 in stage 105.0 (TID 153). 2362 bytes result sent to driver
19/07/31 15:36:02 INFO TaskSetManager: Finished task 1.0 in stage 105.0 (TID 151) in 8 ms on localhost (executor driver) (1/4)
19/07/31 15:36:02 INFO TaskSetManager: Finished task 2.0 in stage 105.0 (TID 152) in 8 ms on localhost (executor driver) (2/4)
19/07/31 15:36:02 INFO TaskSetManager: Finished task 3.0 in stage 105.0 (TID 153) in 7 ms on localhost (executor driver) (3/4)
19/07/31 15:36:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:36:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:36:02 INFO Executor: Finished task 0.0 in stage 105.0 (TID 150). 2382 bytes result sent to driver
19/07/31 15:36:02 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 150) in 11 ms on localhost (executor driver) (4/4)
19/07/31 15:36:02 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
19/07/31 15:36:02 INFO DAGScheduler: ResultStage 105 (collect at utils.scala:204) finished in 0.012 s
19/07/31 15:36:02 INFO DAGScheduler: Job 73 finished: collect at utils.scala:204, took 0.043419 s
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 1541
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2315
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2316
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 127.0.0.1:64327 in memory (size: 8.0 KB, free: 911.6 MB)
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2882
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2718
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2802
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2721
19/07/31 15:36:28 INFO ContextCleaner: Cleaned shuffle 24
19/07/31 15:36:28 INFO ContextCleaner: Cleaned shuffle 26
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 127.0.0.1:64327 in memory (size: 30.5 KB, free: 911.7 MB)
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2804
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2401
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2803
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 127.0.0.1:64327 in memory (size: 8.0 KB, free: 911.7 MB)
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2908
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2479
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2799
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 127.0.0.1:64327 in memory (size: 30.4 KB, free: 911.7 MB)
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 127.0.0.1:64327 in memory (size: 31.7 KB, free: 911.7 MB)
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 127.0.0.1:64327 in memory (size: 30.4 KB, free: 911.8 MB)
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2317
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2564
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2482
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2320
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 127.0.0.1:64327 in memory (size: 31.8 KB, free: 911.8 MB)
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2720
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2321
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 127.0.0.1:64327 in memory (size: 31.8 KB, free: 911.8 MB)
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2723
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2719
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 127.0.0.1:64327 in memory (size: 31.8 KB, free: 911.8 MB)
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2475
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 127.0.0.1:64327 in memory (size: 31.8 KB, free: 911.9 MB)
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2912
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 127.0.0.1:64327 in memory (size: 30.5 KB, free: 911.9 MB)
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2722
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2806
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2726
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2637
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 127.0.0.1:64327 in memory (size: 8.0 KB, free: 911.9 MB)
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2402
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2400
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 127.0.0.1:64327 in memory (size: 8.0 KB, free: 911.9 MB)
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2557
19/07/31 15:36:28 INFO ContextCleaner: Cleaned shuffle 25
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 127.0.0.1:64327 in memory (size: 31.7 KB, free: 912.0 MB)
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 127.0.0.1:64327 in memory (size: 31.7 KB, free: 912.0 MB)
19/07/31 15:36:28 INFO ContextCleaner: Cleaned shuffle 30
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2398
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2476
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2478
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2562
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 127.0.0.1:64327 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2477
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2556
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2800
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2725
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2480
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2394
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2915
19/07/31 15:36:28 INFO ContextCleaner: Cleaned shuffle 29
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2913
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2563
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2801
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2880
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2724
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 127.0.0.1:64327 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 127.0.0.1:64327 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 127.0.0.1:64327 in memory (size: 30.5 KB, free: 912.0 MB)
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2807
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2399
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2881
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2395
19/07/31 15:36:28 INFO ContextCleaner: Cleaned shuffle 23
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2483
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2914
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 127.0.0.1:64327 in memory (size: 31.8 KB, free: 912.1 MB)
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 127.0.0.1:64327 in memory (size: 30.4 KB, free: 912.1 MB)
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2319
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 127.0.0.1:64327 in memory (size: 30.5 KB, free: 912.1 MB)
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2558
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2909
19/07/31 15:36:28 INFO ContextCleaner: Cleaned shuffle 28
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2318
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 127.0.0.1:64327 in memory (size: 30.4 KB, free: 912.2 MB)
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2481
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2396
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2397
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2314
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2561
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 127.0.0.1:64327 in memory (size: 30.9 KB, free: 912.2 MB)
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2910
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2559
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 127.0.0.1:64327 in memory (size: 8.0 KB, free: 912.2 MB)
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2805
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2911
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2988
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2560
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 127.0.0.1:64327 in memory (size: 8.0 KB, free: 912.2 MB)
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 2907
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 1613
19/07/31 15:36:28 INFO BlockManager: Removing RDD 201
19/07/31 15:36:28 INFO ContextCleaner: Cleaned RDD 201
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 1542
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 1545
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 1544
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 1618
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 1546
19/07/31 15:36:28 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:64327 in memory (size: 24.0 KB, free: 912.2 MB)
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 1615
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 1614
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 1616
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 1609
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 1620
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 1611
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 1610
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 1612
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 1543
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 1617
19/07/31 15:36:28 INFO ContextCleaner: Cleaned accumulator 1619
19/07/31 15:36:28 INFO ContextCleaner: Cleaned shuffle 15
19/07/31 15:40:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_169`) `dbplyr_170`
ORDER BY `date`) `dbplyr_171`) `dbplyr_172`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:40:22 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:40:22 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:40:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_173`) `dbplyr_174`
ORDER BY `date`) `dbplyr_175`) `dbplyr_176`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:40:22 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:40:22 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:40:22 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#3129) generates partition filter: ((cust_prospect_ind.count#4959 - cust_prospect_ind.nullCount#4958) > 0)
19/07/31 15:40:22 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#3130) generates partition filter: ((visit_device_type.count#4964 - visit_device_type.nullCount#4963) > 0)
19/07/31 15:40:22 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#3129 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4957 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4956))
19/07/31 15:40:22 INFO InMemoryTableScanExec: Predicate (visit_device_type#3130 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4962 <= All Devices) && (All Devices <= visit_device_type.upperBound#4961))
19/07/31 15:40:22 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:40:22 INFO DAGScheduler: Got job 74 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:40:22 INFO DAGScheduler: Final stage: ResultStage 106 (collect at utils.scala:204)
19/07/31 15:40:22 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:40:22 INFO DAGScheduler: Missing parents: List()
19/07/31 15:40:22 INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[380] at collect at utils.scala:204), which has no missing parents
19/07/31 15:40:22 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 72.1 KB, free 911.9 MB)
19/07/31 15:40:22 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 30.5 KB, free 911.9 MB)
19/07/31 15:40:22 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 127.0.0.1:64327 (size: 30.5 KB, free: 912.2 MB)
19/07/31 15:40:22 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1006
19/07/31 15:40:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[380] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:40:22 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks
19/07/31 15:40:22 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 154, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:40:22 INFO Executor: Running task 0.0 in stage 106.0 (TID 154)
19/07/31 15:40:22 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:40:22 INFO Executor: Finished task 0.0 in stage 106.0 (TID 154). 7542 bytes result sent to driver
19/07/31 15:40:22 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 154) in 6 ms on localhost (executor driver) (1/1)
19/07/31 15:40:22 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
19/07/31 15:40:22 INFO DAGScheduler: ResultStage 106 (collect at utils.scala:204) finished in 0.007 s
19/07/31 15:40:22 INFO DAGScheduler: Job 74 finished: collect at utils.scala:204, took 0.016540 s
19/07/31 15:40:22 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:40:22 INFO DAGScheduler: Registering RDD 381 (collect at utils.scala:204)
19/07/31 15:40:22 INFO DAGScheduler: Got job 75 (collect at utils.scala:204) with 4 output partitions
19/07/31 15:40:22 INFO DAGScheduler: Final stage: ResultStage 108 (collect at utils.scala:204)
19/07/31 15:40:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 107)
19/07/31 15:40:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 107)
19/07/31 15:40:22 INFO DAGScheduler: Submitting ShuffleMapStage 107 (MapPartitionsRDD[381] at collect at utils.scala:204), which has no missing parents
19/07/31 15:40:22 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 74.6 KB, free 911.8 MB)
19/07/31 15:40:22 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.7 MB)
19/07/31 15:40:22 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 127.0.0.1:64327 (size: 31.8 KB, free: 912.2 MB)
19/07/31 15:40:22 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1006
19/07/31 15:40:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 107 (MapPartitionsRDD[381] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:40:22 INFO TaskSchedulerImpl: Adding task set 107.0 with 1 tasks
19/07/31 15:40:22 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 155, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 15:40:22 INFO Executor: Running task 0.0 in stage 107.0 (TID 155)
19/07/31 15:40:22 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:40:22 INFO Executor: Finished task 0.0 in stage 107.0 (TID 155). 1687 bytes result sent to driver
19/07/31 15:40:22 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 155) in 10 ms on localhost (executor driver) (1/1)
19/07/31 15:40:22 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
19/07/31 15:40:22 INFO DAGScheduler: ShuffleMapStage 107 (collect at utils.scala:204) finished in 0.010 s
19/07/31 15:40:22 INFO DAGScheduler: looking for newly runnable stages
19/07/31 15:40:22 INFO DAGScheduler: running: Set()
19/07/31 15:40:22 INFO DAGScheduler: waiting: Set(ResultStage 108)
19/07/31 15:40:22 INFO DAGScheduler: failed: Set()
19/07/31 15:40:22 INFO DAGScheduler: Submitting ResultStage 108 (MapPartitionsRDD[384] at collect at utils.scala:204), which has no missing parents
19/07/31 15:40:22 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 16.8 KB, free 911.7 MB)
19/07/31 15:40:22 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.7 MB)
19/07/31 15:40:22 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 127.0.0.1:64327 (size: 8.0 KB, free: 912.2 MB)
19/07/31 15:40:22 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1006
19/07/31 15:40:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 108 (MapPartitionsRDD[384] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 15:40:22 INFO TaskSchedulerImpl: Adding task set 108.0 with 4 tasks
19/07/31 15:40:22 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 156, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 15:40:22 INFO TaskSetManager: Starting task 1.0 in stage 108.0 (TID 157, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 15:40:22 INFO TaskSetManager: Starting task 2.0 in stage 108.0 (TID 158, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 15:40:22 INFO TaskSetManager: Starting task 3.0 in stage 108.0 (TID 159, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 15:40:22 INFO Executor: Running task 0.0 in stage 108.0 (TID 156)
19/07/31 15:40:22 INFO Executor: Running task 1.0 in stage 108.0 (TID 157)
19/07/31 15:40:22 INFO Executor: Running task 2.0 in stage 108.0 (TID 158)
19/07/31 15:40:22 INFO Executor: Running task 3.0 in stage 108.0 (TID 159)
19/07/31 15:40:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:40:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:40:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:40:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:40:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:40:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:40:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:40:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 15:40:22 INFO Executor: Finished task 1.0 in stage 108.0 (TID 157). 2403 bytes result sent to driver
19/07/31 15:40:22 INFO Executor: Finished task 0.0 in stage 108.0 (TID 156). 2382 bytes result sent to driver
19/07/31 15:40:22 INFO TaskSetManager: Finished task 1.0 in stage 108.0 (TID 157) in 7 ms on localhost (executor driver) (1/4)
19/07/31 15:40:22 INFO Executor: Finished task 2.0 in stage 108.0 (TID 158). 2390 bytes result sent to driver
19/07/31 15:40:22 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 156) in 7 ms on localhost (executor driver) (2/4)
19/07/31 15:40:22 INFO Executor: Finished task 3.0 in stage 108.0 (TID 159). 2362 bytes result sent to driver
19/07/31 15:40:22 INFO TaskSetManager: Finished task 2.0 in stage 108.0 (TID 158) in 8 ms on localhost (executor driver) (3/4)
19/07/31 15:40:22 INFO TaskSetManager: Finished task 3.0 in stage 108.0 (TID 159) in 8 ms on localhost (executor driver) (4/4)
19/07/31 15:40:22 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool 
19/07/31 15:40:22 INFO DAGScheduler: ResultStage 108 (collect at utils.scala:204) finished in 0.008 s
19/07/31 15:40:22 INFO DAGScheduler: Job 75 finished: collect at utils.scala:204, took 0.037244 s
19/07/31 15:40:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_177`) `dbplyr_178`
ORDER BY `date`) `dbplyr_179`) `dbplyr_180`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:40:46 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:40:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:40:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_181`) `dbplyr_182`
ORDER BY `date`) `dbplyr_183`) `dbplyr_184`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:40:46 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:40:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:40:46 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#3129) generates partition filter: ((cust_prospect_ind.count#5057 - cust_prospect_ind.nullCount#5056) > 0)
19/07/31 15:40:46 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#3130) generates partition filter: ((visit_device_type.count#5062 - visit_device_type.nullCount#5061) > 0)
19/07/31 15:40:46 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#3129 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#5055 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#5054))
19/07/31 15:40:46 INFO InMemoryTableScanExec: Predicate (visit_device_type#3130 = All Devices) generates partition filter: ((visit_device_type.lowerBound#5060 <= All Devices) && (All Devices <= visit_device_type.upperBound#5059))
19/07/31 15:40:46 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:40:46 INFO DAGScheduler: Got job 76 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:40:46 INFO DAGScheduler: Final stage: ResultStage 109 (collect at utils.scala:204)
19/07/31 15:40:46 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:40:46 INFO DAGScheduler: Missing parents: List()
19/07/31 15:40:46 INFO DAGScheduler: Submitting ResultStage 109 (MapPartitionsRDD[389] at collect at utils.scala:204), which has no missing parents
19/07/31 15:40:46 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 72.1 KB, free 911.7 MB)
19/07/31 15:40:46 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.6 MB)
19/07/31 15:40:46 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 127.0.0.1:64327 (size: 30.4 KB, free: 912.1 MB)
19/07/31 15:40:46 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1006
19/07/31 15:40:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 109 (MapPartitionsRDD[389] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:40:46 INFO TaskSchedulerImpl: Adding task set 109.0 with 1 tasks
19/07/31 15:40:46 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 160, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:40:46 INFO Executor: Running task 0.0 in stage 109.0 (TID 160)
19/07/31 15:40:46 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:40:46 INFO Executor: Finished task 0.0 in stage 109.0 (TID 160). 7542 bytes result sent to driver
19/07/31 15:40:46 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 160) in 5 ms on localhost (executor driver) (1/1)
19/07/31 15:40:46 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool 
19/07/31 15:40:46 INFO DAGScheduler: ResultStage 109 (collect at utils.scala:204) finished in 0.006 s
19/07/31 15:40:46 INFO DAGScheduler: Job 76 finished: collect at utils.scala:204, took 0.012670 s
19/07/31 15:40:46 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:40:46 INFO DAGScheduler: Registering RDD 390 (collect at utils.scala:204)
19/07/31 15:40:46 INFO DAGScheduler: Got job 77 (collect at utils.scala:204) with 4 output partitions
19/07/31 15:40:46 INFO DAGScheduler: Final stage: ResultStage 111 (collect at utils.scala:204)
19/07/31 15:40:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 110)
19/07/31 15:40:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 110)
19/07/31 15:40:46 INFO DAGScheduler: Submitting ShuffleMapStage 110 (MapPartitionsRDD[390] at collect at utils.scala:204), which has no missing parents
19/07/31 15:40:46 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 74.6 KB, free 911.6 MB)
19/07/31 15:40:46 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 31.7 KB, free 911.5 MB)
19/07/31 15:40:46 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 127.0.0.1:64327 (size: 31.7 KB, free: 912.1 MB)
19/07/31 15:40:46 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1006
19/07/31 15:40:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 110 (MapPartitionsRDD[390] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:40:46 INFO TaskSchedulerImpl: Adding task set 110.0 with 1 tasks
19/07/31 15:40:46 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 161, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 15:40:46 INFO Executor: Running task 0.0 in stage 110.0 (TID 161)
19/07/31 15:40:46 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:40:46 INFO Executor: Finished task 0.0 in stage 110.0 (TID 161). 1687 bytes result sent to driver
19/07/31 15:40:46 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 161) in 10 ms on localhost (executor driver) (1/1)
19/07/31 15:40:46 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool 
19/07/31 15:40:46 INFO DAGScheduler: ShuffleMapStage 110 (collect at utils.scala:204) finished in 0.010 s
19/07/31 15:40:46 INFO DAGScheduler: looking for newly runnable stages
19/07/31 15:40:46 INFO DAGScheduler: running: Set()
19/07/31 15:40:46 INFO DAGScheduler: waiting: Set(ResultStage 111)
19/07/31 15:40:46 INFO DAGScheduler: failed: Set()
19/07/31 15:40:46 INFO DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[393] at collect at utils.scala:204), which has no missing parents
19/07/31 15:40:46 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 16.8 KB, free 911.5 MB)
19/07/31 15:40:46 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.5 MB)
19/07/31 15:40:46 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 127.0.0.1:64327 (size: 8.0 KB, free: 912.1 MB)
19/07/31 15:40:46 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1006
19/07/31 15:40:46 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 111 (MapPartitionsRDD[393] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 15:40:46 INFO TaskSchedulerImpl: Adding task set 111.0 with 4 tasks
19/07/31 15:40:46 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 162, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 15:40:46 INFO TaskSetManager: Starting task 1.0 in stage 111.0 (TID 163, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 15:40:46 INFO TaskSetManager: Starting task 2.0 in stage 111.0 (TID 164, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 15:40:46 INFO TaskSetManager: Starting task 3.0 in stage 111.0 (TID 165, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 15:40:46 INFO Executor: Running task 0.0 in stage 111.0 (TID 162)
19/07/31 15:40:46 INFO Executor: Running task 1.0 in stage 111.0 (TID 163)
19/07/31 15:40:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:40:46 INFO Executor: Running task 2.0 in stage 111.0 (TID 164)
19/07/31 15:40:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 15:40:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:40:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:40:46 INFO Executor: Running task 3.0 in stage 111.0 (TID 165)
19/07/31 15:40:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:40:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:40:46 INFO Executor: Finished task 0.0 in stage 111.0 (TID 162). 2382 bytes result sent to driver
19/07/31 15:40:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:40:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:40:46 INFO Executor: Finished task 2.0 in stage 111.0 (TID 164). 2390 bytes result sent to driver
19/07/31 15:40:46 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 162) in 6 ms on localhost (executor driver) (1/4)
19/07/31 15:40:46 INFO TaskSetManager: Finished task 2.0 in stage 111.0 (TID 164) in 7 ms on localhost (executor driver) (2/4)
19/07/31 15:40:46 INFO Executor: Finished task 1.0 in stage 111.0 (TID 163). 2403 bytes result sent to driver
19/07/31 15:40:46 INFO TaskSetManager: Finished task 1.0 in stage 111.0 (TID 163) in 7 ms on localhost (executor driver) (3/4)
19/07/31 15:40:46 INFO Executor: Finished task 3.0 in stage 111.0 (TID 165). 2362 bytes result sent to driver
19/07/31 15:40:46 INFO TaskSetManager: Finished task 3.0 in stage 111.0 (TID 165) in 7 ms on localhost (executor driver) (4/4)
19/07/31 15:40:46 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool 
19/07/31 15:40:46 INFO DAGScheduler: ResultStage 111 (collect at utils.scala:204) finished in 0.009 s
19/07/31 15:40:46 INFO DAGScheduler: Job 77 finished: collect at utils.scala:204, took 0.029930 s
19/07/31 15:40:58 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_185`) `dbplyr_186`
ORDER BY `date`) `dbplyr_187`) `dbplyr_188`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:40:58 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:40:58 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:40:58 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_189`) `dbplyr_190`
ORDER BY `date`) `dbplyr_191`) `dbplyr_192`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:40:58 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:40:58 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:40:58 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#3129) generates partition filter: ((cust_prospect_ind.count#5155 - cust_prospect_ind.nullCount#5154) > 0)
19/07/31 15:40:58 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#3130) generates partition filter: ((visit_device_type.count#5160 - visit_device_type.nullCount#5159) > 0)
19/07/31 15:40:58 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#3129 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#5153 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#5152))
19/07/31 15:40:58 INFO InMemoryTableScanExec: Predicate (visit_device_type#3130 = All Devices) generates partition filter: ((visit_device_type.lowerBound#5158 <= All Devices) && (All Devices <= visit_device_type.upperBound#5157))
19/07/31 15:40:58 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:40:58 INFO DAGScheduler: Got job 78 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:40:58 INFO DAGScheduler: Final stage: ResultStage 112 (collect at utils.scala:204)
19/07/31 15:40:58 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:40:58 INFO DAGScheduler: Missing parents: List()
19/07/31 15:40:58 INFO DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[398] at collect at utils.scala:204), which has no missing parents
19/07/31 15:40:58 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 72.1 KB, free 911.4 MB)
19/07/31 15:40:58 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 30.5 KB, free 911.4 MB)
19/07/31 15:40:58 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 127.0.0.1:64327 (size: 30.5 KB, free: 912.1 MB)
19/07/31 15:40:58 INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1006
19/07/31 15:40:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[398] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:40:58 INFO TaskSchedulerImpl: Adding task set 112.0 with 1 tasks
19/07/31 15:40:58 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 166, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:40:58 INFO Executor: Running task 0.0 in stage 112.0 (TID 166)
19/07/31 15:40:58 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:40:58 INFO Executor: Finished task 0.0 in stage 112.0 (TID 166). 7542 bytes result sent to driver
19/07/31 15:40:58 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 166) in 4 ms on localhost (executor driver) (1/1)
19/07/31 15:40:58 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool 
19/07/31 15:40:58 INFO DAGScheduler: ResultStage 112 (collect at utils.scala:204) finished in 0.004 s
19/07/31 15:40:58 INFO DAGScheduler: Job 78 finished: collect at utils.scala:204, took 0.008667 s
19/07/31 15:40:58 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:40:58 INFO DAGScheduler: Registering RDD 399 (collect at utils.scala:204)
19/07/31 15:40:58 INFO DAGScheduler: Got job 79 (collect at utils.scala:204) with 4 output partitions
19/07/31 15:40:58 INFO DAGScheduler: Final stage: ResultStage 114 (collect at utils.scala:204)
19/07/31 15:40:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 113)
19/07/31 15:40:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 113)
19/07/31 15:40:58 INFO DAGScheduler: Submitting ShuffleMapStage 113 (MapPartitionsRDD[399] at collect at utils.scala:204), which has no missing parents
19/07/31 15:40:58 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 74.6 KB, free 911.3 MB)
19/07/31 15:40:58 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.3 MB)
19/07/31 15:40:58 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 127.0.0.1:64327 (size: 31.8 KB, free: 912.0 MB)
19/07/31 15:40:58 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1006
19/07/31 15:40:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 113 (MapPartitionsRDD[399] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:40:58 INFO TaskSchedulerImpl: Adding task set 113.0 with 1 tasks
19/07/31 15:40:58 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 167, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 15:40:58 INFO Executor: Running task 0.0 in stage 113.0 (TID 167)
19/07/31 15:40:58 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:40:58 INFO Executor: Finished task 0.0 in stage 113.0 (TID 167). 1687 bytes result sent to driver
19/07/31 15:40:58 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 167) in 8 ms on localhost (executor driver) (1/1)
19/07/31 15:40:58 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool 
19/07/31 15:40:58 INFO DAGScheduler: ShuffleMapStage 113 (collect at utils.scala:204) finished in 0.009 s
19/07/31 15:40:58 INFO DAGScheduler: looking for newly runnable stages
19/07/31 15:40:58 INFO DAGScheduler: running: Set()
19/07/31 15:40:58 INFO DAGScheduler: waiting: Set(ResultStage 114)
19/07/31 15:40:58 INFO DAGScheduler: failed: Set()
19/07/31 15:40:58 INFO DAGScheduler: Submitting ResultStage 114 (MapPartitionsRDD[402] at collect at utils.scala:204), which has no missing parents
19/07/31 15:40:58 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 16.8 KB, free 911.3 MB)
19/07/31 15:40:58 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.3 MB)
19/07/31 15:40:58 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 127.0.0.1:64327 (size: 8.0 KB, free: 912.0 MB)
19/07/31 15:40:58 INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1006
19/07/31 15:40:58 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 114 (MapPartitionsRDD[402] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 15:40:58 INFO TaskSchedulerImpl: Adding task set 114.0 with 4 tasks
19/07/31 15:40:58 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 168, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 15:40:58 INFO TaskSetManager: Starting task 1.0 in stage 114.0 (TID 169, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 15:40:58 INFO TaskSetManager: Starting task 2.0 in stage 114.0 (TID 170, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 15:40:58 INFO TaskSetManager: Starting task 3.0 in stage 114.0 (TID 171, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 15:40:58 INFO Executor: Running task 1.0 in stage 114.0 (TID 169)
19/07/31 15:40:58 INFO Executor: Running task 2.0 in stage 114.0 (TID 170)
19/07/31 15:40:58 INFO Executor: Running task 0.0 in stage 114.0 (TID 168)
19/07/31 15:40:58 INFO Executor: Running task 3.0 in stage 114.0 (TID 171)
19/07/31 15:40:58 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:40:58 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:40:58 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:40:58 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:40:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:40:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:40:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 15:40:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 15:40:58 INFO Executor: Finished task 0.0 in stage 114.0 (TID 168). 2382 bytes result sent to driver
19/07/31 15:40:58 INFO Executor: Finished task 3.0 in stage 114.0 (TID 171). 2362 bytes result sent to driver
19/07/31 15:40:58 INFO Executor: Finished task 1.0 in stage 114.0 (TID 169). 2403 bytes result sent to driver
19/07/31 15:40:58 INFO Executor: Finished task 2.0 in stage 114.0 (TID 170). 2390 bytes result sent to driver
19/07/31 15:40:58 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 168) in 5 ms on localhost (executor driver) (1/4)
19/07/31 15:40:58 INFO TaskSetManager: Finished task 1.0 in stage 114.0 (TID 169) in 4 ms on localhost (executor driver) (2/4)
19/07/31 15:40:58 INFO TaskSetManager: Finished task 3.0 in stage 114.0 (TID 171) in 4 ms on localhost (executor driver) (3/4)
19/07/31 15:40:58 INFO TaskSetManager: Finished task 2.0 in stage 114.0 (TID 170) in 4 ms on localhost (executor driver) (4/4)
19/07/31 15:40:58 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool 
19/07/31 15:40:58 INFO DAGScheduler: ResultStage 114 (collect at utils.scala:204) finished in 0.005 s
19/07/31 15:40:58 INFO DAGScheduler: Job 79 finished: collect at utils.scala:204, took 0.020037 s
19/07/31 15:41:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_193`) `dbplyr_194`
ORDER BY `date`) `dbplyr_195`) `dbplyr_196`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:41:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:41:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:41:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_197`) `dbplyr_198`
ORDER BY `date`) `dbplyr_199`) `dbplyr_200`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:41:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:41:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:41:21 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#3129) generates partition filter: ((cust_prospect_ind.count#5253 - cust_prospect_ind.nullCount#5252) > 0)
19/07/31 15:41:21 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#3130) generates partition filter: ((visit_device_type.count#5258 - visit_device_type.nullCount#5257) > 0)
19/07/31 15:41:21 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#3129 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#5251 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#5250))
19/07/31 15:41:21 INFO InMemoryTableScanExec: Predicate (visit_device_type#3130 = All Devices) generates partition filter: ((visit_device_type.lowerBound#5256 <= All Devices) && (All Devices <= visit_device_type.upperBound#5255))
19/07/31 15:41:21 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:41:21 INFO DAGScheduler: Got job 80 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:41:21 INFO DAGScheduler: Final stage: ResultStage 115 (collect at utils.scala:204)
19/07/31 15:41:21 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:41:21 INFO DAGScheduler: Missing parents: List()
19/07/31 15:41:21 INFO DAGScheduler: Submitting ResultStage 115 (MapPartitionsRDD[407] at collect at utils.scala:204), which has no missing parents
19/07/31 15:41:21 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 72.1 KB, free 911.2 MB)
19/07/31 15:41:21 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 30.5 KB, free 911.2 MB)
19/07/31 15:41:21 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 127.0.0.1:64327 (size: 30.5 KB, free: 912.0 MB)
19/07/31 15:41:21 INFO SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:1006
19/07/31 15:41:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 115 (MapPartitionsRDD[407] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:41:21 INFO TaskSchedulerImpl: Adding task set 115.0 with 1 tasks
19/07/31 15:41:21 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 172, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:41:21 INFO Executor: Running task 0.0 in stage 115.0 (TID 172)
19/07/31 15:41:21 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:41:21 INFO Executor: Finished task 0.0 in stage 115.0 (TID 172). 7542 bytes result sent to driver
19/07/31 15:41:21 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 172) in 5 ms on localhost (executor driver) (1/1)
19/07/31 15:41:21 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
19/07/31 15:41:21 INFO DAGScheduler: ResultStage 115 (collect at utils.scala:204) finished in 0.005 s
19/07/31 15:41:21 INFO DAGScheduler: Job 80 finished: collect at utils.scala:204, took 0.010438 s
19/07/31 15:41:21 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:41:21 INFO DAGScheduler: Registering RDD 408 (collect at utils.scala:204)
19/07/31 15:41:21 INFO DAGScheduler: Got job 81 (collect at utils.scala:204) with 4 output partitions
19/07/31 15:41:21 INFO DAGScheduler: Final stage: ResultStage 117 (collect at utils.scala:204)
19/07/31 15:41:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 116)
19/07/31 15:41:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 116)
19/07/31 15:41:21 INFO DAGScheduler: Submitting ShuffleMapStage 116 (MapPartitionsRDD[408] at collect at utils.scala:204), which has no missing parents
19/07/31 15:41:21 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 74.6 KB, free 911.1 MB)
19/07/31 15:41:21 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.1 MB)
19/07/31 15:41:21 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 127.0.0.1:64327 (size: 31.8 KB, free: 912.0 MB)
19/07/31 15:41:21 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1006
19/07/31 15:41:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 116 (MapPartitionsRDD[408] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:41:21 INFO TaskSchedulerImpl: Adding task set 116.0 with 1 tasks
19/07/31 15:41:21 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 173, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 15:41:21 INFO Executor: Running task 0.0 in stage 116.0 (TID 173)
19/07/31 15:41:21 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:41:21 INFO Executor: Finished task 0.0 in stage 116.0 (TID 173). 1687 bytes result sent to driver
19/07/31 15:41:21 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 173) in 8 ms on localhost (executor driver) (1/1)
19/07/31 15:41:21 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool 
19/07/31 15:41:21 INFO DAGScheduler: ShuffleMapStage 116 (collect at utils.scala:204) finished in 0.008 s
19/07/31 15:41:21 INFO DAGScheduler: looking for newly runnable stages
19/07/31 15:41:21 INFO DAGScheduler: running: Set()
19/07/31 15:41:21 INFO DAGScheduler: waiting: Set(ResultStage 117)
19/07/31 15:41:21 INFO DAGScheduler: failed: Set()
19/07/31 15:41:21 INFO DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[411] at collect at utils.scala:204), which has no missing parents
19/07/31 15:41:21 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 16.8 KB, free 911.0 MB)
19/07/31 15:41:21 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.0 MB)
19/07/31 15:41:21 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 127.0.0.1:64327 (size: 8.0 KB, free: 912.0 MB)
19/07/31 15:41:21 INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1006
19/07/31 15:41:21 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 117 (MapPartitionsRDD[411] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 15:41:21 INFO TaskSchedulerImpl: Adding task set 117.0 with 4 tasks
19/07/31 15:41:21 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 174, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 15:41:21 INFO TaskSetManager: Starting task 1.0 in stage 117.0 (TID 175, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 15:41:21 INFO TaskSetManager: Starting task 2.0 in stage 117.0 (TID 176, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 15:41:21 INFO TaskSetManager: Starting task 3.0 in stage 117.0 (TID 177, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 15:41:21 INFO Executor: Running task 1.0 in stage 117.0 (TID 175)
19/07/31 15:41:21 INFO Executor: Running task 0.0 in stage 117.0 (TID 174)
19/07/31 15:41:21 INFO Executor: Running task 2.0 in stage 117.0 (TID 176)
19/07/31 15:41:21 INFO Executor: Running task 3.0 in stage 117.0 (TID 177)
19/07/31 15:41:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:41:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:41:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:41:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:41:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:41:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:41:21 INFO Executor: Finished task 0.0 in stage 117.0 (TID 174). 2382 bytes result sent to driver
19/07/31 15:41:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:41:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/07/31 15:41:21 INFO Executor: Finished task 1.0 in stage 117.0 (TID 175). 2403 bytes result sent to driver
19/07/31 15:41:21 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 174) in 5 ms on localhost (executor driver) (1/4)
19/07/31 15:41:21 INFO TaskSetManager: Finished task 1.0 in stage 117.0 (TID 175) in 5 ms on localhost (executor driver) (2/4)
19/07/31 15:41:21 INFO Executor: Finished task 3.0 in stage 117.0 (TID 177). 2362 bytes result sent to driver
19/07/31 15:41:21 INFO Executor: Finished task 2.0 in stage 117.0 (TID 176). 2390 bytes result sent to driver
19/07/31 15:41:21 INFO TaskSetManager: Finished task 3.0 in stage 117.0 (TID 177) in 6 ms on localhost (executor driver) (3/4)
19/07/31 15:41:21 INFO TaskSetManager: Finished task 2.0 in stage 117.0 (TID 176) in 6 ms on localhost (executor driver) (4/4)
19/07/31 15:41:21 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool 
19/07/31 15:41:21 INFO DAGScheduler: ResultStage 117 (collect at utils.scala:204) finished in 0.008 s
19/07/31 15:41:21 INFO DAGScheduler: Job 81 finished: collect at utils.scala:204, took 0.024810 s
19/07/31 15:46:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_201`) `dbplyr_202`
ORDER BY `date`) `dbplyr_203`) `dbplyr_204`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:46:43 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:46:43 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:46:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_205`) `dbplyr_206`
ORDER BY `date`) `dbplyr_207`) `dbplyr_208`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:46:43 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:46:43 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:46:43 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#3129) generates partition filter: ((cust_prospect_ind.count#5351 - cust_prospect_ind.nullCount#5350) > 0)
19/07/31 15:46:43 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#3130) generates partition filter: ((visit_device_type.count#5356 - visit_device_type.nullCount#5355) > 0)
19/07/31 15:46:43 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#3129 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#5349 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#5348))
19/07/31 15:46:43 INFO InMemoryTableScanExec: Predicate (visit_device_type#3130 = All Devices) generates partition filter: ((visit_device_type.lowerBound#5354 <= All Devices) && (All Devices <= visit_device_type.upperBound#5353))
19/07/31 15:46:43 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:46:43 INFO DAGScheduler: Got job 82 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:46:43 INFO DAGScheduler: Final stage: ResultStage 118 (collect at utils.scala:204)
19/07/31 15:46:43 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:46:43 INFO DAGScheduler: Missing parents: List()
19/07/31 15:46:43 INFO DAGScheduler: Submitting ResultStage 118 (MapPartitionsRDD[416] at collect at utils.scala:204), which has no missing parents
19/07/31 15:46:43 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 72.1 KB, free 911.0 MB)
19/07/31 15:46:43 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.9 MB)
19/07/31 15:46:43 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 127.0.0.1:64327 (size: 30.4 KB, free: 911.9 MB)
19/07/31 15:46:43 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1006
19/07/31 15:46:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 118 (MapPartitionsRDD[416] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:46:43 INFO TaskSchedulerImpl: Adding task set 118.0 with 1 tasks
19/07/31 15:46:43 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 178, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:46:43 INFO Executor: Running task 0.0 in stage 118.0 (TID 178)
19/07/31 15:46:43 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:46:43 INFO Executor: Finished task 0.0 in stage 118.0 (TID 178). 7542 bytes result sent to driver
19/07/31 15:46:43 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 178) in 10 ms on localhost (executor driver) (1/1)
19/07/31 15:46:43 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool 
19/07/31 15:46:43 INFO DAGScheduler: ResultStage 118 (collect at utils.scala:204) finished in 0.012 s
19/07/31 15:46:43 INFO DAGScheduler: Job 82 finished: collect at utils.scala:204, took 0.029874 s
19/07/31 15:46:43 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:46:43 INFO DAGScheduler: Registering RDD 417 (collect at utils.scala:204)
19/07/31 15:46:43 INFO DAGScheduler: Got job 83 (collect at utils.scala:204) with 4 output partitions
19/07/31 15:46:43 INFO DAGScheduler: Final stage: ResultStage 120 (collect at utils.scala:204)
19/07/31 15:46:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 119)
19/07/31 15:46:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 119)
19/07/31 15:46:43 INFO DAGScheduler: Submitting ShuffleMapStage 119 (MapPartitionsRDD[417] at collect at utils.scala:204), which has no missing parents
19/07/31 15:46:43 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 74.6 KB, free 910.9 MB)
19/07/31 15:46:43 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.8 MB)
19/07/31 15:46:43 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 127.0.0.1:64327 (size: 31.7 KB, free: 911.9 MB)
19/07/31 15:46:43 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1006
19/07/31 15:46:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 119 (MapPartitionsRDD[417] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:46:43 INFO TaskSchedulerImpl: Adding task set 119.0 with 1 tasks
19/07/31 15:46:43 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 179, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 15:46:43 INFO Executor: Running task 0.0 in stage 119.0 (TID 179)
19/07/31 15:46:43 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:46:43 INFO Executor: Finished task 0.0 in stage 119.0 (TID 179). 1687 bytes result sent to driver
19/07/31 15:46:43 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 179) in 11 ms on localhost (executor driver) (1/1)
19/07/31 15:46:43 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
19/07/31 15:46:43 INFO DAGScheduler: ShuffleMapStage 119 (collect at utils.scala:204) finished in 0.011 s
19/07/31 15:46:43 INFO DAGScheduler: looking for newly runnable stages
19/07/31 15:46:43 INFO DAGScheduler: running: Set()
19/07/31 15:46:43 INFO DAGScheduler: waiting: Set(ResultStage 120)
19/07/31 15:46:43 INFO DAGScheduler: failed: Set()
19/07/31 15:46:43 INFO DAGScheduler: Submitting ResultStage 120 (MapPartitionsRDD[420] at collect at utils.scala:204), which has no missing parents
19/07/31 15:46:43 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 16.8 KB, free 910.8 MB)
19/07/31 15:46:43 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.8 MB)
19/07/31 15:46:43 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 127.0.0.1:64327 (size: 8.0 KB, free: 911.9 MB)
19/07/31 15:46:43 INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1006
19/07/31 15:46:43 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 120 (MapPartitionsRDD[420] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 15:46:43 INFO TaskSchedulerImpl: Adding task set 120.0 with 4 tasks
19/07/31 15:46:43 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 180, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 15:46:43 INFO TaskSetManager: Starting task 1.0 in stage 120.0 (TID 181, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 15:46:43 INFO TaskSetManager: Starting task 2.0 in stage 120.0 (TID 182, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 15:46:43 INFO TaskSetManager: Starting task 3.0 in stage 120.0 (TID 183, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 15:46:43 INFO Executor: Running task 0.0 in stage 120.0 (TID 180)
19/07/31 15:46:43 INFO Executor: Running task 1.0 in stage 120.0 (TID 181)
19/07/31 15:46:43 INFO Executor: Running task 3.0 in stage 120.0 (TID 183)
19/07/31 15:46:43 INFO Executor: Running task 2.0 in stage 120.0 (TID 182)
19/07/31 15:46:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:46:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 15:46:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:46:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:46:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:46:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:46:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:46:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:46:43 INFO Executor: Finished task 2.0 in stage 120.0 (TID 182). 2433 bytes result sent to driver
19/07/31 15:46:43 INFO TaskSetManager: Finished task 2.0 in stage 120.0 (TID 182) in 13 ms on localhost (executor driver) (1/4)
19/07/31 15:46:43 INFO Executor: Finished task 1.0 in stage 120.0 (TID 181). 2403 bytes result sent to driver
19/07/31 15:46:43 INFO Executor: Finished task 3.0 in stage 120.0 (TID 183). 2362 bytes result sent to driver
19/07/31 15:46:43 INFO TaskSetManager: Finished task 1.0 in stage 120.0 (TID 181) in 14 ms on localhost (executor driver) (2/4)
19/07/31 15:46:43 INFO TaskSetManager: Finished task 3.0 in stage 120.0 (TID 183) in 13 ms on localhost (executor driver) (3/4)
19/07/31 15:46:43 INFO Executor: Finished task 0.0 in stage 120.0 (TID 180). 2382 bytes result sent to driver
19/07/31 15:46:43 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 180) in 16 ms on localhost (executor driver) (4/4)
19/07/31 15:46:43 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool 
19/07/31 15:46:43 INFO DAGScheduler: ResultStage 120 (collect at utils.scala:204) finished in 0.016 s
19/07/31 15:46:43 INFO DAGScheduler: Job 83 finished: collect at utils.scala:204, took 0.047249 s
19/07/31 15:49:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_209`) `dbplyr_210`
ORDER BY `date`) `dbplyr_211`) `dbplyr_212`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:49:51 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:49:51 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:49:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_213`) `dbplyr_214`
ORDER BY `date`) `dbplyr_215`) `dbplyr_216`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 15:49:51 INFO HiveMetaStore: 0: get_database: default
19/07/31 15:49:51 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 15:49:51 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#3129) generates partition filter: ((cust_prospect_ind.count#5449 - cust_prospect_ind.nullCount#5448) > 0)
19/07/31 15:49:51 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#3130) generates partition filter: ((visit_device_type.count#5454 - visit_device_type.nullCount#5453) > 0)
19/07/31 15:49:51 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#3129 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#5447 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#5446))
19/07/31 15:49:51 INFO InMemoryTableScanExec: Predicate (visit_device_type#3130 = All Devices) generates partition filter: ((visit_device_type.lowerBound#5452 <= All Devices) && (All Devices <= visit_device_type.upperBound#5451))
19/07/31 15:49:51 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:49:51 INFO DAGScheduler: Got job 84 (collect at utils.scala:204) with 1 output partitions
19/07/31 15:49:51 INFO DAGScheduler: Final stage: ResultStage 121 (collect at utils.scala:204)
19/07/31 15:49:51 INFO DAGScheduler: Parents of final stage: List()
19/07/31 15:49:51 INFO DAGScheduler: Missing parents: List()
19/07/31 15:49:51 INFO DAGScheduler: Submitting ResultStage 121 (MapPartitionsRDD[425] at collect at utils.scala:204), which has no missing parents
19/07/31 15:49:51 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 72.1 KB, free 910.7 MB)
19/07/31 15:49:51 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.7 MB)
19/07/31 15:49:51 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 127.0.0.1:64327 (size: 30.5 KB, free: 911.9 MB)
19/07/31 15:49:51 INFO SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:1006
19/07/31 15:49:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 121 (MapPartitionsRDD[425] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:49:51 INFO TaskSchedulerImpl: Adding task set 121.0 with 1 tasks
19/07/31 15:49:51 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 184, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 15:49:51 INFO Executor: Running task 0.0 in stage 121.0 (TID 184)
19/07/31 15:49:51 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:49:51 INFO Executor: Finished task 0.0 in stage 121.0 (TID 184). 7542 bytes result sent to driver
19/07/31 15:49:51 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 184) in 9 ms on localhost (executor driver) (1/1)
19/07/31 15:49:51 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool 
19/07/31 15:49:51 INFO DAGScheduler: ResultStage 121 (collect at utils.scala:204) finished in 0.009 s
19/07/31 15:49:51 INFO DAGScheduler: Job 84 finished: collect at utils.scala:204, took 0.022048 s
19/07/31 15:49:51 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 15:49:51 INFO DAGScheduler: Registering RDD 426 (collect at utils.scala:204)
19/07/31 15:49:51 INFO DAGScheduler: Got job 85 (collect at utils.scala:204) with 4 output partitions
19/07/31 15:49:51 INFO DAGScheduler: Final stage: ResultStage 123 (collect at utils.scala:204)
19/07/31 15:49:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 122)
19/07/31 15:49:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 122)
19/07/31 15:49:51 INFO DAGScheduler: Submitting ShuffleMapStage 122 (MapPartitionsRDD[426] at collect at utils.scala:204), which has no missing parents
19/07/31 15:49:51 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 74.6 KB, free 910.6 MB)
19/07/31 15:49:51 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.6 MB)
19/07/31 15:49:51 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 127.0.0.1:64327 (size: 31.8 KB, free: 911.8 MB)
19/07/31 15:49:51 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1006
19/07/31 15:49:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 122 (MapPartitionsRDD[426] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 15:49:51 INFO TaskSchedulerImpl: Adding task set 122.0 with 1 tasks
19/07/31 15:49:51 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 185, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 15:49:51 INFO Executor: Running task 0.0 in stage 122.0 (TID 185)
19/07/31 15:49:51 INFO BlockManager: Found block rdd_242_0 locally
19/07/31 15:49:51 INFO Executor: Finished task 0.0 in stage 122.0 (TID 185). 1687 bytes result sent to driver
19/07/31 15:49:51 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 185) in 14 ms on localhost (executor driver) (1/1)
19/07/31 15:49:51 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool 
19/07/31 15:49:51 INFO DAGScheduler: ShuffleMapStage 122 (collect at utils.scala:204) finished in 0.014 s
19/07/31 15:49:51 INFO DAGScheduler: looking for newly runnable stages
19/07/31 15:49:51 INFO DAGScheduler: running: Set()
19/07/31 15:49:51 INFO DAGScheduler: waiting: Set(ResultStage 123)
19/07/31 15:49:51 INFO DAGScheduler: failed: Set()
19/07/31 15:49:51 INFO DAGScheduler: Submitting ResultStage 123 (MapPartitionsRDD[429] at collect at utils.scala:204), which has no missing parents
19/07/31 15:49:51 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 16.8 KB, free 910.6 MB)
19/07/31 15:49:51 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.6 MB)
19/07/31 15:49:51 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 127.0.0.1:64327 (size: 8.0 KB, free: 911.8 MB)
19/07/31 15:49:51 INFO SparkContext: Created broadcast 147 from broadcast at DAGScheduler.scala:1006
19/07/31 15:49:51 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 123 (MapPartitionsRDD[429] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 15:49:51 INFO TaskSchedulerImpl: Adding task set 123.0 with 4 tasks
19/07/31 15:49:51 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 186, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 15:49:51 INFO TaskSetManager: Starting task 1.0 in stage 123.0 (TID 187, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 15:49:51 INFO TaskSetManager: Starting task 2.0 in stage 123.0 (TID 188, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 15:49:51 INFO TaskSetManager: Starting task 3.0 in stage 123.0 (TID 189, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 15:49:51 INFO Executor: Running task 0.0 in stage 123.0 (TID 186)
19/07/31 15:49:51 INFO Executor: Running task 1.0 in stage 123.0 (TID 187)
19/07/31 15:49:51 INFO Executor: Running task 2.0 in stage 123.0 (TID 188)
19/07/31 15:49:51 INFO Executor: Running task 3.0 in stage 123.0 (TID 189)
19/07/31 15:49:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:49:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:49:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:49:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:49:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:49:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 15:49:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:49:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 15:49:51 INFO Executor: Finished task 2.0 in stage 123.0 (TID 188). 2390 bytes result sent to driver
19/07/31 15:49:51 INFO Executor: Finished task 1.0 in stage 123.0 (TID 187). 2403 bytes result sent to driver
19/07/31 15:49:51 INFO Executor: Finished task 0.0 in stage 123.0 (TID 186). 2382 bytes result sent to driver
19/07/31 15:49:51 INFO Executor: Finished task 3.0 in stage 123.0 (TID 189). 2362 bytes result sent to driver
19/07/31 15:49:51 INFO TaskSetManager: Finished task 2.0 in stage 123.0 (TID 188) in 7 ms on localhost (executor driver) (1/4)
19/07/31 15:49:51 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 186) in 8 ms on localhost (executor driver) (2/4)
19/07/31 15:49:51 INFO TaskSetManager: Finished task 1.0 in stage 123.0 (TID 187) in 8 ms on localhost (executor driver) (3/4)
19/07/31 15:49:51 INFO TaskSetManager: Finished task 3.0 in stage 123.0 (TID 189) in 8 ms on localhost (executor driver) (4/4)
19/07/31 15:49:51 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool 
19/07/31 15:49:51 INFO DAGScheduler: ResultStage 123 (collect at utils.scala:204) finished in 0.013 s
19/07/31 15:49:51 INFO DAGScheduler: Job 85 finished: collect at utils.scala:204, took 0.056139 s
19/07/31 15:51:42 INFO SparkContext: Invoking stop() from shutdown hook
19/07/31 15:51:42 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
19/07/31 15:51:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/07/31 15:51:42 INFO MemoryStore: MemoryStore cleared
19/07/31 15:51:42 INFO BlockManager: BlockManager stopped
19/07/31 15:51:42 INFO BlockManagerMaster: BlockManagerMaster stopped
19/07/31 15:51:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/07/31 15:51:42 INFO SparkContext: Successfully stopped SparkContext
19/07/31 15:51:42 INFO ShutdownHookManager: Shutdown hook called
19/07/31 15:51:42 INFO ShutdownHookManager: Deleting directory /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-51b847a8-1855-42e9-a904-0b261a3633d8
19/07/31 17:06:00 INFO SparkContext: Running Spark version 2.2.0
19/07/31 17:06:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/07/31 17:06:01 INFO SparkContext: Submitted application: sparklyr
19/07/31 17:06:01 INFO SecurityManager: Changing view acls to: 6jncnk4f
19/07/31 17:06:01 INFO SecurityManager: Changing modify acls to: 6jncnk4f
19/07/31 17:06:01 INFO SecurityManager: Changing view acls groups to: 
19/07/31 17:06:01 INFO SecurityManager: Changing modify acls groups to: 
19/07/31 17:06:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(6jncnk4f); groups with view permissions: Set(); users  with modify permissions: Set(6jncnk4f); groups with modify permissions: Set()
19/07/31 17:06:01 INFO Utils: Successfully started service 'sparkDriver' on port 53889.
19/07/31 17:06:01 INFO SparkEnv: Registering MapOutputTracker
19/07/31 17:06:01 INFO SparkEnv: Registering BlockManagerMaster
19/07/31 17:06:01 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/07/31 17:06:01 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/07/31 17:06:01 INFO DiskBlockManager: Created local directory at /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/blockmgr-2ed3a78f-7dc0-4db1-adaa-714720569434
19/07/31 17:06:01 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/07/31 17:06:01 INFO SparkEnv: Registering OutputCommitCoordinator
19/07/31 17:06:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/07/31 17:06:01 INFO Utils: Successfully started service 'SparkUI' on port 4041.
19/07/31 17:06:01 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
19/07/31 17:06:01 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:53889/jars/sparklyr-2.0-2.11.jar with timestamp 1564607161761
19/07/31 17:06:01 INFO Executor: Starting executor ID driver on host localhost
19/07/31 17:06:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53890.
19/07/31 17:06:01 INFO NettyBlockTransferService: Server created on 127.0.0.1:53890
19/07/31 17:06:01 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/07/31 17:06:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 53890, None)
19/07/31 17:06:01 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:53890 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 53890, None)
19/07/31 17:06:01 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 53890, None)
19/07/31 17:06:01 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 53890, None)
19/07/31 17:06:02 INFO SharedState: loading hive config file: file:/Users/6jncnk4f/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/07/31 17:06:02 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse').
19/07/31 17:06:02 INFO SharedState: Warehouse path is 'file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse'.
19/07/31 17:06:02 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/07/31 17:06:03 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/07/31 17:06:03 INFO ObjectStore: ObjectStore, initialize called
19/07/31 17:06:03 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/07/31 17:06:03 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/07/31 17:06:04 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/07/31 17:06:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:06:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:06:06 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:06:06 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:06:06 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/07/31 17:06:06 INFO ObjectStore: Initialized ObjectStore
19/07/31 17:06:06 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/07/31 17:06:06 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/07/31 17:06:06 INFO HiveMetaStore: Added admin role in metastore
19/07/31 17:06:06 INFO HiveMetaStore: Added public role in metastore
19/07/31 17:06:06 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/07/31 17:06:06 INFO HiveMetaStore: 0: get_all_databases
19/07/31 17:06:06 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_all_databases	
19/07/31 17:06:06 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/07/31 17:06:06 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/07/31 17:06:06 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:06:06 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/79bbce66-2a59-4033-9b14-1e2a0893921c_resources
19/07/31 17:06:06 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/79bbce66-2a59-4033-9b14-1e2a0893921c
19/07/31 17:06:06 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/79bbce66-2a59-4033-9b14-1e2a0893921c
19/07/31 17:06:06 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/79bbce66-2a59-4033-9b14-1e2a0893921c/_tmp_space.db
19/07/31 17:06:06 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 17:06:07 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:07 INFO HiveMetaStore: 0: get_database: global_temp
19/07/31 17:06:07 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/07/31 17:06:07 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/07/31 17:06:07 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/4111140d-5f9d-4721-846e-aa1895958095_resources
19/07/31 17:06:07 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/4111140d-5f9d-4721-846e-aa1895958095
19/07/31 17:06:07 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/4111140d-5f9d-4721-846e-aa1895958095
19/07/31 17:06:07 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/4111140d-5f9d-4721-846e-aa1895958095/_tmp_space.db
19/07/31 17:06:07 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 17:06:07 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/07/31 17:06:07 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 17:06:08 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:08 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:08 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:08 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:08 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 17:06:08 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 17:06:09 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 17:06:09 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/07/31 17:06:09 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/07/31 17:06:09 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:09 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:09 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/07/31 17:06:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/07/31 17:06:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/07/31 17:06:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:53890 (size: 3.4 KB, free: 912.3 MB)
19/07/31 17:06:09 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:09 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/07/31 17:06:09 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/07/31 17:06:09 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/07/31 17:06:09 INFO Executor: Fetching spark://127.0.0.1:53889/jars/sparklyr-2.0-2.11.jar with timestamp 1564607161761
19/07/31 17:06:09 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:53889 after 11 ms (0 ms spent in bootstraps)
19/07/31 17:06:09 INFO Utils: Fetching spark://127.0.0.1:53889/jars/sparklyr-2.0-2.11.jar to /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-24a9b421-5ead-49de-b042-583502535619/userFiles-b6fbc7ec-894b-45ef-b4da-8f375da67278/fetchFileTemp4643478710072977491.tmp
19/07/31 17:06:09 INFO Executor: Adding file:/private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-24a9b421-5ead-49de-b042-583502535619/userFiles-b6fbc7ec-894b-45ef-b4da-8f375da67278/sparklyr-2.0-2.11.jar to class loader
19/07/31 17:06:09 INFO CodeGenerator: Code generated in 195.661936 ms
19/07/31 17:06:09 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
19/07/31 17:06:09 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 448 ms on localhost (executor driver) (1/1)
19/07/31 17:06:09 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/07/31 17:06:09 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.462 s
19/07/31 17:06:09 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0.592496 s
19/07/31 17:06:10 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 17:06:10 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#10)) > 0)
19/07/31 17:06:10 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 17:06:10 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 17:06:10 INFO CodeGenerator: Code generated in 17.225105 ms
19/07/31 17:06:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 281.2 KB, free 912.0 MB)
19/07/31 17:06:10 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.8 KB, free 912.0 MB)
19/07/31 17:06:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:53890 (size: 23.8 KB, free: 912.3 MB)
19/07/31 17:06:10 INFO SparkContext: Created broadcast 1 from csv at NativeMethodAccessorImpl.java:0
19/07/31 17:06:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 17:06:10 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 17:06:10 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 17:06:10 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 17:06:10 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:10 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:10 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 17:06:10 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 912.0 MB)
19/07/31 17:06:10 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 912.0 MB)
19/07/31 17:06:10 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:53890 (size: 4.3 KB, free: 912.3 MB)
19/07/31 17:06:10 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:10 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/07/31 17:06:10 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:10 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/07/31 17:06:10 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 17:06:10 INFO CodeGenerator: Code generated in 8.144323 ms
19/07/31 17:06:10 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:53890 in memory (size: 3.4 KB, free: 912.3 MB)
19/07/31 17:06:10 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1437 bytes result sent to driver
19/07/31 17:06:10 INFO ContextCleaner: Cleaned accumulator 0
19/07/31 17:06:10 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 252 ms on localhost (executor driver) (1/1)
19/07/31 17:06:10 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/07/31 17:06:10 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0.253 s
19/07/31 17:06:10 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0.269340 s
19/07/31 17:06:10 INFO CodeGenerator: Code generated in 5.696143 ms
19/07/31 17:06:10 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 17:06:10 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 17:06:10 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 17:06:10 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 17:06:10 INFO CodeGenerator: Code generated in 5.227115 ms
19/07/31 17:06:10 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 281.2 KB, free 911.7 MB)
19/07/31 17:06:10 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.7 MB)
19/07/31 17:06:10 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:53890 (size: 23.8 KB, free: 912.2 MB)
19/07/31 17:06:10 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:0
19/07/31 17:06:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 17:06:10 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 17:06:10 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 17:06:10 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 17:06:10 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:10 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:10 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 17:06:10 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.8 KB, free 911.7 MB)
19/07/31 17:06:10 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.7 MB)
19/07/31 17:06:10 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:53890 (size: 8.6 KB, free: 912.2 MB)
19/07/31 17:06:10 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:10 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/07/31 17:06:10 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:10 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/07/31 17:06:10 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 17:06:10 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1627 bytes result sent to driver
19/07/31 17:06:10 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 74 ms on localhost (executor driver) (1/1)
19/07/31 17:06:10 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/07/31 17:06:10 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.075 s
19/07/31 17:06:10 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.083140 s
19/07/31 17:06:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 17:06:11 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:11 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:11 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:11 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 17:06:11 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 17:06:11 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 17:06:11 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 17:06:11 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 17:06:11 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 17:06:11 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 17:06:11 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 17:06:11 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 17:06:11 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 282.3 KB, free 911.4 MB)
19/07/31 17:06:11 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.4 MB)
19/07/31 17:06:11 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:53890 (size: 24.0 KB, free: 912.2 MB)
19/07/31 17:06:11 INFO SparkContext: Created broadcast 5 from sql at NativeMethodAccessorImpl.java:0
19/07/31 17:06:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 17:06:11 INFO CodeGenerator: Code generated in 9.595449 ms
19/07/31 17:06:11 INFO CodeGenerator: Code generated in 9.113377 ms
19/07/31 17:06:11 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 17:06:11 INFO DAGScheduler: Registering RDD 18 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 17:06:11 INFO DAGScheduler: Got job 3 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 17:06:11 INFO DAGScheduler: Final stage: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 17:06:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/07/31 17:06:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/07/31 17:06:11 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 17:06:11 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 26.3 KB, free 911.3 MB)
19/07/31 17:06:11 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.8 KB, free 911.3 MB)
19/07/31 17:06:11 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:53890 (size: 11.8 KB, free: 912.2 MB)
19/07/31 17:06:11 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:11 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/07/31 17:06:11 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:11 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/07/31 17:06:11 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 17:06:11 INFO CodeGenerator: Code generated in 20.77686 ms
19/07/31 17:06:11 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 48.9 KB, free 911.3 MB)
19/07/31 17:06:11 INFO BlockManagerInfo: Added rdd_15_0 in memory on 127.0.0.1:53890 (size: 48.9 KB, free: 912.2 MB)
19/07/31 17:06:11 INFO CodeGenerator: Code generated in 4.319979 ms
19/07/31 17:06:11 INFO CodeGenerator: Code generated in 16.398052 ms
19/07/31 17:06:11 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2504 bytes result sent to driver
19/07/31 17:06:11 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 234 ms on localhost (executor driver) (1/1)
19/07/31 17:06:11 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/07/31 17:06:11 INFO DAGScheduler: ShuffleMapStage 3 (sql at NativeMethodAccessorImpl.java:0) finished in 0.235 s
19/07/31 17:06:11 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:11 INFO DAGScheduler: running: Set()
19/07/31 17:06:11 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/07/31 17:06:11 INFO DAGScheduler: failed: Set()
19/07/31 17:06:11 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 17:06:11 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 911.3 MB)
19/07/31 17:06:11 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.3 MB)
19/07/31 17:06:11 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:53890 (size: 3.7 KB, free: 912.2 MB)
19/07/31 17:06:11 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:11 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/07/31 17:06:11 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:11 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/07/31 17:06:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
19/07/31 17:06:11 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1581 bytes result sent to driver
19/07/31 17:06:11 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 29 ms on localhost (executor driver) (1/1)
19/07/31 17:06:11 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/07/31 17:06:11 INFO DAGScheduler: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0) finished in 0.029 s
19/07/31 17:06:11 INFO DAGScheduler: Job 3 finished: sql at NativeMethodAccessorImpl.java:0, took 0.309834 s
19/07/31 17:06:11 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 17:06:11 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:11 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:11 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:11 INFO DAGScheduler: Registering RDD 24 (collect at utils.scala:204)
19/07/31 17:06:11 INFO DAGScheduler: Got job 4 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:11 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
19/07/31 17:06:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/07/31 17:06:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/07/31 17:06:11 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:11 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 26.3 KB, free 911.2 MB)
19/07/31 17:06:11 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.9 KB, free 911.2 MB)
19/07/31 17:06:11 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:53890 (size: 11.9 KB, free: 912.1 MB)
19/07/31 17:06:11 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:11 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/07/31 17:06:11 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:11 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/07/31 17:06:11 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:11 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1780 bytes result sent to driver
19/07/31 17:06:11 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 12 ms on localhost (executor driver) (1/1)
19/07/31 17:06:11 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/07/31 17:06:11 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:204) finished in 0.013 s
19/07/31 17:06:11 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:11 INFO DAGScheduler: running: Set()
19/07/31 17:06:11 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/07/31 17:06:11 INFO DAGScheduler: failed: Set()
19/07/31 17:06:11 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:11 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 911.2 MB)
19/07/31 17:06:11 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.2 MB)
19/07/31 17:06:11 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:53890 (size: 3.7 KB, free: 912.1 MB)
19/07/31 17:06:11 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:11 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/07/31 17:06:11 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:11 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/07/31 17:06:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:11 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1538 bytes result sent to driver
19/07/31 17:06:11 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:06:11 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/07/31 17:06:11 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:11 INFO DAGScheduler: Job 4 finished: collect at utils.scala:204, took 0.036202 s
19/07/31 17:06:11 INFO CodeGenerator: Code generated in 6.269369 ms
19/07/31 17:06:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz1`
WHERE (0 = 1)
19/07/31 17:06:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_001`) `dbplyr_002`
ORDER BY `date`) `dbplyr_003`) `dbplyr_004`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:11 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:11 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_005`) `dbplyr_006`
ORDER BY `date`) `dbplyr_007`) `dbplyr_008`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:12 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:12 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:12 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#442 - cust_prospect_ind.nullCount#441) > 0)
19/07/31 17:06:12 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#447 - visit_device_type.nullCount#446) > 0)
19/07/31 17:06:12 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#440 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#439))
19/07/31 17:06:12 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#445 <= All Devices) && (All Devices <= visit_device_type.upperBound#444))
19/07/31 17:06:12 INFO CodeGenerator: Code generated in 19.97755 ms
19/07/31 17:06:12 INFO CodeGenerator: Code generated in 16.848541 ms
19/07/31 17:06:12 INFO CodeGenerator: Code generated in 8.281026 ms
19/07/31 17:06:12 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:12 INFO DAGScheduler: Got job 5 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:12 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:204)
19/07/31 17:06:12 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:12 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:12 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[32] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:12 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 72.1 KB, free 911.2 MB)
19/07/31 17:06:12 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.1 MB)
19/07/31 17:06:12 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:53890 (size: 30.4 KB, free: 912.1 MB)
19/07/31 17:06:12 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:12 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/07/31 17:06:12 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:12 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
19/07/31 17:06:12 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:12 INFO CodeGenerator: Code generated in 8.565166 ms
19/07/31 17:06:12 INFO CodeGenerator: Code generated in 13.53332 ms
19/07/31 17:06:12 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 7585 bytes result sent to driver
19/07/31 17:06:12 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 56 ms on localhost (executor driver) (1/1)
19/07/31 17:06:12 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/07/31 17:06:12 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:204) finished in 0.057 s
19/07/31 17:06:12 INFO DAGScheduler: Job 5 finished: collect at utils.scala:204, took 0.066853 s
19/07/31 17:06:12 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:12 INFO DAGScheduler: Registering RDD 33 (collect at utils.scala:204)
19/07/31 17:06:12 INFO DAGScheduler: Got job 6 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:12 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:204)
19/07/31 17:06:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
19/07/31 17:06:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
19/07/31 17:06:12 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[33] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:12 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 74.5 KB, free 911.1 MB)
19/07/31 17:06:12 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 31.7 KB, free 911.0 MB)
19/07/31 17:06:12 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:53890 (size: 31.7 KB, free: 912.1 MB)
19/07/31 17:06:12 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[33] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:12 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/07/31 17:06:12 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:12 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
19/07/31 17:06:12 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:12 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1687 bytes result sent to driver
19/07/31 17:06:12 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 19 ms on localhost (executor driver) (1/1)
19/07/31 17:06:12 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/07/31 17:06:12 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:204) finished in 0.020 s
19/07/31 17:06:12 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:12 INFO DAGScheduler: running: Set()
19/07/31 17:06:12 INFO DAGScheduler: waiting: Set(ResultStage 9)
19/07/31 17:06:12 INFO DAGScheduler: failed: Set()
19/07/31 17:06:12 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[36] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:12 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 16.8 KB, free 911.0 MB)
19/07/31 17:06:12 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.0 MB)
19/07/31 17:06:12 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:06:12 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:12 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 9 (MapPartitionsRDD[36] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:12 INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks
19/07/31 17:06:12 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:12 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 10, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:12 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 11, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:12 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 12, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:12 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
19/07/31 17:06:12 INFO Executor: Running task 1.0 in stage 9.0 (TID 10)
19/07/31 17:06:12 INFO Executor: Running task 3.0 in stage 9.0 (TID 12)
19/07/31 17:06:12 INFO Executor: Running task 2.0 in stage 9.0 (TID 11)
19/07/31 17:06:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:12 INFO CodeGenerator: Code generated in 5.742439 ms
19/07/31 17:06:12 INFO Executor: Finished task 1.0 in stage 9.0 (TID 10). 2403 bytes result sent to driver
19/07/31 17:06:12 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2382 bytes result sent to driver
19/07/31 17:06:12 INFO Executor: Finished task 3.0 in stage 9.0 (TID 12). 2362 bytes result sent to driver
19/07/31 17:06:12 INFO Executor: Finished task 2.0 in stage 9.0 (TID 11). 2390 bytes result sent to driver
19/07/31 17:06:12 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 10) in 43 ms on localhost (executor driver) (1/4)
19/07/31 17:06:12 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 44 ms on localhost (executor driver) (2/4)
19/07/31 17:06:12 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 12) in 43 ms on localhost (executor driver) (3/4)
19/07/31 17:06:12 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 11) in 44 ms on localhost (executor driver) (4/4)
19/07/31 17:06:12 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/07/31 17:06:12 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:204) finished in 0.045 s
19/07/31 17:06:12 INFO DAGScheduler: Job 6 finished: collect at utils.scala:204, took 0.082661 s
19/07/31 17:06:12 INFO CodeGenerator: Code generated in 12.054097 ms
19/07/31 17:06:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_009`) `dbplyr_010`
ORDER BY `date`) `dbplyr_011`) `dbplyr_012`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:12 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:12 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_013`) `dbplyr_014`
ORDER BY `date`) `dbplyr_015`) `dbplyr_016`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:12 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:12 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:12 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#540 - cust_prospect_ind.nullCount#539) > 0)
19/07/31 17:06:12 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#545 - visit_device_type.nullCount#544) > 0)
19/07/31 17:06:12 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#538 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#537))
19/07/31 17:06:12 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#543 <= All Devices) && (All Devices <= visit_device_type.upperBound#542))
19/07/31 17:06:12 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:12 INFO DAGScheduler: Got job 7 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:12 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:204)
19/07/31 17:06:12 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:12 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:12 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[41] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:12 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 72.1 KB, free 910.9 MB)
19/07/31 17:06:12 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.9 MB)
19/07/31 17:06:12 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:06:12 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[41] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:12 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/07/31 17:06:12 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:12 INFO Executor: Running task 0.0 in stage 10.0 (TID 13)
19/07/31 17:06:12 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:12 INFO Executor: Finished task 0.0 in stage 10.0 (TID 13). 7585 bytes result sent to driver
19/07/31 17:06:12 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 13) in 10 ms on localhost (executor driver) (1/1)
19/07/31 17:06:12 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/07/31 17:06:12 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:06:12 INFO DAGScheduler: Job 7 finished: collect at utils.scala:204, took 0.018820 s
19/07/31 17:06:12 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:12 INFO DAGScheduler: Registering RDD 42 (collect at utils.scala:204)
19/07/31 17:06:12 INFO DAGScheduler: Got job 8 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:12 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:204)
19/07/31 17:06:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
19/07/31 17:06:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
19/07/31 17:06:12 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[42] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:12 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 74.5 KB, free 910.8 MB)
19/07/31 17:06:12 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.8 MB)
19/07/31 17:06:12 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:06:12 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[42] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:12 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/07/31 17:06:12 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:12 INFO Executor: Running task 0.0 in stage 11.0 (TID 14)
19/07/31 17:06:12 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:12 INFO Executor: Finished task 0.0 in stage 11.0 (TID 14). 1687 bytes result sent to driver
19/07/31 17:06:12 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 14) in 15 ms on localhost (executor driver) (1/1)
19/07/31 17:06:12 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/07/31 17:06:12 INFO DAGScheduler: ShuffleMapStage 11 (collect at utils.scala:204) finished in 0.015 s
19/07/31 17:06:12 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:12 INFO DAGScheduler: running: Set()
19/07/31 17:06:12 INFO DAGScheduler: waiting: Set(ResultStage 12)
19/07/31 17:06:12 INFO DAGScheduler: failed: Set()
19/07/31 17:06:12 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[45] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:12 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 16.8 KB, free 910.8 MB)
19/07/31 17:06:12 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.8 MB)
19/07/31 17:06:12 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:06:12 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:12 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 12 (MapPartitionsRDD[45] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:12 INFO TaskSchedulerImpl: Adding task set 12.0 with 4 tasks
19/07/31 17:06:12 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 15, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:12 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 16, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:12 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 17, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:12 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 18, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:12 INFO Executor: Running task 0.0 in stage 12.0 (TID 15)
19/07/31 17:06:12 INFO Executor: Running task 1.0 in stage 12.0 (TID 16)
19/07/31 17:06:12 INFO Executor: Running task 3.0 in stage 12.0 (TID 18)
19/07/31 17:06:12 INFO Executor: Running task 2.0 in stage 12.0 (TID 17)
19/07/31 17:06:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:12 INFO Executor: Finished task 2.0 in stage 12.0 (TID 17). 2390 bytes result sent to driver
19/07/31 17:06:12 INFO Executor: Finished task 3.0 in stage 12.0 (TID 18). 2362 bytes result sent to driver
19/07/31 17:06:12 INFO Executor: Finished task 1.0 in stage 12.0 (TID 16). 2403 bytes result sent to driver
19/07/31 17:06:12 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 18) in 8 ms on localhost (executor driver) (1/4)
19/07/31 17:06:12 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 17) in 8 ms on localhost (executor driver) (2/4)
19/07/31 17:06:12 INFO Executor: Finished task 0.0 in stage 12.0 (TID 15). 2382 bytes result sent to driver
19/07/31 17:06:12 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 16) in 8 ms on localhost (executor driver) (3/4)
19/07/31 17:06:12 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 15) in 9 ms on localhost (executor driver) (4/4)
19/07/31 17:06:12 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/07/31 17:06:12 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:06:12 INFO DAGScheduler: Job 8 finished: collect at utils.scala:204, took 0.039620 s
19/07/31 17:06:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_017`) `dbplyr_018`
ORDER BY `date`) `dbplyr_019`) `dbplyr_020`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:13 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:13 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_021`) `dbplyr_022`
ORDER BY `date`) `dbplyr_023`) `dbplyr_024`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:13 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:13 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:13 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#638 - cust_prospect_ind.nullCount#637) > 0)
19/07/31 17:06:13 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#643 - visit_device_type.nullCount#642) > 0)
19/07/31 17:06:13 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#636 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#635))
19/07/31 17:06:13 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#641 <= All Devices) && (All Devices <= visit_device_type.upperBound#640))
19/07/31 17:06:13 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:13 INFO DAGScheduler: Got job 9 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:13 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:204)
19/07/31 17:06:13 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:13 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:13 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[50] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:13 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 72.1 KB, free 910.7 MB)
19/07/31 17:06:13 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.7 MB)
19/07/31 17:06:13 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:06:13 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[50] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:13 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/07/31 17:06:13 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:13 INFO Executor: Running task 0.0 in stage 13.0 (TID 19)
19/07/31 17:06:13 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:13 INFO Executor: Finished task 0.0 in stage 13.0 (TID 19). 7542 bytes result sent to driver
19/07/31 17:06:13 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 19) in 10 ms on localhost (executor driver) (1/1)
19/07/31 17:06:13 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/07/31 17:06:13 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:06:13 INFO DAGScheduler: Job 9 finished: collect at utils.scala:204, took 0.018371 s
19/07/31 17:06:13 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:13 INFO DAGScheduler: Registering RDD 51 (collect at utils.scala:204)
19/07/31 17:06:13 INFO DAGScheduler: Got job 10 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:13 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:204)
19/07/31 17:06:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
19/07/31 17:06:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
19/07/31 17:06:13 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[51] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:13 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 74.5 KB, free 910.6 MB)
19/07/31 17:06:13 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.6 MB)
19/07/31 17:06:13 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.9 MB)
19/07/31 17:06:13 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[51] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:13 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/07/31 17:06:13 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:13 INFO Executor: Running task 0.0 in stage 14.0 (TID 20)
19/07/31 17:06:13 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:13 INFO Executor: Finished task 0.0 in stage 14.0 (TID 20). 1687 bytes result sent to driver
19/07/31 17:06:13 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 20) in 14 ms on localhost (executor driver) (1/1)
19/07/31 17:06:13 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/07/31 17:06:13 INFO DAGScheduler: ShuffleMapStage 14 (collect at utils.scala:204) finished in 0.015 s
19/07/31 17:06:13 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:13 INFO DAGScheduler: running: Set()
19/07/31 17:06:13 INFO DAGScheduler: waiting: Set(ResultStage 15)
19/07/31 17:06:13 INFO DAGScheduler: failed: Set()
19/07/31 17:06:13 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[54] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:13 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 16.8 KB, free 910.6 MB)
19/07/31 17:06:13 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.5 MB)
19/07/31 17:06:13 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:06:13 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:13 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:13 INFO TaskSchedulerImpl: Adding task set 15.0 with 4 tasks
19/07/31 17:06:13 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 21, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:13 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 22, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:13 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 23, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:13 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 24, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:13 INFO Executor: Running task 1.0 in stage 15.0 (TID 22)
19/07/31 17:06:13 INFO Executor: Running task 2.0 in stage 15.0 (TID 23)
19/07/31 17:06:13 INFO Executor: Running task 3.0 in stage 15.0 (TID 24)
19/07/31 17:06:13 INFO Executor: Running task 0.0 in stage 15.0 (TID 21)
19/07/31 17:06:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:13 INFO Executor: Finished task 2.0 in stage 15.0 (TID 23). 2390 bytes result sent to driver
19/07/31 17:06:13 INFO Executor: Finished task 1.0 in stage 15.0 (TID 22). 2403 bytes result sent to driver
19/07/31 17:06:13 INFO Executor: Finished task 3.0 in stage 15.0 (TID 24). 2362 bytes result sent to driver
19/07/31 17:06:13 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 23) in 7 ms on localhost (executor driver) (1/4)
19/07/31 17:06:13 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 22) in 7 ms on localhost (executor driver) (2/4)
19/07/31 17:06:13 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 24) in 7 ms on localhost (executor driver) (3/4)
19/07/31 17:06:13 INFO Executor: Finished task 0.0 in stage 15.0 (TID 21). 2382 bytes result sent to driver
19/07/31 17:06:13 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 21) in 11 ms on localhost (executor driver) (4/4)
19/07/31 17:06:13 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/07/31 17:06:13 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:204) finished in 0.011 s
19/07/31 17:06:13 INFO DAGScheduler: Job 10 finished: collect at utils.scala:204, took 0.041454 s
19/07/31 17:06:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_025`) `dbplyr_026`
ORDER BY `date`) `dbplyr_027`) `dbplyr_028`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:13 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:13 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_029`) `dbplyr_030`
ORDER BY `date`) `dbplyr_031`) `dbplyr_032`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:13 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:13 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:13 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#736 - cust_prospect_ind.nullCount#735) > 0)
19/07/31 17:06:13 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#741 - visit_device_type.nullCount#740) > 0)
19/07/31 17:06:13 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#734 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#733))
19/07/31 17:06:13 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#739 <= All Devices) && (All Devices <= visit_device_type.upperBound#738))
19/07/31 17:06:13 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:13 INFO DAGScheduler: Got job 11 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:13 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:204)
19/07/31 17:06:13 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:13 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:13 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[59] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:13 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 72.1 KB, free 910.5 MB)
19/07/31 17:06:13 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.4 MB)
19/07/31 17:06:13 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:53890 (size: 30.4 KB, free: 911.9 MB)
19/07/31 17:06:13 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[59] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:13 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/07/31 17:06:13 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:13 INFO Executor: Running task 0.0 in stage 16.0 (TID 25)
19/07/31 17:06:13 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:13 INFO Executor: Finished task 0.0 in stage 16.0 (TID 25). 7542 bytes result sent to driver
19/07/31 17:06:13 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 25) in 14 ms on localhost (executor driver) (1/1)
19/07/31 17:06:13 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/07/31 17:06:13 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:204) finished in 0.014 s
19/07/31 17:06:13 INFO DAGScheduler: Job 11 finished: collect at utils.scala:204, took 0.026851 s
19/07/31 17:06:13 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:13 INFO DAGScheduler: Registering RDD 60 (collect at utils.scala:204)
19/07/31 17:06:13 INFO DAGScheduler: Got job 12 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:13 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:204)
19/07/31 17:06:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
19/07/31 17:06:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
19/07/31 17:06:13 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[60] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:13 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 74.5 KB, free 910.4 MB)
19/07/31 17:06:13 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.3 MB)
19/07/31 17:06:13 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:53890 (size: 31.7 KB, free: 911.9 MB)
19/07/31 17:06:13 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[60] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:13 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
19/07/31 17:06:13 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:13 INFO Executor: Running task 0.0 in stage 17.0 (TID 26)
19/07/31 17:06:13 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:13 INFO Executor: Finished task 0.0 in stage 17.0 (TID 26). 1730 bytes result sent to driver
19/07/31 17:06:13 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 26) in 14 ms on localhost (executor driver) (1/1)
19/07/31 17:06:13 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/07/31 17:06:13 INFO DAGScheduler: ShuffleMapStage 17 (collect at utils.scala:204) finished in 0.015 s
19/07/31 17:06:13 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:13 INFO DAGScheduler: running: Set()
19/07/31 17:06:13 INFO DAGScheduler: waiting: Set(ResultStage 18)
19/07/31 17:06:13 INFO DAGScheduler: failed: Set()
19/07/31 17:06:13 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[63] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:13 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 16.8 KB, free 910.3 MB)
19/07/31 17:06:13 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.3 MB)
19/07/31 17:06:13 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:06:13 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:13 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 18 (MapPartitionsRDD[63] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:13 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks
19/07/31 17:06:13 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 27, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:13 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 28, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:13 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 29, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:13 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 30, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:13 INFO Executor: Running task 2.0 in stage 18.0 (TID 29)
19/07/31 17:06:13 INFO Executor: Running task 3.0 in stage 18.0 (TID 30)
19/07/31 17:06:13 INFO Executor: Running task 1.0 in stage 18.0 (TID 28)
19/07/31 17:06:13 INFO Executor: Running task 0.0 in stage 18.0 (TID 27)
19/07/31 17:06:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:13 INFO Executor: Finished task 3.0 in stage 18.0 (TID 30). 2362 bytes result sent to driver
19/07/31 17:06:13 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 30) in 8 ms on localhost (executor driver) (1/4)
19/07/31 17:06:13 INFO Executor: Finished task 1.0 in stage 18.0 (TID 28). 2403 bytes result sent to driver
19/07/31 17:06:13 INFO Executor: Finished task 2.0 in stage 18.0 (TID 29). 2390 bytes result sent to driver
19/07/31 17:06:13 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 28) in 9 ms on localhost (executor driver) (2/4)
19/07/31 17:06:13 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 29) in 9 ms on localhost (executor driver) (3/4)
19/07/31 17:06:13 INFO Executor: Finished task 0.0 in stage 18.0 (TID 27). 2382 bytes result sent to driver
19/07/31 17:06:13 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 27) in 10 ms on localhost (executor driver) (4/4)
19/07/31 17:06:13 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/07/31 17:06:13 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:204) finished in 0.011 s
19/07/31 17:06:13 INFO DAGScheduler: Job 12 finished: collect at utils.scala:204, took 0.044466 s
19/07/31 17:06:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_033`) `dbplyr_034`
ORDER BY `date`) `dbplyr_035`) `dbplyr_036`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:13 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:13 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_037`) `dbplyr_038`
ORDER BY `date`) `dbplyr_039`) `dbplyr_040`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:13 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:13 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:14 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#834 - cust_prospect_ind.nullCount#833) > 0)
19/07/31 17:06:14 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#839 - visit_device_type.nullCount#838) > 0)
19/07/31 17:06:14 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#832 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#831))
19/07/31 17:06:14 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#837 <= All Devices) && (All Devices <= visit_device_type.upperBound#836))
19/07/31 17:06:14 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:14 INFO DAGScheduler: Got job 13 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:14 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:204)
19/07/31 17:06:14 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:14 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:14 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[68] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:14 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 72.1 KB, free 910.2 MB)
19/07/31 17:06:14 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.2 MB)
19/07/31 17:06:14 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:06:14 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[68] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:14 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/07/31 17:06:14 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:14 INFO Executor: Running task 0.0 in stage 19.0 (TID 31)
19/07/31 17:06:14 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:14 INFO Executor: Finished task 0.0 in stage 19.0 (TID 31). 7542 bytes result sent to driver
19/07/31 17:06:14 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 31) in 10 ms on localhost (executor driver) (1/1)
19/07/31 17:06:14 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/07/31 17:06:14 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:204) finished in 0.011 s
19/07/31 17:06:14 INFO DAGScheduler: Job 13 finished: collect at utils.scala:204, took 0.020511 s
19/07/31 17:06:14 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:14 INFO DAGScheduler: Registering RDD 69 (collect at utils.scala:204)
19/07/31 17:06:14 INFO DAGScheduler: Got job 14 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:14 INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:204)
19/07/31 17:06:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
19/07/31 17:06:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
19/07/31 17:06:14 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[69] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:14 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 74.5 KB, free 910.1 MB)
19/07/31 17:06:14 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.1 MB)
19/07/31 17:06:14 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:06:14 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[69] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:14 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/07/31 17:06:14 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:14 INFO Executor: Running task 0.0 in stage 20.0 (TID 32)
19/07/31 17:06:14 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:14 INFO Executor: Finished task 0.0 in stage 20.0 (TID 32). 1687 bytes result sent to driver
19/07/31 17:06:14 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 32) in 20 ms on localhost (executor driver) (1/1)
19/07/31 17:06:14 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/07/31 17:06:14 INFO DAGScheduler: ShuffleMapStage 20 (collect at utils.scala:204) finished in 0.020 s
19/07/31 17:06:14 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:14 INFO DAGScheduler: running: Set()
19/07/31 17:06:14 INFO DAGScheduler: waiting: Set(ResultStage 21)
19/07/31 17:06:14 INFO DAGScheduler: failed: Set()
19/07/31 17:06:14 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[72] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:14 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 16.8 KB, free 910.1 MB)
19/07/31 17:06:14 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.1 MB)
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 239
19/07/31 17:06:14 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:06:14 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:06:14 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 21 (MapPartitionsRDD[72] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:14 INFO TaskSchedulerImpl: Adding task set 21.0 with 4 tasks
19/07/31 17:06:14 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 33, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:14 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 34, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:14 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 35, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:14 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 36, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:14 INFO Executor: Running task 1.0 in stage 21.0 (TID 34)
19/07/31 17:06:14 INFO Executor: Running task 3.0 in stage 21.0 (TID 36)
19/07/31 17:06:14 INFO Executor: Running task 2.0 in stage 21.0 (TID 35)
19/07/31 17:06:14 INFO ContextCleaner: Cleaned shuffle 1
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 240
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 325
19/07/31 17:06:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:14 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:06:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 402
19/07/31 17:06:14 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 911.9 MB)
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 122
19/07/31 17:06:14 INFO Executor: Finished task 3.0 in stage 21.0 (TID 36). 2362 bytes result sent to driver
19/07/31 17:06:14 INFO Executor: Finished task 1.0 in stage 21.0 (TID 34). 2403 bytes result sent to driver
19/07/31 17:06:14 INFO Executor: Finished task 2.0 in stage 21.0 (TID 35). 2390 bytes result sent to driver
19/07/31 17:06:14 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 34) in 8 ms on localhost (executor driver) (1/4)
19/07/31 17:06:14 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 36) in 7 ms on localhost (executor driver) (2/4)
19/07/31 17:06:14 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:06:14 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 35) in 8 ms on localhost (executor driver) (3/4)
19/07/31 17:06:14 INFO Executor: Running task 0.0 in stage 21.0 (TID 33)
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 181
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 114
19/07/31 17:06:14 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:53890 in memory (size: 11.9 KB, free: 911.9 MB)
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 117
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 319
19/07/31 17:06:14 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 185
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 404
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 560
19/07/31 17:06:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:14 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 911.9 MB)
19/07/31 17:06:14 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 323
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 398
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 318
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 400
19/07/31 17:06:14 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 237
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 321
19/07/31 17:06:14 INFO Executor: Finished task 0.0 in stage 21.0 (TID 33). 2382 bytes result sent to driver
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 125
19/07/31 17:06:14 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 33) in 14 ms on localhost (executor driver) (4/4)
19/07/31 17:06:14 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/07/31 17:06:14 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:53890 in memory (size: 30.4 KB, free: 912.0 MB)
19/07/31 17:06:14 INFO DAGScheduler: ResultStage 21 (collect at utils.scala:204) finished in 0.014 s
19/07/31 17:06:14 INFO ContextCleaner: Cleaned shuffle 4
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 178
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 244
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 118
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 183
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 324
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 479
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 405
19/07/31 17:06:14 INFO DAGScheduler: Job 14 finished: collect at utils.scala:204, took 0.085694 s
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 182
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 119
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 175
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 317
19/07/31 17:06:14 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:53890 in memory (size: 11.8 KB, free: 912.0 MB)
19/07/31 17:06:14 INFO ContextCleaner: Cleaned shuffle 3
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 124
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 403
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 401
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 187
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 241
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 236
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 243
19/07/31 17:06:14 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:53890 in memory (size: 30.4 KB, free: 912.0 MB)
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 322
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 406
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 121
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 126
19/07/31 17:06:14 INFO ContextCleaner: Cleaned shuffle 2
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 115
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 180
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 177
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 120
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 186
19/07/31 17:06:14 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:53890 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 123
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 179
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 238
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 184
19/07/31 17:06:14 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:53890 in memory (size: 3.7 KB, free: 912.0 MB)
19/07/31 17:06:14 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:53890 in memory (size: 31.7 KB, free: 912.1 MB)
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 320
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 242
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 116
19/07/31 17:06:14 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:53890 in memory (size: 8.6 KB, free: 912.1 MB)
19/07/31 17:06:14 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 912.1 MB)
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 176
19/07/31 17:06:14 INFO ContextCleaner: Cleaned accumulator 399
19/07/31 17:06:14 INFO ContextCleaner: Cleaned shuffle 0
19/07/31 17:06:14 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:53890 in memory (size: 31.7 KB, free: 912.1 MB)
19/07/31 17:06:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_041`) `dbplyr_042`
ORDER BY `date`) `dbplyr_043`) `dbplyr_044`
WHERE ((`customer` = "All Visitors") AND (`device` = "Mobile Phone"))
19/07/31 17:06:14 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:14 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_045`) `dbplyr_046`
ORDER BY `date`) `dbplyr_047`) `dbplyr_048`
WHERE ((`customer` = "All Visitors") AND (`device` = "Mobile Phone"))
19/07/31 17:06:14 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:14 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:14 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#932 - cust_prospect_ind.nullCount#931) > 0)
19/07/31 17:06:14 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#937 - visit_device_type.nullCount#936) > 0)
19/07/31 17:06:14 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#930 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#929))
19/07/31 17:06:14 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#935 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#934))
19/07/31 17:06:14 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:14 INFO DAGScheduler: Got job 15 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:14 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:204)
19/07/31 17:06:14 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:14 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:14 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[77] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:14 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 72.1 KB, free 911.1 MB)
19/07/31 17:06:14 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.1 MB)
19/07/31 17:06:14 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:53890 (size: 30.4 KB, free: 912.1 MB)
19/07/31 17:06:14 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[77] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:14 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
19/07/31 17:06:14 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:14 INFO Executor: Running task 0.0 in stage 22.0 (TID 37)
19/07/31 17:06:14 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:14 INFO Executor: Finished task 0.0 in stage 22.0 (TID 37). 7542 bytes result sent to driver
19/07/31 17:06:14 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 37) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:06:14 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/07/31 17:06:14 INFO DAGScheduler: ResultStage 22 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:06:14 INFO DAGScheduler: Job 15 finished: collect at utils.scala:204, took 0.015381 s
19/07/31 17:06:14 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:14 INFO DAGScheduler: Registering RDD 78 (collect at utils.scala:204)
19/07/31 17:06:14 INFO DAGScheduler: Got job 16 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:14 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:204)
19/07/31 17:06:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
19/07/31 17:06:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 23)
19/07/31 17:06:14 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[78] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:14 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 74.6 KB, free 911.0 MB)
19/07/31 17:06:14 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 31.7 KB, free 911.0 MB)
19/07/31 17:06:14 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:53890 (size: 31.7 KB, free: 912.1 MB)
19/07/31 17:06:14 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[78] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:14 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
19/07/31 17:06:14 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:14 INFO Executor: Running task 0.0 in stage 23.0 (TID 38)
19/07/31 17:06:14 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:14 INFO Executor: Finished task 0.0 in stage 23.0 (TID 38). 1730 bytes result sent to driver
19/07/31 17:06:14 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 38) in 11 ms on localhost (executor driver) (1/1)
19/07/31 17:06:14 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
19/07/31 17:06:14 INFO DAGScheduler: ShuffleMapStage 23 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:06:14 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:14 INFO DAGScheduler: running: Set()
19/07/31 17:06:14 INFO DAGScheduler: waiting: Set(ResultStage 24)
19/07/31 17:06:14 INFO DAGScheduler: failed: Set()
19/07/31 17:06:14 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[81] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:14 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 16.8 KB, free 911.0 MB)
19/07/31 17:06:14 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.0 MB)
19/07/31 17:06:14 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:06:14 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[81] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:14 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks
19/07/31 17:06:14 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 39, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:14 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 40, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:14 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 41, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:14 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 42, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:14 INFO Executor: Running task 0.0 in stage 24.0 (TID 39)
19/07/31 17:06:14 INFO Executor: Running task 1.0 in stage 24.0 (TID 40)
19/07/31 17:06:14 INFO Executor: Running task 3.0 in stage 24.0 (TID 42)
19/07/31 17:06:14 INFO Executor: Running task 2.0 in stage 24.0 (TID 41)
19/07/31 17:06:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:14 INFO Executor: Finished task 1.0 in stage 24.0 (TID 40). 2383 bytes result sent to driver
19/07/31 17:06:14 INFO Executor: Finished task 2.0 in stage 24.0 (TID 41). 2372 bytes result sent to driver
19/07/31 17:06:14 INFO Executor: Finished task 3.0 in stage 24.0 (TID 42). 2358 bytes result sent to driver
19/07/31 17:06:14 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 40) in 7 ms on localhost (executor driver) (1/4)
19/07/31 17:06:14 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 41) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:06:14 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 42) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:06:14 INFO Executor: Finished task 0.0 in stage 24.0 (TID 39). 2385 bytes result sent to driver
19/07/31 17:06:14 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 39) in 8 ms on localhost (executor driver) (4/4)
19/07/31 17:06:14 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
19/07/31 17:06:14 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:06:14 INFO DAGScheduler: Job 16 finished: collect at utils.scala:204, took 0.030815 s
19/07/31 17:06:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_049`) `dbplyr_050`
ORDER BY `date`) `dbplyr_051`) `dbplyr_052`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:14 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:14 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_053`) `dbplyr_054`
ORDER BY `date`) `dbplyr_055`) `dbplyr_056`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:14 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:14 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:14 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1030 - cust_prospect_ind.nullCount#1029) > 0)
19/07/31 17:06:14 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1035 - visit_device_type.nullCount#1034) > 0)
19/07/31 17:06:14 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#1028 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#1027))
19/07/31 17:06:14 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#1033 <= All Devices) && (All Devices <= visit_device_type.upperBound#1032))
19/07/31 17:06:15 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:15 INFO DAGScheduler: Got job 17 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:15 INFO DAGScheduler: Final stage: ResultStage 25 (collect at utils.scala:204)
19/07/31 17:06:15 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:15 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:15 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[86] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:15 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 72.1 KB, free 910.9 MB)
19/07/31 17:06:15 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.9 MB)
19/07/31 17:06:15 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:53890 (size: 30.4 KB, free: 912.0 MB)
19/07/31 17:06:15 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[86] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:15 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
19/07/31 17:06:15 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:15 INFO Executor: Running task 0.0 in stage 25.0 (TID 43)
19/07/31 17:06:15 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:15 INFO Executor: Finished task 0.0 in stage 25.0 (TID 43). 7585 bytes result sent to driver
19/07/31 17:06:15 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 43) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:06:15 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
19/07/31 17:06:15 INFO DAGScheduler: ResultStage 25 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:06:15 INFO DAGScheduler: Job 17 finished: collect at utils.scala:204, took 0.016021 s
19/07/31 17:06:15 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:15 INFO DAGScheduler: Registering RDD 87 (collect at utils.scala:204)
19/07/31 17:06:15 INFO DAGScheduler: Got job 18 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:15 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:204)
19/07/31 17:06:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
19/07/31 17:06:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 26)
19/07/31 17:06:15 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[87] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:15 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 74.5 KB, free 910.8 MB)
19/07/31 17:06:15 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.8 MB)
19/07/31 17:06:15 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:06:15 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[87] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:15 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
19/07/31 17:06:15 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:15 INFO Executor: Running task 0.0 in stage 26.0 (TID 44)
19/07/31 17:06:15 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:15 INFO Executor: Finished task 0.0 in stage 26.0 (TID 44). 1687 bytes result sent to driver
19/07/31 17:06:15 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 44) in 11 ms on localhost (executor driver) (1/1)
19/07/31 17:06:15 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
19/07/31 17:06:15 INFO DAGScheduler: ShuffleMapStage 26 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:06:15 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:15 INFO DAGScheduler: running: Set()
19/07/31 17:06:15 INFO DAGScheduler: waiting: Set(ResultStage 27)
19/07/31 17:06:15 INFO DAGScheduler: failed: Set()
19/07/31 17:06:15 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[90] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:15 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 16.8 KB, free 910.8 MB)
19/07/31 17:06:15 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.8 MB)
19/07/31 17:06:15 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:06:15 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:15 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 27 (MapPartitionsRDD[90] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:15 INFO TaskSchedulerImpl: Adding task set 27.0 with 4 tasks
19/07/31 17:06:15 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 45, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:15 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 46, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:15 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 47, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:15 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 48, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:15 INFO Executor: Running task 2.0 in stage 27.0 (TID 47)
19/07/31 17:06:15 INFO Executor: Running task 1.0 in stage 27.0 (TID 46)
19/07/31 17:06:15 INFO Executor: Running task 3.0 in stage 27.0 (TID 48)
19/07/31 17:06:15 INFO Executor: Running task 0.0 in stage 27.0 (TID 45)
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:15 INFO Executor: Finished task 2.0 in stage 27.0 (TID 47). 2390 bytes result sent to driver
19/07/31 17:06:15 INFO Executor: Finished task 3.0 in stage 27.0 (TID 48). 2362 bytes result sent to driver
19/07/31 17:06:15 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 47) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:06:15 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 48) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:06:15 INFO Executor: Finished task 0.0 in stage 27.0 (TID 45). 2382 bytes result sent to driver
19/07/31 17:06:15 INFO Executor: Finished task 1.0 in stage 27.0 (TID 46). 2403 bytes result sent to driver
19/07/31 17:06:15 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 45) in 8 ms on localhost (executor driver) (3/4)
19/07/31 17:06:15 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 46) in 7 ms on localhost (executor driver) (4/4)
19/07/31 17:06:15 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
19/07/31 17:06:15 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:06:15 INFO DAGScheduler: Job 18 finished: collect at utils.scala:204, took 0.032635 s
19/07/31 17:06:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_057`) `dbplyr_058`
ORDER BY `date`) `dbplyr_059`) `dbplyr_060`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:15 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_061`) `dbplyr_062`
ORDER BY `date`) `dbplyr_063`) `dbplyr_064`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:15 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:15 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1128 - cust_prospect_ind.nullCount#1127) > 0)
19/07/31 17:06:15 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1133 - visit_device_type.nullCount#1132) > 0)
19/07/31 17:06:15 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#1126 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#1125))
19/07/31 17:06:15 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#1131 <= All Devices) && (All Devices <= visit_device_type.upperBound#1130))
19/07/31 17:06:15 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:15 INFO DAGScheduler: Got job 19 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:15 INFO DAGScheduler: Final stage: ResultStage 28 (collect at utils.scala:204)
19/07/31 17:06:15 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:15 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:15 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[95] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:15 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 72.1 KB, free 910.7 MB)
19/07/31 17:06:15 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.7 MB)
19/07/31 17:06:15 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:06:15 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[95] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:15 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
19/07/31 17:06:15 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:15 INFO Executor: Running task 0.0 in stage 28.0 (TID 49)
19/07/31 17:06:15 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:15 INFO Executor: Finished task 0.0 in stage 28.0 (TID 49). 7542 bytes result sent to driver
19/07/31 17:06:15 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 49) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:06:15 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
19/07/31 17:06:15 INFO DAGScheduler: ResultStage 28 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:06:15 INFO DAGScheduler: Job 19 finished: collect at utils.scala:204, took 0.014833 s
19/07/31 17:06:15 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:15 INFO DAGScheduler: Registering RDD 96 (collect at utils.scala:204)
19/07/31 17:06:15 INFO DAGScheduler: Got job 20 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:15 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:204)
19/07/31 17:06:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
19/07/31 17:06:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 29)
19/07/31 17:06:15 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[96] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:15 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 74.5 KB, free 910.6 MB)
19/07/31 17:06:15 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.6 MB)
19/07/31 17:06:15 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.9 MB)
19/07/31 17:06:15 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[96] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:15 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
19/07/31 17:06:15 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:15 INFO Executor: Running task 0.0 in stage 29.0 (TID 50)
19/07/31 17:06:15 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:15 INFO Executor: Finished task 0.0 in stage 29.0 (TID 50). 1687 bytes result sent to driver
19/07/31 17:06:15 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 50) in 13 ms on localhost (executor driver) (1/1)
19/07/31 17:06:15 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
19/07/31 17:06:15 INFO DAGScheduler: ShuffleMapStage 29 (collect at utils.scala:204) finished in 0.014 s
19/07/31 17:06:15 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:15 INFO DAGScheduler: running: Set()
19/07/31 17:06:15 INFO DAGScheduler: waiting: Set(ResultStage 30)
19/07/31 17:06:15 INFO DAGScheduler: failed: Set()
19/07/31 17:06:15 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[99] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:15 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 16.8 KB, free 910.5 MB)
19/07/31 17:06:15 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.5 MB)
19/07/31 17:06:15 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:06:15 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:15 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 30 (MapPartitionsRDD[99] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:15 INFO TaskSchedulerImpl: Adding task set 30.0 with 4 tasks
19/07/31 17:06:15 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 51, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:15 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 52, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:15 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 53, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:15 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 54, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:15 INFO Executor: Running task 0.0 in stage 30.0 (TID 51)
19/07/31 17:06:15 INFO Executor: Running task 2.0 in stage 30.0 (TID 53)
19/07/31 17:06:15 INFO Executor: Running task 3.0 in stage 30.0 (TID 54)
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:15 INFO Executor: Finished task 3.0 in stage 30.0 (TID 54). 2362 bytes result sent to driver
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:15 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 54) in 7 ms on localhost (executor driver) (1/4)
19/07/31 17:06:15 INFO Executor: Running task 1.0 in stage 30.0 (TID 52)
19/07/31 17:06:15 INFO Executor: Finished task 0.0 in stage 30.0 (TID 51). 2382 bytes result sent to driver
19/07/31 17:06:15 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 51) in 9 ms on localhost (executor driver) (2/4)
19/07/31 17:06:15 INFO Executor: Finished task 2.0 in stage 30.0 (TID 53). 2390 bytes result sent to driver
19/07/31 17:06:15 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 53) in 10 ms on localhost (executor driver) (3/4)
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:15 INFO Executor: Finished task 1.0 in stage 30.0 (TID 52). 2403 bytes result sent to driver
19/07/31 17:06:15 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 52) in 14 ms on localhost (executor driver) (4/4)
19/07/31 17:06:15 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
19/07/31 17:06:15 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:204) finished in 0.015 s
19/07/31 17:06:15 INFO DAGScheduler: Job 20 finished: collect at utils.scala:204, took 0.040823 s
19/07/31 17:06:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_065`) `dbplyr_066`
ORDER BY `date`) `dbplyr_067`) `dbplyr_068`
WHERE ((`customer` = "All Visitors") AND (`device` = "Desktop"))
19/07/31 17:06:15 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_069`) `dbplyr_070`
ORDER BY `date`) `dbplyr_071`) `dbplyr_072`
WHERE ((`customer` = "All Visitors") AND (`device` = "Desktop"))
19/07/31 17:06:15 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:15 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:15 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1226 - cust_prospect_ind.nullCount#1225) > 0)
19/07/31 17:06:15 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1231 - visit_device_type.nullCount#1230) > 0)
19/07/31 17:06:15 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#1224 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#1223))
19/07/31 17:06:15 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#1229 <= Desktop) && (Desktop <= visit_device_type.upperBound#1228))
19/07/31 17:06:15 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:15 INFO DAGScheduler: Got job 21 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:15 INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:204)
19/07/31 17:06:15 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:15 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:15 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[104] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:15 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 72.1 KB, free 910.5 MB)
19/07/31 17:06:15 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.4 MB)
19/07/31 17:06:15 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:53890 (size: 30.4 KB, free: 911.9 MB)
19/07/31 17:06:15 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[104] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:15 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
19/07/31 17:06:15 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:15 INFO Executor: Running task 0.0 in stage 31.0 (TID 55)
19/07/31 17:06:15 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:15 INFO Executor: Finished task 0.0 in stage 31.0 (TID 55). 7068 bytes result sent to driver
19/07/31 17:06:15 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 55) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:06:15 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
19/07/31 17:06:15 INFO DAGScheduler: ResultStage 31 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:06:15 INFO DAGScheduler: Job 21 finished: collect at utils.scala:204, took 0.012236 s
19/07/31 17:06:15 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:15 INFO DAGScheduler: Registering RDD 105 (collect at utils.scala:204)
19/07/31 17:06:15 INFO DAGScheduler: Got job 22 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:15 INFO DAGScheduler: Final stage: ResultStage 33 (collect at utils.scala:204)
19/07/31 17:06:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)
19/07/31 17:06:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 32)
19/07/31 17:06:15 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[105] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:15 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 74.5 KB, free 910.4 MB)
19/07/31 17:06:15 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.3 MB)
19/07/31 17:06:15 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:53890 (size: 31.7 KB, free: 911.9 MB)
19/07/31 17:06:15 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[105] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:15 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
19/07/31 17:06:15 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:15 INFO Executor: Running task 0.0 in stage 32.0 (TID 56)
19/07/31 17:06:15 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:15 INFO Executor: Finished task 0.0 in stage 32.0 (TID 56). 1687 bytes result sent to driver
19/07/31 17:06:15 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 56) in 10 ms on localhost (executor driver) (1/1)
19/07/31 17:06:15 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
19/07/31 17:06:15 INFO DAGScheduler: ShuffleMapStage 32 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:06:15 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:15 INFO DAGScheduler: running: Set()
19/07/31 17:06:15 INFO DAGScheduler: waiting: Set(ResultStage 33)
19/07/31 17:06:15 INFO DAGScheduler: failed: Set()
19/07/31 17:06:15 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[108] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:15 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 16.8 KB, free 910.3 MB)
19/07/31 17:06:15 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 8.1 KB, free 910.3 MB)
19/07/31 17:06:15 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:53890 (size: 8.1 KB, free: 911.9 MB)
19/07/31 17:06:15 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:15 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 33 (MapPartitionsRDD[108] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:15 INFO TaskSchedulerImpl: Adding task set 33.0 with 4 tasks
19/07/31 17:06:15 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 57, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:15 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 58, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:15 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 59, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:15 INFO TaskSetManager: Starting task 3.0 in stage 33.0 (TID 60, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:15 INFO Executor: Running task 0.0 in stage 33.0 (TID 57)
19/07/31 17:06:15 INFO Executor: Running task 1.0 in stage 33.0 (TID 58)
19/07/31 17:06:15 INFO Executor: Running task 3.0 in stage 33.0 (TID 60)
19/07/31 17:06:15 INFO Executor: Running task 2.0 in stage 33.0 (TID 59)
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:15 INFO Executor: Finished task 1.0 in stage 33.0 (TID 58). 2385 bytes result sent to driver
19/07/31 17:06:15 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 58) in 6 ms on localhost (executor driver) (1/4)
19/07/31 17:06:15 INFO Executor: Finished task 3.0 in stage 33.0 (TID 60). 2356 bytes result sent to driver
19/07/31 17:06:15 INFO Executor: Finished task 0.0 in stage 33.0 (TID 57). 2381 bytes result sent to driver
19/07/31 17:06:15 INFO Executor: Finished task 2.0 in stage 33.0 (TID 59). 2380 bytes result sent to driver
19/07/31 17:06:15 INFO TaskSetManager: Finished task 3.0 in stage 33.0 (TID 60) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:06:15 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 59) in 7 ms on localhost (executor driver) (3/4)
19/07/31 17:06:15 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 57) in 7 ms on localhost (executor driver) (4/4)
19/07/31 17:06:15 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
19/07/31 17:06:15 INFO DAGScheduler: ResultStage 33 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:15 INFO DAGScheduler: Job 22 finished: collect at utils.scala:204, took 0.029151 s
19/07/31 17:06:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_073`) `dbplyr_074`
ORDER BY `date`) `dbplyr_075`) `dbplyr_076`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:16 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:16 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_077`) `dbplyr_078`
ORDER BY `date`) `dbplyr_079`) `dbplyr_080`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:16 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:16 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:16 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1324 - cust_prospect_ind.nullCount#1323) > 0)
19/07/31 17:06:16 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1329 - visit_device_type.nullCount#1328) > 0)
19/07/31 17:06:16 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#1322 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#1321))
19/07/31 17:06:16 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#1327 <= All Devices) && (All Devices <= visit_device_type.upperBound#1326))
19/07/31 17:06:16 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:16 INFO DAGScheduler: Got job 23 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:16 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:204)
19/07/31 17:06:16 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:16 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:16 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[113] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:16 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 72.1 KB, free 910.2 MB)
19/07/31 17:06:16 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.2 MB)
19/07/31 17:06:16 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:06:16 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[113] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:16 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
19/07/31 17:06:16 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:16 INFO Executor: Running task 0.0 in stage 34.0 (TID 61)
19/07/31 17:06:16 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:16 INFO Executor: Finished task 0.0 in stage 34.0 (TID 61). 7542 bytes result sent to driver
19/07/31 17:06:16 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 61) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:06:16 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
19/07/31 17:06:16 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:16 INFO DAGScheduler: Job 23 finished: collect at utils.scala:204, took 0.013784 s
19/07/31 17:06:16 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:16 INFO DAGScheduler: Registering RDD 114 (collect at utils.scala:204)
19/07/31 17:06:16 INFO DAGScheduler: Got job 24 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:16 INFO DAGScheduler: Final stage: ResultStage 36 (collect at utils.scala:204)
19/07/31 17:06:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
19/07/31 17:06:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 35)
19/07/31 17:06:16 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[114] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:16 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 74.5 KB, free 910.1 MB)
19/07/31 17:06:16 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.1 MB)
19/07/31 17:06:16 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:06:16 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[114] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:16 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
19/07/31 17:06:16 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:16 INFO Executor: Running task 0.0 in stage 35.0 (TID 62)
19/07/31 17:06:16 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:16 INFO Executor: Finished task 0.0 in stage 35.0 (TID 62). 1687 bytes result sent to driver
19/07/31 17:06:16 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 62) in 10 ms on localhost (executor driver) (1/1)
19/07/31 17:06:16 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
19/07/31 17:06:16 INFO DAGScheduler: ShuffleMapStage 35 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:06:16 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:16 INFO DAGScheduler: running: Set()
19/07/31 17:06:16 INFO DAGScheduler: waiting: Set(ResultStage 36)
19/07/31 17:06:16 INFO DAGScheduler: failed: Set()
19/07/31 17:06:16 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[117] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:16 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 16.8 KB, free 910.1 MB)
19/07/31 17:06:16 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.1 MB)
19/07/31 17:06:16 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:06:16 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:16 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 36 (MapPartitionsRDD[117] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:16 INFO TaskSchedulerImpl: Adding task set 36.0 with 4 tasks
19/07/31 17:06:16 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 63, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:16 INFO TaskSetManager: Starting task 1.0 in stage 36.0 (TID 64, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:16 INFO TaskSetManager: Starting task 2.0 in stage 36.0 (TID 65, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:16 INFO TaskSetManager: Starting task 3.0 in stage 36.0 (TID 66, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:16 INFO Executor: Running task 1.0 in stage 36.0 (TID 64)
19/07/31 17:06:16 INFO Executor: Running task 2.0 in stage 36.0 (TID 65)
19/07/31 17:06:16 INFO Executor: Running task 3.0 in stage 36.0 (TID 66)
19/07/31 17:06:16 INFO Executor: Running task 0.0 in stage 36.0 (TID 63)
19/07/31 17:06:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:16 INFO Executor: Finished task 2.0 in stage 36.0 (TID 65). 2390 bytes result sent to driver
19/07/31 17:06:16 INFO Executor: Finished task 0.0 in stage 36.0 (TID 63). 2382 bytes result sent to driver
19/07/31 17:06:16 INFO Executor: Finished task 3.0 in stage 36.0 (TID 66). 2362 bytes result sent to driver
19/07/31 17:06:16 INFO Executor: Finished task 1.0 in stage 36.0 (TID 64). 2403 bytes result sent to driver
19/07/31 17:06:16 INFO TaskSetManager: Finished task 2.0 in stage 36.0 (TID 65) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:06:16 INFO TaskSetManager: Finished task 3.0 in stage 36.0 (TID 66) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:06:16 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 63) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:06:16 INFO TaskSetManager: Finished task 1.0 in stage 36.0 (TID 64) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:06:16 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
19/07/31 17:06:16 INFO DAGScheduler: ResultStage 36 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:06:16 INFO DAGScheduler: Job 24 finished: collect at utils.scala:204, took 0.026970 s
19/07/31 17:06:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_081`) `dbplyr_082`
ORDER BY `date`) `dbplyr_083`) `dbplyr_084`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:16 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:16 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_085`) `dbplyr_086`
ORDER BY `date`) `dbplyr_087`) `dbplyr_088`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:16 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:16 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:16 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1422 - cust_prospect_ind.nullCount#1421) > 0)
19/07/31 17:06:16 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1427 - visit_device_type.nullCount#1426) > 0)
19/07/31 17:06:16 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#1420 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#1419))
19/07/31 17:06:16 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#1425 <= All Devices) && (All Devices <= visit_device_type.upperBound#1424))
19/07/31 17:06:16 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:16 INFO DAGScheduler: Got job 25 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:16 INFO DAGScheduler: Final stage: ResultStage 37 (collect at utils.scala:204)
19/07/31 17:06:16 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:16 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:16 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[122] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:16 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 72.1 KB, free 910.0 MB)
19/07/31 17:06:16 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.0 MB)
19/07/31 17:06:16 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:06:16 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[122] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:16 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
19/07/31 17:06:16 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:16 INFO Executor: Running task 0.0 in stage 37.0 (TID 67)
19/07/31 17:06:16 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:16 INFO Executor: Finished task 0.0 in stage 37.0 (TID 67). 7542 bytes result sent to driver
19/07/31 17:06:16 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 67) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:06:16 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
19/07/31 17:06:16 INFO DAGScheduler: ResultStage 37 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:06:16 INFO DAGScheduler: Job 25 finished: collect at utils.scala:204, took 0.013333 s
19/07/31 17:06:16 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:16 INFO DAGScheduler: Registering RDD 123 (collect at utils.scala:204)
19/07/31 17:06:16 INFO DAGScheduler: Got job 26 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:16 INFO DAGScheduler: Final stage: ResultStage 39 (collect at utils.scala:204)
19/07/31 17:06:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)
19/07/31 17:06:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 38)
19/07/31 17:06:16 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[123] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:16 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 74.5 KB, free 909.9 MB)
19/07/31 17:06:16 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.9 MB)
19/07/31 17:06:16 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.7 MB)
19/07/31 17:06:16 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[123] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:16 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
19/07/31 17:06:16 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:16 INFO Executor: Running task 0.0 in stage 38.0 (TID 68)
19/07/31 17:06:16 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:16 INFO Executor: Finished task 0.0 in stage 38.0 (TID 68). 1687 bytes result sent to driver
19/07/31 17:06:16 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 68) in 11 ms on localhost (executor driver) (1/1)
19/07/31 17:06:16 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
19/07/31 17:06:16 INFO DAGScheduler: ShuffleMapStage 38 (collect at utils.scala:204) finished in 0.011 s
19/07/31 17:06:16 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:16 INFO DAGScheduler: running: Set()
19/07/31 17:06:16 INFO DAGScheduler: waiting: Set(ResultStage 39)
19/07/31 17:06:16 INFO DAGScheduler: failed: Set()
19/07/31 17:06:16 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[126] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:16 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 16.8 KB, free 909.9 MB)
19/07/31 17:06:16 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.8 MB)
19/07/31 17:06:16 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:06:16 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:16 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 39 (MapPartitionsRDD[126] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:16 INFO TaskSchedulerImpl: Adding task set 39.0 with 4 tasks
19/07/31 17:06:16 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 69, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:16 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 70, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:16 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 71, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:16 INFO TaskSetManager: Starting task 3.0 in stage 39.0 (TID 72, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:16 INFO Executor: Running task 2.0 in stage 39.0 (TID 71)
19/07/31 17:06:16 INFO Executor: Running task 3.0 in stage 39.0 (TID 72)
19/07/31 17:06:16 INFO Executor: Running task 0.0 in stage 39.0 (TID 69)
19/07/31 17:06:16 INFO Executor: Running task 1.0 in stage 39.0 (TID 70)
19/07/31 17:06:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:16 INFO Executor: Finished task 1.0 in stage 39.0 (TID 70). 2403 bytes result sent to driver
19/07/31 17:06:16 INFO Executor: Finished task 2.0 in stage 39.0 (TID 71). 2390 bytes result sent to driver
19/07/31 17:06:16 INFO Executor: Finished task 3.0 in stage 39.0 (TID 72). 2362 bytes result sent to driver
19/07/31 17:06:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:16 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 70) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:06:16 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 71) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:06:16 INFO TaskSetManager: Finished task 3.0 in stage 39.0 (TID 72) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:06:16 INFO Executor: Finished task 0.0 in stage 39.0 (TID 69). 2382 bytes result sent to driver
19/07/31 17:06:16 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 69) in 7 ms on localhost (executor driver) (4/4)
19/07/31 17:06:16 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
19/07/31 17:06:16 INFO DAGScheduler: ResultStage 39 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:06:16 INFO DAGScheduler: Job 26 finished: collect at utils.scala:204, took 0.031459 s
19/07/31 17:06:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_089`) `dbplyr_090`
ORDER BY `date`) `dbplyr_091`) `dbplyr_092`
WHERE ((`customer` = "All Visitors") AND (`device` = "Tablet"))
19/07/31 17:06:16 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:16 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_093`) `dbplyr_094`
ORDER BY `date`) `dbplyr_095`) `dbplyr_096`
WHERE ((`customer` = "All Visitors") AND (`device` = "Tablet"))
19/07/31 17:06:16 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:16 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:17 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1520 - cust_prospect_ind.nullCount#1519) > 0)
19/07/31 17:06:17 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1525 - visit_device_type.nullCount#1524) > 0)
19/07/31 17:06:17 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#1518 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#1517))
19/07/31 17:06:17 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#1523 <= Tablet) && (Tablet <= visit_device_type.upperBound#1522))
19/07/31 17:06:17 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:17 INFO DAGScheduler: Got job 27 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:17 INFO DAGScheduler: Final stage: ResultStage 40 (collect at utils.scala:204)
19/07/31 17:06:17 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:17 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:17 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[131] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 72.1 KB, free 909.8 MB)
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 30.4 KB, free 909.7 MB)
19/07/31 17:06:17 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:53890 (size: 30.4 KB, free: 911.7 MB)
19/07/31 17:06:17 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[131] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:17 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
19/07/31 17:06:17 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:17 INFO Executor: Running task 0.0 in stage 40.0 (TID 73)
19/07/31 17:06:17 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:17 INFO Executor: Finished task 0.0 in stage 40.0 (TID 73). 7068 bytes result sent to driver
19/07/31 17:06:17 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 73) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:06:17 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
19/07/31 17:06:17 INFO DAGScheduler: ResultStage 40 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:17 INFO DAGScheduler: Job 27 finished: collect at utils.scala:204, took 0.012226 s
19/07/31 17:06:17 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:17 INFO DAGScheduler: Registering RDD 132 (collect at utils.scala:204)
19/07/31 17:06:17 INFO DAGScheduler: Got job 28 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:17 INFO DAGScheduler: Final stage: ResultStage 42 (collect at utils.scala:204)
19/07/31 17:06:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
19/07/31 17:06:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
19/07/31 17:06:17 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[132] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 74.5 KB, free 909.7 MB)
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 31.7 KB, free 909.6 MB)
19/07/31 17:06:17 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:53890 (size: 31.7 KB, free: 911.7 MB)
19/07/31 17:06:17 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[132] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:17 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
19/07/31 17:06:17 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 74, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:17 INFO Executor: Running task 0.0 in stage 41.0 (TID 74)
19/07/31 17:06:17 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:17 INFO Executor: Finished task 0.0 in stage 41.0 (TID 74). 1687 bytes result sent to driver
19/07/31 17:06:17 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 74) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:06:17 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
19/07/31 17:06:17 INFO DAGScheduler: ShuffleMapStage 41 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:06:17 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:17 INFO DAGScheduler: running: Set()
19/07/31 17:06:17 INFO DAGScheduler: waiting: Set(ResultStage 42)
19/07/31 17:06:17 INFO DAGScheduler: failed: Set()
19/07/31 17:06:17 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[135] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 16.8 KB, free 909.6 MB)
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.6 MB)
19/07/31 17:06:17 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:06:17 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:17 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 42 (MapPartitionsRDD[135] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:17 INFO TaskSchedulerImpl: Adding task set 42.0 with 4 tasks
19/07/31 17:06:17 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 75, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:17 INFO TaskSetManager: Starting task 1.0 in stage 42.0 (TID 76, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:17 INFO TaskSetManager: Starting task 2.0 in stage 42.0 (TID 77, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:17 INFO TaskSetManager: Starting task 3.0 in stage 42.0 (TID 78, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:17 INFO Executor: Running task 3.0 in stage 42.0 (TID 78)
19/07/31 17:06:17 INFO Executor: Running task 0.0 in stage 42.0 (TID 75)
19/07/31 17:06:17 INFO Executor: Running task 2.0 in stage 42.0 (TID 77)
19/07/31 17:06:17 INFO Executor: Running task 1.0 in stage 42.0 (TID 76)
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:17 INFO Executor: Finished task 3.0 in stage 42.0 (TID 78). 2337 bytes result sent to driver
19/07/31 17:06:17 INFO Executor: Finished task 0.0 in stage 42.0 (TID 75). 2363 bytes result sent to driver
19/07/31 17:06:17 INFO Executor: Finished task 2.0 in stage 42.0 (TID 77). 2362 bytes result sent to driver
19/07/31 17:06:17 INFO Executor: Finished task 1.0 in stage 42.0 (TID 76). 2361 bytes result sent to driver
19/07/31 17:06:17 INFO TaskSetManager: Finished task 3.0 in stage 42.0 (TID 78) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:06:17 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 75) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:06:17 INFO TaskSetManager: Finished task 2.0 in stage 42.0 (TID 77) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:06:17 INFO TaskSetManager: Finished task 1.0 in stage 42.0 (TID 76) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:06:17 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
19/07/31 17:06:17 INFO DAGScheduler: ResultStage 42 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:17 INFO DAGScheduler: Job 28 finished: collect at utils.scala:204, took 0.025583 s
19/07/31 17:06:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_097`) `dbplyr_098`
ORDER BY `date`) `dbplyr_099`) `dbplyr_100`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:17 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:17 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_101`) `dbplyr_102`
ORDER BY `date`) `dbplyr_103`) `dbplyr_104`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:17 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:17 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:17 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1618 - cust_prospect_ind.nullCount#1617) > 0)
19/07/31 17:06:17 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1623 - visit_device_type.nullCount#1622) > 0)
19/07/31 17:06:17 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#1616 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#1615))
19/07/31 17:06:17 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#1621 <= All Devices) && (All Devices <= visit_device_type.upperBound#1620))
19/07/31 17:06:17 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:17 INFO DAGScheduler: Got job 29 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:17 INFO DAGScheduler: Final stage: ResultStage 43 (collect at utils.scala:204)
19/07/31 17:06:17 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:17 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:17 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[140] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 72.1 KB, free 909.5 MB)
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.5 MB)
19/07/31 17:06:17 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 911.6 MB)
19/07/31 17:06:17 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[140] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:17 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
19/07/31 17:06:17 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 79, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:17 INFO Executor: Running task 0.0 in stage 43.0 (TID 79)
19/07/31 17:06:17 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:17 INFO Executor: Finished task 0.0 in stage 43.0 (TID 79). 7542 bytes result sent to driver
19/07/31 17:06:17 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 79) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:06:17 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
19/07/31 17:06:17 INFO DAGScheduler: ResultStage 43 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:17 INFO DAGScheduler: Job 29 finished: collect at utils.scala:204, took 0.012366 s
19/07/31 17:06:17 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:17 INFO DAGScheduler: Registering RDD 141 (collect at utils.scala:204)
19/07/31 17:06:17 INFO DAGScheduler: Got job 30 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:17 INFO DAGScheduler: Final stage: ResultStage 45 (collect at utils.scala:204)
19/07/31 17:06:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
19/07/31 17:06:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 44)
19/07/31 17:06:17 INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[141] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 74.5 KB, free 909.4 MB)
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.4 MB)
19/07/31 17:06:17 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.6 MB)
19/07/31 17:06:17 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[141] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:17 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
19/07/31 17:06:17 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 80, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:17 INFO Executor: Running task 0.0 in stage 44.0 (TID 80)
19/07/31 17:06:17 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:17 INFO Executor: Finished task 0.0 in stage 44.0 (TID 80). 1687 bytes result sent to driver
19/07/31 17:06:17 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 80) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:06:17 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
19/07/31 17:06:17 INFO DAGScheduler: ShuffleMapStage 44 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:06:17 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:17 INFO DAGScheduler: running: Set()
19/07/31 17:06:17 INFO DAGScheduler: waiting: Set(ResultStage 45)
19/07/31 17:06:17 INFO DAGScheduler: failed: Set()
19/07/31 17:06:17 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[144] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 16.8 KB, free 909.4 MB)
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.4 MB)
19/07/31 17:06:17 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.6 MB)
19/07/31 17:06:17 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:17 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 45 (MapPartitionsRDD[144] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:17 INFO TaskSchedulerImpl: Adding task set 45.0 with 4 tasks
19/07/31 17:06:17 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 81, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:17 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 82, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:17 INFO TaskSetManager: Starting task 2.0 in stage 45.0 (TID 83, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:17 INFO TaskSetManager: Starting task 3.0 in stage 45.0 (TID 84, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:17 INFO Executor: Running task 1.0 in stage 45.0 (TID 82)
19/07/31 17:06:17 INFO Executor: Running task 2.0 in stage 45.0 (TID 83)
19/07/31 17:06:17 INFO Executor: Running task 0.0 in stage 45.0 (TID 81)
19/07/31 17:06:17 INFO Executor: Running task 3.0 in stage 45.0 (TID 84)
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:17 INFO Executor: Finished task 0.0 in stage 45.0 (TID 81). 2339 bytes result sent to driver
19/07/31 17:06:17 INFO Executor: Finished task 3.0 in stage 45.0 (TID 84). 2362 bytes result sent to driver
19/07/31 17:06:17 INFO Executor: Finished task 2.0 in stage 45.0 (TID 83). 2347 bytes result sent to driver
19/07/31 17:06:17 INFO Executor: Finished task 1.0 in stage 45.0 (TID 82). 2360 bytes result sent to driver
19/07/31 17:06:17 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 81) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:06:17 INFO TaskSetManager: Finished task 3.0 in stage 45.0 (TID 84) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:06:17 INFO TaskSetManager: Finished task 2.0 in stage 45.0 (TID 83) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:06:17 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 82) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:06:17 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
19/07/31 17:06:17 INFO DAGScheduler: ResultStage 45 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:06:17 INFO DAGScheduler: Job 30 finished: collect at utils.scala:204, took 0.025940 s
19/07/31 17:06:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_105`) `dbplyr_106`
ORDER BY `date`) `dbplyr_107`) `dbplyr_108`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:17 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:17 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_109`) `dbplyr_110`
ORDER BY `date`) `dbplyr_111`) `dbplyr_112`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:17 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:17 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:17 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1716 - cust_prospect_ind.nullCount#1715) > 0)
19/07/31 17:06:17 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1721 - visit_device_type.nullCount#1720) > 0)
19/07/31 17:06:17 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#1714 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#1713))
19/07/31 17:06:17 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#1719 <= All Devices) && (All Devices <= visit_device_type.upperBound#1718))
19/07/31 17:06:17 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:17 INFO DAGScheduler: Got job 31 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:17 INFO DAGScheduler: Final stage: ResultStage 46 (collect at utils.scala:204)
19/07/31 17:06:17 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:17 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:17 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[149] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 72.1 KB, free 909.3 MB)
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 30.4 KB, free 909.3 MB)
19/07/31 17:06:17 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:53890 (size: 30.4 KB, free: 911.6 MB)
19/07/31 17:06:17 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[149] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:17 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
19/07/31 17:06:17 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:17 INFO Executor: Running task 0.0 in stage 46.0 (TID 85)
19/07/31 17:06:17 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:17 INFO Executor: Finished task 0.0 in stage 46.0 (TID 85). 7542 bytes result sent to driver
19/07/31 17:06:17 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 85) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:06:17 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
19/07/31 17:06:17 INFO DAGScheduler: ResultStage 46 (collect at utils.scala:204) finished in 0.004 s
19/07/31 17:06:17 INFO DAGScheduler: Job 31 finished: collect at utils.scala:204, took 0.010872 s
19/07/31 17:06:17 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:17 INFO DAGScheduler: Registering RDD 150 (collect at utils.scala:204)
19/07/31 17:06:17 INFO DAGScheduler: Got job 32 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:17 INFO DAGScheduler: Final stage: ResultStage 48 (collect at utils.scala:204)
19/07/31 17:06:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
19/07/31 17:06:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 47)
19/07/31 17:06:17 INFO DAGScheduler: Submitting ShuffleMapStage 47 (MapPartitionsRDD[150] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 74.5 KB, free 909.2 MB)
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 31.7 KB, free 909.2 MB)
19/07/31 17:06:17 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:53890 (size: 31.7 KB, free: 911.5 MB)
19/07/31 17:06:17 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[150] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:17 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
19/07/31 17:06:17 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:17 INFO Executor: Running task 0.0 in stage 47.0 (TID 86)
19/07/31 17:06:17 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:17 INFO Executor: Finished task 0.0 in stage 47.0 (TID 86). 1687 bytes result sent to driver
19/07/31 17:06:17 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 86) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:06:17 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
19/07/31 17:06:17 INFO DAGScheduler: ShuffleMapStage 47 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:06:17 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:17 INFO DAGScheduler: running: Set()
19/07/31 17:06:17 INFO DAGScheduler: waiting: Set(ResultStage 48)
19/07/31 17:06:17 INFO DAGScheduler: failed: Set()
19/07/31 17:06:17 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[153] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 16.8 KB, free 909.2 MB)
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.2 MB)
19/07/31 17:06:17 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.5 MB)
19/07/31 17:06:17 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:17 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 48 (MapPartitionsRDD[153] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:17 INFO TaskSchedulerImpl: Adding task set 48.0 with 4 tasks
19/07/31 17:06:17 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 87, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:17 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 88, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:17 INFO TaskSetManager: Starting task 2.0 in stage 48.0 (TID 89, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:17 INFO TaskSetManager: Starting task 3.0 in stage 48.0 (TID 90, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:17 INFO Executor: Running task 0.0 in stage 48.0 (TID 87)
19/07/31 17:06:17 INFO Executor: Running task 1.0 in stage 48.0 (TID 88)
19/07/31 17:06:17 INFO Executor: Running task 2.0 in stage 48.0 (TID 89)
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:17 INFO Executor: Running task 3.0 in stage 48.0 (TID 90)
19/07/31 17:06:17 INFO Executor: Finished task 2.0 in stage 48.0 (TID 89). 2390 bytes result sent to driver
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:17 INFO TaskSetManager: Finished task 2.0 in stage 48.0 (TID 89) in 6 ms on localhost (executor driver) (1/4)
19/07/31 17:06:17 INFO Executor: Finished task 0.0 in stage 48.0 (TID 87). 2382 bytes result sent to driver
19/07/31 17:06:17 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 87) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:06:17 INFO Executor: Finished task 3.0 in stage 48.0 (TID 90). 2362 bytes result sent to driver
19/07/31 17:06:17 INFO Executor: Finished task 1.0 in stage 48.0 (TID 88). 2403 bytes result sent to driver
19/07/31 17:06:17 INFO TaskSetManager: Finished task 3.0 in stage 48.0 (TID 90) in 7 ms on localhost (executor driver) (3/4)
19/07/31 17:06:17 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 88) in 8 ms on localhost (executor driver) (4/4)
19/07/31 17:06:17 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
19/07/31 17:06:17 INFO DAGScheduler: ResultStage 48 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:06:17 INFO DAGScheduler: Job 32 finished: collect at utils.scala:204, took 0.027664 s
19/07/31 17:06:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_113`) `dbplyr_114`
ORDER BY `date`) `dbplyr_115`) `dbplyr_116`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "All Devices"))
19/07/31 17:06:17 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:17 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_117`) `dbplyr_118`
ORDER BY `date`) `dbplyr_119`) `dbplyr_120`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "All Devices"))
19/07/31 17:06:17 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:17 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:17 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1814 - cust_prospect_ind.nullCount#1813) > 0)
19/07/31 17:06:17 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1819 - visit_device_type.nullCount#1818) > 0)
19/07/31 17:06:17 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#1812 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#1811))
19/07/31 17:06:17 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#1817 <= All Devices) && (All Devices <= visit_device_type.upperBound#1816))
19/07/31 17:06:17 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:17 INFO DAGScheduler: Got job 33 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:17 INFO DAGScheduler: Final stage: ResultStage 49 (collect at utils.scala:204)
19/07/31 17:06:17 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:17 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:17 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[158] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 72.1 KB, free 909.1 MB)
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 30.4 KB, free 909.1 MB)
19/07/31 17:06:17 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:53890 (size: 30.4 KB, free: 911.5 MB)
19/07/31 17:06:17 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[158] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:17 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
19/07/31 17:06:17 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 91, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:17 INFO Executor: Running task 0.0 in stage 49.0 (TID 91)
19/07/31 17:06:17 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:17 INFO Executor: Finished task 0.0 in stage 49.0 (TID 91). 6979 bytes result sent to driver
19/07/31 17:06:17 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 91) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:06:17 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
19/07/31 17:06:17 INFO DAGScheduler: ResultStage 49 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:06:17 INFO DAGScheduler: Job 33 finished: collect at utils.scala:204, took 0.013544 s
19/07/31 17:06:17 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:17 INFO DAGScheduler: Registering RDD 159 (collect at utils.scala:204)
19/07/31 17:06:17 INFO DAGScheduler: Got job 34 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:17 INFO DAGScheduler: Final stage: ResultStage 51 (collect at utils.scala:204)
19/07/31 17:06:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
19/07/31 17:06:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 50)
19/07/31 17:06:17 INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[159] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 74.5 KB, free 909.0 MB)
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.0 MB)
19/07/31 17:06:17 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.5 MB)
19/07/31 17:06:17 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[159] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:17 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
19/07/31 17:06:17 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:17 INFO Executor: Running task 0.0 in stage 50.0 (TID 92)
19/07/31 17:06:17 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:17 INFO Executor: Finished task 0.0 in stage 50.0 (TID 92). 1687 bytes result sent to driver
19/07/31 17:06:17 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 92) in 10 ms on localhost (executor driver) (1/1)
19/07/31 17:06:17 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
19/07/31 17:06:17 INFO DAGScheduler: ShuffleMapStage 50 (collect at utils.scala:204) finished in 0.011 s
19/07/31 17:06:17 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:17 INFO DAGScheduler: running: Set()
19/07/31 17:06:17 INFO DAGScheduler: waiting: Set(ResultStage 51)
19/07/31 17:06:17 INFO DAGScheduler: failed: Set()
19/07/31 17:06:17 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[162] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 16.8 KB, free 908.9 MB)
19/07/31 17:06:17 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 8.0 KB, free 908.9 MB)
19/07/31 17:06:17 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.5 MB)
19/07/31 17:06:17 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:17 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 51 (MapPartitionsRDD[162] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:17 INFO TaskSchedulerImpl: Adding task set 51.0 with 4 tasks
19/07/31 17:06:17 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 93, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:17 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 94, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:17 INFO TaskSetManager: Starting task 2.0 in stage 51.0 (TID 95, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:17 INFO TaskSetManager: Starting task 3.0 in stage 51.0 (TID 96, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:17 INFO Executor: Running task 1.0 in stage 51.0 (TID 94)
19/07/31 17:06:17 INFO Executor: Running task 3.0 in stage 51.0 (TID 96)
19/07/31 17:06:17 INFO Executor: Running task 0.0 in stage 51.0 (TID 93)
19/07/31 17:06:17 INFO Executor: Running task 2.0 in stage 51.0 (TID 95)
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:17 INFO Executor: Finished task 1.0 in stage 51.0 (TID 94). 2359 bytes result sent to driver
19/07/31 17:06:17 INFO Executor: Finished task 0.0 in stage 51.0 (TID 93). 2377 bytes result sent to driver
19/07/31 17:06:17 INFO Executor: Finished task 2.0 in stage 51.0 (TID 95). 2378 bytes result sent to driver
19/07/31 17:06:17 INFO Executor: Finished task 3.0 in stage 51.0 (TID 96). 2396 bytes result sent to driver
19/07/31 17:06:17 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 94) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:06:17 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 93) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:06:17 INFO TaskSetManager: Finished task 2.0 in stage 51.0 (TID 95) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:06:17 INFO TaskSetManager: Finished task 3.0 in stage 51.0 (TID 96) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:06:17 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
19/07/31 17:06:17 INFO DAGScheduler: ResultStage 51 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:06:17 INFO DAGScheduler: Job 34 finished: collect at utils.scala:204, took 0.027837 s
19/07/31 17:06:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_121`) `dbplyr_122`
ORDER BY `date`) `dbplyr_123`) `dbplyr_124`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:18 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:18 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_125`) `dbplyr_126`
ORDER BY `date`) `dbplyr_127`) `dbplyr_128`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:18 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:18 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:18 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1912 - cust_prospect_ind.nullCount#1911) > 0)
19/07/31 17:06:18 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1917 - visit_device_type.nullCount#1916) > 0)
19/07/31 17:06:18 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#1910 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#1909))
19/07/31 17:06:18 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#1915 <= All Devices) && (All Devices <= visit_device_type.upperBound#1914))
19/07/31 17:06:18 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:18 INFO DAGScheduler: Got job 35 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:18 INFO DAGScheduler: Final stage: ResultStage 52 (collect at utils.scala:204)
19/07/31 17:06:18 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:18 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:18 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[167] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:18 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 72.1 KB, free 908.9 MB)
19/07/31 17:06:18 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 30.5 KB, free 908.8 MB)
19/07/31 17:06:18 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 911.4 MB)
19/07/31 17:06:18 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[167] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:18 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
19/07/31 17:06:18 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:18 INFO Executor: Running task 0.0 in stage 52.0 (TID 97)
19/07/31 17:06:18 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:18 INFO Executor: Finished task 0.0 in stage 52.0 (TID 97). 7542 bytes result sent to driver
19/07/31 17:06:18 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 97) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:06:18 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
19/07/31 17:06:18 INFO DAGScheduler: ResultStage 52 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:18 INFO DAGScheduler: Job 35 finished: collect at utils.scala:204, took 0.011933 s
19/07/31 17:06:18 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:18 INFO DAGScheduler: Registering RDD 168 (collect at utils.scala:204)
19/07/31 17:06:18 INFO DAGScheduler: Got job 36 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:18 INFO DAGScheduler: Final stage: ResultStage 54 (collect at utils.scala:204)
19/07/31 17:06:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 53)
19/07/31 17:06:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 53)
19/07/31 17:06:18 INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[168] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:18 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 74.5 KB, free 908.8 MB)
19/07/31 17:06:18 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 31.8 KB, free 908.7 MB)
19/07/31 17:06:18 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.4 MB)
19/07/31 17:06:18 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[168] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:18 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
19/07/31 17:06:18 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 98, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:18 INFO Executor: Running task 0.0 in stage 53.0 (TID 98)
19/07/31 17:06:18 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:18 INFO Executor: Finished task 0.0 in stage 53.0 (TID 98). 1687 bytes result sent to driver
19/07/31 17:06:18 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 98) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:06:18 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
19/07/31 17:06:18 INFO DAGScheduler: ShuffleMapStage 53 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:06:18 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:18 INFO DAGScheduler: running: Set()
19/07/31 17:06:18 INFO DAGScheduler: waiting: Set(ResultStage 54)
19/07/31 17:06:18 INFO DAGScheduler: failed: Set()
19/07/31 17:06:18 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[171] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:18 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 16.8 KB, free 908.7 MB)
19/07/31 17:06:18 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 8.0 KB, free 908.7 MB)
19/07/31 17:06:18 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.4 MB)
19/07/31 17:06:18 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:18 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 54 (MapPartitionsRDD[171] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:18 INFO TaskSchedulerImpl: Adding task set 54.0 with 4 tasks
19/07/31 17:06:18 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 99, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:18 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 100, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:18 INFO TaskSetManager: Starting task 2.0 in stage 54.0 (TID 101, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:18 INFO TaskSetManager: Starting task 3.0 in stage 54.0 (TID 102, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:18 INFO Executor: Running task 2.0 in stage 54.0 (TID 101)
19/07/31 17:06:18 INFO Executor: Running task 3.0 in stage 54.0 (TID 102)
19/07/31 17:06:18 INFO Executor: Running task 1.0 in stage 54.0 (TID 100)
19/07/31 17:06:18 INFO Executor: Running task 0.0 in stage 54.0 (TID 99)
19/07/31 17:06:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:18 INFO Executor: Finished task 0.0 in stage 54.0 (TID 99). 2382 bytes result sent to driver
19/07/31 17:06:18 INFO Executor: Finished task 2.0 in stage 54.0 (TID 101). 2390 bytes result sent to driver
19/07/31 17:06:18 INFO TaskSetManager: Finished task 2.0 in stage 54.0 (TID 101) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:06:18 INFO Executor: Finished task 3.0 in stage 54.0 (TID 102). 2362 bytes result sent to driver
19/07/31 17:06:18 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 99) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:06:18 INFO TaskSetManager: Finished task 3.0 in stage 54.0 (TID 102) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:06:18 INFO Executor: Finished task 1.0 in stage 54.0 (TID 100). 2403 bytes result sent to driver
19/07/31 17:06:18 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 100) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:06:18 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
19/07/31 17:06:18 INFO DAGScheduler: ResultStage 54 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:06:18 INFO DAGScheduler: Job 36 finished: collect at utils.scala:204, took 0.025823 s
19/07/31 17:06:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_129`) `dbplyr_130`
ORDER BY `date`) `dbplyr_131`) `dbplyr_132`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:18 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:18 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_133`) `dbplyr_134`
ORDER BY `date`) `dbplyr_135`) `dbplyr_136`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:18 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:18 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:18 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2010 - cust_prospect_ind.nullCount#2009) > 0)
19/07/31 17:06:18 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2015 - visit_device_type.nullCount#2014) > 0)
19/07/31 17:06:18 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#2008 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#2007))
19/07/31 17:06:18 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#2013 <= All Devices) && (All Devices <= visit_device_type.upperBound#2012))
19/07/31 17:06:18 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:18 INFO DAGScheduler: Got job 37 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:18 INFO DAGScheduler: Final stage: ResultStage 55 (collect at utils.scala:204)
19/07/31 17:06:18 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:18 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:18 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[176] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:18 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 72.1 KB, free 908.6 MB)
19/07/31 17:06:18 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 30.4 KB, free 908.6 MB)
19/07/31 17:06:18 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:53890 (size: 30.4 KB, free: 911.4 MB)
19/07/31 17:06:18 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[176] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:18 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
19/07/31 17:06:18 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 103, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:18 INFO Executor: Running task 0.0 in stage 55.0 (TID 103)
19/07/31 17:06:18 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:18 INFO Executor: Finished task 0.0 in stage 55.0 (TID 103). 7542 bytes result sent to driver
19/07/31 17:06:18 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 103) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:06:18 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
19/07/31 17:06:18 INFO DAGScheduler: ResultStage 55 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:06:18 INFO DAGScheduler: Job 37 finished: collect at utils.scala:204, took 0.014035 s
19/07/31 17:06:18 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:18 INFO DAGScheduler: Registering RDD 177 (collect at utils.scala:204)
19/07/31 17:06:18 INFO DAGScheduler: Got job 38 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:18 INFO DAGScheduler: Final stage: ResultStage 57 (collect at utils.scala:204)
19/07/31 17:06:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
19/07/31 17:06:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 56)
19/07/31 17:06:18 INFO DAGScheduler: Submitting ShuffleMapStage 56 (MapPartitionsRDD[177] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:18 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 74.5 KB, free 908.5 MB)
19/07/31 17:06:18 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 31.7 KB, free 908.5 MB)
19/07/31 17:06:18 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:53890 (size: 31.7 KB, free: 911.3 MB)
19/07/31 17:06:18 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[177] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:18 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
19/07/31 17:06:18 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 104, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:18 INFO Executor: Running task 0.0 in stage 56.0 (TID 104)
19/07/31 17:06:18 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:18 INFO Executor: Finished task 0.0 in stage 56.0 (TID 104). 1687 bytes result sent to driver
19/07/31 17:06:18 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 104) in 13 ms on localhost (executor driver) (1/1)
19/07/31 17:06:18 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
19/07/31 17:06:18 INFO DAGScheduler: ShuffleMapStage 56 (collect at utils.scala:204) finished in 0.013 s
19/07/31 17:06:18 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:18 INFO DAGScheduler: running: Set()
19/07/31 17:06:18 INFO DAGScheduler: waiting: Set(ResultStage 57)
19/07/31 17:06:18 INFO DAGScheduler: failed: Set()
19/07/31 17:06:18 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[180] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:18 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 16.8 KB, free 908.5 MB)
19/07/31 17:06:18 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 8.0 KB, free 908.5 MB)
19/07/31 17:06:18 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.3 MB)
19/07/31 17:06:18 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:18 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 57 (MapPartitionsRDD[180] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:18 INFO TaskSchedulerImpl: Adding task set 57.0 with 4 tasks
19/07/31 17:06:18 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 105, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:18 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 106, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:18 INFO TaskSetManager: Starting task 2.0 in stage 57.0 (TID 107, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:18 INFO TaskSetManager: Starting task 3.0 in stage 57.0 (TID 108, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:18 INFO Executor: Running task 0.0 in stage 57.0 (TID 105)
19/07/31 17:06:18 INFO Executor: Running task 3.0 in stage 57.0 (TID 108)
19/07/31 17:06:18 INFO Executor: Running task 1.0 in stage 57.0 (TID 106)
19/07/31 17:06:18 INFO Executor: Running task 2.0 in stage 57.0 (TID 107)
19/07/31 17:06:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:18 INFO Executor: Finished task 3.0 in stage 57.0 (TID 108). 2362 bytes result sent to driver
19/07/31 17:06:18 INFO TaskSetManager: Finished task 3.0 in stage 57.0 (TID 108) in 7 ms on localhost (executor driver) (1/4)
19/07/31 17:06:18 INFO Executor: Finished task 0.0 in stage 57.0 (TID 105). 2382 bytes result sent to driver
19/07/31 17:06:18 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 105) in 8 ms on localhost (executor driver) (2/4)
19/07/31 17:06:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:18 INFO Executor: Finished task 1.0 in stage 57.0 (TID 106). 2446 bytes result sent to driver
19/07/31 17:06:18 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 106) in 23 ms on localhost (executor driver) (3/4)
19/07/31 17:06:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:18 INFO Executor: Finished task 2.0 in stage 57.0 (TID 107). 2390 bytes result sent to driver
19/07/31 17:06:18 INFO TaskSetManager: Finished task 2.0 in stage 57.0 (TID 107) in 45 ms on localhost (executor driver) (4/4)
19/07/31 17:06:18 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
19/07/31 17:06:18 INFO DAGScheduler: ResultStage 57 (collect at utils.scala:204) finished in 0.045 s
19/07/31 17:06:18 INFO DAGScheduler: Job 38 finished: collect at utils.scala:204, took 0.071969 s
19/07/31 17:06:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_137`) `dbplyr_138`
ORDER BY `date`) `dbplyr_139`) `dbplyr_140`
WHERE ((`customer` = "PROSPECT") AND (`device` = "All Devices"))
19/07/31 17:06:18 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:18 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_141`) `dbplyr_142`
ORDER BY `date`) `dbplyr_143`) `dbplyr_144`
WHERE ((`customer` = "PROSPECT") AND (`device` = "All Devices"))
19/07/31 17:06:18 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:18 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:18 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2108 - cust_prospect_ind.nullCount#2107) > 0)
19/07/31 17:06:18 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2113 - visit_device_type.nullCount#2112) > 0)
19/07/31 17:06:18 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#2106 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#2105))
19/07/31 17:06:18 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#2111 <= All Devices) && (All Devices <= visit_device_type.upperBound#2110))
19/07/31 17:06:19 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:19 INFO DAGScheduler: Got job 39 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:19 INFO DAGScheduler: Final stage: ResultStage 58 (collect at utils.scala:204)
19/07/31 17:06:19 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:19 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:19 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[185] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:19 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 72.1 KB, free 908.4 MB)
19/07/31 17:06:19 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 30.5 KB, free 908.4 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 911.3 MB)
19/07/31 17:06:19 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[185] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:19 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
19/07/31 17:06:19 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 109, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:19 INFO Executor: Running task 0.0 in stage 58.0 (TID 109)
19/07/31 17:06:19 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:19 INFO Executor: Finished task 0.0 in stage 58.0 (TID 109). 6979 bytes result sent to driver
19/07/31 17:06:19 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 109) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:06:19 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
19/07/31 17:06:19 INFO DAGScheduler: ResultStage 58 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:06:19 INFO DAGScheduler: Job 39 finished: collect at utils.scala:204, took 0.020938 s
19/07/31 17:06:19 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:19 INFO DAGScheduler: Registering RDD 186 (collect at utils.scala:204)
19/07/31 17:06:19 INFO DAGScheduler: Got job 40 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:19 INFO DAGScheduler: Final stage: ResultStage 60 (collect at utils.scala:204)
19/07/31 17:06:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
19/07/31 17:06:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 59)
19/07/31 17:06:19 INFO DAGScheduler: Submitting ShuffleMapStage 59 (MapPartitionsRDD[186] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:19 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 74.5 KB, free 908.3 MB)
19/07/31 17:06:19 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 31.8 KB, free 908.3 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.3 MB)
19/07/31 17:06:19 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 59 (MapPartitionsRDD[186] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:19 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
19/07/31 17:06:19 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 110, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:19 INFO Executor: Running task 0.0 in stage 59.0 (TID 110)
19/07/31 17:06:19 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:19 INFO Executor: Finished task 0.0 in stage 59.0 (TID 110). 1687 bytes result sent to driver
19/07/31 17:06:19 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 110) in 14 ms on localhost (executor driver) (1/1)
19/07/31 17:06:19 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
19/07/31 17:06:19 INFO DAGScheduler: ShuffleMapStage 59 (collect at utils.scala:204) finished in 0.015 s
19/07/31 17:06:19 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:19 INFO DAGScheduler: running: Set()
19/07/31 17:06:19 INFO DAGScheduler: waiting: Set(ResultStage 60)
19/07/31 17:06:19 INFO DAGScheduler: failed: Set()
19/07/31 17:06:19 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[189] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:19 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 16.8 KB, free 908.3 MB)
19/07/31 17:06:19 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 8.0 KB, free 908.3 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.2 MB)
19/07/31 17:06:19 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:19 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 60 (MapPartitionsRDD[189] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:19 INFO TaskSchedulerImpl: Adding task set 60.0 with 4 tasks
19/07/31 17:06:19 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 111, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:19 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 112, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:19 INFO TaskSetManager: Starting task 2.0 in stage 60.0 (TID 113, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:19 INFO TaskSetManager: Starting task 3.0 in stage 60.0 (TID 114, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:19 INFO Executor: Running task 0.0 in stage 60.0 (TID 111)
19/07/31 17:06:19 INFO Executor: Running task 1.0 in stage 60.0 (TID 112)
19/07/31 17:06:19 INFO Executor: Running task 2.0 in stage 60.0 (TID 113)
19/07/31 17:06:19 INFO Executor: Running task 3.0 in stage 60.0 (TID 114)
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1135
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 967
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 645
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:19 INFO Executor: Finished task 1.0 in stage 60.0 (TID 112). 2400 bytes result sent to driver
19/07/31 17:06:19 INFO Executor: Finished task 2.0 in stage 60.0 (TID 113). 2434 bytes result sent to driver
19/07/31 17:06:19 INFO Executor: Finished task 3.0 in stage 60.0 (TID 114). 2412 bytes result sent to driver
19/07/31 17:06:19 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 112) in 51 ms on localhost (executor driver) (1/4)
19/07/31 17:06:19 INFO TaskSetManager: Finished task 2.0 in stage 60.0 (TID 113) in 50 ms on localhost (executor driver) (2/4)
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:53890 in memory (size: 8.1 KB, free: 911.3 MB)
19/07/31 17:06:19 INFO TaskSetManager: Finished task 3.0 in stage 60.0 (TID 114) in 50 ms on localhost (executor driver) (3/4)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 641
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.3 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:53890 in memory (size: 30.4 KB, free: 911.3 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:53890 in memory (size: 31.7 KB, free: 911.3 MB)
19/07/31 17:06:19 INFO Executor: Finished task 0.0 in stage 60.0 (TID 111). 2426 bytes result sent to driver
19/07/31 17:06:19 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 111) in 54 ms on localhost (executor driver) (4/4)
19/07/31 17:06:19 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:53890 in memory (size: 30.4 KB, free: 911.4 MB)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 806
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 804
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 970
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 888
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 889
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1453
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 726
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1289
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 911.4 MB)
19/07/31 17:06:19 INFO DAGScheduler: ResultStage 60 (collect at utils.scala:204) finished in 0.055 s
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 810
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 968
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 911.4 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.4 MB)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 890
19/07/31 17:06:19 INFO ContextCleaner: Cleaned shuffle 7
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.4 MB)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 891
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 969
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1454
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 649
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1129
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1455
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.4 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:53890 in memory (size: 30.4 KB, free: 911.5 MB)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned shuffle 8
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 724
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.5 MB)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 884
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:53890 in memory (size: 31.7 KB, free: 911.5 MB)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 811
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1131
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1128
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 966
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 808
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 911.5 MB)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 805
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:53890 in memory (size: 30.4 KB, free: 911.6 MB)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 722
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 723
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 911.6 MB)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1613
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1134
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 911.6 MB)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 728
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:53890 in memory (size: 30.4 KB, free: 911.7 MB)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 887
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 729
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1451
19/07/31 17:06:19 INFO ContextCleaner: Cleaned shuffle 13
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 809
19/07/31 17:06:19 INFO ContextCleaner: Cleaned shuffle 17
19/07/31 17:06:19 INFO ContextCleaner: Cleaned shuffle 11
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 911.7 MB)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 885
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 972
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1452
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 727
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 807
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1458
19/07/31 17:06:19 INFO DAGScheduler: Job 40 finished: collect at utils.scala:204, took 0.109874 s
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 911.7 MB)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1457
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:53890 in memory (size: 31.7 KB, free: 911.8 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 892
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 965
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1370
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:53890 in memory (size: 31.7 KB, free: 911.9 MB)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 803
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1046
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 725
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 647
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1132
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1456
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 886
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 644
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 648
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:53890 in memory (size: 30.4 KB, free: 911.9 MB)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1127
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1532
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 730
19/07/31 17:06:19 INFO ContextCleaner: Cleaned shuffle 9
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 643
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 911.9 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:53890 in memory (size: 30.4 KB, free: 912.0 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 912.1 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 642
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:53890 in memory (size: 31.7 KB, free: 912.1 MB)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 646
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1459
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1208
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1130
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 912.1 MB)
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 1133
19/07/31 17:06:19 INFO ContextCleaner: Cleaned shuffle 10
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 973
19/07/31 17:06:19 INFO ContextCleaner: Cleaned accumulator 971
19/07/31 17:06:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_145`) `dbplyr_146`
ORDER BY `date`) `dbplyr_147`) `dbplyr_148`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:19 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:19 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_149`) `dbplyr_150`
ORDER BY `date`) `dbplyr_151`) `dbplyr_152`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:19 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:19 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:19 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2206 - cust_prospect_ind.nullCount#2205) > 0)
19/07/31 17:06:19 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2211 - visit_device_type.nullCount#2210) > 0)
19/07/31 17:06:19 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#2204 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#2203))
19/07/31 17:06:19 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#2209 <= All Devices) && (All Devices <= visit_device_type.upperBound#2208))
19/07/31 17:06:19 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:19 INFO DAGScheduler: Got job 41 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:19 INFO DAGScheduler: Final stage: ResultStage 61 (collect at utils.scala:204)
19/07/31 17:06:19 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:19 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:19 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[194] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:19 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 72.1 KB, free 911.1 MB)
19/07/31 17:06:19 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.1 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:53890 (size: 30.4 KB, free: 912.1 MB)
19/07/31 17:06:19 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[194] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:19 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
19/07/31 17:06:19 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 115, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:19 INFO Executor: Running task 0.0 in stage 61.0 (TID 115)
19/07/31 17:06:19 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:19 INFO Executor: Finished task 0.0 in stage 61.0 (TID 115). 7542 bytes result sent to driver
19/07/31 17:06:19 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 115) in 12 ms on localhost (executor driver) (1/1)
19/07/31 17:06:19 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
19/07/31 17:06:19 INFO DAGScheduler: ResultStage 61 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:06:19 INFO DAGScheduler: Job 41 finished: collect at utils.scala:204, took 0.062236 s
19/07/31 17:06:19 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:19 INFO DAGScheduler: Registering RDD 195 (collect at utils.scala:204)
19/07/31 17:06:19 INFO DAGScheduler: Got job 42 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:19 INFO DAGScheduler: Final stage: ResultStage 63 (collect at utils.scala:204)
19/07/31 17:06:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
19/07/31 17:06:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 62)
19/07/31 17:06:19 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[195] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:19 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 74.5 KB, free 911.0 MB)
19/07/31 17:06:19 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.0 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 912.1 MB)
19/07/31 17:06:19 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[195] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:19 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
19/07/31 17:06:19 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 116, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:19 INFO Executor: Running task 0.0 in stage 62.0 (TID 116)
19/07/31 17:06:19 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:19 INFO Executor: Finished task 0.0 in stage 62.0 (TID 116). 1687 bytes result sent to driver
19/07/31 17:06:19 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 116) in 10 ms on localhost (executor driver) (1/1)
19/07/31 17:06:19 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
19/07/31 17:06:19 INFO DAGScheduler: ShuffleMapStage 62 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:06:19 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:19 INFO DAGScheduler: running: Set()
19/07/31 17:06:19 INFO DAGScheduler: waiting: Set(ResultStage 63)
19/07/31 17:06:19 INFO DAGScheduler: failed: Set()
19/07/31 17:06:19 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[198] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:19 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 16.8 KB, free 911.0 MB)
19/07/31 17:06:19 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.0 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:06:19 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:19 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 63 (MapPartitionsRDD[198] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:19 INFO TaskSchedulerImpl: Adding task set 63.0 with 4 tasks
19/07/31 17:06:19 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 117, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:19 INFO TaskSetManager: Starting task 1.0 in stage 63.0 (TID 118, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:19 INFO TaskSetManager: Starting task 2.0 in stage 63.0 (TID 119, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:19 INFO TaskSetManager: Starting task 3.0 in stage 63.0 (TID 120, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:19 INFO Executor: Running task 1.0 in stage 63.0 (TID 118)
19/07/31 17:06:19 INFO Executor: Running task 3.0 in stage 63.0 (TID 120)
19/07/31 17:06:19 INFO Executor: Running task 0.0 in stage 63.0 (TID 117)
19/07/31 17:06:19 INFO Executor: Running task 2.0 in stage 63.0 (TID 119)
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:19 INFO Executor: Finished task 1.0 in stage 63.0 (TID 118). 2403 bytes result sent to driver
19/07/31 17:06:19 INFO Executor: Finished task 0.0 in stage 63.0 (TID 117). 2382 bytes result sent to driver
19/07/31 17:06:19 INFO Executor: Finished task 2.0 in stage 63.0 (TID 119). 2390 bytes result sent to driver
19/07/31 17:06:19 INFO TaskSetManager: Finished task 1.0 in stage 63.0 (TID 118) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:06:19 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 117) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:06:19 INFO TaskSetManager: Finished task 2.0 in stage 63.0 (TID 119) in 4 ms on localhost (executor driver) (3/4)
19/07/31 17:06:19 INFO Executor: Finished task 3.0 in stage 63.0 (TID 120). 2405 bytes result sent to driver
19/07/31 17:06:19 INFO TaskSetManager: Finished task 3.0 in stage 63.0 (TID 120) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:06:19 INFO DAGScheduler: ResultStage 63 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:06:19 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
19/07/31 17:06:19 INFO DAGScheduler: Job 42 finished: collect at utils.scala:204, took 0.026922 s
19/07/31 17:06:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_153`) `dbplyr_154`
ORDER BY `date`) `dbplyr_155`) `dbplyr_156`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:19 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:19 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_157`) `dbplyr_158`
ORDER BY `date`) `dbplyr_159`) `dbplyr_160`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:19 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:19 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:19 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2304 - cust_prospect_ind.nullCount#2303) > 0)
19/07/31 17:06:19 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2309 - visit_device_type.nullCount#2308) > 0)
19/07/31 17:06:19 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#2302 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#2301))
19/07/31 17:06:19 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#2307 <= All Devices) && (All Devices <= visit_device_type.upperBound#2306))
19/07/31 17:06:19 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:19 INFO DAGScheduler: Got job 43 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:19 INFO DAGScheduler: Final stage: ResultStage 64 (collect at utils.scala:204)
19/07/31 17:06:19 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:19 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:19 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[203] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:19 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 72.1 KB, free 910.9 MB)
19/07/31 17:06:19 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.9 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:53890 (size: 30.4 KB, free: 912.0 MB)
19/07/31 17:06:19 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[203] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:19 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
19/07/31 17:06:19 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 121, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:19 INFO Executor: Running task 0.0 in stage 64.0 (TID 121)
19/07/31 17:06:19 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:19 INFO Executor: Finished task 0.0 in stage 64.0 (TID 121). 7585 bytes result sent to driver
19/07/31 17:06:19 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 121) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:06:19 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
19/07/31 17:06:19 INFO DAGScheduler: ResultStage 64 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:19 INFO DAGScheduler: Job 43 finished: collect at utils.scala:204, took 0.012126 s
19/07/31 17:06:19 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:19 INFO DAGScheduler: Registering RDD 204 (collect at utils.scala:204)
19/07/31 17:06:19 INFO DAGScheduler: Got job 44 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:19 INFO DAGScheduler: Final stage: ResultStage 66 (collect at utils.scala:204)
19/07/31 17:06:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)
19/07/31 17:06:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 65)
19/07/31 17:06:19 INFO DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[204] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:19 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 74.5 KB, free 910.8 MB)
19/07/31 17:06:19 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.8 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:53890 (size: 31.7 KB, free: 912.0 MB)
19/07/31 17:06:19 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[204] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:19 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
19/07/31 17:06:19 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 122, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:19 INFO Executor: Running task 0.0 in stage 65.0 (TID 122)
19/07/31 17:06:19 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:19 INFO Executor: Finished task 0.0 in stage 65.0 (TID 122). 1687 bytes result sent to driver
19/07/31 17:06:19 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 122) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:06:19 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
19/07/31 17:06:19 INFO DAGScheduler: ShuffleMapStage 65 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:06:19 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:19 INFO DAGScheduler: running: Set()
19/07/31 17:06:19 INFO DAGScheduler: waiting: Set(ResultStage 66)
19/07/31 17:06:19 INFO DAGScheduler: failed: Set()
19/07/31 17:06:19 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[207] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:19 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 16.8 KB, free 910.8 MB)
19/07/31 17:06:19 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.8 MB)
19/07/31 17:06:19 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:06:19 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:19 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 66 (MapPartitionsRDD[207] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:19 INFO TaskSchedulerImpl: Adding task set 66.0 with 4 tasks
19/07/31 17:06:19 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 123, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:19 INFO TaskSetManager: Starting task 1.0 in stage 66.0 (TID 124, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:19 INFO TaskSetManager: Starting task 2.0 in stage 66.0 (TID 125, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:19 INFO TaskSetManager: Starting task 3.0 in stage 66.0 (TID 126, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:19 INFO Executor: Running task 1.0 in stage 66.0 (TID 124)
19/07/31 17:06:19 INFO Executor: Running task 3.0 in stage 66.0 (TID 126)
19/07/31 17:06:19 INFO Executor: Running task 0.0 in stage 66.0 (TID 123)
19/07/31 17:06:19 INFO Executor: Running task 2.0 in stage 66.0 (TID 125)
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:19 INFO Executor: Finished task 2.0 in stage 66.0 (TID 125). 2390 bytes result sent to driver
19/07/31 17:06:19 INFO Executor: Finished task 0.0 in stage 66.0 (TID 123). 2382 bytes result sent to driver
19/07/31 17:06:19 INFO Executor: Finished task 1.0 in stage 66.0 (TID 124). 2403 bytes result sent to driver
19/07/31 17:06:19 INFO TaskSetManager: Finished task 2.0 in stage 66.0 (TID 125) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:06:19 INFO TaskSetManager: Finished task 1.0 in stage 66.0 (TID 124) in 4 ms on localhost (executor driver) (2/4)
19/07/31 17:06:19 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 123) in 4 ms on localhost (executor driver) (3/4)
19/07/31 17:06:19 INFO Executor: Finished task 3.0 in stage 66.0 (TID 126). 2362 bytes result sent to driver
19/07/31 17:06:19 INFO TaskSetManager: Finished task 3.0 in stage 66.0 (TID 126) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:06:19 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
19/07/31 17:06:19 INFO DAGScheduler: ResultStage 66 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:19 INFO DAGScheduler: Job 44 finished: collect at utils.scala:204, took 0.022490 s
19/07/31 17:06:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_161`) `dbplyr_162`
ORDER BY `date`) `dbplyr_163`) `dbplyr_164`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "All Devices"))
19/07/31 17:06:20 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:20 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_165`) `dbplyr_166`
ORDER BY `date`) `dbplyr_167`) `dbplyr_168`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "All Devices"))
19/07/31 17:06:20 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:20 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:20 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2402 - cust_prospect_ind.nullCount#2401) > 0)
19/07/31 17:06:20 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2407 - visit_device_type.nullCount#2406) > 0)
19/07/31 17:06:20 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#2400 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#2399))
19/07/31 17:06:20 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#2405 <= All Devices) && (All Devices <= visit_device_type.upperBound#2404))
19/07/31 17:06:20 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:20 INFO DAGScheduler: Got job 45 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:20 INFO DAGScheduler: Final stage: ResultStage 67 (collect at utils.scala:204)
19/07/31 17:06:20 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:20 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:20 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[212] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 72.1 KB, free 910.7 MB)
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.7 MB)
19/07/31 17:06:20 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:06:20 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[212] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:20 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks
19/07/31 17:06:20 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 127, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:20 INFO Executor: Running task 0.0 in stage 67.0 (TID 127)
19/07/31 17:06:20 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:20 INFO Executor: Finished task 0.0 in stage 67.0 (TID 127). 7542 bytes result sent to driver
19/07/31 17:06:20 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 127) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:06:20 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
19/07/31 17:06:20 INFO DAGScheduler: ResultStage 67 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:06:20 INFO DAGScheduler: Job 45 finished: collect at utils.scala:204, took 0.013171 s
19/07/31 17:06:20 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:20 INFO DAGScheduler: Registering RDD 213 (collect at utils.scala:204)
19/07/31 17:06:20 INFO DAGScheduler: Got job 46 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:20 INFO DAGScheduler: Final stage: ResultStage 69 (collect at utils.scala:204)
19/07/31 17:06:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)
19/07/31 17:06:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 68)
19/07/31 17:06:20 INFO DAGScheduler: Submitting ShuffleMapStage 68 (MapPartitionsRDD[213] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 74.5 KB, free 910.6 MB)
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.6 MB)
19/07/31 17:06:20 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.9 MB)
19/07/31 17:06:20 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[213] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:20 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks
19/07/31 17:06:20 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 128, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:20 INFO Executor: Running task 0.0 in stage 68.0 (TID 128)
19/07/31 17:06:20 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:20 INFO Executor: Finished task 0.0 in stage 68.0 (TID 128). 1687 bytes result sent to driver
19/07/31 17:06:20 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 128) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:06:20 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
19/07/31 17:06:20 INFO DAGScheduler: ShuffleMapStage 68 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:06:20 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:20 INFO DAGScheduler: running: Set()
19/07/31 17:06:20 INFO DAGScheduler: waiting: Set(ResultStage 69)
19/07/31 17:06:20 INFO DAGScheduler: failed: Set()
19/07/31 17:06:20 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[216] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 16.8 KB, free 910.5 MB)
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.5 MB)
19/07/31 17:06:20 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:06:20 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 69 (MapPartitionsRDD[216] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:20 INFO TaskSchedulerImpl: Adding task set 69.0 with 4 tasks
19/07/31 17:06:20 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 129, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:20 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 130, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:20 INFO TaskSetManager: Starting task 2.0 in stage 69.0 (TID 131, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:20 INFO TaskSetManager: Starting task 3.0 in stage 69.0 (TID 132, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:20 INFO Executor: Running task 0.0 in stage 69.0 (TID 129)
19/07/31 17:06:20 INFO Executor: Running task 1.0 in stage 69.0 (TID 130)
19/07/31 17:06:20 INFO Executor: Running task 2.0 in stage 69.0 (TID 131)
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:20 INFO Executor: Running task 3.0 in stage 69.0 (TID 132)
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:20 INFO Executor: Finished task 3.0 in stage 69.0 (TID 132). 2374 bytes result sent to driver
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:20 INFO Executor: Finished task 1.0 in stage 69.0 (TID 130). 2392 bytes result sent to driver
19/07/31 17:06:20 INFO Executor: Finished task 2.0 in stage 69.0 (TID 131). 2386 bytes result sent to driver
19/07/31 17:06:20 INFO TaskSetManager: Finished task 3.0 in stage 69.0 (TID 132) in 6 ms on localhost (executor driver) (1/4)
19/07/31 17:06:20 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 130) in 7 ms on localhost (executor driver) (2/4)
19/07/31 17:06:20 INFO TaskSetManager: Finished task 2.0 in stage 69.0 (TID 131) in 7 ms on localhost (executor driver) (3/4)
19/07/31 17:06:20 INFO Executor: Finished task 0.0 in stage 69.0 (TID 129). 2386 bytes result sent to driver
19/07/31 17:06:20 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 129) in 8 ms on localhost (executor driver) (4/4)
19/07/31 17:06:20 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
19/07/31 17:06:20 INFO DAGScheduler: ResultStage 69 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:06:20 INFO DAGScheduler: Job 46 finished: collect at utils.scala:204, took 0.027329 s
19/07/31 17:06:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_169`) `dbplyr_170`
ORDER BY `date`) `dbplyr_171`) `dbplyr_172`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:20 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:20 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_173`) `dbplyr_174`
ORDER BY `date`) `dbplyr_175`) `dbplyr_176`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:20 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:20 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:20 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2500 - cust_prospect_ind.nullCount#2499) > 0)
19/07/31 17:06:20 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2505 - visit_device_type.nullCount#2504) > 0)
19/07/31 17:06:20 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#2498 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#2497))
19/07/31 17:06:20 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#2503 <= All Devices) && (All Devices <= visit_device_type.upperBound#2502))
19/07/31 17:06:20 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:20 INFO DAGScheduler: Got job 47 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:20 INFO DAGScheduler: Final stage: ResultStage 70 (collect at utils.scala:204)
19/07/31 17:06:20 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:20 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:20 INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[221] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 72.1 KB, free 910.5 MB)
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.4 MB)
19/07/31 17:06:20 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:53890 (size: 30.4 KB, free: 911.9 MB)
19/07/31 17:06:20 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[221] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:20 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks
19/07/31 17:06:20 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 133, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:20 INFO Executor: Running task 0.0 in stage 70.0 (TID 133)
19/07/31 17:06:20 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:20 INFO Executor: Finished task 0.0 in stage 70.0 (TID 133). 7542 bytes result sent to driver
19/07/31 17:06:20 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 133) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:06:20 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
19/07/31 17:06:20 INFO DAGScheduler: ResultStage 70 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:20 INFO DAGScheduler: Job 47 finished: collect at utils.scala:204, took 0.009329 s
19/07/31 17:06:20 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:20 INFO DAGScheduler: Registering RDD 222 (collect at utils.scala:204)
19/07/31 17:06:20 INFO DAGScheduler: Got job 48 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:20 INFO DAGScheduler: Final stage: ResultStage 72 (collect at utils.scala:204)
19/07/31 17:06:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 71)
19/07/31 17:06:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 71)
19/07/31 17:06:20 INFO DAGScheduler: Submitting ShuffleMapStage 71 (MapPartitionsRDD[222] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 74.5 KB, free 910.4 MB)
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.3 MB)
19/07/31 17:06:20 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:53890 (size: 31.7 KB, free: 911.9 MB)
19/07/31 17:06:20 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 71 (MapPartitionsRDD[222] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:20 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks
19/07/31 17:06:20 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 134, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:20 INFO Executor: Running task 0.0 in stage 71.0 (TID 134)
19/07/31 17:06:20 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:20 INFO Executor: Finished task 0.0 in stage 71.0 (TID 134). 1687 bytes result sent to driver
19/07/31 17:06:20 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 134) in 14 ms on localhost (executor driver) (1/1)
19/07/31 17:06:20 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
19/07/31 17:06:20 INFO DAGScheduler: ShuffleMapStage 71 (collect at utils.scala:204) finished in 0.014 s
19/07/31 17:06:20 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:20 INFO DAGScheduler: running: Set()
19/07/31 17:06:20 INFO DAGScheduler: waiting: Set(ResultStage 72)
19/07/31 17:06:20 INFO DAGScheduler: failed: Set()
19/07/31 17:06:20 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[225] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 16.8 KB, free 910.3 MB)
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.3 MB)
19/07/31 17:06:20 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:06:20 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 72 (MapPartitionsRDD[225] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:20 INFO TaskSchedulerImpl: Adding task set 72.0 with 4 tasks
19/07/31 17:06:20 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 135, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:20 INFO TaskSetManager: Starting task 1.0 in stage 72.0 (TID 136, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:20 INFO TaskSetManager: Starting task 2.0 in stage 72.0 (TID 137, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:20 INFO TaskSetManager: Starting task 3.0 in stage 72.0 (TID 138, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:20 INFO Executor: Running task 0.0 in stage 72.0 (TID 135)
19/07/31 17:06:20 INFO Executor: Running task 1.0 in stage 72.0 (TID 136)
19/07/31 17:06:20 INFO Executor: Running task 3.0 in stage 72.0 (TID 138)
19/07/31 17:06:20 INFO Executor: Running task 2.0 in stage 72.0 (TID 137)
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:20 INFO Executor: Finished task 2.0 in stage 72.0 (TID 137). 2390 bytes result sent to driver
19/07/31 17:06:20 INFO Executor: Finished task 1.0 in stage 72.0 (TID 136). 2403 bytes result sent to driver
19/07/31 17:06:20 INFO Executor: Finished task 0.0 in stage 72.0 (TID 135). 2382 bytes result sent to driver
19/07/31 17:06:20 INFO TaskSetManager: Finished task 2.0 in stage 72.0 (TID 137) in 6 ms on localhost (executor driver) (1/4)
19/07/31 17:06:20 INFO Executor: Finished task 3.0 in stage 72.0 (TID 138). 2362 bytes result sent to driver
19/07/31 17:06:20 INFO TaskSetManager: Finished task 1.0 in stage 72.0 (TID 136) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:06:20 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 135) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:06:20 INFO TaskSetManager: Finished task 3.0 in stage 72.0 (TID 138) in 7 ms on localhost (executor driver) (4/4)
19/07/31 17:06:20 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
19/07/31 17:06:20 INFO DAGScheduler: ResultStage 72 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:20 INFO DAGScheduler: Job 48 finished: collect at utils.scala:204, took 0.030885 s
19/07/31 17:06:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_177`) `dbplyr_178`
ORDER BY `date`) `dbplyr_179`) `dbplyr_180`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:20 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:20 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_181`) `dbplyr_182`
ORDER BY `date`) `dbplyr_183`) `dbplyr_184`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:20 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:20 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:20 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2598 - cust_prospect_ind.nullCount#2597) > 0)
19/07/31 17:06:20 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2603 - visit_device_type.nullCount#2602) > 0)
19/07/31 17:06:20 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#2596 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#2595))
19/07/31 17:06:20 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#2601 <= All Devices) && (All Devices <= visit_device_type.upperBound#2600))
19/07/31 17:06:20 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:20 INFO DAGScheduler: Got job 49 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:20 INFO DAGScheduler: Final stage: ResultStage 73 (collect at utils.scala:204)
19/07/31 17:06:20 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:20 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:20 INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[230] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 72.1 KB, free 910.2 MB)
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.2 MB)
19/07/31 17:06:20 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:06:20 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[230] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:20 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks
19/07/31 17:06:20 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 139, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:20 INFO Executor: Running task 0.0 in stage 73.0 (TID 139)
19/07/31 17:06:20 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:20 INFO Executor: Finished task 0.0 in stage 73.0 (TID 139). 7542 bytes result sent to driver
19/07/31 17:06:20 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 139) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:06:20 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
19/07/31 17:06:20 INFO DAGScheduler: ResultStage 73 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:20 INFO DAGScheduler: Job 49 finished: collect at utils.scala:204, took 0.010302 s
19/07/31 17:06:20 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:20 INFO DAGScheduler: Registering RDD 231 (collect at utils.scala:204)
19/07/31 17:06:20 INFO DAGScheduler: Got job 50 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:20 INFO DAGScheduler: Final stage: ResultStage 75 (collect at utils.scala:204)
19/07/31 17:06:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 74)
19/07/31 17:06:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 74)
19/07/31 17:06:20 INFO DAGScheduler: Submitting ShuffleMapStage 74 (MapPartitionsRDD[231] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 74.5 KB, free 910.1 MB)
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.1 MB)
19/07/31 17:06:20 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:06:20 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 74 (MapPartitionsRDD[231] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:20 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks
19/07/31 17:06:20 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 140, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:20 INFO Executor: Running task 0.0 in stage 74.0 (TID 140)
19/07/31 17:06:20 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:20 INFO Executor: Finished task 0.0 in stage 74.0 (TID 140). 1687 bytes result sent to driver
19/07/31 17:06:20 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 140) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:06:20 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
19/07/31 17:06:20 INFO DAGScheduler: ShuffleMapStage 74 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:06:20 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:20 INFO DAGScheduler: running: Set()
19/07/31 17:06:20 INFO DAGScheduler: waiting: Set(ResultStage 75)
19/07/31 17:06:20 INFO DAGScheduler: failed: Set()
19/07/31 17:06:20 INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[234] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 16.8 KB, free 910.1 MB)
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.1 MB)
19/07/31 17:06:20 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:06:20 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 75 (MapPartitionsRDD[234] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:20 INFO TaskSchedulerImpl: Adding task set 75.0 with 4 tasks
19/07/31 17:06:20 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 141, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:20 INFO TaskSetManager: Starting task 1.0 in stage 75.0 (TID 142, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:20 INFO TaskSetManager: Starting task 2.0 in stage 75.0 (TID 143, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:20 INFO TaskSetManager: Starting task 3.0 in stage 75.0 (TID 144, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:20 INFO Executor: Running task 0.0 in stage 75.0 (TID 141)
19/07/31 17:06:20 INFO Executor: Running task 1.0 in stage 75.0 (TID 142)
19/07/31 17:06:20 INFO Executor: Running task 2.0 in stage 75.0 (TID 143)
19/07/31 17:06:20 INFO Executor: Running task 3.0 in stage 75.0 (TID 144)
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:20 INFO Executor: Finished task 2.0 in stage 75.0 (TID 143). 2390 bytes result sent to driver
19/07/31 17:06:20 INFO Executor: Finished task 1.0 in stage 75.0 (TID 142). 2403 bytes result sent to driver
19/07/31 17:06:20 INFO Executor: Finished task 3.0 in stage 75.0 (TID 144). 2362 bytes result sent to driver
19/07/31 17:06:20 INFO Executor: Finished task 0.0 in stage 75.0 (TID 141). 2382 bytes result sent to driver
19/07/31 17:06:20 INFO TaskSetManager: Finished task 2.0 in stage 75.0 (TID 143) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:06:20 INFO TaskSetManager: Finished task 3.0 in stage 75.0 (TID 144) in 4 ms on localhost (executor driver) (2/4)
19/07/31 17:06:20 INFO TaskSetManager: Finished task 1.0 in stage 75.0 (TID 142) in 4 ms on localhost (executor driver) (3/4)
19/07/31 17:06:20 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 141) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:06:20 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
19/07/31 17:06:20 INFO DAGScheduler: ResultStage 75 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:20 INFO DAGScheduler: Job 50 finished: collect at utils.scala:204, took 0.023351 s
19/07/31 17:06:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_185`) `dbplyr_186`
ORDER BY `date`) `dbplyr_187`) `dbplyr_188`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Mobile Phone"))
19/07/31 17:06:20 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:20 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_189`) `dbplyr_190`
ORDER BY `date`) `dbplyr_191`) `dbplyr_192`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Mobile Phone"))
19/07/31 17:06:20 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:20 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:20 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2696 - cust_prospect_ind.nullCount#2695) > 0)
19/07/31 17:06:20 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2701 - visit_device_type.nullCount#2700) > 0)
19/07/31 17:06:20 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#2694 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#2693))
19/07/31 17:06:20 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#2699 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#2698))
19/07/31 17:06:20 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:20 INFO DAGScheduler: Got job 51 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:20 INFO DAGScheduler: Final stage: ResultStage 76 (collect at utils.scala:204)
19/07/31 17:06:20 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:20 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:20 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[239] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 72.1 KB, free 910.0 MB)
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.0 MB)
19/07/31 17:06:20 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:06:20 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[239] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:20 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks
19/07/31 17:06:20 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 145, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:20 INFO Executor: Running task 0.0 in stage 76.0 (TID 145)
19/07/31 17:06:20 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:20 INFO Executor: Finished task 0.0 in stage 76.0 (TID 145). 6979 bytes result sent to driver
19/07/31 17:06:20 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 145) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:06:20 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
19/07/31 17:06:20 INFO DAGScheduler: ResultStage 76 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:20 INFO DAGScheduler: Job 51 finished: collect at utils.scala:204, took 0.010163 s
19/07/31 17:06:20 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:20 INFO DAGScheduler: Registering RDD 240 (collect at utils.scala:204)
19/07/31 17:06:20 INFO DAGScheduler: Got job 52 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:20 INFO DAGScheduler: Final stage: ResultStage 78 (collect at utils.scala:204)
19/07/31 17:06:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 77)
19/07/31 17:06:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 77)
19/07/31 17:06:20 INFO DAGScheduler: Submitting ShuffleMapStage 77 (MapPartitionsRDD[240] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 74.5 KB, free 909.9 MB)
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.9 MB)
19/07/31 17:06:20 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.7 MB)
19/07/31 17:06:20 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 77 (MapPartitionsRDD[240] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:20 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks
19/07/31 17:06:20 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 146, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:20 INFO Executor: Running task 0.0 in stage 77.0 (TID 146)
19/07/31 17:06:20 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:20 INFO Executor: Finished task 0.0 in stage 77.0 (TID 146). 1687 bytes result sent to driver
19/07/31 17:06:20 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 146) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:06:20 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
19/07/31 17:06:20 INFO DAGScheduler: ShuffleMapStage 77 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:20 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:20 INFO DAGScheduler: running: Set()
19/07/31 17:06:20 INFO DAGScheduler: waiting: Set(ResultStage 78)
19/07/31 17:06:20 INFO DAGScheduler: failed: Set()
19/07/31 17:06:20 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[243] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 16.8 KB, free 909.9 MB)
19/07/31 17:06:20 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.8 MB)
19/07/31 17:06:20 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:06:20 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 78 (MapPartitionsRDD[243] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:20 INFO TaskSchedulerImpl: Adding task set 78.0 with 4 tasks
19/07/31 17:06:20 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 147, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:20 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 148, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:20 INFO TaskSetManager: Starting task 2.0 in stage 78.0 (TID 149, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:20 INFO TaskSetManager: Starting task 3.0 in stage 78.0 (TID 150, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:20 INFO Executor: Running task 1.0 in stage 78.0 (TID 148)
19/07/31 17:06:20 INFO Executor: Running task 2.0 in stage 78.0 (TID 149)
19/07/31 17:06:20 INFO Executor: Running task 3.0 in stage 78.0 (TID 150)
19/07/31 17:06:20 INFO Executor: Running task 0.0 in stage 78.0 (TID 147)
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:20 INFO Executor: Finished task 0.0 in stage 78.0 (TID 147). 2366 bytes result sent to driver
19/07/31 17:06:20 INFO Executor: Finished task 3.0 in stage 78.0 (TID 150). 2353 bytes result sent to driver
19/07/31 17:06:20 INFO Executor: Finished task 1.0 in stage 78.0 (TID 148). 2347 bytes result sent to driver
19/07/31 17:06:20 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 147) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:06:20 INFO Executor: Finished task 2.0 in stage 78.0 (TID 149). 2371 bytes result sent to driver
19/07/31 17:06:20 INFO TaskSetManager: Finished task 3.0 in stage 78.0 (TID 150) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:06:20 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 148) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:06:20 INFO TaskSetManager: Finished task 2.0 in stage 78.0 (TID 149) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:06:20 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
19/07/31 17:06:20 INFO DAGScheduler: ResultStage 78 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:06:20 INFO DAGScheduler: Job 52 finished: collect at utils.scala:204, took 0.023796 s
19/07/31 17:06:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_193`) `dbplyr_194`
ORDER BY `date`) `dbplyr_195`) `dbplyr_196`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_197`) `dbplyr_198`
ORDER BY `date`) `dbplyr_199`) `dbplyr_200`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:21 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2794 - cust_prospect_ind.nullCount#2793) > 0)
19/07/31 17:06:21 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2799 - visit_device_type.nullCount#2798) > 0)
19/07/31 17:06:21 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#2792 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#2791))
19/07/31 17:06:21 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#2797 <= All Devices) && (All Devices <= visit_device_type.upperBound#2796))
19/07/31 17:06:21 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:21 INFO DAGScheduler: Got job 53 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:21 INFO DAGScheduler: Final stage: ResultStage 79 (collect at utils.scala:204)
19/07/31 17:06:21 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:21 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:21 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[248] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:21 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 72.1 KB, free 909.8 MB)
19/07/31 17:06:21 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 30.4 KB, free 909.7 MB)
19/07/31 17:06:21 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:53890 (size: 30.4 KB, free: 911.7 MB)
19/07/31 17:06:21 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[248] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:21 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks
19/07/31 17:06:21 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 151, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:21 INFO Executor: Running task 0.0 in stage 79.0 (TID 151)
19/07/31 17:06:21 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:21 INFO Executor: Finished task 0.0 in stage 79.0 (TID 151). 7542 bytes result sent to driver
19/07/31 17:06:21 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 151) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:06:21 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
19/07/31 17:06:21 INFO DAGScheduler: ResultStage 79 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:21 INFO DAGScheduler: Job 53 finished: collect at utils.scala:204, took 0.008738 s
19/07/31 17:06:21 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:21 INFO DAGScheduler: Registering RDD 249 (collect at utils.scala:204)
19/07/31 17:06:21 INFO DAGScheduler: Got job 54 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:21 INFO DAGScheduler: Final stage: ResultStage 81 (collect at utils.scala:204)
19/07/31 17:06:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 80)
19/07/31 17:06:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 80)
19/07/31 17:06:21 INFO DAGScheduler: Submitting ShuffleMapStage 80 (MapPartitionsRDD[249] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:21 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 74.5 KB, free 909.7 MB)
19/07/31 17:06:21 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 31.7 KB, free 909.6 MB)
19/07/31 17:06:21 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:53890 (size: 31.7 KB, free: 911.7 MB)
19/07/31 17:06:21 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 80 (MapPartitionsRDD[249] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:21 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks
19/07/31 17:06:21 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 152, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:21 INFO Executor: Running task 0.0 in stage 80.0 (TID 152)
19/07/31 17:06:21 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:21 INFO Executor: Finished task 0.0 in stage 80.0 (TID 152). 1687 bytes result sent to driver
19/07/31 17:06:21 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 152) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:06:21 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
19/07/31 17:06:21 INFO DAGScheduler: ShuffleMapStage 80 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:21 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:21 INFO DAGScheduler: running: Set()
19/07/31 17:06:21 INFO DAGScheduler: waiting: Set(ResultStage 81)
19/07/31 17:06:21 INFO DAGScheduler: failed: Set()
19/07/31 17:06:21 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[252] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:21 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 16.8 KB, free 909.6 MB)
19/07/31 17:06:21 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.6 MB)
19/07/31 17:06:21 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:06:21 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:21 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 81 (MapPartitionsRDD[252] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:21 INFO TaskSchedulerImpl: Adding task set 81.0 with 4 tasks
19/07/31 17:06:21 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 153, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:21 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 154, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:21 INFO TaskSetManager: Starting task 2.0 in stage 81.0 (TID 155, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:21 INFO TaskSetManager: Starting task 3.0 in stage 81.0 (TID 156, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:21 INFO Executor: Running task 1.0 in stage 81.0 (TID 154)
19/07/31 17:06:21 INFO Executor: Running task 0.0 in stage 81.0 (TID 153)
19/07/31 17:06:21 INFO Executor: Running task 2.0 in stage 81.0 (TID 155)
19/07/31 17:06:21 INFO Executor: Running task 3.0 in stage 81.0 (TID 156)
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:21 INFO Executor: Finished task 1.0 in stage 81.0 (TID 154). 2403 bytes result sent to driver
19/07/31 17:06:21 INFO Executor: Finished task 2.0 in stage 81.0 (TID 155). 2390 bytes result sent to driver
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/07/31 17:06:21 INFO Executor: Finished task 3.0 in stage 81.0 (TID 156). 2362 bytes result sent to driver
19/07/31 17:06:21 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 154) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:06:21 INFO TaskSetManager: Finished task 2.0 in stage 81.0 (TID 155) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:06:21 INFO TaskSetManager: Finished task 3.0 in stage 81.0 (TID 156) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:06:21 INFO Executor: Finished task 0.0 in stage 81.0 (TID 153). 2382 bytes result sent to driver
19/07/31 17:06:21 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 153) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:06:21 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
19/07/31 17:06:21 INFO DAGScheduler: ResultStage 81 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:06:21 INFO DAGScheduler: Job 54 finished: collect at utils.scala:204, took 0.021544 s
19/07/31 17:06:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_201`) `dbplyr_202`
ORDER BY `date`) `dbplyr_203`) `dbplyr_204`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_205`) `dbplyr_206`
ORDER BY `date`) `dbplyr_207`) `dbplyr_208`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:21 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2892 - cust_prospect_ind.nullCount#2891) > 0)
19/07/31 17:06:21 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2897 - visit_device_type.nullCount#2896) > 0)
19/07/31 17:06:21 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#2890 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#2889))
19/07/31 17:06:21 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#2895 <= All Devices) && (All Devices <= visit_device_type.upperBound#2894))
19/07/31 17:06:21 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:21 INFO DAGScheduler: Got job 55 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:21 INFO DAGScheduler: Final stage: ResultStage 82 (collect at utils.scala:204)
19/07/31 17:06:21 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:21 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:21 INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[257] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:21 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 72.1 KB, free 909.5 MB)
19/07/31 17:06:21 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.5 MB)
19/07/31 17:06:21 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 911.6 MB)
19/07/31 17:06:21 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[257] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:21 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks
19/07/31 17:06:21 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 157, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:21 INFO Executor: Running task 0.0 in stage 82.0 (TID 157)
19/07/31 17:06:21 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:21 INFO Executor: Finished task 0.0 in stage 82.0 (TID 157). 7542 bytes result sent to driver
19/07/31 17:06:21 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 157) in 13 ms on localhost (executor driver) (1/1)
19/07/31 17:06:21 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
19/07/31 17:06:21 INFO DAGScheduler: ResultStage 82 (collect at utils.scala:204) finished in 0.013 s
19/07/31 17:06:21 INFO DAGScheduler: Job 55 finished: collect at utils.scala:204, took 0.018372 s
19/07/31 17:06:21 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:21 INFO DAGScheduler: Registering RDD 258 (collect at utils.scala:204)
19/07/31 17:06:21 INFO DAGScheduler: Got job 56 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:21 INFO DAGScheduler: Final stage: ResultStage 84 (collect at utils.scala:204)
19/07/31 17:06:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 83)
19/07/31 17:06:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 83)
19/07/31 17:06:21 INFO DAGScheduler: Submitting ShuffleMapStage 83 (MapPartitionsRDD[258] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:21 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 74.5 KB, free 909.4 MB)
19/07/31 17:06:21 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.4 MB)
19/07/31 17:06:21 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.6 MB)
19/07/31 17:06:21 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 83 (MapPartitionsRDD[258] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:21 INFO TaskSchedulerImpl: Adding task set 83.0 with 1 tasks
19/07/31 17:06:21 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 158, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:21 INFO Executor: Running task 0.0 in stage 83.0 (TID 158)
19/07/31 17:06:21 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:21 INFO Executor: Finished task 0.0 in stage 83.0 (TID 158). 1687 bytes result sent to driver
19/07/31 17:06:21 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 158) in 11 ms on localhost (executor driver) (1/1)
19/07/31 17:06:21 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
19/07/31 17:06:21 INFO DAGScheduler: ShuffleMapStage 83 (collect at utils.scala:204) finished in 0.013 s
19/07/31 17:06:21 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:21 INFO DAGScheduler: running: Set()
19/07/31 17:06:21 INFO DAGScheduler: waiting: Set(ResultStage 84)
19/07/31 17:06:21 INFO DAGScheduler: failed: Set()
19/07/31 17:06:21 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[261] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:21 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 16.8 KB, free 909.4 MB)
19/07/31 17:06:21 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.4 MB)
19/07/31 17:06:21 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.6 MB)
19/07/31 17:06:21 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:21 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 84 (MapPartitionsRDD[261] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:21 INFO TaskSchedulerImpl: Adding task set 84.0 with 4 tasks
19/07/31 17:06:21 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 159, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:21 INFO TaskSetManager: Starting task 1.0 in stage 84.0 (TID 160, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:21 INFO TaskSetManager: Starting task 2.0 in stage 84.0 (TID 161, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:21 INFO TaskSetManager: Starting task 3.0 in stage 84.0 (TID 162, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:21 INFO Executor: Running task 0.0 in stage 84.0 (TID 159)
19/07/31 17:06:21 INFO Executor: Running task 1.0 in stage 84.0 (TID 160)
19/07/31 17:06:21 INFO Executor: Running task 2.0 in stage 84.0 (TID 161)
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:21 INFO Executor: Running task 3.0 in stage 84.0 (TID 162)
19/07/31 17:06:21 INFO Executor: Finished task 0.0 in stage 84.0 (TID 159). 2382 bytes result sent to driver
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:21 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 159) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:06:21 INFO Executor: Finished task 3.0 in stage 84.0 (TID 162). 2362 bytes result sent to driver
19/07/31 17:06:21 INFO Executor: Finished task 1.0 in stage 84.0 (TID 160). 2403 bytes result sent to driver
19/07/31 17:06:21 INFO Executor: Finished task 2.0 in stage 84.0 (TID 161). 2390 bytes result sent to driver
19/07/31 17:06:21 INFO TaskSetManager: Finished task 3.0 in stage 84.0 (TID 162) in 8 ms on localhost (executor driver) (2/4)
19/07/31 17:06:21 INFO TaskSetManager: Finished task 1.0 in stage 84.0 (TID 160) in 9 ms on localhost (executor driver) (3/4)
19/07/31 17:06:21 INFO TaskSetManager: Finished task 2.0 in stage 84.0 (TID 161) in 10 ms on localhost (executor driver) (4/4)
19/07/31 17:06:21 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
19/07/31 17:06:21 INFO DAGScheduler: ResultStage 84 (collect at utils.scala:204) finished in 0.011 s
19/07/31 17:06:21 INFO DAGScheduler: Job 56 finished: collect at utils.scala:204, took 0.034914 s
19/07/31 17:06:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_209`) `dbplyr_210`
ORDER BY `date`) `dbplyr_211`) `dbplyr_212`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Mobile Phone"))
19/07/31 17:06:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_213`) `dbplyr_214`
ORDER BY `date`) `dbplyr_215`) `dbplyr_216`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Mobile Phone"))
19/07/31 17:06:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:21 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2990 - cust_prospect_ind.nullCount#2989) > 0)
19/07/31 17:06:21 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2995 - visit_device_type.nullCount#2994) > 0)
19/07/31 17:06:21 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#2988 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#2987))
19/07/31 17:06:21 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#2993 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#2992))
19/07/31 17:06:21 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:21 INFO DAGScheduler: Got job 57 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:21 INFO DAGScheduler: Final stage: ResultStage 85 (collect at utils.scala:204)
19/07/31 17:06:21 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:21 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:21 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[266] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:21 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 72.1 KB, free 909.3 MB)
19/07/31 17:06:21 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 30.4 KB, free 909.3 MB)
19/07/31 17:06:21 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:53890 (size: 30.4 KB, free: 911.6 MB)
19/07/31 17:06:21 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[266] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:21 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks
19/07/31 17:06:21 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 163, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:21 INFO Executor: Running task 0.0 in stage 85.0 (TID 163)
19/07/31 17:06:21 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:21 INFO Executor: Finished task 0.0 in stage 85.0 (TID 163). 6979 bytes result sent to driver
19/07/31 17:06:21 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 163) in 10 ms on localhost (executor driver) (1/1)
19/07/31 17:06:21 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
19/07/31 17:06:21 INFO DAGScheduler: ResultStage 85 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:06:21 INFO DAGScheduler: Job 57 finished: collect at utils.scala:204, took 0.015396 s
19/07/31 17:06:21 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:21 INFO DAGScheduler: Registering RDD 267 (collect at utils.scala:204)
19/07/31 17:06:21 INFO DAGScheduler: Got job 58 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:21 INFO DAGScheduler: Final stage: ResultStage 87 (collect at utils.scala:204)
19/07/31 17:06:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 86)
19/07/31 17:06:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 86)
19/07/31 17:06:21 INFO DAGScheduler: Submitting ShuffleMapStage 86 (MapPartitionsRDD[267] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:21 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 74.5 KB, free 909.2 MB)
19/07/31 17:06:21 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 31.7 KB, free 909.2 MB)
19/07/31 17:06:21 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:53890 (size: 31.7 KB, free: 911.5 MB)
19/07/31 17:06:21 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 86 (MapPartitionsRDD[267] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:21 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks
19/07/31 17:06:21 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 164, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:21 INFO Executor: Running task 0.0 in stage 86.0 (TID 164)
19/07/31 17:06:21 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:21 INFO Executor: Finished task 0.0 in stage 86.0 (TID 164). 1687 bytes result sent to driver
19/07/31 17:06:21 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 164) in 11 ms on localhost (executor driver) (1/1)
19/07/31 17:06:21 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
19/07/31 17:06:21 INFO DAGScheduler: ShuffleMapStage 86 (collect at utils.scala:204) finished in 0.011 s
19/07/31 17:06:21 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:21 INFO DAGScheduler: running: Set()
19/07/31 17:06:21 INFO DAGScheduler: waiting: Set(ResultStage 87)
19/07/31 17:06:21 INFO DAGScheduler: failed: Set()
19/07/31 17:06:21 INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[270] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:21 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 16.8 KB, free 909.2 MB)
19/07/31 17:06:21 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.2 MB)
19/07/31 17:06:21 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.5 MB)
19/07/31 17:06:21 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:21 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 87 (MapPartitionsRDD[270] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:21 INFO TaskSchedulerImpl: Adding task set 87.0 with 4 tasks
19/07/31 17:06:21 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 165, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:21 INFO TaskSetManager: Starting task 1.0 in stage 87.0 (TID 166, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:21 INFO TaskSetManager: Starting task 2.0 in stage 87.0 (TID 167, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:21 INFO TaskSetManager: Starting task 3.0 in stage 87.0 (TID 168, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:21 INFO Executor: Running task 0.0 in stage 87.0 (TID 165)
19/07/31 17:06:21 INFO Executor: Running task 1.0 in stage 87.0 (TID 166)
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
19/07/31 17:06:21 INFO Executor: Finished task 0.0 in stage 87.0 (TID 165). 2373 bytes result sent to driver
19/07/31 17:06:21 INFO Executor: Running task 3.0 in stage 87.0 (TID 168)
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:21 INFO Executor: Finished task 3.0 in stage 87.0 (TID 168). 2353 bytes result sent to driver
19/07/31 17:06:21 INFO Executor: Finished task 1.0 in stage 87.0 (TID 166). 2370 bytes result sent to driver
19/07/31 17:06:21 INFO Executor: Running task 2.0 in stage 87.0 (TID 167)
19/07/31 17:06:21 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 165) in 14 ms on localhost (executor driver) (1/4)
19/07/31 17:06:21 INFO TaskSetManager: Finished task 1.0 in stage 87.0 (TID 166) in 13 ms on localhost (executor driver) (2/4)
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:21 INFO TaskSetManager: Finished task 3.0 in stage 87.0 (TID 168) in 13 ms on localhost (executor driver) (3/4)
19/07/31 17:06:21 INFO Executor: Finished task 2.0 in stage 87.0 (TID 167). 2384 bytes result sent to driver
19/07/31 17:06:21 INFO TaskSetManager: Finished task 2.0 in stage 87.0 (TID 167) in 15 ms on localhost (executor driver) (4/4)
19/07/31 17:06:21 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
19/07/31 17:06:21 INFO DAGScheduler: ResultStage 87 (collect at utils.scala:204) finished in 0.016 s
19/07/31 17:06:21 INFO DAGScheduler: Job 58 finished: collect at utils.scala:204, took 0.036787 s
19/07/31 17:06:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_217`) `dbplyr_218`
ORDER BY `date`) `dbplyr_219`) `dbplyr_220`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_221`) `dbplyr_222`
ORDER BY `date`) `dbplyr_223`) `dbplyr_224`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:22 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:22 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:22 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3088 - cust_prospect_ind.nullCount#3087) > 0)
19/07/31 17:06:22 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3093 - visit_device_type.nullCount#3092) > 0)
19/07/31 17:06:22 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#3086 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#3085))
19/07/31 17:06:22 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#3091 <= All Devices) && (All Devices <= visit_device_type.upperBound#3090))
19/07/31 17:06:22 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:22 INFO DAGScheduler: Got job 59 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:22 INFO DAGScheduler: Final stage: ResultStage 88 (collect at utils.scala:204)
19/07/31 17:06:22 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:22 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:22 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[275] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 72.1 KB, free 909.1 MB)
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 30.4 KB, free 909.1 MB)
19/07/31 17:06:22 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:53890 (size: 30.4 KB, free: 911.5 MB)
19/07/31 17:06:22 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[275] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:22 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks
19/07/31 17:06:22 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 169, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:22 INFO Executor: Running task 0.0 in stage 88.0 (TID 169)
19/07/31 17:06:22 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:22 INFO Executor: Finished task 0.0 in stage 88.0 (TID 169). 7542 bytes result sent to driver
19/07/31 17:06:22 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 169) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:06:22 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
19/07/31 17:06:22 INFO DAGScheduler: ResultStage 88 (collect at utils.scala:204) finished in 0.004 s
19/07/31 17:06:22 INFO DAGScheduler: Job 59 finished: collect at utils.scala:204, took 0.007900 s
19/07/31 17:06:22 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:22 INFO DAGScheduler: Registering RDD 276 (collect at utils.scala:204)
19/07/31 17:06:22 INFO DAGScheduler: Got job 60 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:22 INFO DAGScheduler: Final stage: ResultStage 90 (collect at utils.scala:204)
19/07/31 17:06:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 89)
19/07/31 17:06:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 89)
19/07/31 17:06:22 INFO DAGScheduler: Submitting ShuffleMapStage 89 (MapPartitionsRDD[276] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 74.5 KB, free 909.0 MB)
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.0 MB)
19/07/31 17:06:22 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.5 MB)
19/07/31 17:06:22 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 89 (MapPartitionsRDD[276] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:22 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks
19/07/31 17:06:22 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 170, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:22 INFO Executor: Running task 0.0 in stage 89.0 (TID 170)
19/07/31 17:06:22 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:22 INFO Executor: Finished task 0.0 in stage 89.0 (TID 170). 1687 bytes result sent to driver
19/07/31 17:06:22 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 170) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:06:22 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
19/07/31 17:06:22 INFO DAGScheduler: ShuffleMapStage 89 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:06:22 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:22 INFO DAGScheduler: running: Set()
19/07/31 17:06:22 INFO DAGScheduler: waiting: Set(ResultStage 90)
19/07/31 17:06:22 INFO DAGScheduler: failed: Set()
19/07/31 17:06:22 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[279] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 16.8 KB, free 908.9 MB)
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 8.0 KB, free 908.9 MB)
19/07/31 17:06:22 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.5 MB)
19/07/31 17:06:22 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 90 (MapPartitionsRDD[279] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:22 INFO TaskSchedulerImpl: Adding task set 90.0 with 4 tasks
19/07/31 17:06:22 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 171, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:22 INFO TaskSetManager: Starting task 1.0 in stage 90.0 (TID 172, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:22 INFO TaskSetManager: Starting task 2.0 in stage 90.0 (TID 173, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:22 INFO TaskSetManager: Starting task 3.0 in stage 90.0 (TID 174, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:22 INFO Executor: Running task 3.0 in stage 90.0 (TID 174)
19/07/31 17:06:22 INFO Executor: Running task 1.0 in stage 90.0 (TID 172)
19/07/31 17:06:22 INFO Executor: Running task 2.0 in stage 90.0 (TID 173)
19/07/31 17:06:22 INFO Executor: Running task 0.0 in stage 90.0 (TID 171)
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:22 INFO Executor: Finished task 0.0 in stage 90.0 (TID 171). 2382 bytes result sent to driver
19/07/31 17:06:22 INFO Executor: Finished task 2.0 in stage 90.0 (TID 173). 2390 bytes result sent to driver
19/07/31 17:06:22 INFO Executor: Finished task 1.0 in stage 90.0 (TID 172). 2403 bytes result sent to driver
19/07/31 17:06:22 INFO Executor: Finished task 3.0 in stage 90.0 (TID 174). 2362 bytes result sent to driver
19/07/31 17:06:22 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 171) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:06:22 INFO TaskSetManager: Finished task 2.0 in stage 90.0 (TID 173) in 4 ms on localhost (executor driver) (2/4)
19/07/31 17:06:22 INFO TaskSetManager: Finished task 3.0 in stage 90.0 (TID 174) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:06:22 INFO TaskSetManager: Finished task 1.0 in stage 90.0 (TID 172) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:06:22 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
19/07/31 17:06:22 INFO DAGScheduler: ResultStage 90 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:22 INFO DAGScheduler: Job 60 finished: collect at utils.scala:204, took 0.019692 s
19/07/31 17:06:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_225`) `dbplyr_226`
ORDER BY `date`) `dbplyr_227`) `dbplyr_228`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:22 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:22 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_229`) `dbplyr_230`
ORDER BY `date`) `dbplyr_231`) `dbplyr_232`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:22 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:22 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:22 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3186 - cust_prospect_ind.nullCount#3185) > 0)
19/07/31 17:06:22 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3191 - visit_device_type.nullCount#3190) > 0)
19/07/31 17:06:22 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#3184 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#3183))
19/07/31 17:06:22 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#3189 <= All Devices) && (All Devices <= visit_device_type.upperBound#3188))
19/07/31 17:06:22 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:22 INFO DAGScheduler: Got job 61 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:22 INFO DAGScheduler: Final stage: ResultStage 91 (collect at utils.scala:204)
19/07/31 17:06:22 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:22 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:22 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[284] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 72.1 KB, free 908.9 MB)
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 30.5 KB, free 908.8 MB)
19/07/31 17:06:22 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 911.4 MB)
19/07/31 17:06:22 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[284] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:22 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks
19/07/31 17:06:22 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 175, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:22 INFO Executor: Running task 0.0 in stage 91.0 (TID 175)
19/07/31 17:06:22 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:22 INFO Executor: Finished task 0.0 in stage 91.0 (TID 175). 7542 bytes result sent to driver
19/07/31 17:06:22 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 175) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:06:22 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
19/07/31 17:06:22 INFO DAGScheduler: ResultStage 91 (collect at utils.scala:204) finished in 0.004 s
19/07/31 17:06:22 INFO DAGScheduler: Job 61 finished: collect at utils.scala:204, took 0.007917 s
19/07/31 17:06:22 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:22 INFO DAGScheduler: Registering RDD 285 (collect at utils.scala:204)
19/07/31 17:06:22 INFO DAGScheduler: Got job 62 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:22 INFO DAGScheduler: Final stage: ResultStage 93 (collect at utils.scala:204)
19/07/31 17:06:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 92)
19/07/31 17:06:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 92)
19/07/31 17:06:22 INFO DAGScheduler: Submitting ShuffleMapStage 92 (MapPartitionsRDD[285] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 74.5 KB, free 908.8 MB)
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 31.8 KB, free 908.7 MB)
19/07/31 17:06:22 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.4 MB)
19/07/31 17:06:22 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 92 (MapPartitionsRDD[285] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:22 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks
19/07/31 17:06:22 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 176, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:22 INFO Executor: Running task 0.0 in stage 92.0 (TID 176)
19/07/31 17:06:22 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:22 INFO Executor: Finished task 0.0 in stage 92.0 (TID 176). 1687 bytes result sent to driver
19/07/31 17:06:22 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 176) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:06:22 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
19/07/31 17:06:22 INFO DAGScheduler: ShuffleMapStage 92 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:22 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:22 INFO DAGScheduler: running: Set()
19/07/31 17:06:22 INFO DAGScheduler: waiting: Set(ResultStage 93)
19/07/31 17:06:22 INFO DAGScheduler: failed: Set()
19/07/31 17:06:22 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[288] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 16.8 KB, free 908.7 MB)
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 8.0 KB, free 908.7 MB)
19/07/31 17:06:22 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.4 MB)
19/07/31 17:06:22 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 93 (MapPartitionsRDD[288] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:22 INFO TaskSchedulerImpl: Adding task set 93.0 with 4 tasks
19/07/31 17:06:22 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 177, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:22 INFO TaskSetManager: Starting task 1.0 in stage 93.0 (TID 178, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:22 INFO TaskSetManager: Starting task 2.0 in stage 93.0 (TID 179, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:22 INFO TaskSetManager: Starting task 3.0 in stage 93.0 (TID 180, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:22 INFO Executor: Running task 1.0 in stage 93.0 (TID 178)
19/07/31 17:06:22 INFO Executor: Running task 0.0 in stage 93.0 (TID 177)
19/07/31 17:06:22 INFO Executor: Running task 3.0 in stage 93.0 (TID 180)
19/07/31 17:06:22 INFO Executor: Running task 2.0 in stage 93.0 (TID 179)
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:22 INFO Executor: Finished task 0.0 in stage 93.0 (TID 177). 2382 bytes result sent to driver
19/07/31 17:06:22 INFO Executor: Finished task 3.0 in stage 93.0 (TID 180). 2362 bytes result sent to driver
19/07/31 17:06:22 INFO Executor: Finished task 2.0 in stage 93.0 (TID 179). 2390 bytes result sent to driver
19/07/31 17:06:22 INFO Executor: Finished task 1.0 in stage 93.0 (TID 178). 2403 bytes result sent to driver
19/07/31 17:06:22 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 177) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:06:22 INFO TaskSetManager: Finished task 3.0 in stage 93.0 (TID 180) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:06:22 INFO TaskSetManager: Finished task 2.0 in stage 93.0 (TID 179) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:06:22 INFO TaskSetManager: Finished task 1.0 in stage 93.0 (TID 178) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:06:22 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
19/07/31 17:06:22 INFO DAGScheduler: ResultStage 93 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:06:22 INFO DAGScheduler: Job 62 finished: collect at utils.scala:204, took 0.019624 s
19/07/31 17:06:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_233`) `dbplyr_234`
ORDER BY `date`) `dbplyr_235`) `dbplyr_236`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 17:06:22 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:22 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_237`) `dbplyr_238`
ORDER BY `date`) `dbplyr_239`) `dbplyr_240`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 17:06:22 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:22 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:22 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3284 - cust_prospect_ind.nullCount#3283) > 0)
19/07/31 17:06:22 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3289 - visit_device_type.nullCount#3288) > 0)
19/07/31 17:06:22 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#3282 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#3281))
19/07/31 17:06:22 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#3287 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#3286))
19/07/31 17:06:22 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:22 INFO DAGScheduler: Got job 63 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:22 INFO DAGScheduler: Final stage: ResultStage 94 (collect at utils.scala:204)
19/07/31 17:06:22 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:22 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:22 INFO DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[293] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 72.1 KB, free 908.6 MB)
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 30.4 KB, free 908.6 MB)
19/07/31 17:06:22 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 127.0.0.1:53890 (size: 30.4 KB, free: 911.4 MB)
19/07/31 17:06:22 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[293] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:22 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks
19/07/31 17:06:22 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 181, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:22 INFO Executor: Running task 0.0 in stage 94.0 (TID 181)
19/07/31 17:06:22 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:22 INFO Executor: Finished task 0.0 in stage 94.0 (TID 181). 7542 bytes result sent to driver
19/07/31 17:06:22 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 181) in 3 ms on localhost (executor driver) (1/1)
19/07/31 17:06:22 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
19/07/31 17:06:22 INFO DAGScheduler: ResultStage 94 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:22 INFO DAGScheduler: Job 63 finished: collect at utils.scala:204, took 0.008072 s
19/07/31 17:06:22 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:22 INFO DAGScheduler: Registering RDD 294 (collect at utils.scala:204)
19/07/31 17:06:22 INFO DAGScheduler: Got job 64 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:22 INFO DAGScheduler: Final stage: ResultStage 96 (collect at utils.scala:204)
19/07/31 17:06:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 95)
19/07/31 17:06:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 95)
19/07/31 17:06:22 INFO DAGScheduler: Submitting ShuffleMapStage 95 (MapPartitionsRDD[294] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 74.6 KB, free 908.5 MB)
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 31.7 KB, free 908.5 MB)
19/07/31 17:06:22 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 127.0.0.1:53890 (size: 31.7 KB, free: 911.3 MB)
19/07/31 17:06:22 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 95 (MapPartitionsRDD[294] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:22 INFO TaskSchedulerImpl: Adding task set 95.0 with 1 tasks
19/07/31 17:06:22 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 182, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:22 INFO Executor: Running task 0.0 in stage 95.0 (TID 182)
19/07/31 17:06:22 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:22 INFO Executor: Finished task 0.0 in stage 95.0 (TID 182). 1687 bytes result sent to driver
19/07/31 17:06:22 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 182) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:06:22 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
19/07/31 17:06:22 INFO DAGScheduler: ShuffleMapStage 95 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:06:22 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:22 INFO DAGScheduler: running: Set()
19/07/31 17:06:22 INFO DAGScheduler: waiting: Set(ResultStage 96)
19/07/31 17:06:22 INFO DAGScheduler: failed: Set()
19/07/31 17:06:22 INFO DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[297] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 16.8 KB, free 908.5 MB)
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 8.0 KB, free 908.5 MB)
19/07/31 17:06:22 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.3 MB)
19/07/31 17:06:22 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 96 (MapPartitionsRDD[297] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:22 INFO TaskSchedulerImpl: Adding task set 96.0 with 4 tasks
19/07/31 17:06:22 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 183, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:22 INFO TaskSetManager: Starting task 1.0 in stage 96.0 (TID 184, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:22 INFO TaskSetManager: Starting task 2.0 in stage 96.0 (TID 185, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:22 INFO TaskSetManager: Starting task 3.0 in stage 96.0 (TID 186, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:22 INFO Executor: Running task 0.0 in stage 96.0 (TID 183)
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:22 INFO Executor: Finished task 0.0 in stage 96.0 (TID 183). 2377 bytes result sent to driver
19/07/31 17:06:22 INFO Executor: Running task 1.0 in stage 96.0 (TID 184)
19/07/31 17:06:22 INFO Executor: Running task 2.0 in stage 96.0 (TID 185)
19/07/31 17:06:22 INFO Executor: Running task 3.0 in stage 96.0 (TID 186)
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:22 INFO Executor: Finished task 1.0 in stage 96.0 (TID 184). 2339 bytes result sent to driver
19/07/31 17:06:22 INFO Executor: Finished task 3.0 in stage 96.0 (TID 186). 2356 bytes result sent to driver
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:22 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 183) in 10 ms on localhost (executor driver) (1/4)
19/07/31 17:06:22 INFO TaskSetManager: Finished task 1.0 in stage 96.0 (TID 184) in 10 ms on localhost (executor driver) (2/4)
19/07/31 17:06:22 INFO TaskSetManager: Finished task 3.0 in stage 96.0 (TID 186) in 10 ms on localhost (executor driver) (3/4)
19/07/31 17:06:22 INFO Executor: Finished task 2.0 in stage 96.0 (TID 185). 2377 bytes result sent to driver
19/07/31 17:06:22 INFO TaskSetManager: Finished task 2.0 in stage 96.0 (TID 185) in 11 ms on localhost (executor driver) (4/4)
19/07/31 17:06:22 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
19/07/31 17:06:22 INFO DAGScheduler: ResultStage 96 (collect at utils.scala:204) finished in 0.011 s
19/07/31 17:06:22 INFO DAGScheduler: Job 64 finished: collect at utils.scala:204, took 0.028888 s
19/07/31 17:06:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_241`) `dbplyr_242`
ORDER BY `date`) `dbplyr_243`) `dbplyr_244`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:22 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:22 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_245`) `dbplyr_246`
ORDER BY `date`) `dbplyr_247`) `dbplyr_248`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:22 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:22 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:22 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3382 - cust_prospect_ind.nullCount#3381) > 0)
19/07/31 17:06:22 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3387 - visit_device_type.nullCount#3386) > 0)
19/07/31 17:06:22 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#3380 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#3379))
19/07/31 17:06:22 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#3385 <= All Devices) && (All Devices <= visit_device_type.upperBound#3384))
19/07/31 17:06:22 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:22 INFO DAGScheduler: Got job 65 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:22 INFO DAGScheduler: Final stage: ResultStage 97 (collect at utils.scala:204)
19/07/31 17:06:22 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:22 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:22 INFO DAGScheduler: Submitting ResultStage 97 (MapPartitionsRDD[302] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 72.1 KB, free 908.4 MB)
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 30.5 KB, free 908.4 MB)
19/07/31 17:06:22 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 911.3 MB)
19/07/31 17:06:22 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 97 (MapPartitionsRDD[302] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:22 INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks
19/07/31 17:06:22 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 187, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:22 INFO Executor: Running task 0.0 in stage 97.0 (TID 187)
19/07/31 17:06:22 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:22 INFO Executor: Finished task 0.0 in stage 97.0 (TID 187). 7542 bytes result sent to driver
19/07/31 17:06:22 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 187) in 3 ms on localhost (executor driver) (1/1)
19/07/31 17:06:22 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
19/07/31 17:06:22 INFO DAGScheduler: ResultStage 97 (collect at utils.scala:204) finished in 0.003 s
19/07/31 17:06:22 INFO DAGScheduler: Job 65 finished: collect at utils.scala:204, took 0.008006 s
19/07/31 17:06:22 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:22 INFO DAGScheduler: Registering RDD 303 (collect at utils.scala:204)
19/07/31 17:06:22 INFO DAGScheduler: Got job 66 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:22 INFO DAGScheduler: Final stage: ResultStage 99 (collect at utils.scala:204)
19/07/31 17:06:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 98)
19/07/31 17:06:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 98)
19/07/31 17:06:22 INFO DAGScheduler: Submitting ShuffleMapStage 98 (MapPartitionsRDD[303] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 74.5 KB, free 908.3 MB)
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 31.8 KB, free 908.3 MB)
19/07/31 17:06:22 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.3 MB)
19/07/31 17:06:22 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 98 (MapPartitionsRDD[303] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:22 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks
19/07/31 17:06:22 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 188, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:22 INFO Executor: Running task 0.0 in stage 98.0 (TID 188)
19/07/31 17:06:22 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:22 INFO Executor: Finished task 0.0 in stage 98.0 (TID 188). 1687 bytes result sent to driver
19/07/31 17:06:22 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 188) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:06:22 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
19/07/31 17:06:22 INFO DAGScheduler: ShuffleMapStage 98 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:22 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:22 INFO DAGScheduler: running: Set()
19/07/31 17:06:22 INFO DAGScheduler: waiting: Set(ResultStage 99)
19/07/31 17:06:22 INFO DAGScheduler: failed: Set()
19/07/31 17:06:22 INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[306] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 16.8 KB, free 908.3 MB)
19/07/31 17:06:22 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 8.0 KB, free 908.3 MB)
19/07/31 17:06:22 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.2 MB)
19/07/31 17:06:22 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 99 (MapPartitionsRDD[306] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:22 INFO TaskSchedulerImpl: Adding task set 99.0 with 4 tasks
19/07/31 17:06:22 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 189, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:22 INFO TaskSetManager: Starting task 1.0 in stage 99.0 (TID 190, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:22 INFO TaskSetManager: Starting task 2.0 in stage 99.0 (TID 191, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:22 INFO TaskSetManager: Starting task 3.0 in stage 99.0 (TID 192, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:22 INFO Executor: Running task 2.0 in stage 99.0 (TID 191)
19/07/31 17:06:22 INFO Executor: Running task 3.0 in stage 99.0 (TID 192)
19/07/31 17:06:22 INFO Executor: Running task 0.0 in stage 99.0 (TID 189)
19/07/31 17:06:22 INFO Executor: Running task 1.0 in stage 99.0 (TID 190)
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:22 INFO Executor: Finished task 0.0 in stage 99.0 (TID 189). 2382 bytes result sent to driver
19/07/31 17:06:22 INFO Executor: Finished task 1.0 in stage 99.0 (TID 190). 2403 bytes result sent to driver
19/07/31 17:06:22 INFO Executor: Finished task 2.0 in stage 99.0 (TID 191). 2390 bytes result sent to driver
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
19/07/31 17:06:22 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 189) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:06:22 INFO TaskSetManager: Finished task 1.0 in stage 99.0 (TID 190) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:06:22 INFO TaskSetManager: Finished task 2.0 in stage 99.0 (TID 191) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:06:22 INFO Executor: Finished task 3.0 in stage 99.0 (TID 192). 2362 bytes result sent to driver
19/07/31 17:06:22 INFO TaskSetManager: Finished task 3.0 in stage 99.0 (TID 192) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:06:22 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
19/07/31 17:06:22 INFO DAGScheduler: ResultStage 99 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:22 INFO DAGScheduler: Job 66 finished: collect at utils.scala:204, took 0.023594 s
19/07/31 17:06:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_249`) `dbplyr_250`
ORDER BY `date`) `dbplyr_251`) `dbplyr_252`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:22 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:22 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_253`) `dbplyr_254`
ORDER BY `date`) `dbplyr_255`) `dbplyr_256`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:22 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:22 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:22 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3480 - cust_prospect_ind.nullCount#3479) > 0)
19/07/31 17:06:22 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3485 - visit_device_type.nullCount#3484) > 0)
19/07/31 17:06:22 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#3478 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#3477))
19/07/31 17:06:22 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#3483 <= All Devices) && (All Devices <= visit_device_type.upperBound#3482))
19/07/31 17:06:23 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:23 INFO DAGScheduler: Got job 67 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:23 INFO DAGScheduler: Final stage: ResultStage 100 (collect at utils.scala:204)
19/07/31 17:06:23 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:23 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:23 INFO DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[311] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 72.1 KB, free 908.2 MB)
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 30.5 KB, free 908.1 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 911.2 MB)
19/07/31 17:06:23 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[311] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:23 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks
19/07/31 17:06:23 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 193, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:23 INFO Executor: Running task 0.0 in stage 100.0 (TID 193)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2423
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 127.0.0.1:53890 in memory (size: 31.7 KB, free: 911.2 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2512
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2342
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2508
19/07/31 17:06:23 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 911.3 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2264
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2269
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2180
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 911.3 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2590
19/07/31 17:06:23 INFO Executor: Finished task 0.0 in stage 100.0 (TID 193). 7585 bytes result sent to driver
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.3 MB)
19/07/31 17:06:23 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 193) in 13 ms on localhost (executor driver) (1/1)
19/07/31 17:06:23 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 911.3 MB)
19/07/31 17:06:23 INFO DAGScheduler: ResultStage 100 (collect at utils.scala:204) finished in 0.013 s
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2263
19/07/31 17:06:23 INFO DAGScheduler: Job 67 finished: collect at utils.scala:204, took 0.018572 s
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2425
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 1694
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 911.4 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:53890 in memory (size: 31.7 KB, free: 911.4 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 1942
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2099
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 127.0.0.1:53890 in memory (size: 30.4 KB, free: 911.4 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2666
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:53890 in memory (size: 31.7 KB, free: 911.5 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:53890 in memory (size: 31.7 KB, free: 911.5 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2585
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2504
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 911.5 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2267
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 1937
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2587
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 127.0.0.1:53890 in memory (size: 30.4 KB, free: 911.6 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2592
19/07/31 17:06:23 INFO ContextCleaner: Cleaned shuffle 30
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 1938
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2265
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 911.6 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2506
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2747
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 911.6 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:53890 in memory (size: 30.4 KB, free: 911.7 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 1944
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 1775
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2510
19/07/31 17:06:23 INFO ContextCleaner: Cleaned shuffle 27
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 911.7 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 127.0.0.1:53890 in memory (size: 30.4 KB, free: 911.7 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2018
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2589
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 1940
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:53890 in memory (size: 30.4 KB, free: 911.8 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2593
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 1941
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2591
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2505
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:53890 in memory (size: 30.4 KB, free: 911.8 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned shuffle 31
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2268
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2266
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 911.9 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2511
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 911.9 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 911.9 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 1856
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2586
19/07/31 17:06:23 INFO ContextCleaner: Cleaned shuffle 23
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2262
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 1943
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2428
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 127.0.0.1:53890 in memory (size: 31.7 KB, free: 912.0 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2588
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2427
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2424
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:53890 in memory (size: 30.4 KB, free: 912.0 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2430
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2429
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2426
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2431
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 912.1 MB)
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 1945
19/07/31 17:06:23 INFO ContextCleaner: Cleaned shuffle 29
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 1939
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2261
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2509
19/07/31 17:06:23 INFO ContextCleaner: Cleaned accumulator 2507
19/07/31 17:06:23 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 912.1 MB)
19/07/31 17:06:23 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:23 INFO DAGScheduler: Registering RDD 312 (collect at utils.scala:204)
19/07/31 17:06:23 INFO DAGScheduler: Got job 68 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:23 INFO DAGScheduler: Final stage: ResultStage 102 (collect at utils.scala:204)
19/07/31 17:06:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 101)
19/07/31 17:06:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 101)
19/07/31 17:06:23 INFO DAGScheduler: Submitting ShuffleMapStage 101 (MapPartitionsRDD[312] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 74.5 KB, free 911.0 MB)
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.0 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 912.1 MB)
19/07/31 17:06:23 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 101 (MapPartitionsRDD[312] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:23 INFO TaskSchedulerImpl: Adding task set 101.0 with 1 tasks
19/07/31 17:06:23 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 194, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:23 INFO Executor: Running task 0.0 in stage 101.0 (TID 194)
19/07/31 17:06:23 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:23 INFO Executor: Finished task 0.0 in stage 101.0 (TID 194). 1687 bytes result sent to driver
19/07/31 17:06:23 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 194) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:06:23 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
19/07/31 17:06:23 INFO DAGScheduler: ShuffleMapStage 101 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:06:23 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:23 INFO DAGScheduler: running: Set()
19/07/31 17:06:23 INFO DAGScheduler: waiting: Set(ResultStage 102)
19/07/31 17:06:23 INFO DAGScheduler: failed: Set()
19/07/31 17:06:23 INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[315] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 16.8 KB, free 911.0 MB)
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.0 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:06:23 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:23 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 102 (MapPartitionsRDD[315] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:23 INFO TaskSchedulerImpl: Adding task set 102.0 with 4 tasks
19/07/31 17:06:23 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 195, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:23 INFO TaskSetManager: Starting task 1.0 in stage 102.0 (TID 196, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:23 INFO TaskSetManager: Starting task 2.0 in stage 102.0 (TID 197, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:23 INFO TaskSetManager: Starting task 3.0 in stage 102.0 (TID 198, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:23 INFO Executor: Running task 0.0 in stage 102.0 (TID 195)
19/07/31 17:06:23 INFO Executor: Running task 2.0 in stage 102.0 (TID 197)
19/07/31 17:06:23 INFO Executor: Running task 1.0 in stage 102.0 (TID 196)
19/07/31 17:06:23 INFO Executor: Running task 3.0 in stage 102.0 (TID 198)
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
19/07/31 17:06:23 INFO Executor: Finished task 1.0 in stage 102.0 (TID 196). 2403 bytes result sent to driver
19/07/31 17:06:23 INFO Executor: Finished task 2.0 in stage 102.0 (TID 197). 2390 bytes result sent to driver
19/07/31 17:06:23 INFO TaskSetManager: Finished task 1.0 in stage 102.0 (TID 196) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:06:23 INFO TaskSetManager: Finished task 2.0 in stage 102.0 (TID 197) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:06:23 INFO Executor: Finished task 0.0 in stage 102.0 (TID 195). 2382 bytes result sent to driver
19/07/31 17:06:23 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 195) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:06:23 INFO Executor: Finished task 3.0 in stage 102.0 (TID 198). 2362 bytes result sent to driver
19/07/31 17:06:23 INFO TaskSetManager: Finished task 3.0 in stage 102.0 (TID 198) in 7 ms on localhost (executor driver) (4/4)
19/07/31 17:06:23 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
19/07/31 17:06:23 INFO DAGScheduler: ResultStage 102 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:23 INFO DAGScheduler: Job 68 finished: collect at utils.scala:204, took 0.025461 s
19/07/31 17:06:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_257`) `dbplyr_258`
ORDER BY `date`) `dbplyr_259`) `dbplyr_260`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Desktop"))
19/07/31 17:06:23 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:23 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_261`) `dbplyr_262`
ORDER BY `date`) `dbplyr_263`) `dbplyr_264`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Desktop"))
19/07/31 17:06:23 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:23 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:23 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3578 - cust_prospect_ind.nullCount#3577) > 0)
19/07/31 17:06:23 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3583 - visit_device_type.nullCount#3582) > 0)
19/07/31 17:06:23 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#3576 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#3575))
19/07/31 17:06:23 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#3581 <= Desktop) && (Desktop <= visit_device_type.upperBound#3580))
19/07/31 17:06:23 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:23 INFO DAGScheduler: Got job 69 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:23 INFO DAGScheduler: Final stage: ResultStage 103 (collect at utils.scala:204)
19/07/31 17:06:23 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:23 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:23 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[320] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 72.1 KB, free 910.9 MB)
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.9 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 127.0.0.1:53890 (size: 30.4 KB, free: 912.0 MB)
19/07/31 17:06:23 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[320] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:23 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks
19/07/31 17:06:23 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 199, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:23 INFO Executor: Running task 0.0 in stage 103.0 (TID 199)
19/07/31 17:06:23 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:23 INFO Executor: Finished task 0.0 in stage 103.0 (TID 199). 6512 bytes result sent to driver
19/07/31 17:06:23 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 199) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:06:23 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
19/07/31 17:06:23 INFO DAGScheduler: ResultStage 103 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:23 INFO DAGScheduler: Job 69 finished: collect at utils.scala:204, took 0.009472 s
19/07/31 17:06:23 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:23 INFO DAGScheduler: Registering RDD 321 (collect at utils.scala:204)
19/07/31 17:06:23 INFO DAGScheduler: Got job 70 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:23 INFO DAGScheduler: Final stage: ResultStage 105 (collect at utils.scala:204)
19/07/31 17:06:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 104)
19/07/31 17:06:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 104)
19/07/31 17:06:23 INFO DAGScheduler: Submitting ShuffleMapStage 104 (MapPartitionsRDD[321] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 74.5 KB, free 910.8 MB)
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.8 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 127.0.0.1:53890 (size: 31.7 KB, free: 912.0 MB)
19/07/31 17:06:23 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 104 (MapPartitionsRDD[321] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:23 INFO TaskSchedulerImpl: Adding task set 104.0 with 1 tasks
19/07/31 17:06:23 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 200, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:23 INFO Executor: Running task 0.0 in stage 104.0 (TID 200)
19/07/31 17:06:23 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:23 INFO Executor: Finished task 0.0 in stage 104.0 (TID 200). 1687 bytes result sent to driver
19/07/31 17:06:23 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 200) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:06:23 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
19/07/31 17:06:23 INFO DAGScheduler: ShuffleMapStage 104 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:06:23 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:23 INFO DAGScheduler: running: Set()
19/07/31 17:06:23 INFO DAGScheduler: waiting: Set(ResultStage 105)
19/07/31 17:06:23 INFO DAGScheduler: failed: Set()
19/07/31 17:06:23 INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[324] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 16.8 KB, free 910.8 MB)
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.8 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:06:23 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:23 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 105 (MapPartitionsRDD[324] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:23 INFO TaskSchedulerImpl: Adding task set 105.0 with 4 tasks
19/07/31 17:06:23 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 201, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:23 INFO TaskSetManager: Starting task 1.0 in stage 105.0 (TID 202, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:23 INFO TaskSetManager: Starting task 2.0 in stage 105.0 (TID 203, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:23 INFO TaskSetManager: Starting task 3.0 in stage 105.0 (TID 204, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:23 INFO Executor: Running task 2.0 in stage 105.0 (TID 203)
19/07/31 17:06:23 INFO Executor: Running task 0.0 in stage 105.0 (TID 201)
19/07/31 17:06:23 INFO Executor: Running task 3.0 in stage 105.0 (TID 204)
19/07/31 17:06:23 INFO Executor: Running task 1.0 in stage 105.0 (TID 202)
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:23 INFO Executor: Finished task 0.0 in stage 105.0 (TID 201). 2367 bytes result sent to driver
19/07/31 17:06:23 INFO Executor: Finished task 2.0 in stage 105.0 (TID 203). 2368 bytes result sent to driver
19/07/31 17:06:23 INFO Executor: Finished task 1.0 in stage 105.0 (TID 202). 2350 bytes result sent to driver
19/07/31 17:06:23 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 201) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:06:23 INFO TaskSetManager: Finished task 1.0 in stage 105.0 (TID 202) in 4 ms on localhost (executor driver) (2/4)
19/07/31 17:06:23 INFO Executor: Finished task 3.0 in stage 105.0 (TID 204). 2357 bytes result sent to driver
19/07/31 17:06:23 INFO TaskSetManager: Finished task 2.0 in stage 105.0 (TID 203) in 4 ms on localhost (executor driver) (3/4)
19/07/31 17:06:23 INFO TaskSetManager: Finished task 3.0 in stage 105.0 (TID 204) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:06:23 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
19/07/31 17:06:23 INFO DAGScheduler: ResultStage 105 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:23 INFO DAGScheduler: Job 70 finished: collect at utils.scala:204, took 0.020716 s
19/07/31 17:06:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_265`) `dbplyr_266`
ORDER BY `date`) `dbplyr_267`) `dbplyr_268`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:23 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:23 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_269`) `dbplyr_270`
ORDER BY `date`) `dbplyr_271`) `dbplyr_272`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:23 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:23 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:23 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3676 - cust_prospect_ind.nullCount#3675) > 0)
19/07/31 17:06:23 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3681 - visit_device_type.nullCount#3680) > 0)
19/07/31 17:06:23 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#3674 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#3673))
19/07/31 17:06:23 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#3679 <= All Devices) && (All Devices <= visit_device_type.upperBound#3678))
19/07/31 17:06:23 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:23 INFO DAGScheduler: Got job 71 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:23 INFO DAGScheduler: Final stage: ResultStage 106 (collect at utils.scala:204)
19/07/31 17:06:23 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:23 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:23 INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[329] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 72.1 KB, free 910.7 MB)
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.7 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:06:23 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[329] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:23 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks
19/07/31 17:06:23 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 205, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:23 INFO Executor: Running task 0.0 in stage 106.0 (TID 205)
19/07/31 17:06:23 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:23 INFO Executor: Finished task 0.0 in stage 106.0 (TID 205). 7542 bytes result sent to driver
19/07/31 17:06:23 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 205) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:06:23 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
19/07/31 17:06:23 INFO DAGScheduler: ResultStage 106 (collect at utils.scala:204) finished in 0.004 s
19/07/31 17:06:23 INFO DAGScheduler: Job 71 finished: collect at utils.scala:204, took 0.008220 s
19/07/31 17:06:23 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:23 INFO DAGScheduler: Registering RDD 330 (collect at utils.scala:204)
19/07/31 17:06:23 INFO DAGScheduler: Got job 72 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:23 INFO DAGScheduler: Final stage: ResultStage 108 (collect at utils.scala:204)
19/07/31 17:06:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 107)
19/07/31 17:06:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 107)
19/07/31 17:06:23 INFO DAGScheduler: Submitting ShuffleMapStage 107 (MapPartitionsRDD[330] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 74.5 KB, free 910.6 MB)
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.6 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.9 MB)
19/07/31 17:06:23 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 107 (MapPartitionsRDD[330] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:23 INFO TaskSchedulerImpl: Adding task set 107.0 with 1 tasks
19/07/31 17:06:23 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 206, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:23 INFO Executor: Running task 0.0 in stage 107.0 (TID 206)
19/07/31 17:06:23 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:23 INFO Executor: Finished task 0.0 in stage 107.0 (TID 206). 1687 bytes result sent to driver
19/07/31 17:06:23 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 206) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:06:23 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
19/07/31 17:06:23 INFO DAGScheduler: ShuffleMapStage 107 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:23 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:23 INFO DAGScheduler: running: Set()
19/07/31 17:06:23 INFO DAGScheduler: waiting: Set(ResultStage 108)
19/07/31 17:06:23 INFO DAGScheduler: failed: Set()
19/07/31 17:06:23 INFO DAGScheduler: Submitting ResultStage 108 (MapPartitionsRDD[333] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 16.8 KB, free 910.5 MB)
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.5 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:06:23 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:23 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 108 (MapPartitionsRDD[333] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:23 INFO TaskSchedulerImpl: Adding task set 108.0 with 4 tasks
19/07/31 17:06:23 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 207, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:23 INFO TaskSetManager: Starting task 1.0 in stage 108.0 (TID 208, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:23 INFO TaskSetManager: Starting task 2.0 in stage 108.0 (TID 209, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:23 INFO TaskSetManager: Starting task 3.0 in stage 108.0 (TID 210, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:23 INFO Executor: Running task 2.0 in stage 108.0 (TID 209)
19/07/31 17:06:23 INFO Executor: Running task 3.0 in stage 108.0 (TID 210)
19/07/31 17:06:23 INFO Executor: Running task 0.0 in stage 108.0 (TID 207)
19/07/31 17:06:23 INFO Executor: Running task 1.0 in stage 108.0 (TID 208)
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/07/31 17:06:23 INFO Executor: Finished task 3.0 in stage 108.0 (TID 210). 2362 bytes result sent to driver
19/07/31 17:06:23 INFO Executor: Finished task 1.0 in stage 108.0 (TID 208). 2403 bytes result sent to driver
19/07/31 17:06:23 INFO TaskSetManager: Finished task 3.0 in stage 108.0 (TID 210) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:06:23 INFO TaskSetManager: Finished task 1.0 in stage 108.0 (TID 208) in 4 ms on localhost (executor driver) (2/4)
19/07/31 17:06:23 INFO Executor: Finished task 0.0 in stage 108.0 (TID 207). 2382 bytes result sent to driver
19/07/31 17:06:23 INFO Executor: Finished task 2.0 in stage 108.0 (TID 209). 2390 bytes result sent to driver
19/07/31 17:06:23 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 207) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:06:23 INFO TaskSetManager: Finished task 2.0 in stage 108.0 (TID 209) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:06:23 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool 
19/07/31 17:06:23 INFO DAGScheduler: ResultStage 108 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:23 INFO DAGScheduler: Job 72 finished: collect at utils.scala:204, took 0.020808 s
19/07/31 17:06:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_273`) `dbplyr_274`
ORDER BY `date`) `dbplyr_275`) `dbplyr_276`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:23 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:23 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_277`) `dbplyr_278`
ORDER BY `date`) `dbplyr_279`) `dbplyr_280`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:23 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:23 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:23 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3774 - cust_prospect_ind.nullCount#3773) > 0)
19/07/31 17:06:23 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3779 - visit_device_type.nullCount#3778) > 0)
19/07/31 17:06:23 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#3772 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#3771))
19/07/31 17:06:23 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#3777 <= All Devices) && (All Devices <= visit_device_type.upperBound#3776))
19/07/31 17:06:23 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:23 INFO DAGScheduler: Got job 73 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:23 INFO DAGScheduler: Final stage: ResultStage 109 (collect at utils.scala:204)
19/07/31 17:06:23 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:23 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:23 INFO DAGScheduler: Submitting ResultStage 109 (MapPartitionsRDD[338] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 72.1 KB, free 910.5 MB)
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.4 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 127.0.0.1:53890 (size: 30.4 KB, free: 911.9 MB)
19/07/31 17:06:23 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 109 (MapPartitionsRDD[338] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:23 INFO TaskSchedulerImpl: Adding task set 109.0 with 1 tasks
19/07/31 17:06:23 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 211, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:23 INFO Executor: Running task 0.0 in stage 109.0 (TID 211)
19/07/31 17:06:23 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:23 INFO Executor: Finished task 0.0 in stage 109.0 (TID 211). 7542 bytes result sent to driver
19/07/31 17:06:23 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 211) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:06:23 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool 
19/07/31 17:06:23 INFO DAGScheduler: ResultStage 109 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:23 INFO DAGScheduler: Job 73 finished: collect at utils.scala:204, took 0.011263 s
19/07/31 17:06:23 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:23 INFO DAGScheduler: Registering RDD 339 (collect at utils.scala:204)
19/07/31 17:06:23 INFO DAGScheduler: Got job 74 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:23 INFO DAGScheduler: Final stage: ResultStage 111 (collect at utils.scala:204)
19/07/31 17:06:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 110)
19/07/31 17:06:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 110)
19/07/31 17:06:23 INFO DAGScheduler: Submitting ShuffleMapStage 110 (MapPartitionsRDD[339] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 74.5 KB, free 910.4 MB)
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.3 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 127.0.0.1:53890 (size: 31.7 KB, free: 911.9 MB)
19/07/31 17:06:23 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 110 (MapPartitionsRDD[339] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:23 INFO TaskSchedulerImpl: Adding task set 110.0 with 1 tasks
19/07/31 17:06:23 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 212, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:23 INFO Executor: Running task 0.0 in stage 110.0 (TID 212)
19/07/31 17:06:23 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:23 INFO Executor: Finished task 0.0 in stage 110.0 (TID 212). 1687 bytes result sent to driver
19/07/31 17:06:23 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 212) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:06:23 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool 
19/07/31 17:06:23 INFO DAGScheduler: ShuffleMapStage 110 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:06:23 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:23 INFO DAGScheduler: running: Set()
19/07/31 17:06:23 INFO DAGScheduler: waiting: Set(ResultStage 111)
19/07/31 17:06:23 INFO DAGScheduler: failed: Set()
19/07/31 17:06:23 INFO DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[342] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 16.8 KB, free 910.3 MB)
19/07/31 17:06:23 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.3 MB)
19/07/31 17:06:23 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:06:23 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:23 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 111 (MapPartitionsRDD[342] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:23 INFO TaskSchedulerImpl: Adding task set 111.0 with 4 tasks
19/07/31 17:06:23 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 213, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:23 INFO TaskSetManager: Starting task 1.0 in stage 111.0 (TID 214, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:23 INFO TaskSetManager: Starting task 2.0 in stage 111.0 (TID 215, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:23 INFO TaskSetManager: Starting task 3.0 in stage 111.0 (TID 216, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:23 INFO Executor: Running task 0.0 in stage 111.0 (TID 213)
19/07/31 17:06:23 INFO Executor: Running task 2.0 in stage 111.0 (TID 215)
19/07/31 17:06:23 INFO Executor: Running task 3.0 in stage 111.0 (TID 216)
19/07/31 17:06:23 INFO Executor: Running task 1.0 in stage 111.0 (TID 214)
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:23 INFO Executor: Finished task 2.0 in stage 111.0 (TID 215). 2390 bytes result sent to driver
19/07/31 17:06:23 INFO Executor: Finished task 0.0 in stage 111.0 (TID 213). 2382 bytes result sent to driver
19/07/31 17:06:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:23 INFO TaskSetManager: Finished task 2.0 in stage 111.0 (TID 215) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:06:23 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 213) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:06:23 INFO Executor: Finished task 3.0 in stage 111.0 (TID 216). 2362 bytes result sent to driver
19/07/31 17:06:23 INFO TaskSetManager: Finished task 3.0 in stage 111.0 (TID 216) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:06:23 INFO Executor: Finished task 1.0 in stage 111.0 (TID 214). 2403 bytes result sent to driver
19/07/31 17:06:23 INFO TaskSetManager: Finished task 1.0 in stage 111.0 (TID 214) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:06:23 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool 
19/07/31 17:06:23 INFO DAGScheduler: ResultStage 111 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:23 INFO DAGScheduler: Job 74 finished: collect at utils.scala:204, took 0.023518 s
19/07/31 17:06:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_281`) `dbplyr_282`
ORDER BY `date`) `dbplyr_283`) `dbplyr_284`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Desktop"))
19/07/31 17:06:24 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:24 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_285`) `dbplyr_286`
ORDER BY `date`) `dbplyr_287`) `dbplyr_288`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Desktop"))
19/07/31 17:06:24 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:24 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:24 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3872 - cust_prospect_ind.nullCount#3871) > 0)
19/07/31 17:06:24 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3877 - visit_device_type.nullCount#3876) > 0)
19/07/31 17:06:24 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#3870 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#3869))
19/07/31 17:06:24 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#3875 <= Desktop) && (Desktop <= visit_device_type.upperBound#3874))
19/07/31 17:06:24 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:24 INFO DAGScheduler: Got job 75 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:24 INFO DAGScheduler: Final stage: ResultStage 112 (collect at utils.scala:204)
19/07/31 17:06:24 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:24 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:24 INFO DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[347] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 72.1 KB, free 910.2 MB)
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.2 MB)
19/07/31 17:06:24 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:06:24 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[347] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:24 INFO TaskSchedulerImpl: Adding task set 112.0 with 1 tasks
19/07/31 17:06:24 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 217, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:24 INFO Executor: Running task 0.0 in stage 112.0 (TID 217)
19/07/31 17:06:24 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:24 INFO Executor: Finished task 0.0 in stage 112.0 (TID 217). 6512 bytes result sent to driver
19/07/31 17:06:24 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 217) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:06:24 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool 
19/07/31 17:06:24 INFO DAGScheduler: ResultStage 112 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:06:24 INFO DAGScheduler: Job 75 finished: collect at utils.scala:204, took 0.010036 s
19/07/31 17:06:24 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:24 INFO DAGScheduler: Registering RDD 348 (collect at utils.scala:204)
19/07/31 17:06:24 INFO DAGScheduler: Got job 76 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:24 INFO DAGScheduler: Final stage: ResultStage 114 (collect at utils.scala:204)
19/07/31 17:06:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 113)
19/07/31 17:06:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 113)
19/07/31 17:06:24 INFO DAGScheduler: Submitting ShuffleMapStage 113 (MapPartitionsRDD[348] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 74.5 KB, free 910.1 MB)
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.1 MB)
19/07/31 17:06:24 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:06:24 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 113 (MapPartitionsRDD[348] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:24 INFO TaskSchedulerImpl: Adding task set 113.0 with 1 tasks
19/07/31 17:06:24 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 218, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:24 INFO Executor: Running task 0.0 in stage 113.0 (TID 218)
19/07/31 17:06:24 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:24 INFO Executor: Finished task 0.0 in stage 113.0 (TID 218). 1687 bytes result sent to driver
19/07/31 17:06:24 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 218) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:06:24 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool 
19/07/31 17:06:24 INFO DAGScheduler: ShuffleMapStage 113 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:24 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:24 INFO DAGScheduler: running: Set()
19/07/31 17:06:24 INFO DAGScheduler: waiting: Set(ResultStage 114)
19/07/31 17:06:24 INFO DAGScheduler: failed: Set()
19/07/31 17:06:24 INFO DAGScheduler: Submitting ResultStage 114 (MapPartitionsRDD[351] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 16.8 KB, free 910.1 MB)
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.1 MB)
19/07/31 17:06:24 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:06:24 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:24 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 114 (MapPartitionsRDD[351] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:24 INFO TaskSchedulerImpl: Adding task set 114.0 with 4 tasks
19/07/31 17:06:24 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 219, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:24 INFO TaskSetManager: Starting task 1.0 in stage 114.0 (TID 220, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:24 INFO TaskSetManager: Starting task 2.0 in stage 114.0 (TID 221, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:24 INFO TaskSetManager: Starting task 3.0 in stage 114.0 (TID 222, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:24 INFO Executor: Running task 3.0 in stage 114.0 (TID 222)
19/07/31 17:06:24 INFO Executor: Running task 1.0 in stage 114.0 (TID 220)
19/07/31 17:06:24 INFO Executor: Running task 2.0 in stage 114.0 (TID 221)
19/07/31 17:06:24 INFO Executor: Running task 0.0 in stage 114.0 (TID 219)
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:24 INFO Executor: Finished task 3.0 in stage 114.0 (TID 222). 2359 bytes result sent to driver
19/07/31 17:06:24 INFO Executor: Finished task 2.0 in stage 114.0 (TID 221). 2373 bytes result sent to driver
19/07/31 17:06:24 INFO Executor: Finished task 1.0 in stage 114.0 (TID 220). 2351 bytes result sent to driver
19/07/31 17:06:24 INFO TaskSetManager: Finished task 3.0 in stage 114.0 (TID 222) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:06:24 INFO TaskSetManager: Finished task 2.0 in stage 114.0 (TID 221) in 4 ms on localhost (executor driver) (2/4)
19/07/31 17:06:24 INFO Executor: Finished task 0.0 in stage 114.0 (TID 219). 2369 bytes result sent to driver
19/07/31 17:06:24 INFO TaskSetManager: Finished task 1.0 in stage 114.0 (TID 220) in 4 ms on localhost (executor driver) (3/4)
19/07/31 17:06:24 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 219) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:06:24 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool 
19/07/31 17:06:24 INFO DAGScheduler: ResultStage 114 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:24 INFO DAGScheduler: Job 76 finished: collect at utils.scala:204, took 0.019013 s
19/07/31 17:06:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_289`) `dbplyr_290`
ORDER BY `date`) `dbplyr_291`) `dbplyr_292`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:24 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:24 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_293`) `dbplyr_294`
ORDER BY `date`) `dbplyr_295`) `dbplyr_296`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:24 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:24 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:24 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3970 - cust_prospect_ind.nullCount#3969) > 0)
19/07/31 17:06:24 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3975 - visit_device_type.nullCount#3974) > 0)
19/07/31 17:06:24 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#3968 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#3967))
19/07/31 17:06:24 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#3973 <= All Devices) && (All Devices <= visit_device_type.upperBound#3972))
19/07/31 17:06:24 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:24 INFO DAGScheduler: Got job 77 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:24 INFO DAGScheduler: Final stage: ResultStage 115 (collect at utils.scala:204)
19/07/31 17:06:24 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:24 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:24 INFO DAGScheduler: Submitting ResultStage 115 (MapPartitionsRDD[356] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 72.1 KB, free 910.0 MB)
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.0 MB)
19/07/31 17:06:24 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:06:24 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 115 (MapPartitionsRDD[356] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:24 INFO TaskSchedulerImpl: Adding task set 115.0 with 1 tasks
19/07/31 17:06:24 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 223, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:24 INFO Executor: Running task 0.0 in stage 115.0 (TID 223)
19/07/31 17:06:24 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:24 INFO Executor: Finished task 0.0 in stage 115.0 (TID 223). 7542 bytes result sent to driver
19/07/31 17:06:24 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 223) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:06:24 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
19/07/31 17:06:24 INFO DAGScheduler: ResultStage 115 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:24 INFO DAGScheduler: Job 77 finished: collect at utils.scala:204, took 0.010670 s
19/07/31 17:06:24 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:24 INFO DAGScheduler: Registering RDD 357 (collect at utils.scala:204)
19/07/31 17:06:24 INFO DAGScheduler: Got job 78 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:24 INFO DAGScheduler: Final stage: ResultStage 117 (collect at utils.scala:204)
19/07/31 17:06:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 116)
19/07/31 17:06:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 116)
19/07/31 17:06:24 INFO DAGScheduler: Submitting ShuffleMapStage 116 (MapPartitionsRDD[357] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 74.5 KB, free 909.9 MB)
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.9 MB)
19/07/31 17:06:24 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.7 MB)
19/07/31 17:06:24 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 116 (MapPartitionsRDD[357] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:24 INFO TaskSchedulerImpl: Adding task set 116.0 with 1 tasks
19/07/31 17:06:24 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 224, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:24 INFO Executor: Running task 0.0 in stage 116.0 (TID 224)
19/07/31 17:06:24 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:24 INFO Executor: Finished task 0.0 in stage 116.0 (TID 224). 1687 bytes result sent to driver
19/07/31 17:06:24 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 224) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:06:24 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool 
19/07/31 17:06:24 INFO DAGScheduler: ShuffleMapStage 116 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:24 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:24 INFO DAGScheduler: running: Set()
19/07/31 17:06:24 INFO DAGScheduler: waiting: Set(ResultStage 117)
19/07/31 17:06:24 INFO DAGScheduler: failed: Set()
19/07/31 17:06:24 INFO DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[360] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 16.8 KB, free 909.9 MB)
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.8 MB)
19/07/31 17:06:24 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:06:24 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:24 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 117 (MapPartitionsRDD[360] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:24 INFO TaskSchedulerImpl: Adding task set 117.0 with 4 tasks
19/07/31 17:06:24 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 225, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:24 INFO TaskSetManager: Starting task 1.0 in stage 117.0 (TID 226, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:24 INFO TaskSetManager: Starting task 2.0 in stage 117.0 (TID 227, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:24 INFO TaskSetManager: Starting task 3.0 in stage 117.0 (TID 228, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:24 INFO Executor: Running task 0.0 in stage 117.0 (TID 225)
19/07/31 17:06:24 INFO Executor: Running task 3.0 in stage 117.0 (TID 228)
19/07/31 17:06:24 INFO Executor: Running task 2.0 in stage 117.0 (TID 227)
19/07/31 17:06:24 INFO Executor: Running task 1.0 in stage 117.0 (TID 226)
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:24 INFO Executor: Finished task 2.0 in stage 117.0 (TID 227). 2390 bytes result sent to driver
19/07/31 17:06:24 INFO Executor: Finished task 1.0 in stage 117.0 (TID 226). 2403 bytes result sent to driver
19/07/31 17:06:24 INFO Executor: Finished task 0.0 in stage 117.0 (TID 225). 2382 bytes result sent to driver
19/07/31 17:06:24 INFO Executor: Finished task 3.0 in stage 117.0 (TID 228). 2362 bytes result sent to driver
19/07/31 17:06:24 INFO TaskSetManager: Finished task 2.0 in stage 117.0 (TID 227) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:06:24 INFO TaskSetManager: Finished task 1.0 in stage 117.0 (TID 226) in 4 ms on localhost (executor driver) (2/4)
19/07/31 17:06:24 INFO TaskSetManager: Finished task 3.0 in stage 117.0 (TID 228) in 4 ms on localhost (executor driver) (3/4)
19/07/31 17:06:24 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 225) in 4 ms on localhost (executor driver) (4/4)
19/07/31 17:06:24 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool 
19/07/31 17:06:24 INFO DAGScheduler: ResultStage 117 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:24 INFO DAGScheduler: Job 78 finished: collect at utils.scala:204, took 0.020911 s
19/07/31 17:06:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_297`) `dbplyr_298`
ORDER BY `date`) `dbplyr_299`) `dbplyr_300`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:24 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:24 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_301`) `dbplyr_302`
ORDER BY `date`) `dbplyr_303`) `dbplyr_304`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:24 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:24 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:24 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4068 - cust_prospect_ind.nullCount#4067) > 0)
19/07/31 17:06:24 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4073 - visit_device_type.nullCount#4072) > 0)
19/07/31 17:06:24 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4066 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4065))
19/07/31 17:06:24 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4071 <= All Devices) && (All Devices <= visit_device_type.upperBound#4070))
19/07/31 17:06:24 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:24 INFO DAGScheduler: Got job 79 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:24 INFO DAGScheduler: Final stage: ResultStage 118 (collect at utils.scala:204)
19/07/31 17:06:24 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:24 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:24 INFO DAGScheduler: Submitting ResultStage 118 (MapPartitionsRDD[365] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 72.1 KB, free 909.8 MB)
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 30.4 KB, free 909.7 MB)
19/07/31 17:06:24 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 127.0.0.1:53890 (size: 30.4 KB, free: 911.7 MB)
19/07/31 17:06:24 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 118 (MapPartitionsRDD[365] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:24 INFO TaskSchedulerImpl: Adding task set 118.0 with 1 tasks
19/07/31 17:06:24 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 229, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:24 INFO Executor: Running task 0.0 in stage 118.0 (TID 229)
19/07/31 17:06:24 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:24 INFO Executor: Finished task 0.0 in stage 118.0 (TID 229). 7542 bytes result sent to driver
19/07/31 17:06:24 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 229) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:06:24 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool 
19/07/31 17:06:24 INFO DAGScheduler: ResultStage 118 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:24 INFO DAGScheduler: Job 79 finished: collect at utils.scala:204, took 0.009236 s
19/07/31 17:06:24 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:24 INFO DAGScheduler: Registering RDD 366 (collect at utils.scala:204)
19/07/31 17:06:24 INFO DAGScheduler: Got job 80 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:24 INFO DAGScheduler: Final stage: ResultStage 120 (collect at utils.scala:204)
19/07/31 17:06:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 119)
19/07/31 17:06:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 119)
19/07/31 17:06:24 INFO DAGScheduler: Submitting ShuffleMapStage 119 (MapPartitionsRDD[366] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 74.5 KB, free 909.7 MB)
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 31.7 KB, free 909.6 MB)
19/07/31 17:06:24 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 127.0.0.1:53890 (size: 31.7 KB, free: 911.7 MB)
19/07/31 17:06:24 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 119 (MapPartitionsRDD[366] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:24 INFO TaskSchedulerImpl: Adding task set 119.0 with 1 tasks
19/07/31 17:06:24 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 230, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:24 INFO Executor: Running task 0.0 in stage 119.0 (TID 230)
19/07/31 17:06:24 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:24 INFO Executor: Finished task 0.0 in stage 119.0 (TID 230). 1687 bytes result sent to driver
19/07/31 17:06:24 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 230) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:06:24 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
19/07/31 17:06:24 INFO DAGScheduler: ShuffleMapStage 119 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:06:24 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:24 INFO DAGScheduler: running: Set()
19/07/31 17:06:24 INFO DAGScheduler: waiting: Set(ResultStage 120)
19/07/31 17:06:24 INFO DAGScheduler: failed: Set()
19/07/31 17:06:24 INFO DAGScheduler: Submitting ResultStage 120 (MapPartitionsRDD[369] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 16.8 KB, free 909.6 MB)
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.6 MB)
19/07/31 17:06:24 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:06:24 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:24 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 120 (MapPartitionsRDD[369] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:24 INFO TaskSchedulerImpl: Adding task set 120.0 with 4 tasks
19/07/31 17:06:24 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 231, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:24 INFO TaskSetManager: Starting task 1.0 in stage 120.0 (TID 232, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:24 INFO TaskSetManager: Starting task 2.0 in stage 120.0 (TID 233, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:24 INFO TaskSetManager: Starting task 3.0 in stage 120.0 (TID 234, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:24 INFO Executor: Running task 1.0 in stage 120.0 (TID 232)
19/07/31 17:06:24 INFO Executor: Running task 0.0 in stage 120.0 (TID 231)
19/07/31 17:06:24 INFO Executor: Running task 2.0 in stage 120.0 (TID 233)
19/07/31 17:06:24 INFO Executor: Running task 3.0 in stage 120.0 (TID 234)
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:24 INFO Executor: Finished task 3.0 in stage 120.0 (TID 234). 2319 bytes result sent to driver
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/07/31 17:06:24 INFO Executor: Finished task 2.0 in stage 120.0 (TID 233). 2390 bytes result sent to driver
19/07/31 17:06:24 INFO Executor: Finished task 0.0 in stage 120.0 (TID 231). 2382 bytes result sent to driver
19/07/31 17:06:24 INFO TaskSetManager: Finished task 3.0 in stage 120.0 (TID 234) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:06:24 INFO Executor: Finished task 1.0 in stage 120.0 (TID 232). 2403 bytes result sent to driver
19/07/31 17:06:24 INFO TaskSetManager: Finished task 2.0 in stage 120.0 (TID 233) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:06:24 INFO TaskSetManager: Finished task 1.0 in stage 120.0 (TID 232) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:06:24 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 231) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:06:24 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool 
19/07/31 17:06:24 INFO DAGScheduler: ResultStage 120 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:06:24 INFO DAGScheduler: Job 80 finished: collect at utils.scala:204, took 0.019484 s
19/07/31 17:06:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_305`) `dbplyr_306`
ORDER BY `date`) `dbplyr_307`) `dbplyr_308`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Desktop"))
19/07/31 17:06:24 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:24 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_309`) `dbplyr_310`
ORDER BY `date`) `dbplyr_311`) `dbplyr_312`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Desktop"))
19/07/31 17:06:24 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:24 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:24 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4166 - cust_prospect_ind.nullCount#4165) > 0)
19/07/31 17:06:24 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4171 - visit_device_type.nullCount#4170) > 0)
19/07/31 17:06:24 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#4164 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#4163))
19/07/31 17:06:24 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#4169 <= Desktop) && (Desktop <= visit_device_type.upperBound#4168))
19/07/31 17:06:24 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:24 INFO DAGScheduler: Got job 81 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:24 INFO DAGScheduler: Final stage: ResultStage 121 (collect at utils.scala:204)
19/07/31 17:06:24 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:24 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:24 INFO DAGScheduler: Submitting ResultStage 121 (MapPartitionsRDD[374] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 72.1 KB, free 909.5 MB)
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.5 MB)
19/07/31 17:06:24 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 911.6 MB)
19/07/31 17:06:24 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 121 (MapPartitionsRDD[374] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:24 INFO TaskSchedulerImpl: Adding task set 121.0 with 1 tasks
19/07/31 17:06:24 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 235, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:24 INFO Executor: Running task 0.0 in stage 121.0 (TID 235)
19/07/31 17:06:24 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:24 INFO Executor: Finished task 0.0 in stage 121.0 (TID 235). 7068 bytes result sent to driver
19/07/31 17:06:24 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 235) in 3 ms on localhost (executor driver) (1/1)
19/07/31 17:06:24 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool 
19/07/31 17:06:24 INFO DAGScheduler: ResultStage 121 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:24 INFO DAGScheduler: Job 81 finished: collect at utils.scala:204, took 0.008779 s
19/07/31 17:06:24 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:24 INFO DAGScheduler: Registering RDD 375 (collect at utils.scala:204)
19/07/31 17:06:24 INFO DAGScheduler: Got job 82 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:24 INFO DAGScheduler: Final stage: ResultStage 123 (collect at utils.scala:204)
19/07/31 17:06:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 122)
19/07/31 17:06:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 122)
19/07/31 17:06:24 INFO DAGScheduler: Submitting ShuffleMapStage 122 (MapPartitionsRDD[375] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 74.5 KB, free 909.4 MB)
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.4 MB)
19/07/31 17:06:24 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.6 MB)
19/07/31 17:06:24 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 122 (MapPartitionsRDD[375] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:24 INFO TaskSchedulerImpl: Adding task set 122.0 with 1 tasks
19/07/31 17:06:24 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 236, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:24 INFO Executor: Running task 0.0 in stage 122.0 (TID 236)
19/07/31 17:06:24 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:24 INFO Executor: Finished task 0.0 in stage 122.0 (TID 236). 1687 bytes result sent to driver
19/07/31 17:06:24 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 236) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:06:24 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool 
19/07/31 17:06:24 INFO DAGScheduler: ShuffleMapStage 122 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:24 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:24 INFO DAGScheduler: running: Set()
19/07/31 17:06:24 INFO DAGScheduler: waiting: Set(ResultStage 123)
19/07/31 17:06:24 INFO DAGScheduler: failed: Set()
19/07/31 17:06:24 INFO DAGScheduler: Submitting ResultStage 123 (MapPartitionsRDD[378] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 16.8 KB, free 909.4 MB)
19/07/31 17:06:24 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 8.1 KB, free 909.4 MB)
19/07/31 17:06:24 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 127.0.0.1:53890 (size: 8.1 KB, free: 911.6 MB)
19/07/31 17:06:24 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:24 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 123 (MapPartitionsRDD[378] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:24 INFO TaskSchedulerImpl: Adding task set 123.0 with 4 tasks
19/07/31 17:06:24 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 237, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:24 INFO TaskSetManager: Starting task 1.0 in stage 123.0 (TID 238, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:24 INFO TaskSetManager: Starting task 2.0 in stage 123.0 (TID 239, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:24 INFO TaskSetManager: Starting task 3.0 in stage 123.0 (TID 240, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:24 INFO Executor: Running task 1.0 in stage 123.0 (TID 238)
19/07/31 17:06:24 INFO Executor: Running task 3.0 in stage 123.0 (TID 240)
19/07/31 17:06:24 INFO Executor: Running task 2.0 in stage 123.0 (TID 239)
19/07/31 17:06:24 INFO Executor: Running task 0.0 in stage 123.0 (TID 237)
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:24 INFO Executor: Finished task 3.0 in stage 123.0 (TID 240). 2371 bytes result sent to driver
19/07/31 17:06:24 INFO Executor: Finished task 1.0 in stage 123.0 (TID 238). 2389 bytes result sent to driver
19/07/31 17:06:24 INFO Executor: Finished task 2.0 in stage 123.0 (TID 239). 2391 bytes result sent to driver
19/07/31 17:06:24 INFO Executor: Finished task 0.0 in stage 123.0 (TID 237). 2396 bytes result sent to driver
19/07/31 17:06:24 INFO TaskSetManager: Finished task 3.0 in stage 123.0 (TID 240) in 3 ms on localhost (executor driver) (1/4)
19/07/31 17:06:24 INFO TaskSetManager: Finished task 2.0 in stage 123.0 (TID 239) in 4 ms on localhost (executor driver) (2/4)
19/07/31 17:06:24 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 237) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:06:24 INFO TaskSetManager: Finished task 1.0 in stage 123.0 (TID 238) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:06:24 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool 
19/07/31 17:06:24 INFO DAGScheduler: ResultStage 123 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:24 INFO DAGScheduler: Job 82 finished: collect at utils.scala:204, took 0.019615 s
19/07/31 17:06:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_313`) `dbplyr_314`
ORDER BY `date`) `dbplyr_315`) `dbplyr_316`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:24 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:24 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_317`) `dbplyr_318`
ORDER BY `date`) `dbplyr_319`) `dbplyr_320`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:24 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:24 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:25 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4264 - cust_prospect_ind.nullCount#4263) > 0)
19/07/31 17:06:25 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4269 - visit_device_type.nullCount#4268) > 0)
19/07/31 17:06:25 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4262 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4261))
19/07/31 17:06:25 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4267 <= All Devices) && (All Devices <= visit_device_type.upperBound#4266))
19/07/31 17:06:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:25 INFO DAGScheduler: Got job 83 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:25 INFO DAGScheduler: Final stage: ResultStage 124 (collect at utils.scala:204)
19/07/31 17:06:25 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:25 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:25 INFO DAGScheduler: Submitting ResultStage 124 (MapPartitionsRDD[383] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 72.1 KB, free 909.3 MB)
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.3 MB)
19/07/31 17:06:25 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 911.6 MB)
19/07/31 17:06:25 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 124 (MapPartitionsRDD[383] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:25 INFO TaskSchedulerImpl: Adding task set 124.0 with 1 tasks
19/07/31 17:06:25 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 241, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:25 INFO Executor: Running task 0.0 in stage 124.0 (TID 241)
19/07/31 17:06:25 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:25 INFO Executor: Finished task 0.0 in stage 124.0 (TID 241). 7542 bytes result sent to driver
19/07/31 17:06:25 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 241) in 3 ms on localhost (executor driver) (1/1)
19/07/31 17:06:25 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool 
19/07/31 17:06:25 INFO DAGScheduler: ResultStage 124 (collect at utils.scala:204) finished in 0.003 s
19/07/31 17:06:25 INFO DAGScheduler: Job 83 finished: collect at utils.scala:204, took 0.008531 s
19/07/31 17:06:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:25 INFO DAGScheduler: Registering RDD 384 (collect at utils.scala:204)
19/07/31 17:06:25 INFO DAGScheduler: Got job 84 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:25 INFO DAGScheduler: Final stage: ResultStage 126 (collect at utils.scala:204)
19/07/31 17:06:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 125)
19/07/31 17:06:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 125)
19/07/31 17:06:25 INFO DAGScheduler: Submitting ShuffleMapStage 125 (MapPartitionsRDD[384] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 74.5 KB, free 909.2 MB)
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.2 MB)
19/07/31 17:06:25 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.5 MB)
19/07/31 17:06:25 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 125 (MapPartitionsRDD[384] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:25 INFO TaskSchedulerImpl: Adding task set 125.0 with 1 tasks
19/07/31 17:06:25 INFO TaskSetManager: Starting task 0.0 in stage 125.0 (TID 242, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:25 INFO Executor: Running task 0.0 in stage 125.0 (TID 242)
19/07/31 17:06:25 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:25 INFO Executor: Finished task 0.0 in stage 125.0 (TID 242). 1687 bytes result sent to driver
19/07/31 17:06:25 INFO TaskSetManager: Finished task 0.0 in stage 125.0 (TID 242) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:06:25 INFO TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool 
19/07/31 17:06:25 INFO DAGScheduler: ShuffleMapStage 125 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:06:25 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:25 INFO DAGScheduler: running: Set()
19/07/31 17:06:25 INFO DAGScheduler: waiting: Set(ResultStage 126)
19/07/31 17:06:25 INFO DAGScheduler: failed: Set()
19/07/31 17:06:25 INFO DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[387] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 16.8 KB, free 909.2 MB)
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.2 MB)
19/07/31 17:06:25 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.5 MB)
19/07/31 17:06:25 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:25 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 126 (MapPartitionsRDD[387] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:25 INFO TaskSchedulerImpl: Adding task set 126.0 with 4 tasks
19/07/31 17:06:25 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 243, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:25 INFO TaskSetManager: Starting task 1.0 in stage 126.0 (TID 244, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:25 INFO TaskSetManager: Starting task 2.0 in stage 126.0 (TID 245, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:25 INFO TaskSetManager: Starting task 3.0 in stage 126.0 (TID 246, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:25 INFO Executor: Running task 0.0 in stage 126.0 (TID 243)
19/07/31 17:06:25 INFO Executor: Running task 3.0 in stage 126.0 (TID 246)
19/07/31 17:06:25 INFO Executor: Running task 2.0 in stage 126.0 (TID 245)
19/07/31 17:06:25 INFO Executor: Running task 1.0 in stage 126.0 (TID 244)
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:25 INFO Executor: Finished task 0.0 in stage 126.0 (TID 243). 2382 bytes result sent to driver
19/07/31 17:06:25 INFO Executor: Finished task 1.0 in stage 126.0 (TID 244). 2403 bytes result sent to driver
19/07/31 17:06:25 INFO Executor: Finished task 2.0 in stage 126.0 (TID 245). 2390 bytes result sent to driver
19/07/31 17:06:25 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 243) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:06:25 INFO TaskSetManager: Finished task 2.0 in stage 126.0 (TID 245) in 4 ms on localhost (executor driver) (2/4)
19/07/31 17:06:25 INFO TaskSetManager: Finished task 1.0 in stage 126.0 (TID 244) in 4 ms on localhost (executor driver) (3/4)
19/07/31 17:06:25 INFO Executor: Finished task 3.0 in stage 126.0 (TID 246). 2362 bytes result sent to driver
19/07/31 17:06:25 INFO TaskSetManager: Finished task 3.0 in stage 126.0 (TID 246) in 4 ms on localhost (executor driver) (4/4)
19/07/31 17:06:25 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool 
19/07/31 17:06:25 INFO DAGScheduler: ResultStage 126 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:25 INFO DAGScheduler: Job 84 finished: collect at utils.scala:204, took 0.019442 s
19/07/31 17:06:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_321`) `dbplyr_322`
ORDER BY `date`) `dbplyr_323`) `dbplyr_324`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:25 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_325`) `dbplyr_326`
ORDER BY `date`) `dbplyr_327`) `dbplyr_328`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:25 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:25 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4362 - cust_prospect_ind.nullCount#4361) > 0)
19/07/31 17:06:25 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4367 - visit_device_type.nullCount#4366) > 0)
19/07/31 17:06:25 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4360 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4359))
19/07/31 17:06:25 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4365 <= All Devices) && (All Devices <= visit_device_type.upperBound#4364))
19/07/31 17:06:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:25 INFO DAGScheduler: Got job 85 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:25 INFO DAGScheduler: Final stage: ResultStage 127 (collect at utils.scala:204)
19/07/31 17:06:25 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:25 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:25 INFO DAGScheduler: Submitting ResultStage 127 (MapPartitionsRDD[392] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 72.1 KB, free 909.1 MB)
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.1 MB)
19/07/31 17:06:25 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 911.5 MB)
19/07/31 17:06:25 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 127 (MapPartitionsRDD[392] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:25 INFO TaskSchedulerImpl: Adding task set 127.0 with 1 tasks
19/07/31 17:06:25 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 247, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:25 INFO Executor: Running task 0.0 in stage 127.0 (TID 247)
19/07/31 17:06:25 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:25 INFO Executor: Finished task 0.0 in stage 127.0 (TID 247). 7542 bytes result sent to driver
19/07/31 17:06:25 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 247) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:06:25 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool 
19/07/31 17:06:25 INFO DAGScheduler: ResultStage 127 (collect at utils.scala:204) finished in 0.004 s
19/07/31 17:06:25 INFO DAGScheduler: Job 85 finished: collect at utils.scala:204, took 0.008266 s
19/07/31 17:06:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:25 INFO DAGScheduler: Registering RDD 393 (collect at utils.scala:204)
19/07/31 17:06:25 INFO DAGScheduler: Got job 86 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:25 INFO DAGScheduler: Final stage: ResultStage 129 (collect at utils.scala:204)
19/07/31 17:06:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 128)
19/07/31 17:06:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 128)
19/07/31 17:06:25 INFO DAGScheduler: Submitting ShuffleMapStage 128 (MapPartitionsRDD[393] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 74.5 KB, free 909.0 MB)
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.0 MB)
19/07/31 17:06:25 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.5 MB)
19/07/31 17:06:25 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 128 (MapPartitionsRDD[393] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:25 INFO TaskSchedulerImpl: Adding task set 128.0 with 1 tasks
19/07/31 17:06:25 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 248, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:25 INFO Executor: Running task 0.0 in stage 128.0 (TID 248)
19/07/31 17:06:25 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:25 INFO Executor: Finished task 0.0 in stage 128.0 (TID 248). 1687 bytes result sent to driver
19/07/31 17:06:25 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 248) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:06:25 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool 
19/07/31 17:06:25 INFO DAGScheduler: ShuffleMapStage 128 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:06:25 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:25 INFO DAGScheduler: running: Set()
19/07/31 17:06:25 INFO DAGScheduler: waiting: Set(ResultStage 129)
19/07/31 17:06:25 INFO DAGScheduler: failed: Set()
19/07/31 17:06:25 INFO DAGScheduler: Submitting ResultStage 129 (MapPartitionsRDD[396] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 16.8 KB, free 908.9 MB)
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 8.0 KB, free 908.9 MB)
19/07/31 17:06:25 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.5 MB)
19/07/31 17:06:25 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:25 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 129 (MapPartitionsRDD[396] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:25 INFO TaskSchedulerImpl: Adding task set 129.0 with 4 tasks
19/07/31 17:06:25 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 249, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:25 INFO TaskSetManager: Starting task 1.0 in stage 129.0 (TID 250, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:25 INFO TaskSetManager: Starting task 2.0 in stage 129.0 (TID 251, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:25 INFO TaskSetManager: Starting task 3.0 in stage 129.0 (TID 252, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:25 INFO Executor: Running task 2.0 in stage 129.0 (TID 251)
19/07/31 17:06:25 INFO Executor: Running task 3.0 in stage 129.0 (TID 252)
19/07/31 17:06:25 INFO Executor: Running task 0.0 in stage 129.0 (TID 249)
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:25 INFO Executor: Running task 1.0 in stage 129.0 (TID 250)
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:25 INFO Executor: Finished task 2.0 in stage 129.0 (TID 251). 2390 bytes result sent to driver
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:25 INFO Executor: Finished task 0.0 in stage 129.0 (TID 249). 2339 bytes result sent to driver
19/07/31 17:06:25 INFO Executor: Finished task 3.0 in stage 129.0 (TID 252). 2362 bytes result sent to driver
19/07/31 17:06:25 INFO TaskSetManager: Finished task 2.0 in stage 129.0 (TID 251) in 6 ms on localhost (executor driver) (1/4)
19/07/31 17:06:25 INFO TaskSetManager: Finished task 3.0 in stage 129.0 (TID 252) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:06:25 INFO Executor: Finished task 1.0 in stage 129.0 (TID 250). 2403 bytes result sent to driver
19/07/31 17:06:25 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 249) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:06:25 INFO TaskSetManager: Finished task 1.0 in stage 129.0 (TID 250) in 7 ms on localhost (executor driver) (4/4)
19/07/31 17:06:25 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool 
19/07/31 17:06:25 INFO DAGScheduler: ResultStage 129 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:25 INFO DAGScheduler: Job 86 finished: collect at utils.scala:204, took 0.021932 s
19/07/31 17:06:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_329`) `dbplyr_330`
ORDER BY `date`) `dbplyr_331`) `dbplyr_332`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Tablet"))
19/07/31 17:06:25 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_333`) `dbplyr_334`
ORDER BY `date`) `dbplyr_335`) `dbplyr_336`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Tablet"))
19/07/31 17:06:25 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:25 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4460 - cust_prospect_ind.nullCount#4459) > 0)
19/07/31 17:06:25 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4465 - visit_device_type.nullCount#4464) > 0)
19/07/31 17:06:25 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#4458 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#4457))
19/07/31 17:06:25 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#4463 <= Tablet) && (Tablet <= visit_device_type.upperBound#4462))
19/07/31 17:06:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:25 INFO DAGScheduler: Got job 87 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:25 INFO DAGScheduler: Final stage: ResultStage 130 (collect at utils.scala:204)
19/07/31 17:06:25 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:25 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:25 INFO DAGScheduler: Submitting ResultStage 130 (MapPartitionsRDD[401] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 72.1 KB, free 908.9 MB)
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 30.5 KB, free 908.8 MB)
19/07/31 17:06:25 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 911.4 MB)
19/07/31 17:06:25 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 130 (MapPartitionsRDD[401] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:25 INFO TaskSchedulerImpl: Adding task set 130.0 with 1 tasks
19/07/31 17:06:25 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 253, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:25 INFO Executor: Running task 0.0 in stage 130.0 (TID 253)
19/07/31 17:06:25 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:25 INFO Executor: Finished task 0.0 in stage 130.0 (TID 253). 6512 bytes result sent to driver
19/07/31 17:06:25 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 253) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:06:25 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool 
19/07/31 17:06:25 INFO DAGScheduler: ResultStage 130 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:06:25 INFO DAGScheduler: Job 87 finished: collect at utils.scala:204, took 0.009620 s
19/07/31 17:06:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:25 INFO DAGScheduler: Registering RDD 402 (collect at utils.scala:204)
19/07/31 17:06:25 INFO DAGScheduler: Got job 88 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:25 INFO DAGScheduler: Final stage: ResultStage 132 (collect at utils.scala:204)
19/07/31 17:06:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 131)
19/07/31 17:06:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 131)
19/07/31 17:06:25 INFO DAGScheduler: Submitting ShuffleMapStage 131 (MapPartitionsRDD[402] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 74.5 KB, free 908.8 MB)
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 31.8 KB, free 908.7 MB)
19/07/31 17:06:25 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.4 MB)
19/07/31 17:06:25 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 131 (MapPartitionsRDD[402] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:25 INFO TaskSchedulerImpl: Adding task set 131.0 with 1 tasks
19/07/31 17:06:25 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 254, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:25 INFO Executor: Running task 0.0 in stage 131.0 (TID 254)
19/07/31 17:06:25 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:25 INFO Executor: Finished task 0.0 in stage 131.0 (TID 254). 1687 bytes result sent to driver
19/07/31 17:06:25 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 254) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:06:25 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool 
19/07/31 17:06:25 INFO DAGScheduler: ShuffleMapStage 131 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:06:25 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:25 INFO DAGScheduler: running: Set()
19/07/31 17:06:25 INFO DAGScheduler: waiting: Set(ResultStage 132)
19/07/31 17:06:25 INFO DAGScheduler: failed: Set()
19/07/31 17:06:25 INFO DAGScheduler: Submitting ResultStage 132 (MapPartitionsRDD[405] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 16.8 KB, free 908.7 MB)
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 8.0 KB, free 908.7 MB)
19/07/31 17:06:25 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.4 MB)
19/07/31 17:06:25 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:25 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 132 (MapPartitionsRDD[405] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:25 INFO TaskSchedulerImpl: Adding task set 132.0 with 4 tasks
19/07/31 17:06:25 INFO TaskSetManager: Starting task 0.0 in stage 132.0 (TID 255, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:25 INFO TaskSetManager: Starting task 1.0 in stage 132.0 (TID 256, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:25 INFO TaskSetManager: Starting task 2.0 in stage 132.0 (TID 257, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:25 INFO TaskSetManager: Starting task 3.0 in stage 132.0 (TID 258, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:25 INFO Executor: Running task 1.0 in stage 132.0 (TID 256)
19/07/31 17:06:25 INFO Executor: Running task 2.0 in stage 132.0 (TID 257)
19/07/31 17:06:25 INFO Executor: Running task 3.0 in stage 132.0 (TID 258)
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:25 INFO Executor: Running task 0.0 in stage 132.0 (TID 255)
19/07/31 17:06:25 INFO Executor: Finished task 3.0 in stage 132.0 (TID 258). 2336 bytes result sent to driver
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:25 INFO Executor: Finished task 1.0 in stage 132.0 (TID 256). 2340 bytes result sent to driver
19/07/31 17:06:25 INFO Executor: Finished task 0.0 in stage 132.0 (TID 255). 2357 bytes result sent to driver
19/07/31 17:06:25 INFO TaskSetManager: Finished task 3.0 in stage 132.0 (TID 258) in 6 ms on localhost (executor driver) (1/4)
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:25 INFO TaskSetManager: Finished task 1.0 in stage 132.0 (TID 256) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:06:25 INFO TaskSetManager: Finished task 0.0 in stage 132.0 (TID 255) in 7 ms on localhost (executor driver) (3/4)
19/07/31 17:06:25 INFO Executor: Finished task 2.0 in stage 132.0 (TID 257). 2362 bytes result sent to driver
19/07/31 17:06:25 INFO TaskSetManager: Finished task 2.0 in stage 132.0 (TID 257) in 7 ms on localhost (executor driver) (4/4)
19/07/31 17:06:25 INFO TaskSchedulerImpl: Removed TaskSet 132.0, whose tasks have all completed, from pool 
19/07/31 17:06:25 INFO DAGScheduler: ResultStage 132 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:06:25 INFO DAGScheduler: Job 88 finished: collect at utils.scala:204, took 0.024831 s
19/07/31 17:06:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_337`) `dbplyr_338`
ORDER BY `date`) `dbplyr_339`) `dbplyr_340`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:25 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_341`) `dbplyr_342`
ORDER BY `date`) `dbplyr_343`) `dbplyr_344`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:25 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:25 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4558 - cust_prospect_ind.nullCount#4557) > 0)
19/07/31 17:06:25 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4563 - visit_device_type.nullCount#4562) > 0)
19/07/31 17:06:25 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4556 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4555))
19/07/31 17:06:25 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4561 <= All Devices) && (All Devices <= visit_device_type.upperBound#4560))
19/07/31 17:06:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:25 INFO DAGScheduler: Got job 89 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:25 INFO DAGScheduler: Final stage: ResultStage 133 (collect at utils.scala:204)
19/07/31 17:06:25 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:25 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:25 INFO DAGScheduler: Submitting ResultStage 133 (MapPartitionsRDD[410] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 72.1 KB, free 908.6 MB)
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 30.4 KB, free 908.6 MB)
19/07/31 17:06:25 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 127.0.0.1:53890 (size: 30.4 KB, free: 911.4 MB)
19/07/31 17:06:25 INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 133 (MapPartitionsRDD[410] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:25 INFO TaskSchedulerImpl: Adding task set 133.0 with 1 tasks
19/07/31 17:06:25 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 259, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:25 INFO Executor: Running task 0.0 in stage 133.0 (TID 259)
19/07/31 17:06:25 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:25 INFO Executor: Finished task 0.0 in stage 133.0 (TID 259). 7499 bytes result sent to driver
19/07/31 17:06:25 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 259) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:06:25 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool 
19/07/31 17:06:25 INFO DAGScheduler: ResultStage 133 (collect at utils.scala:204) finished in 0.004 s
19/07/31 17:06:25 INFO DAGScheduler: Job 89 finished: collect at utils.scala:204, took 0.007130 s
19/07/31 17:06:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:25 INFO DAGScheduler: Registering RDD 411 (collect at utils.scala:204)
19/07/31 17:06:25 INFO DAGScheduler: Got job 90 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:25 INFO DAGScheduler: Final stage: ResultStage 135 (collect at utils.scala:204)
19/07/31 17:06:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 134)
19/07/31 17:06:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 134)
19/07/31 17:06:25 INFO DAGScheduler: Submitting ShuffleMapStage 134 (MapPartitionsRDD[411] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 74.5 KB, free 908.5 MB)
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 31.7 KB, free 908.5 MB)
19/07/31 17:06:25 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 127.0.0.1:53890 (size: 31.7 KB, free: 911.3 MB)
19/07/31 17:06:25 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 134 (MapPartitionsRDD[411] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:25 INFO TaskSchedulerImpl: Adding task set 134.0 with 1 tasks
19/07/31 17:06:25 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 260, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:25 INFO Executor: Running task 0.0 in stage 134.0 (TID 260)
19/07/31 17:06:25 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:25 INFO Executor: Finished task 0.0 in stage 134.0 (TID 260). 1687 bytes result sent to driver
19/07/31 17:06:25 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 260) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:06:25 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool 
19/07/31 17:06:25 INFO DAGScheduler: ShuffleMapStage 134 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:25 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:25 INFO DAGScheduler: running: Set()
19/07/31 17:06:25 INFO DAGScheduler: waiting: Set(ResultStage 135)
19/07/31 17:06:25 INFO DAGScheduler: failed: Set()
19/07/31 17:06:25 INFO DAGScheduler: Submitting ResultStage 135 (MapPartitionsRDD[414] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 16.8 KB, free 908.5 MB)
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 8.0 KB, free 908.5 MB)
19/07/31 17:06:25 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.3 MB)
19/07/31 17:06:25 INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:25 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 135 (MapPartitionsRDD[414] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:25 INFO TaskSchedulerImpl: Adding task set 135.0 with 4 tasks
19/07/31 17:06:25 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 261, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:25 INFO TaskSetManager: Starting task 1.0 in stage 135.0 (TID 262, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:25 INFO TaskSetManager: Starting task 2.0 in stage 135.0 (TID 263, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:25 INFO TaskSetManager: Starting task 3.0 in stage 135.0 (TID 264, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:25 INFO Executor: Running task 3.0 in stage 135.0 (TID 264)
19/07/31 17:06:25 INFO Executor: Running task 2.0 in stage 135.0 (TID 263)
19/07/31 17:06:25 INFO Executor: Running task 1.0 in stage 135.0 (TID 262)
19/07/31 17:06:25 INFO Executor: Running task 0.0 in stage 135.0 (TID 261)
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:25 INFO Executor: Finished task 2.0 in stage 135.0 (TID 263). 2390 bytes result sent to driver
19/07/31 17:06:25 INFO Executor: Finished task 3.0 in stage 135.0 (TID 264). 2362 bytes result sent to driver
19/07/31 17:06:25 INFO Executor: Finished task 1.0 in stage 135.0 (TID 262). 2403 bytes result sent to driver
19/07/31 17:06:25 INFO Executor: Finished task 0.0 in stage 135.0 (TID 261). 2382 bytes result sent to driver
19/07/31 17:06:25 INFO TaskSetManager: Finished task 2.0 in stage 135.0 (TID 263) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:06:25 INFO TaskSetManager: Finished task 3.0 in stage 135.0 (TID 264) in 4 ms on localhost (executor driver) (2/4)
19/07/31 17:06:25 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 261) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:06:25 INFO TaskSetManager: Finished task 1.0 in stage 135.0 (TID 262) in 4 ms on localhost (executor driver) (4/4)
19/07/31 17:06:25 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool 
19/07/31 17:06:25 INFO DAGScheduler: ResultStage 135 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:25 INFO DAGScheduler: Job 90 finished: collect at utils.scala:204, took 0.017528 s
19/07/31 17:06:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_345`) `dbplyr_346`
ORDER BY `date`) `dbplyr_347`) `dbplyr_348`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:25 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_349`) `dbplyr_350`
ORDER BY `date`) `dbplyr_351`) `dbplyr_352`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:25 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:25 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4656 - cust_prospect_ind.nullCount#4655) > 0)
19/07/31 17:06:25 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4661 - visit_device_type.nullCount#4660) > 0)
19/07/31 17:06:25 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4654 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4653))
19/07/31 17:06:25 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4659 <= All Devices) && (All Devices <= visit_device_type.upperBound#4658))
19/07/31 17:06:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:25 INFO DAGScheduler: Got job 91 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:25 INFO DAGScheduler: Final stage: ResultStage 136 (collect at utils.scala:204)
19/07/31 17:06:25 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:25 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:25 INFO DAGScheduler: Submitting ResultStage 136 (MapPartitionsRDD[419] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 72.1 KB, free 908.4 MB)
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 30.5 KB, free 908.4 MB)
19/07/31 17:06:25 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 911.3 MB)
19/07/31 17:06:25 INFO SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 136 (MapPartitionsRDD[419] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:25 INFO TaskSchedulerImpl: Adding task set 136.0 with 1 tasks
19/07/31 17:06:25 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 265, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:25 INFO Executor: Running task 0.0 in stage 136.0 (TID 265)
19/07/31 17:06:25 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:25 INFO Executor: Finished task 0.0 in stage 136.0 (TID 265). 7542 bytes result sent to driver
19/07/31 17:06:25 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 265) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:06:25 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool 
19/07/31 17:06:25 INFO DAGScheduler: ResultStage 136 (collect at utils.scala:204) finished in 0.004 s
19/07/31 17:06:25 INFO DAGScheduler: Job 91 finished: collect at utils.scala:204, took 0.007290 s
19/07/31 17:06:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:25 INFO DAGScheduler: Registering RDD 420 (collect at utils.scala:204)
19/07/31 17:06:25 INFO DAGScheduler: Got job 92 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:25 INFO DAGScheduler: Final stage: ResultStage 138 (collect at utils.scala:204)
19/07/31 17:06:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 137)
19/07/31 17:06:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 137)
19/07/31 17:06:25 INFO DAGScheduler: Submitting ShuffleMapStage 137 (MapPartitionsRDD[420] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 74.5 KB, free 908.3 MB)
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 31.8 KB, free 908.3 MB)
19/07/31 17:06:25 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.3 MB)
19/07/31 17:06:25 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 137 (MapPartitionsRDD[420] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:25 INFO TaskSchedulerImpl: Adding task set 137.0 with 1 tasks
19/07/31 17:06:25 INFO TaskSetManager: Starting task 0.0 in stage 137.0 (TID 266, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:25 INFO Executor: Running task 0.0 in stage 137.0 (TID 266)
19/07/31 17:06:25 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:25 INFO Executor: Finished task 0.0 in stage 137.0 (TID 266). 1687 bytes result sent to driver
19/07/31 17:06:25 INFO TaskSetManager: Finished task 0.0 in stage 137.0 (TID 266) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:06:25 INFO TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool 
19/07/31 17:06:25 INFO DAGScheduler: ShuffleMapStage 137 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:06:25 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:25 INFO DAGScheduler: running: Set()
19/07/31 17:06:25 INFO DAGScheduler: waiting: Set(ResultStage 138)
19/07/31 17:06:25 INFO DAGScheduler: failed: Set()
19/07/31 17:06:25 INFO DAGScheduler: Submitting ResultStage 138 (MapPartitionsRDD[423] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 16.8 KB, free 908.3 MB)
19/07/31 17:06:25 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 8.0 KB, free 908.3 MB)
19/07/31 17:06:25 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.2 MB)
19/07/31 17:06:25 INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:25 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 138 (MapPartitionsRDD[423] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:25 INFO TaskSchedulerImpl: Adding task set 138.0 with 4 tasks
19/07/31 17:06:25 INFO TaskSetManager: Starting task 0.0 in stage 138.0 (TID 267, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:25 INFO TaskSetManager: Starting task 1.0 in stage 138.0 (TID 268, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:25 INFO TaskSetManager: Starting task 2.0 in stage 138.0 (TID 269, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:25 INFO TaskSetManager: Starting task 3.0 in stage 138.0 (TID 270, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:25 INFO Executor: Running task 1.0 in stage 138.0 (TID 268)
19/07/31 17:06:25 INFO Executor: Running task 3.0 in stage 138.0 (TID 270)
19/07/31 17:06:25 INFO Executor: Running task 2.0 in stage 138.0 (TID 269)
19/07/31 17:06:25 INFO Executor: Running task 0.0 in stage 138.0 (TID 267)
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:25 INFO Executor: Finished task 3.0 in stage 138.0 (TID 270). 2362 bytes result sent to driver
19/07/31 17:06:25 INFO Executor: Finished task 2.0 in stage 138.0 (TID 269). 2390 bytes result sent to driver
19/07/31 17:06:25 INFO Executor: Finished task 1.0 in stage 138.0 (TID 268). 2403 bytes result sent to driver
19/07/31 17:06:25 INFO TaskSetManager: Finished task 3.0 in stage 138.0 (TID 270) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:06:25 INFO TaskSetManager: Finished task 2.0 in stage 138.0 (TID 269) in 4 ms on localhost (executor driver) (2/4)
19/07/31 17:06:25 INFO Executor: Finished task 0.0 in stage 138.0 (TID 267). 2382 bytes result sent to driver
19/07/31 17:06:25 INFO TaskSetManager: Finished task 1.0 in stage 138.0 (TID 268) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:06:25 INFO TaskSetManager: Finished task 0.0 in stage 138.0 (TID 267) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:06:25 INFO TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool 
19/07/31 17:06:25 INFO DAGScheduler: ResultStage 138 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:25 INFO DAGScheduler: Job 92 finished: collect at utils.scala:204, took 0.020386 s
19/07/31 17:06:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_353`) `dbplyr_354`
ORDER BY `date`) `dbplyr_355`) `dbplyr_356`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Tablet"))
19/07/31 17:06:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_357`) `dbplyr_358`
ORDER BY `date`) `dbplyr_359`) `dbplyr_360`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Tablet"))
19/07/31 17:06:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:26 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4754 - cust_prospect_ind.nullCount#4753) > 0)
19/07/31 17:06:26 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4759 - visit_device_type.nullCount#4758) > 0)
19/07/31 17:06:26 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#4752 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#4751))
19/07/31 17:06:26 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#4757 <= Tablet) && (Tablet <= visit_device_type.upperBound#4756))
19/07/31 17:06:26 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:26 INFO DAGScheduler: Got job 93 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:26 INFO DAGScheduler: Final stage: ResultStage 139 (collect at utils.scala:204)
19/07/31 17:06:26 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:26 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:26 INFO DAGScheduler: Submitting ResultStage 139 (MapPartitionsRDD[428] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 72.1 KB, free 908.2 MB)
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 30.5 KB, free 908.2 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 911.2 MB)
19/07/31 17:06:26 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 139 (MapPartitionsRDD[428] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:26 INFO TaskSchedulerImpl: Adding task set 139.0 with 1 tasks
19/07/31 17:06:26 INFO TaskSetManager: Starting task 0.0 in stage 139.0 (TID 271, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:26 INFO Executor: Running task 0.0 in stage 139.0 (TID 271)
19/07/31 17:06:26 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:26 INFO Executor: Finished task 0.0 in stage 139.0 (TID 271). 6512 bytes result sent to driver
19/07/31 17:06:26 INFO TaskSetManager: Finished task 0.0 in stage 139.0 (TID 271) in 3 ms on localhost (executor driver) (1/1)
19/07/31 17:06:26 INFO TaskSchedulerImpl: Removed TaskSet 139.0, whose tasks have all completed, from pool 
19/07/31 17:06:26 INFO DAGScheduler: ResultStage 139 (collect at utils.scala:204) finished in 0.004 s
19/07/31 17:06:26 INFO DAGScheduler: Job 93 finished: collect at utils.scala:204, took 0.007600 s
19/07/31 17:06:26 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:26 INFO DAGScheduler: Registering RDD 429 (collect at utils.scala:204)
19/07/31 17:06:26 INFO DAGScheduler: Got job 94 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:26 INFO DAGScheduler: Final stage: ResultStage 141 (collect at utils.scala:204)
19/07/31 17:06:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 140)
19/07/31 17:06:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 140)
19/07/31 17:06:26 INFO DAGScheduler: Submitting ShuffleMapStage 140 (MapPartitionsRDD[429] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 74.5 KB, free 908.1 MB)
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 31.8 KB, free 908.0 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.2 MB)
19/07/31 17:06:26 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 140 (MapPartitionsRDD[429] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:26 INFO TaskSchedulerImpl: Adding task set 140.0 with 1 tasks
19/07/31 17:06:26 INFO TaskSetManager: Starting task 0.0 in stage 140.0 (TID 272, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:26 INFO Executor: Running task 0.0 in stage 140.0 (TID 272)
19/07/31 17:06:26 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:26 INFO Executor: Finished task 0.0 in stage 140.0 (TID 272). 1687 bytes result sent to driver
19/07/31 17:06:26 INFO TaskSetManager: Finished task 0.0 in stage 140.0 (TID 272) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:06:26 INFO TaskSchedulerImpl: Removed TaskSet 140.0, whose tasks have all completed, from pool 
19/07/31 17:06:26 INFO DAGScheduler: ShuffleMapStage 140 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:26 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:26 INFO DAGScheduler: running: Set()
19/07/31 17:06:26 INFO DAGScheduler: waiting: Set(ResultStage 141)
19/07/31 17:06:26 INFO DAGScheduler: failed: Set()
19/07/31 17:06:26 INFO DAGScheduler: Submitting ResultStage 141 (MapPartitionsRDD[432] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 16.8 KB, free 908.0 MB)
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 8.0 KB, free 908.0 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.2 MB)
19/07/31 17:06:26 INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 141 (MapPartitionsRDD[432] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:26 INFO TaskSchedulerImpl: Adding task set 141.0 with 4 tasks
19/07/31 17:06:26 INFO TaskSetManager: Starting task 0.0 in stage 141.0 (TID 273, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:26 INFO TaskSetManager: Starting task 1.0 in stage 141.0 (TID 274, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:26 INFO TaskSetManager: Starting task 2.0 in stage 141.0 (TID 275, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:26 INFO TaskSetManager: Starting task 3.0 in stage 141.0 (TID 276, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:26 INFO Executor: Running task 2.0 in stage 141.0 (TID 275)
19/07/31 17:06:26 INFO Executor: Running task 0.0 in stage 141.0 (TID 273)
19/07/31 17:06:26 INFO Executor: Running task 3.0 in stage 141.0 (TID 276)
19/07/31 17:06:26 INFO Executor: Running task 1.0 in stage 141.0 (TID 274)
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:26 INFO Executor: Finished task 1.0 in stage 141.0 (TID 274). 2294 bytes result sent to driver
19/07/31 17:06:26 INFO Executor: Finished task 3.0 in stage 141.0 (TID 276). 2346 bytes result sent to driver
19/07/31 17:06:26 INFO TaskSetManager: Finished task 1.0 in stage 141.0 (TID 274) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:06:26 INFO TaskSetManager: Finished task 3.0 in stage 141.0 (TID 276) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:06:26 INFO Executor: Finished task 2.0 in stage 141.0 (TID 275). 2360 bytes result sent to driver
19/07/31 17:06:26 INFO Executor: Finished task 0.0 in stage 141.0 (TID 273). 2385 bytes result sent to driver
19/07/31 17:06:26 INFO TaskSetManager: Finished task 2.0 in stage 141.0 (TID 275) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:06:26 INFO TaskSetManager: Finished task 0.0 in stage 141.0 (TID 273) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:06:26 INFO TaskSchedulerImpl: Removed TaskSet 141.0, whose tasks have all completed, from pool 
19/07/31 17:06:26 INFO DAGScheduler: ResultStage 141 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:06:26 INFO DAGScheduler: Job 94 finished: collect at utils.scala:204, took 0.021141 s
19/07/31 17:06:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_361`) `dbplyr_362`
ORDER BY `date`) `dbplyr_363`) `dbplyr_364`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_365`) `dbplyr_366`
ORDER BY `date`) `dbplyr_367`) `dbplyr_368`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:26 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4852 - cust_prospect_ind.nullCount#4851) > 0)
19/07/31 17:06:26 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4857 - visit_device_type.nullCount#4856) > 0)
19/07/31 17:06:26 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4850 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4849))
19/07/31 17:06:26 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4855 <= All Devices) && (All Devices <= visit_device_type.upperBound#4854))
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3073
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3802
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 911.2 MB)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3726
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3316
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3154
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.2 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 127.0.0.1:53890 in memory (size: 31.7 KB, free: 911.2 MB)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3315
19/07/31 17:06:26 INFO ContextCleaner: Cleaned shuffle 34
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3319
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3803
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3644
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3805
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 2835
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 911.3 MB)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 2828
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.3 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 911.3 MB)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3160
19/07/31 17:06:26 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.3 MB)
19/07/31 17:06:26 INFO DAGScheduler: Got job 95 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:26 INFO DAGScheduler: Final stage: ResultStage 142 (collect at utils.scala:204)
19/07/31 17:06:26 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:26 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3639
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3314
19/07/31 17:06:26 INFO DAGScheduler: Submitting ResultStage 142 (MapPartitionsRDD[437] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 911.4 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 911.4 MB)
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 72.1 KB, free 908.6 MB)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 2911
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3800
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3642
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3155
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 30.4 KB, free 908.7 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 911.4 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 127.0.0.1:53890 (size: 30.4 KB, free: 911.4 MB)
19/07/31 17:06:26 INFO SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 142 (MapPartitionsRDD[437] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:26 INFO TaskSchedulerImpl: Adding task set 142.0 with 1 tasks
19/07/31 17:06:26 INFO TaskSetManager: Starting task 0.0 in stage 142.0 (TID 277, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 2910
19/07/31 17:06:26 INFO Executor: Running task 0.0 in stage 142.0 (TID 277)
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_144_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.4 MB)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3077
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3321
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3322
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3806
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.4 MB)
19/07/31 17:06:26 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:26 INFO Executor: Finished task 0.0 in stage 142.0 (TID 277). 7542 bytes result sent to driver
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 911.4 MB)
19/07/31 17:06:26 INFO TaskSetManager: Finished task 0.0 in stage 142.0 (TID 277) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:06:26 INFO TaskSchedulerImpl: Removed TaskSet 142.0, whose tasks have all completed, from pool 
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 2909
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3557
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 2917
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3072
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3641
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3727
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 2913
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3153
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3159
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3318
19/07/31 17:06:26 INFO DAGScheduler: ResultStage 142 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:06:26 INFO DAGScheduler: Job 95 finished: collect at utils.scala:204, took 0.010739 s
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 127.0.0.1:53890 in memory (size: 30.4 KB, free: 911.5 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 127.0.0.1:53890 in memory (size: 31.7 KB, free: 911.5 MB)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3079
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3643
19/07/31 17:06:26 INFO ContextCleaner: Cleaned shuffle 35
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 911.5 MB)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3807
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 127.0.0.1:53890 in memory (size: 31.7 KB, free: 911.6 MB)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 2831
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 2915
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 2912
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3075
19/07/31 17:06:26 INFO ContextCleaner: Cleaned shuffle 37
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_139_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 911.6 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.6 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 127.0.0.1:53890 in memory (size: 31.7 KB, free: 911.6 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 911.7 MB)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 2833
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3722
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 127.0.0.1:53890 in memory (size: 30.4 KB, free: 911.7 MB)
19/07/31 17:06:26 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:06:26 INFO DAGScheduler: Registering RDD 438 (collect at utils.scala:204)
19/07/31 17:06:26 INFO DAGScheduler: Got job 96 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:26 INFO DAGScheduler: Final stage: ResultStage 144 (collect at utils.scala:204)
19/07/31 17:06:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 143)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3638
19/07/31 17:06:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 143)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3158
19/07/31 17:06:26 INFO DAGScheduler: Submitting ShuffleMapStage 143 (MapPartitionsRDD[438] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 911.7 MB)
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 74.5 KB, free 909.7 MB)
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 31.7 KB, free 909.7 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 127.0.0.1:53890 (size: 31.7 KB, free: 911.7 MB)
19/07/31 17:06:26 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 143 (MapPartitionsRDD[438] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:26 INFO TaskSchedulerImpl: Adding task set 143.0 with 1 tasks
19/07/31 17:06:26 INFO TaskSetManager: Starting task 0.0 in stage 143.0 (TID 278, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:26 INFO Executor: Running task 0.0 in stage 143.0 (TID 278)
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:06:26 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3724
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:06:26 INFO Executor: Finished task 0.0 in stage 143.0 (TID 278). 1687 bytes result sent to driver
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:06:26 INFO TaskSetManager: Finished task 0.0 in stage 143.0 (TID 278) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:06:26 INFO TaskSchedulerImpl: Removed TaskSet 143.0, whose tasks have all completed, from pool 
19/07/31 17:06:26 INFO DAGScheduler: ShuffleMapStage 143 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:06:26 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:26 INFO DAGScheduler: running: Set()
19/07/31 17:06:26 INFO DAGScheduler: waiting: Set(ResultStage 144)
19/07/31 17:06:26 INFO DAGScheduler: failed: Set()
19/07/31 17:06:26 INFO DAGScheduler: Submitting ResultStage 144 (MapPartitionsRDD[441] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned shuffle 46
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 2914
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 16.8 KB, free 910.1 MB)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3720
19/07/31 17:06:26 INFO ContextCleaner: Cleaned shuffle 38
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3476
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.2 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:06:26 INFO SparkContext: Created broadcast 147 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 911.9 MB)
19/07/31 17:06:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 144 (MapPartitionsRDD[441] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:26 INFO TaskSchedulerImpl: Adding task set 144.0 with 4 tasks
19/07/31 17:06:26 INFO TaskSetManager: Starting task 0.0 in stage 144.0 (TID 279, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 127.0.0.1:53890 in memory (size: 8.1 KB, free: 911.9 MB)
19/07/31 17:06:26 INFO TaskSetManager: Starting task 1.0 in stage 144.0 (TID 280, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:26 INFO TaskSetManager: Starting task 2.0 in stage 144.0 (TID 281, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned shuffle 33
19/07/31 17:06:26 INFO TaskSetManager: Starting task 3.0 in stage 144.0 (TID 282, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3801
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 2829
19/07/31 17:06:26 INFO Executor: Running task 3.0 in stage 144.0 (TID 282)
19/07/31 17:06:26 INFO Executor: Running task 2.0 in stage 144.0 (TID 281)
19/07/31 17:06:26 INFO Executor: Running task 1.0 in stage 144.0 (TID 280)
19/07/31 17:06:26 INFO Executor: Running task 0.0 in stage 144.0 (TID 279)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3721
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3725
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3076
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3157
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 2990
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3233
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 127.0.0.1:53890 in memory (size: 30.4 KB, free: 911.9 MB)
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3317
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3645
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 2834
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3808
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3320
19/07/31 17:06:26 INFO Executor: Finished task 0.0 in stage 144.0 (TID 279). 2339 bytes result sent to driver
19/07/31 17:06:26 INFO Executor: Finished task 1.0 in stage 144.0 (TID 280). 2403 bytes result sent to driver
19/07/31 17:06:26 INFO Executor: Finished task 2.0 in stage 144.0 (TID 281). 2347 bytes result sent to driver
19/07/31 17:06:26 INFO Executor: Finished task 3.0 in stage 144.0 (TID 282). 2319 bytes result sent to driver
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 127.0.0.1:53890 in memory (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:06:26 INFO TaskSetManager: Finished task 1.0 in stage 144.0 (TID 280) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:06:26 INFO TaskSetManager: Finished task 2.0 in stage 144.0 (TID 281) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3152
19/07/31 17:06:26 INFO TaskSetManager: Finished task 0.0 in stage 144.0 (TID 279) in 7 ms on localhost (executor driver) (3/4)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3723
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3071
19/07/31 17:06:26 INFO TaskSetManager: Finished task 3.0 in stage 144.0 (TID 282) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 2916
19/07/31 17:06:26 INFO TaskSchedulerImpl: Removed TaskSet 144.0, whose tasks have all completed, from pool 
19/07/31 17:06:26 INFO ContextCleaner: Cleaned shuffle 44
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 2830
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 127.0.0.1:53890 in memory (size: 30.4 KB, free: 912.0 MB)
19/07/31 17:06:26 INFO DAGScheduler: ResultStage 144 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3719
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 2832
19/07/31 17:06:26 INFO DAGScheduler: Job 96 finished: collect at utils.scala:204, took 0.024578 s
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3395
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3156
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3074
19/07/31 17:06:26 INFO ContextCleaner: Cleaned shuffle 45
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3646
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3078
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 2836
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 127.0.0.1:53890 in memory (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3640
19/07/31 17:06:26 INFO ContextCleaner: Cleaned shuffle 40
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3881
19/07/31 17:06:26 INFO ContextCleaner: Cleaned accumulator 3804
19/07/31 17:06:26 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 127.0.0.1:53890 in memory (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:06:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_369`) `dbplyr_370`
ORDER BY `date`) `dbplyr_371`) `dbplyr_372`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_373`) `dbplyr_374`
ORDER BY `date`) `dbplyr_375`) `dbplyr_376`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:26 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4950 - cust_prospect_ind.nullCount#4949) > 0)
19/07/31 17:06:26 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4955 - visit_device_type.nullCount#4954) > 0)
19/07/31 17:06:26 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4948 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4947))
19/07/31 17:06:26 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4953 <= All Devices) && (All Devices <= visit_device_type.upperBound#4952))
19/07/31 17:06:26 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:26 INFO DAGScheduler: Got job 97 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:26 INFO DAGScheduler: Final stage: ResultStage 145 (collect at utils.scala:204)
19/07/31 17:06:26 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:26 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:26 INFO DAGScheduler: Submitting ResultStage 145 (MapPartitionsRDD[446] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 72.1 KB, free 910.8 MB)
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.8 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:06:26 INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 145 (MapPartitionsRDD[446] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:26 INFO TaskSchedulerImpl: Adding task set 145.0 with 1 tasks
19/07/31 17:06:26 INFO TaskSetManager: Starting task 0.0 in stage 145.0 (TID 283, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:26 INFO Executor: Running task 0.0 in stage 145.0 (TID 283)
19/07/31 17:06:26 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:26 INFO Executor: Finished task 0.0 in stage 145.0 (TID 283). 7542 bytes result sent to driver
19/07/31 17:06:26 INFO TaskSetManager: Finished task 0.0 in stage 145.0 (TID 283) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:06:26 INFO TaskSchedulerImpl: Removed TaskSet 145.0, whose tasks have all completed, from pool 
19/07/31 17:06:26 INFO DAGScheduler: ResultStage 145 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:26 INFO DAGScheduler: Job 97 finished: collect at utils.scala:204, took 0.009309 s
19/07/31 17:06:26 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:26 INFO DAGScheduler: Registering RDD 447 (collect at utils.scala:204)
19/07/31 17:06:26 INFO DAGScheduler: Got job 98 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:26 INFO DAGScheduler: Final stage: ResultStage 147 (collect at utils.scala:204)
19/07/31 17:06:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 146)
19/07/31 17:06:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 146)
19/07/31 17:06:26 INFO DAGScheduler: Submitting ShuffleMapStage 146 (MapPartitionsRDD[447] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 74.5 KB, free 910.7 MB)
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.7 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:06:26 INFO SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 146 (MapPartitionsRDD[447] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:26 INFO TaskSchedulerImpl: Adding task set 146.0 with 1 tasks
19/07/31 17:06:26 INFO TaskSetManager: Starting task 0.0 in stage 146.0 (TID 284, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:26 INFO Executor: Running task 0.0 in stage 146.0 (TID 284)
19/07/31 17:06:26 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:26 INFO Executor: Finished task 0.0 in stage 146.0 (TID 284). 1687 bytes result sent to driver
19/07/31 17:06:26 INFO TaskSetManager: Finished task 0.0 in stage 146.0 (TID 284) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:06:26 INFO TaskSchedulerImpl: Removed TaskSet 146.0, whose tasks have all completed, from pool 
19/07/31 17:06:26 INFO DAGScheduler: ShuffleMapStage 146 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:06:26 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:26 INFO DAGScheduler: running: Set()
19/07/31 17:06:26 INFO DAGScheduler: waiting: Set(ResultStage 147)
19/07/31 17:06:26 INFO DAGScheduler: failed: Set()
19/07/31 17:06:26 INFO DAGScheduler: Submitting ResultStage 147 (MapPartitionsRDD[450] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 16.8 KB, free 910.7 MB)
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.7 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:06:26 INFO SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 147 (MapPartitionsRDD[450] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:26 INFO TaskSchedulerImpl: Adding task set 147.0 with 4 tasks
19/07/31 17:06:26 INFO TaskSetManager: Starting task 0.0 in stage 147.0 (TID 285, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:26 INFO TaskSetManager: Starting task 1.0 in stage 147.0 (TID 286, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:26 INFO TaskSetManager: Starting task 2.0 in stage 147.0 (TID 287, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:26 INFO TaskSetManager: Starting task 3.0 in stage 147.0 (TID 288, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:26 INFO Executor: Running task 1.0 in stage 147.0 (TID 286)
19/07/31 17:06:26 INFO Executor: Running task 0.0 in stage 147.0 (TID 285)
19/07/31 17:06:26 INFO Executor: Running task 2.0 in stage 147.0 (TID 287)
19/07/31 17:06:26 INFO Executor: Running task 3.0 in stage 147.0 (TID 288)
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:26 INFO Executor: Finished task 3.0 in stage 147.0 (TID 288). 2362 bytes result sent to driver
19/07/31 17:06:26 INFO Executor: Finished task 0.0 in stage 147.0 (TID 285). 2382 bytes result sent to driver
19/07/31 17:06:26 INFO Executor: Finished task 1.0 in stage 147.0 (TID 286). 2403 bytes result sent to driver
19/07/31 17:06:26 INFO Executor: Finished task 2.0 in stage 147.0 (TID 287). 2390 bytes result sent to driver
19/07/31 17:06:26 INFO TaskSetManager: Finished task 3.0 in stage 147.0 (TID 288) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:06:26 INFO TaskSetManager: Finished task 0.0 in stage 147.0 (TID 285) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:06:26 INFO TaskSetManager: Finished task 2.0 in stage 147.0 (TID 287) in 4 ms on localhost (executor driver) (3/4)
19/07/31 17:06:26 INFO TaskSetManager: Finished task 1.0 in stage 147.0 (TID 286) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:06:26 INFO TaskSchedulerImpl: Removed TaskSet 147.0, whose tasks have all completed, from pool 
19/07/31 17:06:26 INFO DAGScheduler: ResultStage 147 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:26 INFO DAGScheduler: Job 98 finished: collect at utils.scala:204, took 0.019967 s
19/07/31 17:06:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_377`) `dbplyr_378`
ORDER BY `date`) `dbplyr_379`) `dbplyr_380`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Tablet"))
19/07/31 17:06:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_381`) `dbplyr_382`
ORDER BY `date`) `dbplyr_383`) `dbplyr_384`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Tablet"))
19/07/31 17:06:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:26 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#5048 - cust_prospect_ind.nullCount#5047) > 0)
19/07/31 17:06:26 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#5053 - visit_device_type.nullCount#5052) > 0)
19/07/31 17:06:26 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#5046 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#5045))
19/07/31 17:06:26 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#5051 <= Tablet) && (Tablet <= visit_device_type.upperBound#5050))
19/07/31 17:06:26 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:26 INFO DAGScheduler: Got job 99 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:26 INFO DAGScheduler: Final stage: ResultStage 148 (collect at utils.scala:204)
19/07/31 17:06:26 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:26 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:26 INFO DAGScheduler: Submitting ResultStage 148 (MapPartitionsRDD[455] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 72.1 KB, free 910.6 MB)
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.6 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 127.0.0.1:53890 (size: 30.4 KB, free: 911.9 MB)
19/07/31 17:06:26 INFO SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 148 (MapPartitionsRDD[455] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:26 INFO TaskSchedulerImpl: Adding task set 148.0 with 1 tasks
19/07/31 17:06:26 INFO TaskSetManager: Starting task 0.0 in stage 148.0 (TID 289, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:26 INFO Executor: Running task 0.0 in stage 148.0 (TID 289)
19/07/31 17:06:26 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:26 INFO Executor: Finished task 0.0 in stage 148.0 (TID 289). 7068 bytes result sent to driver
19/07/31 17:06:26 INFO TaskSetManager: Finished task 0.0 in stage 148.0 (TID 289) in 3 ms on localhost (executor driver) (1/1)
19/07/31 17:06:26 INFO TaskSchedulerImpl: Removed TaskSet 148.0, whose tasks have all completed, from pool 
19/07/31 17:06:26 INFO DAGScheduler: ResultStage 148 (collect at utils.scala:204) finished in 0.004 s
19/07/31 17:06:26 INFO DAGScheduler: Job 99 finished: collect at utils.scala:204, took 0.007513 s
19/07/31 17:06:26 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:26 INFO DAGScheduler: Registering RDD 456 (collect at utils.scala:204)
19/07/31 17:06:26 INFO DAGScheduler: Got job 100 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:26 INFO DAGScheduler: Final stage: ResultStage 150 (collect at utils.scala:204)
19/07/31 17:06:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 149)
19/07/31 17:06:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 149)
19/07/31 17:06:26 INFO DAGScheduler: Submitting ShuffleMapStage 149 (MapPartitionsRDD[456] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 74.5 KB, free 910.5 MB)
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.5 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.9 MB)
19/07/31 17:06:26 INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 149 (MapPartitionsRDD[456] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:26 INFO TaskSchedulerImpl: Adding task set 149.0 with 1 tasks
19/07/31 17:06:26 INFO TaskSetManager: Starting task 0.0 in stage 149.0 (TID 290, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:26 INFO Executor: Running task 0.0 in stage 149.0 (TID 290)
19/07/31 17:06:26 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:26 INFO Executor: Finished task 0.0 in stage 149.0 (TID 290). 1687 bytes result sent to driver
19/07/31 17:06:26 INFO TaskSetManager: Finished task 0.0 in stage 149.0 (TID 290) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:06:26 INFO TaskSchedulerImpl: Removed TaskSet 149.0, whose tasks have all completed, from pool 
19/07/31 17:06:26 INFO DAGScheduler: ShuffleMapStage 149 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:06:26 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:26 INFO DAGScheduler: running: Set()
19/07/31 17:06:26 INFO DAGScheduler: waiting: Set(ResultStage 150)
19/07/31 17:06:26 INFO DAGScheduler: failed: Set()
19/07/31 17:06:26 INFO DAGScheduler: Submitting ResultStage 150 (MapPartitionsRDD[459] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 16.8 KB, free 910.4 MB)
19/07/31 17:06:26 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.4 MB)
19/07/31 17:06:26 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:06:26 INFO SparkContext: Created broadcast 153 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 150 (MapPartitionsRDD[459] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:26 INFO TaskSchedulerImpl: Adding task set 150.0 with 4 tasks
19/07/31 17:06:26 INFO TaskSetManager: Starting task 0.0 in stage 150.0 (TID 291, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:26 INFO TaskSetManager: Starting task 1.0 in stage 150.0 (TID 292, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:26 INFO TaskSetManager: Starting task 2.0 in stage 150.0 (TID 293, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:26 INFO TaskSetManager: Starting task 3.0 in stage 150.0 (TID 294, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:26 INFO Executor: Running task 1.0 in stage 150.0 (TID 292)
19/07/31 17:06:26 INFO Executor: Running task 2.0 in stage 150.0 (TID 293)
19/07/31 17:06:26 INFO Executor: Running task 3.0 in stage 150.0 (TID 294)
19/07/31 17:06:26 INFO Executor: Running task 0.0 in stage 150.0 (TID 291)
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:26 INFO Executor: Finished task 3.0 in stage 150.0 (TID 294). 2357 bytes result sent to driver
19/07/31 17:06:26 INFO Executor: Finished task 2.0 in stage 150.0 (TID 293). 2379 bytes result sent to driver
19/07/31 17:06:26 INFO TaskSetManager: Finished task 3.0 in stage 150.0 (TID 294) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:06:26 INFO TaskSetManager: Finished task 2.0 in stage 150.0 (TID 293) in 4 ms on localhost (executor driver) (2/4)
19/07/31 17:06:26 INFO Executor: Finished task 1.0 in stage 150.0 (TID 292). 2381 bytes result sent to driver
19/07/31 17:06:26 INFO TaskSetManager: Finished task 1.0 in stage 150.0 (TID 292) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:06:26 INFO Executor: Finished task 0.0 in stage 150.0 (TID 291). 2376 bytes result sent to driver
19/07/31 17:06:26 INFO TaskSetManager: Finished task 0.0 in stage 150.0 (TID 291) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:06:26 INFO TaskSchedulerImpl: Removed TaskSet 150.0, whose tasks have all completed, from pool 
19/07/31 17:06:26 INFO DAGScheduler: ResultStage 150 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:26 INFO DAGScheduler: Job 100 finished: collect at utils.scala:204, took 0.019859 s
19/07/31 17:06:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_385`) `dbplyr_386`
ORDER BY `date`) `dbplyr_387`) `dbplyr_388`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_389`) `dbplyr_390`
ORDER BY `date`) `dbplyr_391`) `dbplyr_392`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:27 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:27 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:27 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#5146 - cust_prospect_ind.nullCount#5145) > 0)
19/07/31 17:06:27 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#5151 - visit_device_type.nullCount#5150) > 0)
19/07/31 17:06:27 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#5144 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#5143))
19/07/31 17:06:27 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#5149 <= All Devices) && (All Devices <= visit_device_type.upperBound#5148))
19/07/31 17:06:27 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:27 INFO DAGScheduler: Got job 101 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:27 INFO DAGScheduler: Final stage: ResultStage 151 (collect at utils.scala:204)
19/07/31 17:06:27 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:27 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:27 INFO DAGScheduler: Submitting ResultStage 151 (MapPartitionsRDD[464] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:27 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 72.1 KB, free 910.4 MB)
19/07/31 17:06:27 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.3 MB)
19/07/31 17:06:27 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 911.9 MB)
19/07/31 17:06:27 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 151 (MapPartitionsRDD[464] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:27 INFO TaskSchedulerImpl: Adding task set 151.0 with 1 tasks
19/07/31 17:06:27 INFO TaskSetManager: Starting task 0.0 in stage 151.0 (TID 295, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:27 INFO Executor: Running task 0.0 in stage 151.0 (TID 295)
19/07/31 17:06:27 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:27 INFO Executor: Finished task 0.0 in stage 151.0 (TID 295). 7542 bytes result sent to driver
19/07/31 17:06:27 INFO TaskSetManager: Finished task 0.0 in stage 151.0 (TID 295) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:06:27 INFO TaskSchedulerImpl: Removed TaskSet 151.0, whose tasks have all completed, from pool 
19/07/31 17:06:27 INFO DAGScheduler: ResultStage 151 (collect at utils.scala:204) finished in 0.004 s
19/07/31 17:06:27 INFO DAGScheduler: Job 101 finished: collect at utils.scala:204, took 0.006727 s
19/07/31 17:06:27 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:27 INFO DAGScheduler: Registering RDD 465 (collect at utils.scala:204)
19/07/31 17:06:27 INFO DAGScheduler: Got job 102 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:27 INFO DAGScheduler: Final stage: ResultStage 153 (collect at utils.scala:204)
19/07/31 17:06:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 152)
19/07/31 17:06:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 152)
19/07/31 17:06:27 INFO DAGScheduler: Submitting ShuffleMapStage 152 (MapPartitionsRDD[465] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:27 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 74.5 KB, free 910.3 MB)
19/07/31 17:06:27 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.2 MB)
19/07/31 17:06:27 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:06:27 INFO SparkContext: Created broadcast 155 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 152 (MapPartitionsRDD[465] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:27 INFO TaskSchedulerImpl: Adding task set 152.0 with 1 tasks
19/07/31 17:06:27 INFO TaskSetManager: Starting task 0.0 in stage 152.0 (TID 296, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:27 INFO Executor: Running task 0.0 in stage 152.0 (TID 296)
19/07/31 17:06:27 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:27 INFO Executor: Finished task 0.0 in stage 152.0 (TID 296). 1687 bytes result sent to driver
19/07/31 17:06:27 INFO TaskSetManager: Finished task 0.0 in stage 152.0 (TID 296) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:06:27 INFO TaskSchedulerImpl: Removed TaskSet 152.0, whose tasks have all completed, from pool 
19/07/31 17:06:27 INFO DAGScheduler: ShuffleMapStage 152 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:06:27 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:27 INFO DAGScheduler: running: Set()
19/07/31 17:06:27 INFO DAGScheduler: waiting: Set(ResultStage 153)
19/07/31 17:06:27 INFO DAGScheduler: failed: Set()
19/07/31 17:06:27 INFO DAGScheduler: Submitting ResultStage 153 (MapPartitionsRDD[468] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:27 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 16.8 KB, free 910.2 MB)
19/07/31 17:06:27 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.2 MB)
19/07/31 17:06:27 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:06:27 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 153 (MapPartitionsRDD[468] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:27 INFO TaskSchedulerImpl: Adding task set 153.0 with 4 tasks
19/07/31 17:06:27 INFO TaskSetManager: Starting task 0.0 in stage 153.0 (TID 297, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:27 INFO TaskSetManager: Starting task 1.0 in stage 153.0 (TID 298, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:27 INFO TaskSetManager: Starting task 2.0 in stage 153.0 (TID 299, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:27 INFO TaskSetManager: Starting task 3.0 in stage 153.0 (TID 300, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:27 INFO Executor: Running task 1.0 in stage 153.0 (TID 298)
19/07/31 17:06:27 INFO Executor: Running task 2.0 in stage 153.0 (TID 299)
19/07/31 17:06:27 INFO Executor: Running task 0.0 in stage 153.0 (TID 297)
19/07/31 17:06:27 INFO Executor: Running task 3.0 in stage 153.0 (TID 300)
19/07/31 17:06:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:27 INFO Executor: Finished task 3.0 in stage 153.0 (TID 300). 2319 bytes result sent to driver
19/07/31 17:06:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:06:27 INFO Executor: Finished task 2.0 in stage 153.0 (TID 299). 2390 bytes result sent to driver
19/07/31 17:06:27 INFO Executor: Finished task 1.0 in stage 153.0 (TID 298). 2360 bytes result sent to driver
19/07/31 17:06:27 INFO Executor: Finished task 0.0 in stage 153.0 (TID 297). 2339 bytes result sent to driver
19/07/31 17:06:27 INFO TaskSetManager: Finished task 3.0 in stage 153.0 (TID 300) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:06:27 INFO TaskSetManager: Finished task 2.0 in stage 153.0 (TID 299) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:06:27 INFO TaskSetManager: Finished task 1.0 in stage 153.0 (TID 298) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:06:27 INFO TaskSetManager: Finished task 0.0 in stage 153.0 (TID 297) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:06:27 INFO TaskSchedulerImpl: Removed TaskSet 153.0, whose tasks have all completed, from pool 
19/07/31 17:06:27 INFO DAGScheduler: ResultStage 153 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:27 INFO DAGScheduler: Job 102 finished: collect at utils.scala:204, took 0.018305 s
19/07/31 17:06:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_393`) `dbplyr_394`
ORDER BY `date`) `dbplyr_395`) `dbplyr_396`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:27 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:27 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_397`) `dbplyr_398`
ORDER BY `date`) `dbplyr_399`) `dbplyr_400`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:06:27 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:06:27 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:06:27 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#5244 - cust_prospect_ind.nullCount#5243) > 0)
19/07/31 17:06:27 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#5249 - visit_device_type.nullCount#5248) > 0)
19/07/31 17:06:27 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#5242 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#5241))
19/07/31 17:06:27 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#5247 <= All Devices) && (All Devices <= visit_device_type.upperBound#5246))
19/07/31 17:06:27 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:27 INFO DAGScheduler: Got job 103 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:06:27 INFO DAGScheduler: Final stage: ResultStage 154 (collect at utils.scala:204)
19/07/31 17:06:27 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:06:27 INFO DAGScheduler: Missing parents: List()
19/07/31 17:06:27 INFO DAGScheduler: Submitting ResultStage 154 (MapPartitionsRDD[473] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:27 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 72.1 KB, free 910.1 MB)
19/07/31 17:06:27 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.1 MB)
19/07/31 17:06:27 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 127.0.0.1:53890 (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:06:27 INFO SparkContext: Created broadcast 157 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 154 (MapPartitionsRDD[473] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:27 INFO TaskSchedulerImpl: Adding task set 154.0 with 1 tasks
19/07/31 17:06:27 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 301, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:06:27 INFO Executor: Running task 0.0 in stage 154.0 (TID 301)
19/07/31 17:06:27 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:27 INFO Executor: Finished task 0.0 in stage 154.0 (TID 301). 7542 bytes result sent to driver
19/07/31 17:06:27 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 301) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:06:27 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool 
19/07/31 17:06:27 INFO DAGScheduler: ResultStage 154 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:06:27 INFO DAGScheduler: Job 103 finished: collect at utils.scala:204, took 0.010564 s
19/07/31 17:06:27 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:06:27 INFO DAGScheduler: Registering RDD 474 (collect at utils.scala:204)
19/07/31 17:06:27 INFO DAGScheduler: Got job 104 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:06:27 INFO DAGScheduler: Final stage: ResultStage 156 (collect at utils.scala:204)
19/07/31 17:06:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 155)
19/07/31 17:06:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 155)
19/07/31 17:06:27 INFO DAGScheduler: Submitting ShuffleMapStage 155 (MapPartitionsRDD[474] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:27 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 74.5 KB, free 910.0 MB)
19/07/31 17:06:27 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.0 MB)
19/07/31 17:06:27 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 127.0.0.1:53890 (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:06:27 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 155 (MapPartitionsRDD[474] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:06:27 INFO TaskSchedulerImpl: Adding task set 155.0 with 1 tasks
19/07/31 17:06:27 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 302, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:06:27 INFO Executor: Running task 0.0 in stage 155.0 (TID 302)
19/07/31 17:06:27 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:06:27 INFO Executor: Finished task 0.0 in stage 155.0 (TID 302). 1687 bytes result sent to driver
19/07/31 17:06:27 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 302) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:06:27 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool 
19/07/31 17:06:27 INFO DAGScheduler: ShuffleMapStage 155 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:06:27 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:06:27 INFO DAGScheduler: running: Set()
19/07/31 17:06:27 INFO DAGScheduler: waiting: Set(ResultStage 156)
19/07/31 17:06:27 INFO DAGScheduler: failed: Set()
19/07/31 17:06:27 INFO DAGScheduler: Submitting ResultStage 156 (MapPartitionsRDD[477] at collect at utils.scala:204), which has no missing parents
19/07/31 17:06:27 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 16.8 KB, free 910.0 MB)
19/07/31 17:06:27 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.0 MB)
19/07/31 17:06:27 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on 127.0.0.1:53890 (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:06:27 INFO SparkContext: Created broadcast 159 from broadcast at DAGScheduler.scala:1006
19/07/31 17:06:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 156 (MapPartitionsRDD[477] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:06:27 INFO TaskSchedulerImpl: Adding task set 156.0 with 4 tasks
19/07/31 17:06:27 INFO TaskSetManager: Starting task 0.0 in stage 156.0 (TID 303, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:06:27 INFO TaskSetManager: Starting task 1.0 in stage 156.0 (TID 304, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:06:27 INFO TaskSetManager: Starting task 2.0 in stage 156.0 (TID 305, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:06:27 INFO TaskSetManager: Starting task 3.0 in stage 156.0 (TID 306, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:06:27 INFO Executor: Running task 1.0 in stage 156.0 (TID 304)
19/07/31 17:06:27 INFO Executor: Running task 0.0 in stage 156.0 (TID 303)
19/07/31 17:06:27 INFO Executor: Running task 2.0 in stage 156.0 (TID 305)
19/07/31 17:06:27 INFO Executor: Running task 3.0 in stage 156.0 (TID 306)
19/07/31 17:06:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:06:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:06:27 INFO Executor: Finished task 2.0 in stage 156.0 (TID 305). 2390 bytes result sent to driver
19/07/31 17:06:27 INFO Executor: Finished task 1.0 in stage 156.0 (TID 304). 2403 bytes result sent to driver
19/07/31 17:06:27 INFO TaskSetManager: Finished task 2.0 in stage 156.0 (TID 305) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:06:27 INFO TaskSetManager: Finished task 1.0 in stage 156.0 (TID 304) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:06:27 INFO Executor: Finished task 0.0 in stage 156.0 (TID 303). 2382 bytes result sent to driver
19/07/31 17:06:27 INFO Executor: Finished task 3.0 in stage 156.0 (TID 306). 2362 bytes result sent to driver
19/07/31 17:06:27 INFO TaskSetManager: Finished task 0.0 in stage 156.0 (TID 303) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:06:27 INFO TaskSetManager: Finished task 3.0 in stage 156.0 (TID 306) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:06:27 INFO TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool 
19/07/31 17:06:27 INFO DAGScheduler: ResultStage 156 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:06:27 INFO DAGScheduler: Job 104 finished: collect at utils.scala:204, took 0.019665 s
19/07/31 17:06:28 INFO SparkContext: Invoking stop() from shutdown hook
19/07/31 17:06:28 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
19/07/31 17:06:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/07/31 17:06:28 INFO MemoryStore: MemoryStore cleared
19/07/31 17:06:28 INFO BlockManager: BlockManager stopped
19/07/31 17:06:28 INFO BlockManagerMaster: BlockManagerMaster stopped
19/07/31 17:06:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/07/31 17:06:28 INFO SparkContext: Successfully stopped SparkContext
19/07/31 17:06:28 INFO ShutdownHookManager: Shutdown hook called
19/07/31 17:06:28 INFO ShutdownHookManager: Deleting directory /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-24a9b421-5ead-49de-b042-583502535619
19/07/31 17:07:19 INFO SparkContext: Running Spark version 2.2.0
19/07/31 17:07:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/07/31 17:07:19 INFO SparkContext: Submitted application: sparklyr
19/07/31 17:07:19 INFO SecurityManager: Changing view acls to: 6jncnk4f
19/07/31 17:07:19 INFO SecurityManager: Changing modify acls to: 6jncnk4f
19/07/31 17:07:19 INFO SecurityManager: Changing view acls groups to: 
19/07/31 17:07:19 INFO SecurityManager: Changing modify acls groups to: 
19/07/31 17:07:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(6jncnk4f); groups with view permissions: Set(); users  with modify permissions: Set(6jncnk4f); groups with modify permissions: Set()
19/07/31 17:07:19 INFO Utils: Successfully started service 'sparkDriver' on port 53948.
19/07/31 17:07:19 INFO SparkEnv: Registering MapOutputTracker
19/07/31 17:07:20 INFO SparkEnv: Registering BlockManagerMaster
19/07/31 17:07:20 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/07/31 17:07:20 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/07/31 17:07:20 INFO DiskBlockManager: Created local directory at /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/blockmgr-e017b170-7127-4dfd-868e-3acd317ad47a
19/07/31 17:07:20 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/07/31 17:07:20 INFO SparkEnv: Registering OutputCommitCoordinator
19/07/31 17:07:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/07/31 17:07:20 INFO Utils: Successfully started service 'SparkUI' on port 4041.
19/07/31 17:07:20 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
19/07/31 17:07:20 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:53948/jars/sparklyr-2.0-2.11.jar with timestamp 1564607240292
19/07/31 17:07:20 INFO Executor: Starting executor ID driver on host localhost
19/07/31 17:07:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53949.
19/07/31 17:07:20 INFO NettyBlockTransferService: Server created on 127.0.0.1:53949
19/07/31 17:07:20 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/07/31 17:07:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 53949, None)
19/07/31 17:07:20 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:53949 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 53949, None)
19/07/31 17:07:20 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 53949, None)
19/07/31 17:07:20 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 53949, None)
19/07/31 17:07:20 INFO SharedState: loading hive config file: file:/Users/6jncnk4f/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/07/31 17:07:20 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse').
19/07/31 17:07:20 INFO SharedState: Warehouse path is 'file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse'.
19/07/31 17:07:21 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/07/31 17:07:21 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/07/31 17:07:21 INFO ObjectStore: ObjectStore, initialize called
19/07/31 17:07:21 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/07/31 17:07:21 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/07/31 17:07:23 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/07/31 17:07:23 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:07:23 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:07:24 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:07:24 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:07:24 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/07/31 17:07:24 INFO ObjectStore: Initialized ObjectStore
19/07/31 17:07:24 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/07/31 17:07:24 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/07/31 17:07:24 INFO HiveMetaStore: Added admin role in metastore
19/07/31 17:07:24 INFO HiveMetaStore: Added public role in metastore
19/07/31 17:07:24 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/07/31 17:07:24 INFO HiveMetaStore: 0: get_all_databases
19/07/31 17:07:24 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_all_databases	
19/07/31 17:07:24 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/07/31 17:07:24 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/07/31 17:07:24 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:07:24 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/2bf67699-4dbc-418e-9777-ea0660b8d590_resources
19/07/31 17:07:24 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/2bf67699-4dbc-418e-9777-ea0660b8d590
19/07/31 17:07:24 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/2bf67699-4dbc-418e-9777-ea0660b8d590
19/07/31 17:07:24 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/2bf67699-4dbc-418e-9777-ea0660b8d590/_tmp_space.db
19/07/31 17:07:24 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 17:07:24 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:24 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:25 INFO HiveMetaStore: 0: get_database: global_temp
19/07/31 17:07:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/07/31 17:07:25 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/07/31 17:07:25 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/4a98d5d9-8a61-4831-94b9-b0587edf3630_resources
19/07/31 17:07:25 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/4a98d5d9-8a61-4831-94b9-b0587edf3630
19/07/31 17:07:25 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/4a98d5d9-8a61-4831-94b9-b0587edf3630
19/07/31 17:07:25 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/4a98d5d9-8a61-4831-94b9-b0587edf3630/_tmp_space.db
19/07/31 17:07:25 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 17:07:25 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/07/31 17:07:25 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 17:07:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:26 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 17:07:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 17:07:27 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 17:07:27 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/07/31 17:07:27 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/07/31 17:07:27 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:27 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:27 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/07/31 17:07:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/07/31 17:07:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/07/31 17:07:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:53949 (size: 3.4 KB, free: 912.3 MB)
19/07/31 17:07:27 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/07/31 17:07:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/07/31 17:07:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/07/31 17:07:27 INFO Executor: Fetching spark://127.0.0.1:53948/jars/sparklyr-2.0-2.11.jar with timestamp 1564607240292
19/07/31 17:07:27 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:53948 after 12 ms (0 ms spent in bootstraps)
19/07/31 17:07:27 INFO Utils: Fetching spark://127.0.0.1:53948/jars/sparklyr-2.0-2.11.jar to /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-3ab3356b-cfa2-49f9-a98e-d760fb07ca60/userFiles-d0b7f6f4-a21e-460a-b389-090779801c0e/fetchFileTemp503052627762755673.tmp
19/07/31 17:07:27 INFO Executor: Adding file:/private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-3ab3356b-cfa2-49f9-a98e-d760fb07ca60/userFiles-d0b7f6f4-a21e-460a-b389-090779801c0e/sparklyr-2.0-2.11.jar to class loader
19/07/31 17:07:27 INFO CodeGenerator: Code generated in 238.985598 ms
19/07/31 17:07:27 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
19/07/31 17:07:27 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 562 ms on localhost (executor driver) (1/1)
19/07/31 17:07:27 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/07/31 17:07:27 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.579 s
19/07/31 17:07:27 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0.710607 s
19/07/31 17:07:28 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 17:07:28 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#10)) > 0)
19/07/31 17:07:28 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 17:07:28 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 17:07:28 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:53949 in memory (size: 3.4 KB, free: 912.3 MB)
19/07/31 17:07:28 INFO ContextCleaner: Cleaned accumulator 0
19/07/31 17:07:28 INFO CodeGenerator: Code generated in 19.706044 ms
19/07/31 17:07:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 281.2 KB, free 912.0 MB)
19/07/31 17:07:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.8 KB, free 912.0 MB)
19/07/31 17:07:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:53949 (size: 23.8 KB, free: 912.3 MB)
19/07/31 17:07:28 INFO SparkContext: Created broadcast 1 from csv at NativeMethodAccessorImpl.java:0
19/07/31 17:07:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 17:07:28 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 17:07:28 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 17:07:28 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 17:07:28 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:28 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:28 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 17:07:28 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 912.0 MB)
19/07/31 17:07:28 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 912.0 MB)
19/07/31 17:07:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:53949 (size: 4.3 KB, free: 912.3 MB)
19/07/31 17:07:28 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/07/31 17:07:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/07/31 17:07:28 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 17:07:28 INFO CodeGenerator: Code generated in 8.606129 ms
19/07/31 17:07:28 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1437 bytes result sent to driver
19/07/31 17:07:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 200 ms on localhost (executor driver) (1/1)
19/07/31 17:07:28 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/07/31 17:07:28 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0.201 s
19/07/31 17:07:28 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0.212813 s
19/07/31 17:07:28 INFO CodeGenerator: Code generated in 8.766385 ms
19/07/31 17:07:28 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 17:07:28 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 17:07:28 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 17:07:28 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 17:07:28 INFO CodeGenerator: Code generated in 8.164073 ms
19/07/31 17:07:28 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 281.2 KB, free 911.7 MB)
19/07/31 17:07:28 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.7 MB)
19/07/31 17:07:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:53949 (size: 23.8 KB, free: 912.2 MB)
19/07/31 17:07:28 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:0
19/07/31 17:07:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 17:07:28 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 17:07:28 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 17:07:28 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 17:07:28 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:28 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:28 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 17:07:28 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.8 KB, free 911.7 MB)
19/07/31 17:07:28 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.7 MB)
19/07/31 17:07:28 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:53949 (size: 8.6 KB, free: 912.2 MB)
19/07/31 17:07:28 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:28 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/07/31 17:07:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:29 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/07/31 17:07:29 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 17:07:29 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1627 bytes result sent to driver
19/07/31 17:07:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 101 ms on localhost (executor driver) (1/1)
19/07/31 17:07:29 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/07/31 17:07:29 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.102 s
19/07/31 17:07:29 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.116418 s
19/07/31 17:07:29 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 17:07:29 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:29 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:29 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:29 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:29 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 17:07:29 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 17:07:29 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 17:07:29 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 17:07:29 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 17:07:29 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 17:07:29 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 17:07:29 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 17:07:29 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 17:07:29 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 282.3 KB, free 911.4 MB)
19/07/31 17:07:29 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.4 MB)
19/07/31 17:07:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:53949 (size: 24.0 KB, free: 912.2 MB)
19/07/31 17:07:29 INFO SparkContext: Created broadcast 5 from sql at NativeMethodAccessorImpl.java:0
19/07/31 17:07:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 17:07:29 INFO CodeGenerator: Code generated in 8.765002 ms
19/07/31 17:07:29 INFO CodeGenerator: Code generated in 8.178724 ms
19/07/31 17:07:29 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 17:07:29 INFO DAGScheduler: Registering RDD 18 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 17:07:29 INFO DAGScheduler: Got job 3 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 17:07:29 INFO DAGScheduler: Final stage: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 17:07:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/07/31 17:07:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/07/31 17:07:29 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 17:07:29 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 26.3 KB, free 911.3 MB)
19/07/31 17:07:29 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.8 KB, free 911.3 MB)
19/07/31 17:07:29 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:53949 (size: 11.8 KB, free: 912.2 MB)
19/07/31 17:07:29 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:29 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/07/31 17:07:29 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:29 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/07/31 17:07:29 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 17:07:29 INFO CodeGenerator: Code generated in 14.040068 ms
19/07/31 17:07:29 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 48.9 KB, free 911.3 MB)
19/07/31 17:07:29 INFO BlockManagerInfo: Added rdd_15_0 in memory on 127.0.0.1:53949 (size: 48.9 KB, free: 912.2 MB)
19/07/31 17:07:29 INFO CodeGenerator: Code generated in 6.55682 ms
19/07/31 17:07:29 INFO CodeGenerator: Code generated in 105.18389 ms
19/07/31 17:07:29 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2504 bytes result sent to driver
19/07/31 17:07:29 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 415 ms on localhost (executor driver) (1/1)
19/07/31 17:07:29 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/07/31 17:07:29 INFO DAGScheduler: ShuffleMapStage 3 (sql at NativeMethodAccessorImpl.java:0) finished in 0.417 s
19/07/31 17:07:29 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:29 INFO DAGScheduler: running: Set()
19/07/31 17:07:29 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/07/31 17:07:29 INFO DAGScheduler: failed: Set()
19/07/31 17:07:29 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 17:07:29 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 911.3 MB)
19/07/31 17:07:29 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.3 MB)
19/07/31 17:07:29 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:53949 (size: 3.7 KB, free: 912.2 MB)
19/07/31 17:07:29 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:29 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/07/31 17:07:29 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:29 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/07/31 17:07:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
19/07/31 17:07:30 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1581 bytes result sent to driver
19/07/31 17:07:30 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 86 ms on localhost (executor driver) (1/1)
19/07/31 17:07:30 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/07/31 17:07:30 INFO DAGScheduler: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0) finished in 0.086 s
19/07/31 17:07:30 INFO DAGScheduler: Job 3 finished: sql at NativeMethodAccessorImpl.java:0, took 0.553022 s
19/07/31 17:07:30 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 17:07:30 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:30 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:30 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:30 INFO DAGScheduler: Registering RDD 24 (collect at utils.scala:204)
19/07/31 17:07:30 INFO DAGScheduler: Got job 4 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:30 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
19/07/31 17:07:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/07/31 17:07:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/07/31 17:07:30 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:30 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 26.3 KB, free 911.2 MB)
19/07/31 17:07:30 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.9 KB, free 911.2 MB)
19/07/31 17:07:30 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:53949 (size: 11.9 KB, free: 912.1 MB)
19/07/31 17:07:30 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:30 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/07/31 17:07:30 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:30 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/07/31 17:07:30 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:30 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1780 bytes result sent to driver
19/07/31 17:07:30 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 12 ms on localhost (executor driver) (1/1)
19/07/31 17:07:30 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/07/31 17:07:30 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:204) finished in 0.013 s
19/07/31 17:07:30 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:30 INFO DAGScheduler: running: Set()
19/07/31 17:07:30 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/07/31 17:07:30 INFO DAGScheduler: failed: Set()
19/07/31 17:07:30 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:30 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 911.2 MB)
19/07/31 17:07:30 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.2 MB)
19/07/31 17:07:30 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:53949 (size: 3.7 KB, free: 912.1 MB)
19/07/31 17:07:30 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:30 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/07/31 17:07:30 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:30 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/07/31 17:07:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:30 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1581 bytes result sent to driver
19/07/31 17:07:30 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:07:30 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/07/31 17:07:30 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:07:30 INFO DAGScheduler: Job 4 finished: collect at utils.scala:204, took 0.044782 s
19/07/31 17:07:30 INFO CodeGenerator: Code generated in 8.141505 ms
19/07/31 17:07:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz1`
WHERE (0 = 1)
19/07/31 17:07:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_001`) `dbplyr_002`
ORDER BY `date`) `dbplyr_003`) `dbplyr_004`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:30 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:30 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_005`) `dbplyr_006`
ORDER BY `date`) `dbplyr_007`) `dbplyr_008`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:30 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:30 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:30 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#442 - cust_prospect_ind.nullCount#441) > 0)
19/07/31 17:07:30 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#447 - visit_device_type.nullCount#446) > 0)
19/07/31 17:07:30 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#440 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#439))
19/07/31 17:07:30 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#445 <= All Devices) && (All Devices <= visit_device_type.upperBound#444))
19/07/31 17:07:30 INFO CodeGenerator: Code generated in 16.683649 ms
19/07/31 17:07:30 INFO CodeGenerator: Code generated in 18.699365 ms
19/07/31 17:07:30 INFO CodeGenerator: Code generated in 7.267309 ms
19/07/31 17:07:30 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:30 INFO DAGScheduler: Got job 5 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:30 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:204)
19/07/31 17:07:30 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:30 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:30 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[32] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:30 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 72.1 KB, free 911.2 MB)
19/07/31 17:07:30 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.1 MB)
19/07/31 17:07:30 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:53949 (size: 30.4 KB, free: 912.1 MB)
19/07/31 17:07:30 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:30 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/07/31 17:07:30 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:30 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
19/07/31 17:07:30 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:30 INFO CodeGenerator: Code generated in 5.396816 ms
19/07/31 17:07:30 INFO CodeGenerator: Code generated in 21.276576 ms
19/07/31 17:07:31 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 7585 bytes result sent to driver
19/07/31 17:07:31 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 101 ms on localhost (executor driver) (1/1)
19/07/31 17:07:31 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/07/31 17:07:31 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:204) finished in 0.103 s
19/07/31 17:07:31 INFO DAGScheduler: Job 5 finished: collect at utils.scala:204, took 0.113420 s
19/07/31 17:07:31 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:31 INFO DAGScheduler: Registering RDD 33 (collect at utils.scala:204)
19/07/31 17:07:31 INFO DAGScheduler: Got job 6 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:31 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:204)
19/07/31 17:07:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
19/07/31 17:07:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
19/07/31 17:07:31 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[33] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:31 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 74.5 KB, free 911.1 MB)
19/07/31 17:07:31 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 31.7 KB, free 911.0 MB)
19/07/31 17:07:31 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:53949 (size: 31.7 KB, free: 912.1 MB)
19/07/31 17:07:31 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[33] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:31 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/07/31 17:07:31 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:31 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
19/07/31 17:07:31 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:31 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1687 bytes result sent to driver
19/07/31 17:07:31 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 26 ms on localhost (executor driver) (1/1)
19/07/31 17:07:31 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/07/31 17:07:31 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:204) finished in 0.027 s
19/07/31 17:07:31 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:31 INFO DAGScheduler: running: Set()
19/07/31 17:07:31 INFO DAGScheduler: waiting: Set(ResultStage 9)
19/07/31 17:07:31 INFO DAGScheduler: failed: Set()
19/07/31 17:07:31 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[36] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:31 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 16.8 KB, free 911.0 MB)
19/07/31 17:07:31 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.0 MB)
19/07/31 17:07:31 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:07:31 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:31 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 9 (MapPartitionsRDD[36] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:31 INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks
19/07/31 17:07:31 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:31 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 10, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:31 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 11, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:31 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 12, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:31 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
19/07/31 17:07:31 INFO Executor: Running task 1.0 in stage 9.0 (TID 10)
19/07/31 17:07:31 INFO Executor: Running task 3.0 in stage 9.0 (TID 12)
19/07/31 17:07:31 INFO Executor: Running task 2.0 in stage 9.0 (TID 11)
19/07/31 17:07:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:31 INFO CodeGenerator: Code generated in 5.409117 ms
19/07/31 17:07:31 INFO Executor: Finished task 2.0 in stage 9.0 (TID 11). 2390 bytes result sent to driver
19/07/31 17:07:31 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 11) in 44 ms on localhost (executor driver) (1/4)
19/07/31 17:07:31 INFO Executor: Finished task 1.0 in stage 9.0 (TID 10). 2403 bytes result sent to driver
19/07/31 17:07:31 INFO Executor: Finished task 3.0 in stage 9.0 (TID 12). 2362 bytes result sent to driver
19/07/31 17:07:31 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2382 bytes result sent to driver
19/07/31 17:07:31 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 10) in 45 ms on localhost (executor driver) (2/4)
19/07/31 17:07:31 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 12) in 45 ms on localhost (executor driver) (3/4)
19/07/31 17:07:31 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 46 ms on localhost (executor driver) (4/4)
19/07/31 17:07:31 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/07/31 17:07:31 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:204) finished in 0.047 s
19/07/31 17:07:31 INFO DAGScheduler: Job 6 finished: collect at utils.scala:204, took 0.095663 s
19/07/31 17:07:31 INFO CodeGenerator: Code generated in 11.956988 ms
19/07/31 17:07:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_009`) `dbplyr_010`
ORDER BY `date`) `dbplyr_011`) `dbplyr_012`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:31 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:31 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_013`) `dbplyr_014`
ORDER BY `date`) `dbplyr_015`) `dbplyr_016`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:31 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:31 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:31 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#540 - cust_prospect_ind.nullCount#539) > 0)
19/07/31 17:07:31 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#545 - visit_device_type.nullCount#544) > 0)
19/07/31 17:07:31 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#538 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#537))
19/07/31 17:07:31 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#543 <= All Devices) && (All Devices <= visit_device_type.upperBound#542))
19/07/31 17:07:31 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:31 INFO DAGScheduler: Got job 7 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:31 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:204)
19/07/31 17:07:31 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:31 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:31 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[41] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:31 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 72.1 KB, free 910.9 MB)
19/07/31 17:07:31 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.9 MB)
19/07/31 17:07:31 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:07:31 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[41] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:31 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/07/31 17:07:31 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:31 INFO Executor: Running task 0.0 in stage 10.0 (TID 13)
19/07/31 17:07:31 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:31 INFO Executor: Finished task 0.0 in stage 10.0 (TID 13). 7542 bytes result sent to driver
19/07/31 17:07:31 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 13) in 13 ms on localhost (executor driver) (1/1)
19/07/31 17:07:31 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/07/31 17:07:31 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:204) finished in 0.013 s
19/07/31 17:07:31 INFO DAGScheduler: Job 7 finished: collect at utils.scala:204, took 0.022865 s
19/07/31 17:07:31 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:31 INFO DAGScheduler: Registering RDD 42 (collect at utils.scala:204)
19/07/31 17:07:31 INFO DAGScheduler: Got job 8 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:31 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:204)
19/07/31 17:07:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
19/07/31 17:07:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
19/07/31 17:07:31 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[42] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:31 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 74.5 KB, free 910.8 MB)
19/07/31 17:07:31 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.8 MB)
19/07/31 17:07:31 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:07:31 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[42] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:31 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/07/31 17:07:31 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:31 INFO Executor: Running task 0.0 in stage 11.0 (TID 14)
19/07/31 17:07:31 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:31 INFO Executor: Finished task 0.0 in stage 11.0 (TID 14). 1687 bytes result sent to driver
19/07/31 17:07:31 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 14) in 19 ms on localhost (executor driver) (1/1)
19/07/31 17:07:31 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/07/31 17:07:31 INFO DAGScheduler: ShuffleMapStage 11 (collect at utils.scala:204) finished in 0.020 s
19/07/31 17:07:31 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:31 INFO DAGScheduler: running: Set()
19/07/31 17:07:31 INFO DAGScheduler: waiting: Set(ResultStage 12)
19/07/31 17:07:31 INFO DAGScheduler: failed: Set()
19/07/31 17:07:31 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[45] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:31 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 16.8 KB, free 910.8 MB)
19/07/31 17:07:31 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.8 MB)
19/07/31 17:07:31 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:07:31 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:31 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 12 (MapPartitionsRDD[45] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:31 INFO TaskSchedulerImpl: Adding task set 12.0 with 4 tasks
19/07/31 17:07:31 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 15, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:31 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 16, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:31 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 17, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:31 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 18, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:31 INFO Executor: Running task 1.0 in stage 12.0 (TID 16)
19/07/31 17:07:31 INFO Executor: Running task 0.0 in stage 12.0 (TID 15)
19/07/31 17:07:31 INFO Executor: Running task 3.0 in stage 12.0 (TID 18)
19/07/31 17:07:31 INFO Executor: Running task 2.0 in stage 12.0 (TID 17)
19/07/31 17:07:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:31 INFO Executor: Finished task 1.0 in stage 12.0 (TID 16). 2403 bytes result sent to driver
19/07/31 17:07:31 INFO Executor: Finished task 3.0 in stage 12.0 (TID 18). 2362 bytes result sent to driver
19/07/31 17:07:31 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 18) in 9 ms on localhost (executor driver) (1/4)
19/07/31 17:07:31 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 16) in 10 ms on localhost (executor driver) (2/4)
19/07/31 17:07:31 INFO Executor: Finished task 2.0 in stage 12.0 (TID 17). 2390 bytes result sent to driver
19/07/31 17:07:31 INFO Executor: Finished task 0.0 in stage 12.0 (TID 15). 2382 bytes result sent to driver
19/07/31 17:07:31 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 17) in 11 ms on localhost (executor driver) (3/4)
19/07/31 17:07:31 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 15) in 11 ms on localhost (executor driver) (4/4)
19/07/31 17:07:31 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/07/31 17:07:31 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:204) finished in 0.011 s
19/07/31 17:07:31 INFO DAGScheduler: Job 8 finished: collect at utils.scala:204, took 0.045939 s
19/07/31 17:07:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_017`) `dbplyr_018`
ORDER BY `date`) `dbplyr_019`) `dbplyr_020`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:31 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:31 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_021`) `dbplyr_022`
ORDER BY `date`) `dbplyr_023`) `dbplyr_024`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:31 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:31 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:31 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#638 - cust_prospect_ind.nullCount#637) > 0)
19/07/31 17:07:31 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#643 - visit_device_type.nullCount#642) > 0)
19/07/31 17:07:31 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#636 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#635))
19/07/31 17:07:31 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#641 <= All Devices) && (All Devices <= visit_device_type.upperBound#640))
19/07/31 17:07:31 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:32 INFO DAGScheduler: Got job 9 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:32 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:204)
19/07/31 17:07:32 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:32 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:32 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[50] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:32 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 72.1 KB, free 910.7 MB)
19/07/31 17:07:32 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.7 MB)
19/07/31 17:07:32 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:07:32 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[50] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:32 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/07/31 17:07:32 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:32 INFO Executor: Running task 0.0 in stage 13.0 (TID 19)
19/07/31 17:07:32 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:32 INFO Executor: Finished task 0.0 in stage 13.0 (TID 19). 7585 bytes result sent to driver
19/07/31 17:07:32 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 19) in 16 ms on localhost (executor driver) (1/1)
19/07/31 17:07:32 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/07/31 17:07:32 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:204) finished in 0.017 s
19/07/31 17:07:32 INFO DAGScheduler: Job 9 finished: collect at utils.scala:204, took 0.029028 s
19/07/31 17:07:32 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:32 INFO DAGScheduler: Registering RDD 51 (collect at utils.scala:204)
19/07/31 17:07:32 INFO DAGScheduler: Got job 10 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:32 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:204)
19/07/31 17:07:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
19/07/31 17:07:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
19/07/31 17:07:32 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[51] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:32 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 74.5 KB, free 910.6 MB)
19/07/31 17:07:32 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.6 MB)
19/07/31 17:07:32 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.9 MB)
19/07/31 17:07:32 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[51] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:32 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/07/31 17:07:32 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:32 INFO Executor: Running task 0.0 in stage 14.0 (TID 20)
19/07/31 17:07:32 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:32 INFO Executor: Finished task 0.0 in stage 14.0 (TID 20). 1687 bytes result sent to driver
19/07/31 17:07:32 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 20) in 15 ms on localhost (executor driver) (1/1)
19/07/31 17:07:32 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/07/31 17:07:32 INFO DAGScheduler: ShuffleMapStage 14 (collect at utils.scala:204) finished in 0.015 s
19/07/31 17:07:32 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:32 INFO DAGScheduler: running: Set()
19/07/31 17:07:32 INFO DAGScheduler: waiting: Set(ResultStage 15)
19/07/31 17:07:32 INFO DAGScheduler: failed: Set()
19/07/31 17:07:32 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[54] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:32 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 16.8 KB, free 910.6 MB)
19/07/31 17:07:32 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.5 MB)
19/07/31 17:07:32 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:07:32 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:32 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:32 INFO TaskSchedulerImpl: Adding task set 15.0 with 4 tasks
19/07/31 17:07:32 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 21, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:32 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 22, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:32 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 23, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:32 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 24, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:32 INFO Executor: Running task 0.0 in stage 15.0 (TID 21)
19/07/31 17:07:32 INFO Executor: Running task 2.0 in stage 15.0 (TID 23)
19/07/31 17:07:32 INFO Executor: Running task 3.0 in stage 15.0 (TID 24)
19/07/31 17:07:32 INFO Executor: Running task 1.0 in stage 15.0 (TID 22)
19/07/31 17:07:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:32 INFO Executor: Finished task 2.0 in stage 15.0 (TID 23). 2390 bytes result sent to driver
19/07/31 17:07:32 INFO Executor: Finished task 0.0 in stage 15.0 (TID 21). 2382 bytes result sent to driver
19/07/31 17:07:32 INFO Executor: Finished task 3.0 in stage 15.0 (TID 24). 2362 bytes result sent to driver
19/07/31 17:07:32 INFO Executor: Finished task 1.0 in stage 15.0 (TID 22). 2403 bytes result sent to driver
19/07/31 17:07:32 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 21) in 8 ms on localhost (executor driver) (1/4)
19/07/31 17:07:32 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 23) in 7 ms on localhost (executor driver) (2/4)
19/07/31 17:07:32 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 24) in 7 ms on localhost (executor driver) (3/4)
19/07/31 17:07:32 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 22) in 8 ms on localhost (executor driver) (4/4)
19/07/31 17:07:32 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/07/31 17:07:32 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:07:32 INFO DAGScheduler: Job 10 finished: collect at utils.scala:204, took 0.040223 s
19/07/31 17:07:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_025`) `dbplyr_026`
ORDER BY `date`) `dbplyr_027`) `dbplyr_028`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:32 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:32 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_029`) `dbplyr_030`
ORDER BY `date`) `dbplyr_031`) `dbplyr_032`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:32 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:32 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:32 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#736 - cust_prospect_ind.nullCount#735) > 0)
19/07/31 17:07:32 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#741 - visit_device_type.nullCount#740) > 0)
19/07/31 17:07:32 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#734 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#733))
19/07/31 17:07:32 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#739 <= All Devices) && (All Devices <= visit_device_type.upperBound#738))
19/07/31 17:07:32 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:32 INFO DAGScheduler: Got job 11 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:32 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:204)
19/07/31 17:07:32 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:32 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:32 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[59] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:32 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 72.1 KB, free 910.5 MB)
19/07/31 17:07:32 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.4 MB)
19/07/31 17:07:32 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:53949 (size: 30.4 KB, free: 911.9 MB)
19/07/31 17:07:32 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[59] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:32 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/07/31 17:07:32 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:32 INFO Executor: Running task 0.0 in stage 16.0 (TID 25)
19/07/31 17:07:32 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:32 INFO Executor: Finished task 0.0 in stage 16.0 (TID 25). 7542 bytes result sent to driver
19/07/31 17:07:32 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 25) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:07:32 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/07/31 17:07:32 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:07:32 INFO DAGScheduler: Job 11 finished: collect at utils.scala:204, took 0.019366 s
19/07/31 17:07:32 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:32 INFO DAGScheduler: Registering RDD 60 (collect at utils.scala:204)
19/07/31 17:07:32 INFO DAGScheduler: Got job 12 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:32 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:204)
19/07/31 17:07:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
19/07/31 17:07:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
19/07/31 17:07:32 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[60] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:32 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 74.5 KB, free 910.4 MB)
19/07/31 17:07:32 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.3 MB)
19/07/31 17:07:32 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:53949 (size: 31.7 KB, free: 911.9 MB)
19/07/31 17:07:32 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[60] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:32 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
19/07/31 17:07:32 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:32 INFO Executor: Running task 0.0 in stage 17.0 (TID 26)
19/07/31 17:07:32 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:32 INFO Executor: Finished task 0.0 in stage 17.0 (TID 26). 1687 bytes result sent to driver
19/07/31 17:07:32 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 26) in 16 ms on localhost (executor driver) (1/1)
19/07/31 17:07:32 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/07/31 17:07:32 INFO DAGScheduler: ShuffleMapStage 17 (collect at utils.scala:204) finished in 0.016 s
19/07/31 17:07:32 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:32 INFO DAGScheduler: running: Set()
19/07/31 17:07:32 INFO DAGScheduler: waiting: Set(ResultStage 18)
19/07/31 17:07:32 INFO DAGScheduler: failed: Set()
19/07/31 17:07:32 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[63] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:32 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 16.8 KB, free 910.3 MB)
19/07/31 17:07:32 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.3 MB)
19/07/31 17:07:32 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:07:32 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:32 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 18 (MapPartitionsRDD[63] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:32 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks
19/07/31 17:07:32 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 27, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:32 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 28, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:32 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 29, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:32 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 30, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:32 INFO Executor: Running task 0.0 in stage 18.0 (TID 27)
19/07/31 17:07:32 INFO Executor: Running task 1.0 in stage 18.0 (TID 28)
19/07/31 17:07:32 INFO Executor: Running task 2.0 in stage 18.0 (TID 29)
19/07/31 17:07:32 INFO Executor: Running task 3.0 in stage 18.0 (TID 30)
19/07/31 17:07:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:32 INFO Executor: Finished task 3.0 in stage 18.0 (TID 30). 2362 bytes result sent to driver
19/07/31 17:07:32 INFO Executor: Finished task 0.0 in stage 18.0 (TID 27). 2382 bytes result sent to driver
19/07/31 17:07:32 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 30) in 6 ms on localhost (executor driver) (1/4)
19/07/31 17:07:32 INFO Executor: Finished task 2.0 in stage 18.0 (TID 29). 2390 bytes result sent to driver
19/07/31 17:07:32 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 27) in 10 ms on localhost (executor driver) (2/4)
19/07/31 17:07:32 INFO Executor: Finished task 1.0 in stage 18.0 (TID 28). 2403 bytes result sent to driver
19/07/31 17:07:32 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 29) in 8 ms on localhost (executor driver) (3/4)
19/07/31 17:07:32 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 28) in 9 ms on localhost (executor driver) (4/4)
19/07/31 17:07:32 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/07/31 17:07:32 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:07:32 INFO DAGScheduler: Job 12 finished: collect at utils.scala:204, took 0.049831 s
19/07/31 17:07:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_033`) `dbplyr_034`
ORDER BY `date`) `dbplyr_035`) `dbplyr_036`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:32 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:32 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_037`) `dbplyr_038`
ORDER BY `date`) `dbplyr_039`) `dbplyr_040`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:33 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:33 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:33 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#834 - cust_prospect_ind.nullCount#833) > 0)
19/07/31 17:07:33 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#839 - visit_device_type.nullCount#838) > 0)
19/07/31 17:07:33 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#832 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#831))
19/07/31 17:07:33 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#837 <= All Devices) && (All Devices <= visit_device_type.upperBound#836))
19/07/31 17:07:33 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:33 INFO DAGScheduler: Got job 13 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:33 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:204)
19/07/31 17:07:33 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:33 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:33 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[68] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:33 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 72.1 KB, free 910.2 MB)
19/07/31 17:07:33 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.2 MB)
19/07/31 17:07:33 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:07:33 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[68] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:33 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/07/31 17:07:33 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:33 INFO Executor: Running task 0.0 in stage 19.0 (TID 31)
19/07/31 17:07:33 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:33 INFO Executor: Finished task 0.0 in stage 19.0 (TID 31). 7542 bytes result sent to driver
19/07/31 17:07:33 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 31) in 13 ms on localhost (executor driver) (1/1)
19/07/31 17:07:33 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/07/31 17:07:33 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:204) finished in 0.013 s
19/07/31 17:07:33 INFO DAGScheduler: Job 13 finished: collect at utils.scala:204, took 0.023689 s
19/07/31 17:07:33 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:33 INFO DAGScheduler: Registering RDD 69 (collect at utils.scala:204)
19/07/31 17:07:33 INFO DAGScheduler: Got job 14 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:33 INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:204)
19/07/31 17:07:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
19/07/31 17:07:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
19/07/31 17:07:33 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[69] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:33 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 74.5 KB, free 910.1 MB)
19/07/31 17:07:33 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.1 MB)
19/07/31 17:07:33 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:07:33 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[69] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:33 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/07/31 17:07:33 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:33 INFO Executor: Running task 0.0 in stage 20.0 (TID 32)
19/07/31 17:07:33 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:33 INFO Executor: Finished task 0.0 in stage 20.0 (TID 32). 1687 bytes result sent to driver
19/07/31 17:07:33 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 32) in 16 ms on localhost (executor driver) (1/1)
19/07/31 17:07:33 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/07/31 17:07:33 INFO DAGScheduler: ShuffleMapStage 20 (collect at utils.scala:204) finished in 0.016 s
19/07/31 17:07:33 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:33 INFO DAGScheduler: running: Set()
19/07/31 17:07:33 INFO DAGScheduler: waiting: Set(ResultStage 21)
19/07/31 17:07:33 INFO DAGScheduler: failed: Set()
19/07/31 17:07:33 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[72] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:33 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 16.8 KB, free 910.1 MB)
19/07/31 17:07:33 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.1 MB)
19/07/31 17:07:33 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:07:33 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:33 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 21 (MapPartitionsRDD[72] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:33 INFO TaskSchedulerImpl: Adding task set 21.0 with 4 tasks
19/07/31 17:07:33 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 33, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:33 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 34, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:33 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 35, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:33 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 36, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:33 INFO Executor: Running task 0.0 in stage 21.0 (TID 33)
19/07/31 17:07:33 INFO Executor: Running task 1.0 in stage 21.0 (TID 34)
19/07/31 17:07:33 INFO Executor: Running task 3.0 in stage 21.0 (TID 36)
19/07/31 17:07:33 INFO Executor: Running task 2.0 in stage 21.0 (TID 35)
19/07/31 17:07:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:33 INFO Executor: Finished task 0.0 in stage 21.0 (TID 33). 2382 bytes result sent to driver
19/07/31 17:07:33 INFO Executor: Finished task 3.0 in stage 21.0 (TID 36). 2362 bytes result sent to driver
19/07/31 17:07:33 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 33) in 10 ms on localhost (executor driver) (1/4)
19/07/31 17:07:33 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 36) in 10 ms on localhost (executor driver) (2/4)
19/07/31 17:07:33 INFO Executor: Finished task 1.0 in stage 21.0 (TID 34). 2403 bytes result sent to driver
19/07/31 17:07:33 INFO Executor: Finished task 2.0 in stage 21.0 (TID 35). 2390 bytes result sent to driver
19/07/31 17:07:33 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 34) in 14 ms on localhost (executor driver) (3/4)
19/07/31 17:07:33 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 35) in 14 ms on localhost (executor driver) (4/4)
19/07/31 17:07:33 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/07/31 17:07:33 INFO DAGScheduler: ResultStage 21 (collect at utils.scala:204) finished in 0.015 s
19/07/31 17:07:33 INFO DAGScheduler: Job 14 finished: collect at utils.scala:204, took 0.054593 s
19/07/31 17:07:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_041`) `dbplyr_042`
ORDER BY `date`) `dbplyr_043`) `dbplyr_044`
WHERE ((`customer` = "All Visitors") AND (`device` = "Mobile Phone"))
19/07/31 17:07:33 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:33 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_045`) `dbplyr_046`
ORDER BY `date`) `dbplyr_047`) `dbplyr_048`
WHERE ((`customer` = "All Visitors") AND (`device` = "Mobile Phone"))
19/07/31 17:07:33 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:33 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:33 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#932 - cust_prospect_ind.nullCount#931) > 0)
19/07/31 17:07:33 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#937 - visit_device_type.nullCount#936) > 0)
19/07/31 17:07:33 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#930 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#929))
19/07/31 17:07:33 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#935 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#934))
19/07/31 17:07:33 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:33 INFO DAGScheduler: Got job 15 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:33 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:204)
19/07/31 17:07:33 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:33 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:33 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[77] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:33 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 72.1 KB, free 910.0 MB)
19/07/31 17:07:33 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.0 MB)
19/07/31 17:07:33 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:53949 (size: 30.4 KB, free: 911.8 MB)
19/07/31 17:07:33 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[77] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:33 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
19/07/31 17:07:33 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:33 INFO Executor: Running task 0.0 in stage 22.0 (TID 37)
19/07/31 17:07:33 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:33 INFO Executor: Finished task 0.0 in stage 22.0 (TID 37). 7585 bytes result sent to driver
19/07/31 17:07:33 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 37) in 10 ms on localhost (executor driver) (1/1)
19/07/31 17:07:33 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/07/31 17:07:33 INFO DAGScheduler: ResultStage 22 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:07:33 INFO DAGScheduler: Job 15 finished: collect at utils.scala:204, took 0.024736 s
19/07/31 17:07:33 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:33 INFO DAGScheduler: Registering RDD 78 (collect at utils.scala:204)
19/07/31 17:07:33 INFO DAGScheduler: Got job 16 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:33 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:204)
19/07/31 17:07:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
19/07/31 17:07:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 23)
19/07/31 17:07:33 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[78] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:33 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 74.6 KB, free 909.9 MB)
19/07/31 17:07:33 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 31.7 KB, free 909.9 MB)
19/07/31 17:07:33 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:53949 (size: 31.7 KB, free: 911.7 MB)
19/07/31 17:07:33 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[78] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:33 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
19/07/31 17:07:33 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:33 INFO Executor: Running task 0.0 in stage 23.0 (TID 38)
19/07/31 17:07:33 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:33 INFO Executor: Finished task 0.0 in stage 23.0 (TID 38). 1687 bytes result sent to driver
19/07/31 17:07:33 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 38) in 14 ms on localhost (executor driver) (1/1)
19/07/31 17:07:33 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
19/07/31 17:07:33 INFO DAGScheduler: ShuffleMapStage 23 (collect at utils.scala:204) finished in 0.014 s
19/07/31 17:07:33 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:33 INFO DAGScheduler: running: Set()
19/07/31 17:07:33 INFO DAGScheduler: waiting: Set(ResultStage 24)
19/07/31 17:07:33 INFO DAGScheduler: failed: Set()
19/07/31 17:07:33 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[81] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:33 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 16.8 KB, free 909.9 MB)
19/07/31 17:07:33 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.9 MB)
19/07/31 17:07:33 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:07:33 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:33 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[81] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:33 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks
19/07/31 17:07:33 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 39, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:33 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 40, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:33 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 41, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:33 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 42, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:33 INFO Executor: Running task 0.0 in stage 24.0 (TID 39)
19/07/31 17:07:33 INFO Executor: Running task 1.0 in stage 24.0 (TID 40)
19/07/31 17:07:33 INFO Executor: Running task 2.0 in stage 24.0 (TID 41)
19/07/31 17:07:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:33 INFO Executor: Running task 3.0 in stage 24.0 (TID 42)
19/07/31 17:07:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:33 INFO Executor: Finished task 0.0 in stage 24.0 (TID 39). 2385 bytes result sent to driver
19/07/31 17:07:33 INFO Executor: Finished task 1.0 in stage 24.0 (TID 40). 2383 bytes result sent to driver
19/07/31 17:07:33 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 40) in 11 ms on localhost (executor driver) (1/4)
19/07/31 17:07:33 INFO Executor: Finished task 3.0 in stage 24.0 (TID 42). 2358 bytes result sent to driver
19/07/31 17:07:33 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 39) in 11 ms on localhost (executor driver) (2/4)
19/07/31 17:07:33 INFO Executor: Finished task 2.0 in stage 24.0 (TID 41). 2372 bytes result sent to driver
19/07/31 17:07:33 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 42) in 12 ms on localhost (executor driver) (3/4)
19/07/31 17:07:33 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 41) in 12 ms on localhost (executor driver) (4/4)
19/07/31 17:07:33 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
19/07/31 17:07:33 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:07:33 INFO DAGScheduler: Job 16 finished: collect at utils.scala:204, took 0.048160 s
19/07/31 17:07:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_049`) `dbplyr_050`
ORDER BY `date`) `dbplyr_051`) `dbplyr_052`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:33 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:33 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_053`) `dbplyr_054`
ORDER BY `date`) `dbplyr_055`) `dbplyr_056`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:34 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:34 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1030 - cust_prospect_ind.nullCount#1029) > 0)
19/07/31 17:07:34 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1035 - visit_device_type.nullCount#1034) > 0)
19/07/31 17:07:34 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#1028 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#1027))
19/07/31 17:07:34 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#1033 <= All Devices) && (All Devices <= visit_device_type.upperBound#1032))
19/07/31 17:07:34 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:34 INFO DAGScheduler: Got job 17 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:34 INFO DAGScheduler: Final stage: ResultStage 25 (collect at utils.scala:204)
19/07/31 17:07:34 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:34 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:34 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[86] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:34 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 72.1 KB, free 909.8 MB)
19/07/31 17:07:34 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.8 MB)
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 323
19/07/31 17:07:34 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.7 MB)
19/07/31 17:07:34 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[86] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:34 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 911.7 MB)
19/07/31 17:07:34 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 481
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 180
19/07/31 17:07:34 INFO Executor: Running task 0.0 in stage 25.0 (TID 43)
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:53949 in memory (size: 31.7 KB, free: 911.8 MB)
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 565
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 123
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:53949 in memory (size: 3.7 KB, free: 911.8 MB)
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 181
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 483
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:53949 in memory (size: 8.6 KB, free: 911.8 MB)
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:53949 in memory (size: 31.7 KB, free: 911.8 MB)
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:53949 in memory (size: 30.4 KB, free: 911.8 MB)
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 911.9 MB)
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 114
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 178
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 722
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 176
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 479
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 563
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 185
19/07/31 17:07:34 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:34 INFO Executor: Finished task 0.0 in stage 25.0 (TID 43). 7585 bytes result sent to driver
19/07/31 17:07:34 INFO ContextCleaner: Cleaned shuffle 2
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 117
19/07/31 17:07:34 INFO ContextCleaner: Cleaned shuffle 0
19/07/31 17:07:34 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 43) in 13 ms on localhost (executor driver) (1/1)
19/07/31 17:07:34 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
19/07/31 17:07:34 INFO DAGScheduler: ResultStage 25 (collect at utils.scala:204) finished in 0.013 s
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:53949 in memory (size: 11.8 KB, free: 911.9 MB)
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 183
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 401
19/07/31 17:07:34 INFO DAGScheduler: Job 17 finished: collect at utils.scala:204, took 0.066316 s
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 911.9 MB)
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 560
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 322
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:53949 in memory (size: 3.7 KB, free: 911.9 MB)
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:53949 in memory (size: 30.4 KB, free: 911.9 MB)
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 566
19/07/31 17:07:34 INFO ContextCleaner: Cleaned shuffle 6
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 641
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 568
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 244
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 319
19/07/31 17:07:34 INFO ContextCleaner: Cleaned shuffle 1
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 480
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 486
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 126
19/07/31 17:07:34 INFO ContextCleaner: Cleaned shuffle 4
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 186
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 318
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 487
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 121
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 240
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 482
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 400
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 243
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 175
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 179
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 398
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 184
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 237
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 118
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 238
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 317
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 406
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 325
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 177
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 236
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 324
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 562
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 241
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 120
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 115
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 399
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 320
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 119
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 567
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 116
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 122
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 402
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 403
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 242
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 182
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 124
19/07/31 17:07:34 INFO ContextCleaner: Cleaned shuffle 3
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 912.1 MB)
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:53949 in memory (size: 11.9 KB, free: 912.1 MB)
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 484
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 239
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 321
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 404
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:53949 in memory (size: 31.7 KB, free: 912.1 MB)
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 187
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 485
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 564
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 405
19/07/31 17:07:34 INFO ContextCleaner: Cleaned shuffle 5
19/07/31 17:07:34 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:53949 in memory (size: 30.4 KB, free: 912.1 MB)
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 125
19/07/31 17:07:34 INFO ContextCleaner: Cleaned accumulator 561
19/07/31 17:07:34 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:34 INFO DAGScheduler: Registering RDD 87 (collect at utils.scala:204)
19/07/31 17:07:34 INFO DAGScheduler: Got job 18 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:34 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:204)
19/07/31 17:07:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
19/07/31 17:07:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 26)
19/07/31 17:07:34 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[87] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:34 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 74.5 KB, free 911.2 MB)
19/07/31 17:07:34 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.1 MB)
19/07/31 17:07:34 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 912.1 MB)
19/07/31 17:07:34 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[87] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:34 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
19/07/31 17:07:34 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:34 INFO Executor: Running task 0.0 in stage 26.0 (TID 44)
19/07/31 17:07:34 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:34 INFO Executor: Finished task 0.0 in stage 26.0 (TID 44). 1687 bytes result sent to driver
19/07/31 17:07:34 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 44) in 17 ms on localhost (executor driver) (1/1)
19/07/31 17:07:34 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
19/07/31 17:07:34 INFO DAGScheduler: ShuffleMapStage 26 (collect at utils.scala:204) finished in 0.018 s
19/07/31 17:07:34 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:34 INFO DAGScheduler: running: Set()
19/07/31 17:07:34 INFO DAGScheduler: waiting: Set(ResultStage 27)
19/07/31 17:07:34 INFO DAGScheduler: failed: Set()
19/07/31 17:07:34 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[90] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:34 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 16.8 KB, free 911.1 MB)
19/07/31 17:07:34 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.1 MB)
19/07/31 17:07:34 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:07:34 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:34 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 27 (MapPartitionsRDD[90] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:34 INFO TaskSchedulerImpl: Adding task set 27.0 with 4 tasks
19/07/31 17:07:34 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 45, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:34 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 46, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:34 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 47, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:34 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 48, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:34 INFO Executor: Running task 0.0 in stage 27.0 (TID 45)
19/07/31 17:07:34 INFO Executor: Running task 1.0 in stage 27.0 (TID 46)
19/07/31 17:07:34 INFO Executor: Running task 2.0 in stage 27.0 (TID 47)
19/07/31 17:07:34 INFO Executor: Running task 3.0 in stage 27.0 (TID 48)
19/07/31 17:07:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:34 INFO Executor: Finished task 2.0 in stage 27.0 (TID 47). 2390 bytes result sent to driver
19/07/31 17:07:34 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 47) in 38 ms on localhost (executor driver) (1/4)
19/07/31 17:07:34 INFO Executor: Finished task 0.0 in stage 27.0 (TID 45). 2382 bytes result sent to driver
19/07/31 17:07:34 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 45) in 40 ms on localhost (executor driver) (2/4)
19/07/31 17:07:34 INFO Executor: Finished task 1.0 in stage 27.0 (TID 46). 2403 bytes result sent to driver
19/07/31 17:07:34 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 46) in 48 ms on localhost (executor driver) (3/4)
19/07/31 17:07:34 INFO Executor: Finished task 3.0 in stage 27.0 (TID 48). 2362 bytes result sent to driver
19/07/31 17:07:34 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 48) in 48 ms on localhost (executor driver) (4/4)
19/07/31 17:07:34 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
19/07/31 17:07:34 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:204) finished in 0.050 s
19/07/31 17:07:34 INFO DAGScheduler: Job 18 finished: collect at utils.scala:204, took 0.095982 s
19/07/31 17:07:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_057`) `dbplyr_058`
ORDER BY `date`) `dbplyr_059`) `dbplyr_060`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:34 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_061`) `dbplyr_062`
ORDER BY `date`) `dbplyr_063`) `dbplyr_064`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:34 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:34 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1128 - cust_prospect_ind.nullCount#1127) > 0)
19/07/31 17:07:34 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1133 - visit_device_type.nullCount#1132) > 0)
19/07/31 17:07:34 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#1126 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#1125))
19/07/31 17:07:34 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#1131 <= All Devices) && (All Devices <= visit_device_type.upperBound#1130))
19/07/31 17:07:34 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:34 INFO DAGScheduler: Got job 19 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:34 INFO DAGScheduler: Final stage: ResultStage 28 (collect at utils.scala:204)
19/07/31 17:07:34 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:34 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:34 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[95] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:34 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 72.1 KB, free 911.0 MB)
19/07/31 17:07:34 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 30.5 KB, free 911.0 MB)
19/07/31 17:07:34 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 912.1 MB)
19/07/31 17:07:34 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[95] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:34 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
19/07/31 17:07:34 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:34 INFO Executor: Running task 0.0 in stage 28.0 (TID 49)
19/07/31 17:07:34 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:34 INFO Executor: Finished task 0.0 in stage 28.0 (TID 49). 7542 bytes result sent to driver
19/07/31 17:07:34 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 49) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:07:34 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
19/07/31 17:07:34 INFO DAGScheduler: ResultStage 28 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:07:34 INFO DAGScheduler: Job 19 finished: collect at utils.scala:204, took 0.019248 s
19/07/31 17:07:34 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:34 INFO DAGScheduler: Registering RDD 96 (collect at utils.scala:204)
19/07/31 17:07:34 INFO DAGScheduler: Got job 20 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:34 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:204)
19/07/31 17:07:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
19/07/31 17:07:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 29)
19/07/31 17:07:34 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[96] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:34 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 74.5 KB, free 910.9 MB)
19/07/31 17:07:34 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.9 MB)
19/07/31 17:07:34 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:07:34 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[96] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:34 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
19/07/31 17:07:34 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:34 INFO Executor: Running task 0.0 in stage 29.0 (TID 50)
19/07/31 17:07:34 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:34 INFO Executor: Finished task 0.0 in stage 29.0 (TID 50). 1687 bytes result sent to driver
19/07/31 17:07:34 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 50) in 15 ms on localhost (executor driver) (1/1)
19/07/31 17:07:34 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
19/07/31 17:07:34 INFO DAGScheduler: ShuffleMapStage 29 (collect at utils.scala:204) finished in 0.015 s
19/07/31 17:07:34 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:34 INFO DAGScheduler: running: Set()
19/07/31 17:07:34 INFO DAGScheduler: waiting: Set(ResultStage 30)
19/07/31 17:07:34 INFO DAGScheduler: failed: Set()
19/07/31 17:07:34 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[99] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:34 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 16.8 KB, free 910.9 MB)
19/07/31 17:07:34 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.9 MB)
19/07/31 17:07:34 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:07:34 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:34 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 30 (MapPartitionsRDD[99] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:34 INFO TaskSchedulerImpl: Adding task set 30.0 with 4 tasks
19/07/31 17:07:34 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 51, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:34 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 52, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:34 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 53, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:34 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 54, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:34 INFO Executor: Running task 0.0 in stage 30.0 (TID 51)
19/07/31 17:07:34 INFO Executor: Running task 2.0 in stage 30.0 (TID 53)
19/07/31 17:07:34 INFO Executor: Running task 1.0 in stage 30.0 (TID 52)
19/07/31 17:07:34 INFO Executor: Running task 3.0 in stage 30.0 (TID 54)
19/07/31 17:07:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:34 INFO Executor: Finished task 3.0 in stage 30.0 (TID 54). 2362 bytes result sent to driver
19/07/31 17:07:34 INFO Executor: Finished task 1.0 in stage 30.0 (TID 52). 2403 bytes result sent to driver
19/07/31 17:07:34 INFO Executor: Finished task 0.0 in stage 30.0 (TID 51). 2382 bytes result sent to driver
19/07/31 17:07:34 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 54) in 6 ms on localhost (executor driver) (1/4)
19/07/31 17:07:34 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 52) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:07:34 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 51) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:07:34 INFO Executor: Finished task 2.0 in stage 30.0 (TID 53). 2390 bytes result sent to driver
19/07/31 17:07:34 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 53) in 7 ms on localhost (executor driver) (4/4)
19/07/31 17:07:34 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
19/07/31 17:07:34 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:07:34 INFO DAGScheduler: Job 20 finished: collect at utils.scala:204, took 0.038556 s
19/07/31 17:07:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_065`) `dbplyr_066`
ORDER BY `date`) `dbplyr_067`) `dbplyr_068`
WHERE ((`customer` = "All Visitors") AND (`device` = "Desktop"))
19/07/31 17:07:34 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_069`) `dbplyr_070`
ORDER BY `date`) `dbplyr_071`) `dbplyr_072`
WHERE ((`customer` = "All Visitors") AND (`device` = "Desktop"))
19/07/31 17:07:34 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:35 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1226 - cust_prospect_ind.nullCount#1225) > 0)
19/07/31 17:07:35 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1231 - visit_device_type.nullCount#1230) > 0)
19/07/31 17:07:35 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#1224 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#1223))
19/07/31 17:07:35 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#1229 <= Desktop) && (Desktop <= visit_device_type.upperBound#1228))
19/07/31 17:07:35 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:35 INFO DAGScheduler: Got job 21 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:35 INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:204)
19/07/31 17:07:35 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:35 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:35 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[104] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:35 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 72.1 KB, free 910.8 MB)
19/07/31 17:07:35 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.8 MB)
19/07/31 17:07:35 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:53949 (size: 30.4 KB, free: 912.0 MB)
19/07/31 17:07:35 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[104] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:35 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
19/07/31 17:07:35 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:35 INFO Executor: Running task 0.0 in stage 31.0 (TID 55)
19/07/31 17:07:35 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:35 INFO Executor: Finished task 0.0 in stage 31.0 (TID 55). 7068 bytes result sent to driver
19/07/31 17:07:35 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 55) in 10 ms on localhost (executor driver) (1/1)
19/07/31 17:07:35 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
19/07/31 17:07:35 INFO DAGScheduler: ResultStage 31 (collect at utils.scala:204) finished in 0.011 s
19/07/31 17:07:35 INFO DAGScheduler: Job 21 finished: collect at utils.scala:204, took 0.019688 s
19/07/31 17:07:35 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:35 INFO DAGScheduler: Registering RDD 105 (collect at utils.scala:204)
19/07/31 17:07:35 INFO DAGScheduler: Got job 22 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:35 INFO DAGScheduler: Final stage: ResultStage 33 (collect at utils.scala:204)
19/07/31 17:07:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)
19/07/31 17:07:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 32)
19/07/31 17:07:35 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[105] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:35 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 74.5 KB, free 910.7 MB)
19/07/31 17:07:35 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.7 MB)
19/07/31 17:07:35 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:53949 (size: 31.7 KB, free: 912.0 MB)
19/07/31 17:07:35 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[105] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:35 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
19/07/31 17:07:35 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:35 INFO Executor: Running task 0.0 in stage 32.0 (TID 56)
19/07/31 17:07:35 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:35 INFO Executor: Finished task 0.0 in stage 32.0 (TID 56). 1687 bytes result sent to driver
19/07/31 17:07:35 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 56) in 11 ms on localhost (executor driver) (1/1)
19/07/31 17:07:35 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
19/07/31 17:07:35 INFO DAGScheduler: ShuffleMapStage 32 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:07:35 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:35 INFO DAGScheduler: running: Set()
19/07/31 17:07:35 INFO DAGScheduler: waiting: Set(ResultStage 33)
19/07/31 17:07:35 INFO DAGScheduler: failed: Set()
19/07/31 17:07:35 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[108] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:35 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 16.8 KB, free 910.7 MB)
19/07/31 17:07:35 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 8.1 KB, free 910.7 MB)
19/07/31 17:07:35 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:53949 (size: 8.1 KB, free: 912.0 MB)
19/07/31 17:07:35 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:35 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 33 (MapPartitionsRDD[108] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:35 INFO TaskSchedulerImpl: Adding task set 33.0 with 4 tasks
19/07/31 17:07:35 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 57, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:35 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 58, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:35 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 59, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:35 INFO TaskSetManager: Starting task 3.0 in stage 33.0 (TID 60, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:35 INFO Executor: Running task 2.0 in stage 33.0 (TID 59)
19/07/31 17:07:35 INFO Executor: Running task 1.0 in stage 33.0 (TID 58)
19/07/31 17:07:35 INFO Executor: Running task 0.0 in stage 33.0 (TID 57)
19/07/31 17:07:35 INFO Executor: Running task 3.0 in stage 33.0 (TID 60)
19/07/31 17:07:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:35 INFO Executor: Finished task 3.0 in stage 33.0 (TID 60). 2356 bytes result sent to driver
19/07/31 17:07:35 INFO Executor: Finished task 1.0 in stage 33.0 (TID 58). 2385 bytes result sent to driver
19/07/31 17:07:35 INFO Executor: Finished task 2.0 in stage 33.0 (TID 59). 2380 bytes result sent to driver
19/07/31 17:07:35 INFO TaskSetManager: Finished task 3.0 in stage 33.0 (TID 60) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:07:35 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 58) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:07:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:35 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 59) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:07:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:35 INFO Executor: Finished task 0.0 in stage 33.0 (TID 57). 2381 bytes result sent to driver
19/07/31 17:07:35 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 57) in 9 ms on localhost (executor driver) (4/4)
19/07/31 17:07:35 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
19/07/31 17:07:35 INFO DAGScheduler: ResultStage 33 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:07:35 INFO DAGScheduler: Job 22 finished: collect at utils.scala:204, took 0.037695 s
19/07/31 17:07:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_073`) `dbplyr_074`
ORDER BY `date`) `dbplyr_075`) `dbplyr_076`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:35 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:35 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_077`) `dbplyr_078`
ORDER BY `date`) `dbplyr_079`) `dbplyr_080`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:35 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:35 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:35 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1324 - cust_prospect_ind.nullCount#1323) > 0)
19/07/31 17:07:35 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1329 - visit_device_type.nullCount#1328) > 0)
19/07/31 17:07:35 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#1322 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#1321))
19/07/31 17:07:35 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#1327 <= All Devices) && (All Devices <= visit_device_type.upperBound#1326))
19/07/31 17:07:36 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:36 INFO DAGScheduler: Got job 23 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:36 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:204)
19/07/31 17:07:36 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:36 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:36 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[113] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:36 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 72.1 KB, free 910.6 MB)
19/07/31 17:07:36 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.6 MB)
19/07/31 17:07:36 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.9 MB)
19/07/31 17:07:36 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[113] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:36 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
19/07/31 17:07:36 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:36 INFO Executor: Running task 0.0 in stage 34.0 (TID 61)
19/07/31 17:07:36 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:36 INFO Executor: Finished task 0.0 in stage 34.0 (TID 61). 7542 bytes result sent to driver
19/07/31 17:07:36 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 61) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:07:36 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
19/07/31 17:07:36 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:07:36 INFO DAGScheduler: Job 23 finished: collect at utils.scala:204, took 0.016211 s
19/07/31 17:07:36 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:36 INFO DAGScheduler: Registering RDD 114 (collect at utils.scala:204)
19/07/31 17:07:36 INFO DAGScheduler: Got job 24 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:36 INFO DAGScheduler: Final stage: ResultStage 36 (collect at utils.scala:204)
19/07/31 17:07:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
19/07/31 17:07:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 35)
19/07/31 17:07:36 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[114] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:36 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 74.5 KB, free 910.5 MB)
19/07/31 17:07:36 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.5 MB)
19/07/31 17:07:36 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.9 MB)
19/07/31 17:07:36 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[114] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:36 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
19/07/31 17:07:36 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:36 INFO Executor: Running task 0.0 in stage 35.0 (TID 62)
19/07/31 17:07:36 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:36 INFO Executor: Finished task 0.0 in stage 35.0 (TID 62). 1687 bytes result sent to driver
19/07/31 17:07:36 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 62) in 12 ms on localhost (executor driver) (1/1)
19/07/31 17:07:36 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
19/07/31 17:07:36 INFO DAGScheduler: ShuffleMapStage 35 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:07:36 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:36 INFO DAGScheduler: running: Set()
19/07/31 17:07:36 INFO DAGScheduler: waiting: Set(ResultStage 36)
19/07/31 17:07:36 INFO DAGScheduler: failed: Set()
19/07/31 17:07:36 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[117] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:36 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 16.8 KB, free 910.4 MB)
19/07/31 17:07:36 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 8.1 KB, free 910.4 MB)
19/07/31 17:07:36 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:53949 (size: 8.1 KB, free: 911.9 MB)
19/07/31 17:07:36 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:36 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 36 (MapPartitionsRDD[117] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:36 INFO TaskSchedulerImpl: Adding task set 36.0 with 4 tasks
19/07/31 17:07:36 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 63, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:36 INFO TaskSetManager: Starting task 1.0 in stage 36.0 (TID 64, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:36 INFO TaskSetManager: Starting task 2.0 in stage 36.0 (TID 65, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:36 INFO TaskSetManager: Starting task 3.0 in stage 36.0 (TID 66, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:36 INFO Executor: Running task 0.0 in stage 36.0 (TID 63)
19/07/31 17:07:36 INFO Executor: Running task 2.0 in stage 36.0 (TID 65)
19/07/31 17:07:36 INFO Executor: Running task 1.0 in stage 36.0 (TID 64)
19/07/31 17:07:36 INFO Executor: Running task 3.0 in stage 36.0 (TID 66)
19/07/31 17:07:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:36 INFO Executor: Finished task 1.0 in stage 36.0 (TID 64). 2403 bytes result sent to driver
19/07/31 17:07:36 INFO Executor: Finished task 3.0 in stage 36.0 (TID 66). 2405 bytes result sent to driver
19/07/31 17:07:36 INFO Executor: Finished task 2.0 in stage 36.0 (TID 65). 2390 bytes result sent to driver
19/07/31 17:07:36 INFO TaskSetManager: Finished task 1.0 in stage 36.0 (TID 64) in 9 ms on localhost (executor driver) (1/4)
19/07/31 17:07:36 INFO Executor: Finished task 0.0 in stage 36.0 (TID 63). 2382 bytes result sent to driver
19/07/31 17:07:36 INFO TaskSetManager: Finished task 3.0 in stage 36.0 (TID 66) in 8 ms on localhost (executor driver) (2/4)
19/07/31 17:07:36 INFO TaskSetManager: Finished task 2.0 in stage 36.0 (TID 65) in 10 ms on localhost (executor driver) (3/4)
19/07/31 17:07:36 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 63) in 10 ms on localhost (executor driver) (4/4)
19/07/31 17:07:36 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
19/07/31 17:07:36 INFO DAGScheduler: ResultStage 36 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:07:36 INFO DAGScheduler: Job 24 finished: collect at utils.scala:204, took 0.037983 s
19/07/31 17:07:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_081`) `dbplyr_082`
ORDER BY `date`) `dbplyr_083`) `dbplyr_084`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_085`) `dbplyr_086`
ORDER BY `date`) `dbplyr_087`) `dbplyr_088`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:36 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1422 - cust_prospect_ind.nullCount#1421) > 0)
19/07/31 17:07:36 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1427 - visit_device_type.nullCount#1426) > 0)
19/07/31 17:07:36 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#1420 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#1419))
19/07/31 17:07:36 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#1425 <= All Devices) && (All Devices <= visit_device_type.upperBound#1424))
19/07/31 17:07:36 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:36 INFO DAGScheduler: Got job 25 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:36 INFO DAGScheduler: Final stage: ResultStage 37 (collect at utils.scala:204)
19/07/31 17:07:36 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:36 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:36 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[122] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:36 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 72.1 KB, free 910.4 MB)
19/07/31 17:07:36 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.3 MB)
19/07/31 17:07:36 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.9 MB)
19/07/31 17:07:36 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[122] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:36 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
19/07/31 17:07:36 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:36 INFO Executor: Running task 0.0 in stage 37.0 (TID 67)
19/07/31 17:07:36 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:36 INFO Executor: Finished task 0.0 in stage 37.0 (TID 67). 7542 bytes result sent to driver
19/07/31 17:07:36 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 67) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:07:36 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
19/07/31 17:07:36 INFO DAGScheduler: ResultStage 37 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:07:36 INFO DAGScheduler: Job 25 finished: collect at utils.scala:204, took 0.016355 s
19/07/31 17:07:36 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:36 INFO DAGScheduler: Registering RDD 123 (collect at utils.scala:204)
19/07/31 17:07:36 INFO DAGScheduler: Got job 26 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:36 INFO DAGScheduler: Final stage: ResultStage 39 (collect at utils.scala:204)
19/07/31 17:07:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)
19/07/31 17:07:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 38)
19/07/31 17:07:36 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[123] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:36 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 74.5 KB, free 910.3 MB)
19/07/31 17:07:36 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.2 MB)
19/07/31 17:07:36 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:07:36 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[123] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:36 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
19/07/31 17:07:36 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:36 INFO Executor: Running task 0.0 in stage 38.0 (TID 68)
19/07/31 17:07:36 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:36 INFO Executor: Finished task 0.0 in stage 38.0 (TID 68). 1687 bytes result sent to driver
19/07/31 17:07:36 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 68) in 12 ms on localhost (executor driver) (1/1)
19/07/31 17:07:36 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
19/07/31 17:07:36 INFO DAGScheduler: ShuffleMapStage 38 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:07:36 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:36 INFO DAGScheduler: running: Set()
19/07/31 17:07:36 INFO DAGScheduler: waiting: Set(ResultStage 39)
19/07/31 17:07:36 INFO DAGScheduler: failed: Set()
19/07/31 17:07:36 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[126] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:36 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 16.8 KB, free 910.2 MB)
19/07/31 17:07:36 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.2 MB)
19/07/31 17:07:36 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:07:36 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:36 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 39 (MapPartitionsRDD[126] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:36 INFO TaskSchedulerImpl: Adding task set 39.0 with 4 tasks
19/07/31 17:07:36 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 69, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:36 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 70, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:36 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 71, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:36 INFO TaskSetManager: Starting task 3.0 in stage 39.0 (TID 72, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:36 INFO Executor: Running task 1.0 in stage 39.0 (TID 70)
19/07/31 17:07:36 INFO Executor: Running task 2.0 in stage 39.0 (TID 71)
19/07/31 17:07:36 INFO Executor: Running task 0.0 in stage 39.0 (TID 69)
19/07/31 17:07:36 INFO Executor: Running task 3.0 in stage 39.0 (TID 72)
19/07/31 17:07:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:36 INFO Executor: Finished task 3.0 in stage 39.0 (TID 72). 2362 bytes result sent to driver
19/07/31 17:07:36 INFO Executor: Finished task 0.0 in stage 39.0 (TID 69). 2382 bytes result sent to driver
19/07/31 17:07:36 INFO Executor: Finished task 1.0 in stage 39.0 (TID 70). 2403 bytes result sent to driver
19/07/31 17:07:36 INFO Executor: Finished task 2.0 in stage 39.0 (TID 71). 2390 bytes result sent to driver
19/07/31 17:07:36 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 69) in 6 ms on localhost (executor driver) (1/4)
19/07/31 17:07:36 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 71) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:07:36 INFO TaskSetManager: Finished task 3.0 in stage 39.0 (TID 72) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:07:36 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 70) in 7 ms on localhost (executor driver) (4/4)
19/07/31 17:07:36 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
19/07/31 17:07:36 INFO DAGScheduler: ResultStage 39 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:07:36 INFO DAGScheduler: Job 26 finished: collect at utils.scala:204, took 0.031929 s
19/07/31 17:07:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_089`) `dbplyr_090`
ORDER BY `date`) `dbplyr_091`) `dbplyr_092`
WHERE ((`customer` = "All Visitors") AND (`device` = "Tablet"))
19/07/31 17:07:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_093`) `dbplyr_094`
ORDER BY `date`) `dbplyr_095`) `dbplyr_096`
WHERE ((`customer` = "All Visitors") AND (`device` = "Tablet"))
19/07/31 17:07:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:37 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1520 - cust_prospect_ind.nullCount#1519) > 0)
19/07/31 17:07:37 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1525 - visit_device_type.nullCount#1524) > 0)
19/07/31 17:07:37 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#1518 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#1517))
19/07/31 17:07:37 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#1523 <= Tablet) && (Tablet <= visit_device_type.upperBound#1522))
19/07/31 17:07:37 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:37 INFO DAGScheduler: Got job 27 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:37 INFO DAGScheduler: Final stage: ResultStage 40 (collect at utils.scala:204)
19/07/31 17:07:37 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:37 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:37 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[131] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:37 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 72.1 KB, free 910.1 MB)
19/07/31 17:07:37 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.1 MB)
19/07/31 17:07:37 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:53949 (size: 30.4 KB, free: 911.8 MB)
19/07/31 17:07:37 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[131] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:37 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
19/07/31 17:07:37 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:37 INFO Executor: Running task 0.0 in stage 40.0 (TID 73)
19/07/31 17:07:37 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:37 INFO Executor: Finished task 0.0 in stage 40.0 (TID 73). 7068 bytes result sent to driver
19/07/31 17:07:37 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 73) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:07:37 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
19/07/31 17:07:37 INFO DAGScheduler: ResultStage 40 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:07:37 INFO DAGScheduler: Job 27 finished: collect at utils.scala:204, took 0.013372 s
19/07/31 17:07:37 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:37 INFO DAGScheduler: Registering RDD 132 (collect at utils.scala:204)
19/07/31 17:07:37 INFO DAGScheduler: Got job 28 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:37 INFO DAGScheduler: Final stage: ResultStage 42 (collect at utils.scala:204)
19/07/31 17:07:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
19/07/31 17:07:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
19/07/31 17:07:37 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[132] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:37 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 74.5 KB, free 910.0 MB)
19/07/31 17:07:37 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.0 MB)
19/07/31 17:07:37 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:53949 (size: 31.7 KB, free: 911.8 MB)
19/07/31 17:07:37 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[132] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:37 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
19/07/31 17:07:37 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 74, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:37 INFO Executor: Running task 0.0 in stage 41.0 (TID 74)
19/07/31 17:07:37 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:37 INFO Executor: Finished task 0.0 in stage 41.0 (TID 74). 1687 bytes result sent to driver
19/07/31 17:07:37 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 74) in 10 ms on localhost (executor driver) (1/1)
19/07/31 17:07:37 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
19/07/31 17:07:37 INFO DAGScheduler: ShuffleMapStage 41 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:07:37 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:37 INFO DAGScheduler: running: Set()
19/07/31 17:07:37 INFO DAGScheduler: waiting: Set(ResultStage 42)
19/07/31 17:07:37 INFO DAGScheduler: failed: Set()
19/07/31 17:07:37 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[135] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:37 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 16.8 KB, free 910.0 MB)
19/07/31 17:07:37 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.0 MB)
19/07/31 17:07:37 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:07:37 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:37 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 42 (MapPartitionsRDD[135] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:37 INFO TaskSchedulerImpl: Adding task set 42.0 with 4 tasks
19/07/31 17:07:37 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 75, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:37 INFO TaskSetManager: Starting task 1.0 in stage 42.0 (TID 76, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:37 INFO TaskSetManager: Starting task 2.0 in stage 42.0 (TID 77, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:37 INFO TaskSetManager: Starting task 3.0 in stage 42.0 (TID 78, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:37 INFO Executor: Running task 0.0 in stage 42.0 (TID 75)
19/07/31 17:07:37 INFO Executor: Running task 1.0 in stage 42.0 (TID 76)
19/07/31 17:07:37 INFO Executor: Running task 3.0 in stage 42.0 (TID 78)
19/07/31 17:07:37 INFO Executor: Running task 2.0 in stage 42.0 (TID 77)
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:37 INFO Executor: Finished task 0.0 in stage 42.0 (TID 75). 2363 bytes result sent to driver
19/07/31 17:07:37 INFO Executor: Finished task 1.0 in stage 42.0 (TID 76). 2361 bytes result sent to driver
19/07/31 17:07:37 INFO Executor: Finished task 3.0 in stage 42.0 (TID 78). 2337 bytes result sent to driver
19/07/31 17:07:37 INFO Executor: Finished task 2.0 in stage 42.0 (TID 77). 2362 bytes result sent to driver
19/07/31 17:07:37 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 75) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:07:37 INFO TaskSetManager: Finished task 3.0 in stage 42.0 (TID 78) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:07:37 INFO TaskSetManager: Finished task 1.0 in stage 42.0 (TID 76) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:07:37 INFO TaskSetManager: Finished task 2.0 in stage 42.0 (TID 77) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:07:37 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
19/07/31 17:07:37 INFO DAGScheduler: ResultStage 42 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:07:37 INFO DAGScheduler: Job 28 finished: collect at utils.scala:204, took 0.028524 s
19/07/31 17:07:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_097`) `dbplyr_098`
ORDER BY `date`) `dbplyr_099`) `dbplyr_100`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_101`) `dbplyr_102`
ORDER BY `date`) `dbplyr_103`) `dbplyr_104`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:37 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1618 - cust_prospect_ind.nullCount#1617) > 0)
19/07/31 17:07:37 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1623 - visit_device_type.nullCount#1622) > 0)
19/07/31 17:07:37 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#1616 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#1615))
19/07/31 17:07:37 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#1621 <= All Devices) && (All Devices <= visit_device_type.upperBound#1620))
19/07/31 17:07:37 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:37 INFO DAGScheduler: Got job 29 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:37 INFO DAGScheduler: Final stage: ResultStage 43 (collect at utils.scala:204)
19/07/31 17:07:37 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:37 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:37 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[140] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:37 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 72.1 KB, free 909.9 MB)
19/07/31 17:07:37 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.9 MB)
19/07/31 17:07:37 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.7 MB)
19/07/31 17:07:37 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[140] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:37 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
19/07/31 17:07:37 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 79, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:37 INFO Executor: Running task 0.0 in stage 43.0 (TID 79)
19/07/31 17:07:37 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:37 INFO Executor: Finished task 0.0 in stage 43.0 (TID 79). 7542 bytes result sent to driver
19/07/31 17:07:37 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 79) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:07:37 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
19/07/31 17:07:37 INFO DAGScheduler: ResultStage 43 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:07:37 INFO DAGScheduler: Job 29 finished: collect at utils.scala:204, took 0.015889 s
19/07/31 17:07:37 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:37 INFO DAGScheduler: Registering RDD 141 (collect at utils.scala:204)
19/07/31 17:07:37 INFO DAGScheduler: Got job 30 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:37 INFO DAGScheduler: Final stage: ResultStage 45 (collect at utils.scala:204)
19/07/31 17:07:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
19/07/31 17:07:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 44)
19/07/31 17:07:37 INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[141] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:37 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 74.5 KB, free 909.8 MB)
19/07/31 17:07:37 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.8 MB)
19/07/31 17:07:37 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.7 MB)
19/07/31 17:07:37 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[141] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:37 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
19/07/31 17:07:37 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 80, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:37 INFO Executor: Running task 0.0 in stage 44.0 (TID 80)
19/07/31 17:07:37 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:37 INFO Executor: Finished task 0.0 in stage 44.0 (TID 80). 1687 bytes result sent to driver
19/07/31 17:07:37 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 80) in 13 ms on localhost (executor driver) (1/1)
19/07/31 17:07:37 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
19/07/31 17:07:37 INFO DAGScheduler: ShuffleMapStage 44 (collect at utils.scala:204) finished in 0.014 s
19/07/31 17:07:37 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:37 INFO DAGScheduler: running: Set()
19/07/31 17:07:37 INFO DAGScheduler: waiting: Set(ResultStage 45)
19/07/31 17:07:37 INFO DAGScheduler: failed: Set()
19/07/31 17:07:37 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[144] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:37 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 16.8 KB, free 909.8 MB)
19/07/31 17:07:37 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.7 MB)
19/07/31 17:07:37 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:07:37 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:37 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 45 (MapPartitionsRDD[144] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:37 INFO TaskSchedulerImpl: Adding task set 45.0 with 4 tasks
19/07/31 17:07:37 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 81, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:37 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 82, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:37 INFO TaskSetManager: Starting task 2.0 in stage 45.0 (TID 83, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:37 INFO TaskSetManager: Starting task 3.0 in stage 45.0 (TID 84, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:37 INFO Executor: Running task 1.0 in stage 45.0 (TID 82)
19/07/31 17:07:37 INFO Executor: Running task 3.0 in stage 45.0 (TID 84)
19/07/31 17:07:37 INFO Executor: Running task 2.0 in stage 45.0 (TID 83)
19/07/31 17:07:37 INFO Executor: Running task 0.0 in stage 45.0 (TID 81)
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:37 INFO Executor: Finished task 0.0 in stage 45.0 (TID 81). 2382 bytes result sent to driver
19/07/31 17:07:37 INFO Executor: Finished task 2.0 in stage 45.0 (TID 83). 2390 bytes result sent to driver
19/07/31 17:07:37 INFO Executor: Finished task 3.0 in stage 45.0 (TID 84). 2362 bytes result sent to driver
19/07/31 17:07:37 INFO Executor: Finished task 1.0 in stage 45.0 (TID 82). 2403 bytes result sent to driver
19/07/31 17:07:37 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 81) in 7 ms on localhost (executor driver) (1/4)
19/07/31 17:07:37 INFO TaskSetManager: Finished task 2.0 in stage 45.0 (TID 83) in 7 ms on localhost (executor driver) (2/4)
19/07/31 17:07:37 INFO TaskSetManager: Finished task 3.0 in stage 45.0 (TID 84) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:07:37 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 82) in 7 ms on localhost (executor driver) (4/4)
19/07/31 17:07:37 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
19/07/31 17:07:37 INFO DAGScheduler: ResultStage 45 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:07:37 INFO DAGScheduler: Job 30 finished: collect at utils.scala:204, took 0.046596 s
19/07/31 17:07:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_105`) `dbplyr_106`
ORDER BY `date`) `dbplyr_107`) `dbplyr_108`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_109`) `dbplyr_110`
ORDER BY `date`) `dbplyr_111`) `dbplyr_112`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:37 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1716 - cust_prospect_ind.nullCount#1715) > 0)
19/07/31 17:07:37 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1721 - visit_device_type.nullCount#1720) > 0)
19/07/31 17:07:37 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#1714 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#1713))
19/07/31 17:07:37 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#1719 <= All Devices) && (All Devices <= visit_device_type.upperBound#1718))
19/07/31 17:07:37 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:37 INFO DAGScheduler: Got job 31 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:37 INFO DAGScheduler: Final stage: ResultStage 46 (collect at utils.scala:204)
19/07/31 17:07:37 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:37 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:37 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[149] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:37 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 72.1 KB, free 909.7 MB)
19/07/31 17:07:37 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 30.4 KB, free 909.6 MB)
19/07/31 17:07:37 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:53949 (size: 30.4 KB, free: 911.7 MB)
19/07/31 17:07:37 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[149] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:37 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
19/07/31 17:07:37 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:37 INFO Executor: Running task 0.0 in stage 46.0 (TID 85)
19/07/31 17:07:37 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:37 INFO Executor: Finished task 0.0 in stage 46.0 (TID 85). 7542 bytes result sent to driver
19/07/31 17:07:37 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 85) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:07:37 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
19/07/31 17:07:37 INFO DAGScheduler: ResultStage 46 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:07:37 INFO DAGScheduler: Job 31 finished: collect at utils.scala:204, took 0.020621 s
19/07/31 17:07:37 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:37 INFO DAGScheduler: Registering RDD 150 (collect at utils.scala:204)
19/07/31 17:07:37 INFO DAGScheduler: Got job 32 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:37 INFO DAGScheduler: Final stage: ResultStage 48 (collect at utils.scala:204)
19/07/31 17:07:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
19/07/31 17:07:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 47)
19/07/31 17:07:37 INFO DAGScheduler: Submitting ShuffleMapStage 47 (MapPartitionsRDD[150] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:37 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 74.5 KB, free 909.6 MB)
19/07/31 17:07:37 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 31.7 KB, free 909.5 MB)
19/07/31 17:07:37 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:53949 (size: 31.7 KB, free: 911.6 MB)
19/07/31 17:07:37 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[150] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:37 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
19/07/31 17:07:37 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:37 INFO Executor: Running task 0.0 in stage 47.0 (TID 86)
19/07/31 17:07:37 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:37 INFO Executor: Finished task 0.0 in stage 47.0 (TID 86). 1687 bytes result sent to driver
19/07/31 17:07:37 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 86) in 14 ms on localhost (executor driver) (1/1)
19/07/31 17:07:37 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
19/07/31 17:07:37 INFO DAGScheduler: ShuffleMapStage 47 (collect at utils.scala:204) finished in 0.015 s
19/07/31 17:07:37 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:37 INFO DAGScheduler: running: Set()
19/07/31 17:07:37 INFO DAGScheduler: waiting: Set(ResultStage 48)
19/07/31 17:07:37 INFO DAGScheduler: failed: Set()
19/07/31 17:07:37 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[153] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:37 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 16.8 KB, free 909.5 MB)
19/07/31 17:07:37 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.5 MB)
19/07/31 17:07:37 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.6 MB)
19/07/31 17:07:37 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:37 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 48 (MapPartitionsRDD[153] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:37 INFO TaskSchedulerImpl: Adding task set 48.0 with 4 tasks
19/07/31 17:07:37 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 87, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:37 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 88, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:37 INFO TaskSetManager: Starting task 2.0 in stage 48.0 (TID 89, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:37 INFO TaskSetManager: Starting task 3.0 in stage 48.0 (TID 90, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:37 INFO Executor: Running task 0.0 in stage 48.0 (TID 87)
19/07/31 17:07:37 INFO Executor: Running task 1.0 in stage 48.0 (TID 88)
19/07/31 17:07:37 INFO Executor: Running task 3.0 in stage 48.0 (TID 90)
19/07/31 17:07:37 INFO Executor: Running task 2.0 in stage 48.0 (TID 89)
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:37 INFO Executor: Finished task 3.0 in stage 48.0 (TID 90). 2362 bytes result sent to driver
19/07/31 17:07:37 INFO Executor: Finished task 1.0 in stage 48.0 (TID 88). 2403 bytes result sent to driver
19/07/31 17:07:37 INFO Executor: Finished task 2.0 in stage 48.0 (TID 89). 2390 bytes result sent to driver
19/07/31 17:07:37 INFO TaskSetManager: Finished task 3.0 in stage 48.0 (TID 90) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:07:37 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 88) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:07:37 INFO Executor: Finished task 0.0 in stage 48.0 (TID 87). 2382 bytes result sent to driver
19/07/31 17:07:37 INFO TaskSetManager: Finished task 2.0 in stage 48.0 (TID 89) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:07:37 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 87) in 7 ms on localhost (executor driver) (4/4)
19/07/31 17:07:37 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
19/07/31 17:07:37 INFO DAGScheduler: ResultStage 48 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:07:37 INFO DAGScheduler: Job 32 finished: collect at utils.scala:204, took 0.037239 s
19/07/31 17:07:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_113`) `dbplyr_114`
ORDER BY `date`) `dbplyr_115`) `dbplyr_116`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "All Devices"))
19/07/31 17:07:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_117`) `dbplyr_118`
ORDER BY `date`) `dbplyr_119`) `dbplyr_120`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "All Devices"))
19/07/31 17:07:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:38 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1814 - cust_prospect_ind.nullCount#1813) > 0)
19/07/31 17:07:38 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1819 - visit_device_type.nullCount#1818) > 0)
19/07/31 17:07:38 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#1812 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#1811))
19/07/31 17:07:38 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#1817 <= All Devices) && (All Devices <= visit_device_type.upperBound#1816))
19/07/31 17:07:38 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:38 INFO DAGScheduler: Got job 33 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:38 INFO DAGScheduler: Final stage: ResultStage 49 (collect at utils.scala:204)
19/07/31 17:07:38 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:38 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:38 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[158] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:38 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 72.1 KB, free 909.4 MB)
19/07/31 17:07:38 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.4 MB)
19/07/31 17:07:38 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.6 MB)
19/07/31 17:07:38 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[158] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:38 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
19/07/31 17:07:38 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 91, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:38 INFO Executor: Running task 0.0 in stage 49.0 (TID 91)
19/07/31 17:07:38 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:38 INFO Executor: Finished task 0.0 in stage 49.0 (TID 91). 6979 bytes result sent to driver
19/07/31 17:07:38 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 91) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:07:38 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
19/07/31 17:07:38 INFO DAGScheduler: ResultStage 49 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:07:38 INFO DAGScheduler: Job 33 finished: collect at utils.scala:204, took 0.020032 s
19/07/31 17:07:38 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:38 INFO DAGScheduler: Registering RDD 159 (collect at utils.scala:204)
19/07/31 17:07:38 INFO DAGScheduler: Got job 34 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:38 INFO DAGScheduler: Final stage: ResultStage 51 (collect at utils.scala:204)
19/07/31 17:07:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
19/07/31 17:07:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 50)
19/07/31 17:07:38 INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[159] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:38 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 74.5 KB, free 909.3 MB)
19/07/31 17:07:38 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.3 MB)
19/07/31 17:07:38 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.6 MB)
19/07/31 17:07:38 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[159] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:38 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
19/07/31 17:07:38 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:38 INFO Executor: Running task 0.0 in stage 50.0 (TID 92)
19/07/31 17:07:38 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:38 INFO Executor: Finished task 0.0 in stage 50.0 (TID 92). 1687 bytes result sent to driver
19/07/31 17:07:38 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 92) in 13 ms on localhost (executor driver) (1/1)
19/07/31 17:07:38 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
19/07/31 17:07:38 INFO DAGScheduler: ShuffleMapStage 50 (collect at utils.scala:204) finished in 0.013 s
19/07/31 17:07:38 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:38 INFO DAGScheduler: running: Set()
19/07/31 17:07:38 INFO DAGScheduler: waiting: Set(ResultStage 51)
19/07/31 17:07:38 INFO DAGScheduler: failed: Set()
19/07/31 17:07:38 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[162] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:38 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 16.8 KB, free 909.3 MB)
19/07/31 17:07:38 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.3 MB)
19/07/31 17:07:38 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.6 MB)
19/07/31 17:07:38 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:38 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 51 (MapPartitionsRDD[162] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:38 INFO TaskSchedulerImpl: Adding task set 51.0 with 4 tasks
19/07/31 17:07:38 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 93, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:38 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 94, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:38 INFO TaskSetManager: Starting task 2.0 in stage 51.0 (TID 95, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:38 INFO TaskSetManager: Starting task 3.0 in stage 51.0 (TID 96, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:38 INFO Executor: Running task 0.0 in stage 51.0 (TID 93)
19/07/31 17:07:38 INFO Executor: Running task 1.0 in stage 51.0 (TID 94)
19/07/31 17:07:38 INFO Executor: Running task 3.0 in stage 51.0 (TID 96)
19/07/31 17:07:38 INFO Executor: Running task 2.0 in stage 51.0 (TID 95)
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:38 INFO Executor: Finished task 0.0 in stage 51.0 (TID 93). 2377 bytes result sent to driver
19/07/31 17:07:38 INFO Executor: Finished task 2.0 in stage 51.0 (TID 95). 2378 bytes result sent to driver
19/07/31 17:07:38 INFO Executor: Finished task 3.0 in stage 51.0 (TID 96). 2353 bytes result sent to driver
19/07/31 17:07:38 INFO Executor: Finished task 1.0 in stage 51.0 (TID 94). 2359 bytes result sent to driver
19/07/31 17:07:38 INFO TaskSetManager: Finished task 2.0 in stage 51.0 (TID 95) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:07:38 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 93) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:07:38 INFO TaskSetManager: Finished task 3.0 in stage 51.0 (TID 96) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:07:38 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 94) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:07:38 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
19/07/31 17:07:38 INFO DAGScheduler: ResultStage 51 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:07:38 INFO DAGScheduler: Job 34 finished: collect at utils.scala:204, took 0.032095 s
19/07/31 17:07:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_121`) `dbplyr_122`
ORDER BY `date`) `dbplyr_123`) `dbplyr_124`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_125`) `dbplyr_126`
ORDER BY `date`) `dbplyr_127`) `dbplyr_128`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:38 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1912 - cust_prospect_ind.nullCount#1911) > 0)
19/07/31 17:07:38 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1917 - visit_device_type.nullCount#1916) > 0)
19/07/31 17:07:38 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#1910 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#1909))
19/07/31 17:07:38 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#1915 <= All Devices) && (All Devices <= visit_device_type.upperBound#1914))
19/07/31 17:07:38 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:38 INFO DAGScheduler: Got job 35 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:38 INFO DAGScheduler: Final stage: ResultStage 52 (collect at utils.scala:204)
19/07/31 17:07:38 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:38 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:38 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[167] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:38 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 72.1 KB, free 909.2 MB)
19/07/31 17:07:38 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.2 MB)
19/07/31 17:07:38 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.5 MB)
19/07/31 17:07:38 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[167] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:38 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
19/07/31 17:07:38 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:38 INFO Executor: Running task 0.0 in stage 52.0 (TID 97)
19/07/31 17:07:38 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:38 INFO Executor: Finished task 0.0 in stage 52.0 (TID 97). 7542 bytes result sent to driver
19/07/31 17:07:38 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 97) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:07:38 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
19/07/31 17:07:38 INFO DAGScheduler: ResultStage 52 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:07:38 INFO DAGScheduler: Job 35 finished: collect at utils.scala:204, took 0.011661 s
19/07/31 17:07:38 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:38 INFO DAGScheduler: Registering RDD 168 (collect at utils.scala:204)
19/07/31 17:07:38 INFO DAGScheduler: Got job 36 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:38 INFO DAGScheduler: Final stage: ResultStage 54 (collect at utils.scala:204)
19/07/31 17:07:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 53)
19/07/31 17:07:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 53)
19/07/31 17:07:38 INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[168] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:38 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 74.5 KB, free 909.1 MB)
19/07/31 17:07:38 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.1 MB)
19/07/31 17:07:38 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.5 MB)
19/07/31 17:07:38 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[168] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:38 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
19/07/31 17:07:38 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 98, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:38 INFO Executor: Running task 0.0 in stage 53.0 (TID 98)
19/07/31 17:07:38 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:38 INFO Executor: Finished task 0.0 in stage 53.0 (TID 98). 1687 bytes result sent to driver
19/07/31 17:07:38 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 98) in 16 ms on localhost (executor driver) (1/1)
19/07/31 17:07:38 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
19/07/31 17:07:38 INFO DAGScheduler: ShuffleMapStage 53 (collect at utils.scala:204) finished in 0.016 s
19/07/31 17:07:38 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:38 INFO DAGScheduler: running: Set()
19/07/31 17:07:38 INFO DAGScheduler: waiting: Set(ResultStage 54)
19/07/31 17:07:38 INFO DAGScheduler: failed: Set()
19/07/31 17:07:38 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[171] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:38 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 16.8 KB, free 909.1 MB)
19/07/31 17:07:38 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.1 MB)
19/07/31 17:07:38 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.5 MB)
19/07/31 17:07:38 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:38 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 54 (MapPartitionsRDD[171] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:38 INFO TaskSchedulerImpl: Adding task set 54.0 with 4 tasks
19/07/31 17:07:38 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 99, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:38 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 100, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:38 INFO TaskSetManager: Starting task 2.0 in stage 54.0 (TID 101, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:38 INFO TaskSetManager: Starting task 3.0 in stage 54.0 (TID 102, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:38 INFO Executor: Running task 1.0 in stage 54.0 (TID 100)
19/07/31 17:07:38 INFO Executor: Running task 2.0 in stage 54.0 (TID 101)
19/07/31 17:07:38 INFO Executor: Running task 0.0 in stage 54.0 (TID 99)
19/07/31 17:07:38 INFO Executor: Running task 3.0 in stage 54.0 (TID 102)
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:38 INFO Executor: Finished task 0.0 in stage 54.0 (TID 99). 2382 bytes result sent to driver
19/07/31 17:07:38 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 99) in 6 ms on localhost (executor driver) (1/4)
19/07/31 17:07:38 INFO Executor: Finished task 3.0 in stage 54.0 (TID 102). 2362 bytes result sent to driver
19/07/31 17:07:38 INFO Executor: Finished task 1.0 in stage 54.0 (TID 100). 2403 bytes result sent to driver
19/07/31 17:07:38 INFO Executor: Finished task 2.0 in stage 54.0 (TID 101). 2390 bytes result sent to driver
19/07/31 17:07:38 INFO TaskSetManager: Finished task 3.0 in stage 54.0 (TID 102) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:07:38 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 100) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:07:38 INFO TaskSetManager: Finished task 2.0 in stage 54.0 (TID 101) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:07:38 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
19/07/31 17:07:38 INFO DAGScheduler: ResultStage 54 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:07:38 INFO DAGScheduler: Job 36 finished: collect at utils.scala:204, took 0.048444 s
19/07/31 17:07:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_129`) `dbplyr_130`
ORDER BY `date`) `dbplyr_131`) `dbplyr_132`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_133`) `dbplyr_134`
ORDER BY `date`) `dbplyr_135`) `dbplyr_136`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:38 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:38 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:38 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2010 - cust_prospect_ind.nullCount#2009) > 0)
19/07/31 17:07:38 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2015 - visit_device_type.nullCount#2014) > 0)
19/07/31 17:07:38 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#2008 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#2007))
19/07/31 17:07:38 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#2013 <= All Devices) && (All Devices <= visit_device_type.upperBound#2012))
19/07/31 17:07:38 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:38 INFO DAGScheduler: Got job 37 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:38 INFO DAGScheduler: Final stage: ResultStage 55 (collect at utils.scala:204)
19/07/31 17:07:38 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:38 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:38 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[176] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:38 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 72.1 KB, free 909.0 MB)
19/07/31 17:07:38 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 30.4 KB, free 909.0 MB)
19/07/31 17:07:38 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:53949 (size: 30.4 KB, free: 911.5 MB)
19/07/31 17:07:38 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[176] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:38 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
19/07/31 17:07:38 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 103, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:38 INFO Executor: Running task 0.0 in stage 55.0 (TID 103)
19/07/31 17:07:38 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:38 INFO Executor: Finished task 0.0 in stage 55.0 (TID 103). 7542 bytes result sent to driver
19/07/31 17:07:38 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 103) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:07:38 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
19/07/31 17:07:38 INFO DAGScheduler: ResultStage 55 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:07:38 INFO DAGScheduler: Job 37 finished: collect at utils.scala:204, took 0.019770 s
19/07/31 17:07:38 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:38 INFO DAGScheduler: Registering RDD 177 (collect at utils.scala:204)
19/07/31 17:07:38 INFO DAGScheduler: Got job 38 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:38 INFO DAGScheduler: Final stage: ResultStage 57 (collect at utils.scala:204)
19/07/31 17:07:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
19/07/31 17:07:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 56)
19/07/31 17:07:38 INFO DAGScheduler: Submitting ShuffleMapStage 56 (MapPartitionsRDD[177] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:38 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 74.5 KB, free 908.9 MB)
19/07/31 17:07:38 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 31.7 KB, free 908.9 MB)
19/07/31 17:07:38 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:53949 (size: 31.7 KB, free: 911.4 MB)
19/07/31 17:07:38 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[177] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:38 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
19/07/31 17:07:38 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 104, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:38 INFO Executor: Running task 0.0 in stage 56.0 (TID 104)
19/07/31 17:07:38 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:38 INFO Executor: Finished task 0.0 in stage 56.0 (TID 104). 1687 bytes result sent to driver
19/07/31 17:07:38 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 104) in 11 ms on localhost (executor driver) (1/1)
19/07/31 17:07:38 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
19/07/31 17:07:38 INFO DAGScheduler: ShuffleMapStage 56 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:07:38 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:38 INFO DAGScheduler: running: Set()
19/07/31 17:07:38 INFO DAGScheduler: waiting: Set(ResultStage 57)
19/07/31 17:07:38 INFO DAGScheduler: failed: Set()
19/07/31 17:07:38 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[180] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:38 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 16.8 KB, free 908.8 MB)
19/07/31 17:07:38 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 8.0 KB, free 908.8 MB)
19/07/31 17:07:38 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.4 MB)
19/07/31 17:07:38 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:38 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 57 (MapPartitionsRDD[180] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:38 INFO TaskSchedulerImpl: Adding task set 57.0 with 4 tasks
19/07/31 17:07:38 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 105, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:38 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 106, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:38 INFO TaskSetManager: Starting task 2.0 in stage 57.0 (TID 107, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:38 INFO TaskSetManager: Starting task 3.0 in stage 57.0 (TID 108, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:38 INFO Executor: Running task 0.0 in stage 57.0 (TID 105)
19/07/31 17:07:38 INFO Executor: Running task 1.0 in stage 57.0 (TID 106)
19/07/31 17:07:38 INFO Executor: Running task 2.0 in stage 57.0 (TID 107)
19/07/31 17:07:38 INFO Executor: Running task 3.0 in stage 57.0 (TID 108)
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:38 INFO Executor: Finished task 2.0 in stage 57.0 (TID 107). 2390 bytes result sent to driver
19/07/31 17:07:38 INFO Executor: Finished task 3.0 in stage 57.0 (TID 108). 2362 bytes result sent to driver
19/07/31 17:07:38 INFO Executor: Finished task 1.0 in stage 57.0 (TID 106). 2403 bytes result sent to driver
19/07/31 17:07:38 INFO TaskSetManager: Finished task 2.0 in stage 57.0 (TID 107) in 6 ms on localhost (executor driver) (1/4)
19/07/31 17:07:38 INFO TaskSetManager: Finished task 3.0 in stage 57.0 (TID 108) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:07:38 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 106) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:07:38 INFO Executor: Finished task 0.0 in stage 57.0 (TID 105). 2382 bytes result sent to driver
19/07/31 17:07:38 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 105) in 7 ms on localhost (executor driver) (4/4)
19/07/31 17:07:38 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
19/07/31 17:07:38 INFO DAGScheduler: ResultStage 57 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:07:38 INFO DAGScheduler: Job 38 finished: collect at utils.scala:204, took 0.039898 s
19/07/31 17:07:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_137`) `dbplyr_138`
ORDER BY `date`) `dbplyr_139`) `dbplyr_140`
WHERE ((`customer` = "PROSPECT") AND (`device` = "All Devices"))
19/07/31 17:07:39 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_141`) `dbplyr_142`
ORDER BY `date`) `dbplyr_143`) `dbplyr_144`
WHERE ((`customer` = "PROSPECT") AND (`device` = "All Devices"))
19/07/31 17:07:39 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:39 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2108 - cust_prospect_ind.nullCount#2107) > 0)
19/07/31 17:07:39 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2113 - visit_device_type.nullCount#2112) > 0)
19/07/31 17:07:39 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#2106 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#2105))
19/07/31 17:07:39 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#2111 <= All Devices) && (All Devices <= visit_device_type.upperBound#2110))
19/07/31 17:07:39 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:39 INFO DAGScheduler: Got job 39 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:39 INFO DAGScheduler: Final stage: ResultStage 58 (collect at utils.scala:204)
19/07/31 17:07:39 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:39 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:39 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[185] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:39 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 72.1 KB, free 908.8 MB)
19/07/31 17:07:39 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 30.5 KB, free 908.7 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.4 MB)
19/07/31 17:07:39 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[185] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:39 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
19/07/31 17:07:39 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 109, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:39 INFO Executor: Running task 0.0 in stage 58.0 (TID 109)
19/07/31 17:07:39 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:39 INFO Executor: Finished task 0.0 in stage 58.0 (TID 109). 7022 bytes result sent to driver
19/07/31 17:07:39 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 109) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:07:39 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
19/07/31 17:07:39 INFO DAGScheduler: ResultStage 58 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:07:39 INFO DAGScheduler: Job 39 finished: collect at utils.scala:204, took 0.011811 s
19/07/31 17:07:39 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:39 INFO DAGScheduler: Registering RDD 186 (collect at utils.scala:204)
19/07/31 17:07:39 INFO DAGScheduler: Got job 40 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:39 INFO DAGScheduler: Final stage: ResultStage 60 (collect at utils.scala:204)
19/07/31 17:07:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
19/07/31 17:07:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 59)
19/07/31 17:07:39 INFO DAGScheduler: Submitting ShuffleMapStage 59 (MapPartitionsRDD[186] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:39 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 74.5 KB, free 908.7 MB)
19/07/31 17:07:39 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 31.8 KB, free 908.6 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.4 MB)
19/07/31 17:07:39 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 59 (MapPartitionsRDD[186] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:39 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
19/07/31 17:07:39 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 110, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:39 INFO Executor: Running task 0.0 in stage 59.0 (TID 110)
19/07/31 17:07:39 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:39 INFO Executor: Finished task 0.0 in stage 59.0 (TID 110). 1687 bytes result sent to driver
19/07/31 17:07:39 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 110) in 10 ms on localhost (executor driver) (1/1)
19/07/31 17:07:39 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
19/07/31 17:07:39 INFO DAGScheduler: ShuffleMapStage 59 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:07:39 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:39 INFO DAGScheduler: running: Set()
19/07/31 17:07:39 INFO DAGScheduler: waiting: Set(ResultStage 60)
19/07/31 17:07:39 INFO DAGScheduler: failed: Set()
19/07/31 17:07:39 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[189] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:39 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 16.8 KB, free 908.6 MB)
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 810
19/07/31 17:07:39 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 8.0 KB, free 908.6 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.4 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 911.4 MB)
19/07/31 17:07:39 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:39 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 60 (MapPartitionsRDD[189] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:39 INFO ContextCleaner: Cleaned shuffle 17
19/07/31 17:07:39 INFO TaskSchedulerImpl: Adding task set 60.0 with 4 tasks
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 891
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1135
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 889
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1455
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1127
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1131
19/07/31 17:07:39 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 111, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:39 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 112, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:39 INFO TaskSetManager: Starting task 2.0 in stage 60.0 (TID 113, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:39 INFO TaskSetManager: Starting task 3.0 in stage 60.0 (TID 114, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.4 MB)
19/07/31 17:07:39 INFO Executor: Running task 0.0 in stage 60.0 (TID 111)
19/07/31 17:07:39 INFO Executor: Running task 2.0 in stage 60.0 (TID 113)
19/07/31 17:07:39 INFO Executor: Running task 3.0 in stage 60.0 (TID 114)
19/07/31 17:07:39 INFO Executor: Running task 1.0 in stage 60.0 (TID 112)
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:39 INFO Executor: Finished task 3.0 in stage 60.0 (TID 114). 2369 bytes result sent to driver
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:53949 in memory (size: 31.7 KB, free: 911.4 MB)
19/07/31 17:07:39 INFO Executor: Finished task 0.0 in stage 60.0 (TID 111). 2383 bytes result sent to driver
19/07/31 17:07:39 INFO TaskSetManager: Finished task 3.0 in stage 60.0 (TID 114) in 12 ms on localhost (executor driver) (1/4)
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1370
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1453
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1046
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 968
19/07/31 17:07:39 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 111) in 14 ms on localhost (executor driver) (2/4)
19/07/31 17:07:39 INFO Executor: Finished task 1.0 in stage 60.0 (TID 112). 2357 bytes result sent to driver
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.4 MB)
19/07/31 17:07:39 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 112) in 14 ms on localhost (executor driver) (3/4)
19/07/31 17:07:39 INFO Executor: Finished task 2.0 in stage 60.0 (TID 113). 2391 bytes result sent to driver
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1208
19/07/31 17:07:39 INFO TaskSetManager: Finished task 2.0 in stage 60.0 (TID 113) in 14 ms on localhost (executor driver) (4/4)
19/07/31 17:07:39 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
19/07/31 17:07:39 INFO ContextCleaner: Cleaned shuffle 8
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 806
19/07/31 17:07:39 INFO DAGScheduler: ResultStage 60 (collect at utils.scala:204) finished in 0.016 s
19/07/31 17:07:39 INFO DAGScheduler: Job 40 finished: collect at utils.scala:204, took 0.045563 s
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 911.5 MB)
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 892
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 887
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 911.5 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.5 MB)
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1132
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 886
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 969
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 972
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 911.5 MB)
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 811
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 888
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:53949 in memory (size: 31.7 KB, free: 911.6 MB)
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1133
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:53949 in memory (size: 30.4 KB, free: 911.6 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:53949 in memory (size: 8.1 KB, free: 911.6 MB)
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 809
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:53949 in memory (size: 30.4 KB, free: 911.6 MB)
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 966
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1451
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1129
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 911.7 MB)
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1130
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 973
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 911.7 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 127.0.0.1:53949 in memory (size: 31.7 KB, free: 911.7 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1457
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1452
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 804
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1532
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1458
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 971
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1289
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 967
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1613
19/07/31 17:07:39 INFO ContextCleaner: Cleaned shuffle 11
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:53949 in memory (size: 31.7 KB, free: 911.8 MB)
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1454
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 805
19/07/31 17:07:39 INFO ContextCleaner: Cleaned shuffle 9
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 808
19/07/31 17:07:39 INFO ContextCleaner: Cleaned shuffle 10
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1128
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 911.9 MB)
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 885
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1456
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:53949 in memory (size: 30.4 KB, free: 911.9 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 911.9 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:53949 in memory (size: 8.1 KB, free: 912.0 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 912.1 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 912.1 MB)
19/07/31 17:07:39 INFO ContextCleaner: Cleaned shuffle 13
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:53949 in memory (size: 30.4 KB, free: 912.1 MB)
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 890
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 807
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 965
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 884
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1459
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 803
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 970
19/07/31 17:07:39 INFO ContextCleaner: Cleaned accumulator 1134
19/07/31 17:07:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_145`) `dbplyr_146`
ORDER BY `date`) `dbplyr_147`) `dbplyr_148`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:39 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_149`) `dbplyr_150`
ORDER BY `date`) `dbplyr_151`) `dbplyr_152`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:39 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:39 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2206 - cust_prospect_ind.nullCount#2205) > 0)
19/07/31 17:07:39 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2211 - visit_device_type.nullCount#2210) > 0)
19/07/31 17:07:39 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#2204 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#2203))
19/07/31 17:07:39 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#2209 <= All Devices) && (All Devices <= visit_device_type.upperBound#2208))
19/07/31 17:07:39 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:39 INFO DAGScheduler: Got job 41 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:39 INFO DAGScheduler: Final stage: ResultStage 61 (collect at utils.scala:204)
19/07/31 17:07:39 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:39 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:39 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[194] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:39 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 72.1 KB, free 911.1 MB)
19/07/31 17:07:39 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.1 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:53949 (size: 30.4 KB, free: 912.1 MB)
19/07/31 17:07:39 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[194] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:39 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
19/07/31 17:07:39 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 115, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:39 INFO Executor: Running task 0.0 in stage 61.0 (TID 115)
19/07/31 17:07:39 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:39 INFO Executor: Finished task 0.0 in stage 61.0 (TID 115). 7542 bytes result sent to driver
19/07/31 17:07:39 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 115) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:07:39 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
19/07/31 17:07:39 INFO DAGScheduler: ResultStage 61 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:07:39 INFO DAGScheduler: Job 41 finished: collect at utils.scala:204, took 0.009807 s
19/07/31 17:07:39 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:39 INFO DAGScheduler: Registering RDD 195 (collect at utils.scala:204)
19/07/31 17:07:39 INFO DAGScheduler: Got job 42 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:39 INFO DAGScheduler: Final stage: ResultStage 63 (collect at utils.scala:204)
19/07/31 17:07:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
19/07/31 17:07:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 62)
19/07/31 17:07:39 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[195] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:39 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 74.5 KB, free 911.0 MB)
19/07/31 17:07:39 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.0 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 912.1 MB)
19/07/31 17:07:39 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[195] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:39 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
19/07/31 17:07:39 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 116, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:39 INFO Executor: Running task 0.0 in stage 62.0 (TID 116)
19/07/31 17:07:39 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:39 INFO Executor: Finished task 0.0 in stage 62.0 (TID 116). 1687 bytes result sent to driver
19/07/31 17:07:39 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 116) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:07:39 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
19/07/31 17:07:39 INFO DAGScheduler: ShuffleMapStage 62 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:07:39 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:39 INFO DAGScheduler: running: Set()
19/07/31 17:07:39 INFO DAGScheduler: waiting: Set(ResultStage 63)
19/07/31 17:07:39 INFO DAGScheduler: failed: Set()
19/07/31 17:07:39 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[198] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:39 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 16.8 KB, free 911.0 MB)
19/07/31 17:07:39 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.0 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:07:39 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:39 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 63 (MapPartitionsRDD[198] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:39 INFO TaskSchedulerImpl: Adding task set 63.0 with 4 tasks
19/07/31 17:07:39 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 117, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:39 INFO TaskSetManager: Starting task 1.0 in stage 63.0 (TID 118, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:39 INFO TaskSetManager: Starting task 2.0 in stage 63.0 (TID 119, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:39 INFO TaskSetManager: Starting task 3.0 in stage 63.0 (TID 120, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:39 INFO Executor: Running task 2.0 in stage 63.0 (TID 119)
19/07/31 17:07:39 INFO Executor: Running task 0.0 in stage 63.0 (TID 117)
19/07/31 17:07:39 INFO Executor: Running task 3.0 in stage 63.0 (TID 120)
19/07/31 17:07:39 INFO Executor: Running task 1.0 in stage 63.0 (TID 118)
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:39 INFO Executor: Finished task 2.0 in stage 63.0 (TID 119). 2390 bytes result sent to driver
19/07/31 17:07:39 INFO Executor: Finished task 3.0 in stage 63.0 (TID 120). 2362 bytes result sent to driver
19/07/31 17:07:39 INFO Executor: Finished task 0.0 in stage 63.0 (TID 117). 2382 bytes result sent to driver
19/07/31 17:07:39 INFO TaskSetManager: Finished task 2.0 in stage 63.0 (TID 119) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:07:39 INFO Executor: Finished task 1.0 in stage 63.0 (TID 118). 2403 bytes result sent to driver
19/07/31 17:07:39 INFO TaskSetManager: Finished task 3.0 in stage 63.0 (TID 120) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:07:39 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 117) in 7 ms on localhost (executor driver) (3/4)
19/07/31 17:07:39 INFO TaskSetManager: Finished task 1.0 in stage 63.0 (TID 118) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:07:39 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
19/07/31 17:07:39 INFO DAGScheduler: ResultStage 63 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:07:39 INFO DAGScheduler: Job 42 finished: collect at utils.scala:204, took 0.024851 s
19/07/31 17:07:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_153`) `dbplyr_154`
ORDER BY `date`) `dbplyr_155`) `dbplyr_156`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:39 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_157`) `dbplyr_158`
ORDER BY `date`) `dbplyr_159`) `dbplyr_160`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:39 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:39 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:39 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2304 - cust_prospect_ind.nullCount#2303) > 0)
19/07/31 17:07:39 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2309 - visit_device_type.nullCount#2308) > 0)
19/07/31 17:07:39 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#2302 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#2301))
19/07/31 17:07:39 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#2307 <= All Devices) && (All Devices <= visit_device_type.upperBound#2306))
19/07/31 17:07:39 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:39 INFO DAGScheduler: Got job 43 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:39 INFO DAGScheduler: Final stage: ResultStage 64 (collect at utils.scala:204)
19/07/31 17:07:39 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:39 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:39 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[203] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:39 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 72.1 KB, free 910.9 MB)
19/07/31 17:07:39 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.9 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:53949 (size: 30.4 KB, free: 912.0 MB)
19/07/31 17:07:39 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[203] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:39 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
19/07/31 17:07:39 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 121, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:39 INFO Executor: Running task 0.0 in stage 64.0 (TID 121)
19/07/31 17:07:39 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:39 INFO Executor: Finished task 0.0 in stage 64.0 (TID 121). 7542 bytes result sent to driver
19/07/31 17:07:39 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 121) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:07:39 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
19/07/31 17:07:39 INFO DAGScheduler: ResultStage 64 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:07:39 INFO DAGScheduler: Job 43 finished: collect at utils.scala:204, took 0.010409 s
19/07/31 17:07:39 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:39 INFO DAGScheduler: Registering RDD 204 (collect at utils.scala:204)
19/07/31 17:07:39 INFO DAGScheduler: Got job 44 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:39 INFO DAGScheduler: Final stage: ResultStage 66 (collect at utils.scala:204)
19/07/31 17:07:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)
19/07/31 17:07:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 65)
19/07/31 17:07:39 INFO DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[204] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:39 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 74.5 KB, free 910.8 MB)
19/07/31 17:07:39 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.8 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:53949 (size: 31.7 KB, free: 912.0 MB)
19/07/31 17:07:39 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[204] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:39 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
19/07/31 17:07:39 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 122, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:39 INFO Executor: Running task 0.0 in stage 65.0 (TID 122)
19/07/31 17:07:39 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:39 INFO Executor: Finished task 0.0 in stage 65.0 (TID 122). 1687 bytes result sent to driver
19/07/31 17:07:39 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 122) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:07:39 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
19/07/31 17:07:39 INFO DAGScheduler: ShuffleMapStage 65 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:07:39 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:39 INFO DAGScheduler: running: Set()
19/07/31 17:07:39 INFO DAGScheduler: waiting: Set(ResultStage 66)
19/07/31 17:07:39 INFO DAGScheduler: failed: Set()
19/07/31 17:07:39 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[207] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:39 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 16.8 KB, free 910.8 MB)
19/07/31 17:07:39 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.8 MB)
19/07/31 17:07:39 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:07:39 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:39 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 66 (MapPartitionsRDD[207] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:39 INFO TaskSchedulerImpl: Adding task set 66.0 with 4 tasks
19/07/31 17:07:39 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 123, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:39 INFO TaskSetManager: Starting task 1.0 in stage 66.0 (TID 124, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:39 INFO TaskSetManager: Starting task 2.0 in stage 66.0 (TID 125, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:39 INFO TaskSetManager: Starting task 3.0 in stage 66.0 (TID 126, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:39 INFO Executor: Running task 0.0 in stage 66.0 (TID 123)
19/07/31 17:07:39 INFO Executor: Running task 3.0 in stage 66.0 (TID 126)
19/07/31 17:07:39 INFO Executor: Running task 1.0 in stage 66.0 (TID 124)
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:39 INFO Executor: Running task 2.0 in stage 66.0 (TID 125)
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:39 INFO Executor: Finished task 0.0 in stage 66.0 (TID 123). 2382 bytes result sent to driver
19/07/31 17:07:39 INFO Executor: Finished task 1.0 in stage 66.0 (TID 124). 2403 bytes result sent to driver
19/07/31 17:07:39 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 123) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:07:39 INFO Executor: Finished task 3.0 in stage 66.0 (TID 126). 2362 bytes result sent to driver
19/07/31 17:07:39 INFO TaskSetManager: Finished task 1.0 in stage 66.0 (TID 124) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:07:39 INFO Executor: Finished task 2.0 in stage 66.0 (TID 125). 2390 bytes result sent to driver
19/07/31 17:07:39 INFO TaskSetManager: Finished task 3.0 in stage 66.0 (TID 126) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:07:39 INFO TaskSetManager: Finished task 2.0 in stage 66.0 (TID 125) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:07:39 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
19/07/31 17:07:39 INFO DAGScheduler: ResultStage 66 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:07:39 INFO DAGScheduler: Job 44 finished: collect at utils.scala:204, took 0.023523 s
19/07/31 17:07:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_161`) `dbplyr_162`
ORDER BY `date`) `dbplyr_163`) `dbplyr_164`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "All Devices"))
19/07/31 17:07:40 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:40 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_165`) `dbplyr_166`
ORDER BY `date`) `dbplyr_167`) `dbplyr_168`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "All Devices"))
19/07/31 17:07:40 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:40 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:40 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2402 - cust_prospect_ind.nullCount#2401) > 0)
19/07/31 17:07:40 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2407 - visit_device_type.nullCount#2406) > 0)
19/07/31 17:07:40 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#2400 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#2399))
19/07/31 17:07:40 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#2405 <= All Devices) && (All Devices <= visit_device_type.upperBound#2404))
19/07/31 17:07:40 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:40 INFO DAGScheduler: Got job 45 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:40 INFO DAGScheduler: Final stage: ResultStage 67 (collect at utils.scala:204)
19/07/31 17:07:40 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:40 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:40 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[212] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:40 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 72.1 KB, free 910.7 MB)
19/07/31 17:07:40 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.7 MB)
19/07/31 17:07:40 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:07:40 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[212] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:40 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks
19/07/31 17:07:40 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 127, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:40 INFO Executor: Running task 0.0 in stage 67.0 (TID 127)
19/07/31 17:07:40 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:40 INFO Executor: Finished task 0.0 in stage 67.0 (TID 127). 7542 bytes result sent to driver
19/07/31 17:07:40 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 127) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:07:40 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
19/07/31 17:07:40 INFO DAGScheduler: ResultStage 67 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:07:40 INFO DAGScheduler: Job 45 finished: collect at utils.scala:204, took 0.011234 s
19/07/31 17:07:40 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:40 INFO DAGScheduler: Registering RDD 213 (collect at utils.scala:204)
19/07/31 17:07:40 INFO DAGScheduler: Got job 46 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:40 INFO DAGScheduler: Final stage: ResultStage 69 (collect at utils.scala:204)
19/07/31 17:07:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)
19/07/31 17:07:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 68)
19/07/31 17:07:40 INFO DAGScheduler: Submitting ShuffleMapStage 68 (MapPartitionsRDD[213] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:40 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 74.5 KB, free 910.6 MB)
19/07/31 17:07:40 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.6 MB)
19/07/31 17:07:40 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.9 MB)
19/07/31 17:07:40 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 68 (MapPartitionsRDD[213] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:40 INFO TaskSchedulerImpl: Adding task set 68.0 with 1 tasks
19/07/31 17:07:40 INFO TaskSetManager: Starting task 0.0 in stage 68.0 (TID 128, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:40 INFO Executor: Running task 0.0 in stage 68.0 (TID 128)
19/07/31 17:07:40 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:40 INFO Executor: Finished task 0.0 in stage 68.0 (TID 128). 1687 bytes result sent to driver
19/07/31 17:07:40 INFO TaskSetManager: Finished task 0.0 in stage 68.0 (TID 128) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:07:40 INFO TaskSchedulerImpl: Removed TaskSet 68.0, whose tasks have all completed, from pool 
19/07/31 17:07:40 INFO DAGScheduler: ShuffleMapStage 68 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:07:40 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:40 INFO DAGScheduler: running: Set()
19/07/31 17:07:40 INFO DAGScheduler: waiting: Set(ResultStage 69)
19/07/31 17:07:40 INFO DAGScheduler: failed: Set()
19/07/31 17:07:40 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[216] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:40 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 16.8 KB, free 910.5 MB)
19/07/31 17:07:40 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.5 MB)
19/07/31 17:07:40 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:07:40 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:40 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 69 (MapPartitionsRDD[216] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:40 INFO TaskSchedulerImpl: Adding task set 69.0 with 4 tasks
19/07/31 17:07:40 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 129, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:40 INFO TaskSetManager: Starting task 1.0 in stage 69.0 (TID 130, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:40 INFO TaskSetManager: Starting task 2.0 in stage 69.0 (TID 131, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:40 INFO TaskSetManager: Starting task 3.0 in stage 69.0 (TID 132, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:40 INFO Executor: Running task 0.0 in stage 69.0 (TID 129)
19/07/31 17:07:40 INFO Executor: Running task 2.0 in stage 69.0 (TID 131)
19/07/31 17:07:40 INFO Executor: Running task 1.0 in stage 69.0 (TID 130)
19/07/31 17:07:40 INFO Executor: Running task 3.0 in stage 69.0 (TID 132)
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:40 INFO Executor: Finished task 0.0 in stage 69.0 (TID 129). 2386 bytes result sent to driver
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:40 INFO Executor: Finished task 2.0 in stage 69.0 (TID 131). 2386 bytes result sent to driver
19/07/31 17:07:40 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 129) in 6 ms on localhost (executor driver) (1/4)
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:40 INFO TaskSetManager: Finished task 2.0 in stage 69.0 (TID 131) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:07:40 INFO Executor: Finished task 3.0 in stage 69.0 (TID 132). 2374 bytes result sent to driver
19/07/31 17:07:40 INFO TaskSetManager: Finished task 3.0 in stage 69.0 (TID 132) in 7 ms on localhost (executor driver) (3/4)
19/07/31 17:07:40 INFO Executor: Finished task 1.0 in stage 69.0 (TID 130). 2392 bytes result sent to driver
19/07/31 17:07:40 INFO TaskSetManager: Finished task 1.0 in stage 69.0 (TID 130) in 8 ms on localhost (executor driver) (4/4)
19/07/31 17:07:40 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
19/07/31 17:07:40 INFO DAGScheduler: ResultStage 69 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:07:40 INFO DAGScheduler: Job 46 finished: collect at utils.scala:204, took 0.026383 s
19/07/31 17:07:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_169`) `dbplyr_170`
ORDER BY `date`) `dbplyr_171`) `dbplyr_172`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:40 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:40 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_173`) `dbplyr_174`
ORDER BY `date`) `dbplyr_175`) `dbplyr_176`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:40 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:40 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:40 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2500 - cust_prospect_ind.nullCount#2499) > 0)
19/07/31 17:07:40 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2505 - visit_device_type.nullCount#2504) > 0)
19/07/31 17:07:40 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#2498 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#2497))
19/07/31 17:07:40 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#2503 <= All Devices) && (All Devices <= visit_device_type.upperBound#2502))
19/07/31 17:07:40 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:40 INFO DAGScheduler: Got job 47 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:40 INFO DAGScheduler: Final stage: ResultStage 70 (collect at utils.scala:204)
19/07/31 17:07:40 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:40 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:40 INFO DAGScheduler: Submitting ResultStage 70 (MapPartitionsRDD[221] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:40 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 72.1 KB, free 910.5 MB)
19/07/31 17:07:40 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.4 MB)
19/07/31 17:07:40 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:53949 (size: 30.4 KB, free: 911.9 MB)
19/07/31 17:07:40 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 70 (MapPartitionsRDD[221] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:40 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks
19/07/31 17:07:40 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 133, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:40 INFO Executor: Running task 0.0 in stage 70.0 (TID 133)
19/07/31 17:07:40 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:40 INFO Executor: Finished task 0.0 in stage 70.0 (TID 133). 7542 bytes result sent to driver
19/07/31 17:07:40 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 133) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:07:40 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool 
19/07/31 17:07:40 INFO DAGScheduler: ResultStage 70 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:07:40 INFO DAGScheduler: Job 47 finished: collect at utils.scala:204, took 0.011956 s
19/07/31 17:07:40 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:40 INFO DAGScheduler: Registering RDD 222 (collect at utils.scala:204)
19/07/31 17:07:40 INFO DAGScheduler: Got job 48 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:40 INFO DAGScheduler: Final stage: ResultStage 72 (collect at utils.scala:204)
19/07/31 17:07:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 71)
19/07/31 17:07:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 71)
19/07/31 17:07:40 INFO DAGScheduler: Submitting ShuffleMapStage 71 (MapPartitionsRDD[222] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:40 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 74.5 KB, free 910.4 MB)
19/07/31 17:07:40 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.3 MB)
19/07/31 17:07:40 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 127.0.0.1:53949 (size: 31.7 KB, free: 911.9 MB)
19/07/31 17:07:40 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 71 (MapPartitionsRDD[222] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:40 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks
19/07/31 17:07:40 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 134, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:40 INFO Executor: Running task 0.0 in stage 71.0 (TID 134)
19/07/31 17:07:40 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:40 INFO Executor: Finished task 0.0 in stage 71.0 (TID 134). 1687 bytes result sent to driver
19/07/31 17:07:40 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 134) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:07:40 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
19/07/31 17:07:40 INFO DAGScheduler: ShuffleMapStage 71 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:07:40 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:40 INFO DAGScheduler: running: Set()
19/07/31 17:07:40 INFO DAGScheduler: waiting: Set(ResultStage 72)
19/07/31 17:07:40 INFO DAGScheduler: failed: Set()
19/07/31 17:07:40 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[225] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:40 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 16.8 KB, free 910.3 MB)
19/07/31 17:07:40 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.3 MB)
19/07/31 17:07:40 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:07:40 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:40 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 72 (MapPartitionsRDD[225] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:40 INFO TaskSchedulerImpl: Adding task set 72.0 with 4 tasks
19/07/31 17:07:40 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 135, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:40 INFO TaskSetManager: Starting task 1.0 in stage 72.0 (TID 136, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:40 INFO TaskSetManager: Starting task 2.0 in stage 72.0 (TID 137, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:40 INFO TaskSetManager: Starting task 3.0 in stage 72.0 (TID 138, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:40 INFO Executor: Running task 0.0 in stage 72.0 (TID 135)
19/07/31 17:07:40 INFO Executor: Running task 2.0 in stage 72.0 (TID 137)
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:40 INFO Executor: Running task 3.0 in stage 72.0 (TID 138)
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:40 INFO Executor: Running task 1.0 in stage 72.0 (TID 136)
19/07/31 17:07:40 INFO Executor: Finished task 3.0 in stage 72.0 (TID 138). 2362 bytes result sent to driver
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:40 INFO Executor: Finished task 0.0 in stage 72.0 (TID 135). 2382 bytes result sent to driver
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
19/07/31 17:07:40 INFO Executor: Finished task 1.0 in stage 72.0 (TID 136). 2403 bytes result sent to driver
19/07/31 17:07:40 INFO TaskSetManager: Finished task 3.0 in stage 72.0 (TID 138) in 8 ms on localhost (executor driver) (1/4)
19/07/31 17:07:40 INFO Executor: Finished task 2.0 in stage 72.0 (TID 137). 2390 bytes result sent to driver
19/07/31 17:07:40 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 135) in 11 ms on localhost (executor driver) (2/4)
19/07/31 17:07:40 INFO TaskSetManager: Finished task 1.0 in stage 72.0 (TID 136) in 11 ms on localhost (executor driver) (3/4)
19/07/31 17:07:40 INFO TaskSetManager: Finished task 2.0 in stage 72.0 (TID 137) in 11 ms on localhost (executor driver) (4/4)
19/07/31 17:07:40 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
19/07/31 17:07:40 INFO DAGScheduler: ResultStage 72 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:07:40 INFO DAGScheduler: Job 48 finished: collect at utils.scala:204, took 0.031180 s
19/07/31 17:07:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_177`) `dbplyr_178`
ORDER BY `date`) `dbplyr_179`) `dbplyr_180`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:40 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:40 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:40 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_181`) `dbplyr_182`
ORDER BY `date`) `dbplyr_183`) `dbplyr_184`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:40 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:40 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:40 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2598 - cust_prospect_ind.nullCount#2597) > 0)
19/07/31 17:07:40 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2603 - visit_device_type.nullCount#2602) > 0)
19/07/31 17:07:40 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#2596 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#2595))
19/07/31 17:07:40 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#2601 <= All Devices) && (All Devices <= visit_device_type.upperBound#2600))
19/07/31 17:07:40 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:40 INFO DAGScheduler: Got job 49 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:40 INFO DAGScheduler: Final stage: ResultStage 73 (collect at utils.scala:204)
19/07/31 17:07:40 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:40 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:40 INFO DAGScheduler: Submitting ResultStage 73 (MapPartitionsRDD[230] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:40 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 72.1 KB, free 910.2 MB)
19/07/31 17:07:40 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.2 MB)
19/07/31 17:07:40 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:07:40 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 73 (MapPartitionsRDD[230] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:40 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks
19/07/31 17:07:40 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 139, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:40 INFO Executor: Running task 0.0 in stage 73.0 (TID 139)
19/07/31 17:07:40 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:40 INFO Executor: Finished task 0.0 in stage 73.0 (TID 139). 7542 bytes result sent to driver
19/07/31 17:07:40 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 139) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:07:40 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool 
19/07/31 17:07:40 INFO DAGScheduler: ResultStage 73 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:07:40 INFO DAGScheduler: Job 49 finished: collect at utils.scala:204, took 0.014069 s
19/07/31 17:07:40 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:40 INFO DAGScheduler: Registering RDD 231 (collect at utils.scala:204)
19/07/31 17:07:40 INFO DAGScheduler: Got job 50 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:40 INFO DAGScheduler: Final stage: ResultStage 75 (collect at utils.scala:204)
19/07/31 17:07:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 74)
19/07/31 17:07:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 74)
19/07/31 17:07:40 INFO DAGScheduler: Submitting ShuffleMapStage 74 (MapPartitionsRDD[231] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:40 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 74.5 KB, free 910.1 MB)
19/07/31 17:07:40 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.1 MB)
19/07/31 17:07:40 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:07:40 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 74 (MapPartitionsRDD[231] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:40 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks
19/07/31 17:07:40 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 140, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:40 INFO Executor: Running task 0.0 in stage 74.0 (TID 140)
19/07/31 17:07:40 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:40 INFO Executor: Finished task 0.0 in stage 74.0 (TID 140). 1687 bytes result sent to driver
19/07/31 17:07:40 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 140) in 14 ms on localhost (executor driver) (1/1)
19/07/31 17:07:40 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
19/07/31 17:07:40 INFO DAGScheduler: ShuffleMapStage 74 (collect at utils.scala:204) finished in 0.015 s
19/07/31 17:07:40 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:40 INFO DAGScheduler: running: Set()
19/07/31 17:07:40 INFO DAGScheduler: waiting: Set(ResultStage 75)
19/07/31 17:07:40 INFO DAGScheduler: failed: Set()
19/07/31 17:07:40 INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[234] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:40 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 16.8 KB, free 910.1 MB)
19/07/31 17:07:40 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.1 MB)
19/07/31 17:07:40 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:07:40 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:40 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 75 (MapPartitionsRDD[234] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:40 INFO TaskSchedulerImpl: Adding task set 75.0 with 4 tasks
19/07/31 17:07:40 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 141, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:40 INFO TaskSetManager: Starting task 1.0 in stage 75.0 (TID 142, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:40 INFO TaskSetManager: Starting task 2.0 in stage 75.0 (TID 143, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:40 INFO TaskSetManager: Starting task 3.0 in stage 75.0 (TID 144, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:40 INFO Executor: Running task 1.0 in stage 75.0 (TID 142)
19/07/31 17:07:40 INFO Executor: Running task 2.0 in stage 75.0 (TID 143)
19/07/31 17:07:40 INFO Executor: Running task 3.0 in stage 75.0 (TID 144)
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:40 INFO Executor: Finished task 2.0 in stage 75.0 (TID 143). 2390 bytes result sent to driver
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:40 INFO TaskSetManager: Finished task 2.0 in stage 75.0 (TID 143) in 9 ms on localhost (executor driver) (1/4)
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:40 INFO Executor: Running task 0.0 in stage 75.0 (TID 141)
19/07/31 17:07:40 INFO Executor: Finished task 3.0 in stage 75.0 (TID 144). 2362 bytes result sent to driver
19/07/31 17:07:40 INFO Executor: Finished task 1.0 in stage 75.0 (TID 142). 2403 bytes result sent to driver
19/07/31 17:07:40 INFO TaskSetManager: Finished task 3.0 in stage 75.0 (TID 144) in 11 ms on localhost (executor driver) (2/4)
19/07/31 17:07:40 INFO TaskSetManager: Finished task 1.0 in stage 75.0 (TID 142) in 11 ms on localhost (executor driver) (3/4)
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:40 INFO Executor: Finished task 0.0 in stage 75.0 (TID 141). 2382 bytes result sent to driver
19/07/31 17:07:40 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 141) in 15 ms on localhost (executor driver) (4/4)
19/07/31 17:07:40 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool 
19/07/31 17:07:40 INFO DAGScheduler: ResultStage 75 (collect at utils.scala:204) finished in 0.015 s
19/07/31 17:07:40 INFO DAGScheduler: Job 50 finished: collect at utils.scala:204, took 0.047917 s
19/07/31 17:07:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_185`) `dbplyr_186`
ORDER BY `date`) `dbplyr_187`) `dbplyr_188`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Mobile Phone"))
19/07/31 17:07:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_189`) `dbplyr_190`
ORDER BY `date`) `dbplyr_191`) `dbplyr_192`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Mobile Phone"))
19/07/31 17:07:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:41 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2696 - cust_prospect_ind.nullCount#2695) > 0)
19/07/31 17:07:41 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2701 - visit_device_type.nullCount#2700) > 0)
19/07/31 17:07:41 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#2694 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#2693))
19/07/31 17:07:41 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#2699 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#2698))
19/07/31 17:07:41 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:41 INFO DAGScheduler: Got job 51 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:41 INFO DAGScheduler: Final stage: ResultStage 76 (collect at utils.scala:204)
19/07/31 17:07:41 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:41 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:41 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[239] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:41 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 72.1 KB, free 910.0 MB)
19/07/31 17:07:41 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.0 MB)
19/07/31 17:07:41 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:07:41 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[239] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:41 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks
19/07/31 17:07:41 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 145, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:41 INFO Executor: Running task 0.0 in stage 76.0 (TID 145)
19/07/31 17:07:41 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:41 INFO Executor: Finished task 0.0 in stage 76.0 (TID 145). 6979 bytes result sent to driver
19/07/31 17:07:41 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 145) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:07:41 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
19/07/31 17:07:41 INFO DAGScheduler: ResultStage 76 (collect at utils.scala:204) finished in 0.004 s
19/07/31 17:07:41 INFO DAGScheduler: Job 51 finished: collect at utils.scala:204, took 0.007939 s
19/07/31 17:07:41 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:41 INFO DAGScheduler: Registering RDD 240 (collect at utils.scala:204)
19/07/31 17:07:41 INFO DAGScheduler: Got job 52 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:41 INFO DAGScheduler: Final stage: ResultStage 78 (collect at utils.scala:204)
19/07/31 17:07:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 77)
19/07/31 17:07:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 77)
19/07/31 17:07:41 INFO DAGScheduler: Submitting ShuffleMapStage 77 (MapPartitionsRDD[240] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:41 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 74.5 KB, free 909.9 MB)
19/07/31 17:07:41 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.9 MB)
19/07/31 17:07:41 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.7 MB)
19/07/31 17:07:41 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 77 (MapPartitionsRDD[240] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:41 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks
19/07/31 17:07:41 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 146, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:41 INFO Executor: Running task 0.0 in stage 77.0 (TID 146)
19/07/31 17:07:41 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:41 INFO Executor: Finished task 0.0 in stage 77.0 (TID 146). 1687 bytes result sent to driver
19/07/31 17:07:41 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 146) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:07:41 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
19/07/31 17:07:41 INFO DAGScheduler: ShuffleMapStage 77 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:07:41 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:41 INFO DAGScheduler: running: Set()
19/07/31 17:07:41 INFO DAGScheduler: waiting: Set(ResultStage 78)
19/07/31 17:07:41 INFO DAGScheduler: failed: Set()
19/07/31 17:07:41 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[243] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:41 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 16.8 KB, free 909.9 MB)
19/07/31 17:07:41 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.8 MB)
19/07/31 17:07:41 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:07:41 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:41 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 78 (MapPartitionsRDD[243] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:41 INFO TaskSchedulerImpl: Adding task set 78.0 with 4 tasks
19/07/31 17:07:41 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 147, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:41 INFO TaskSetManager: Starting task 1.0 in stage 78.0 (TID 148, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:41 INFO TaskSetManager: Starting task 2.0 in stage 78.0 (TID 149, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:41 INFO TaskSetManager: Starting task 3.0 in stage 78.0 (TID 150, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:41 INFO Executor: Running task 2.0 in stage 78.0 (TID 149)
19/07/31 17:07:41 INFO Executor: Running task 3.0 in stage 78.0 (TID 150)
19/07/31 17:07:41 INFO Executor: Running task 0.0 in stage 78.0 (TID 147)
19/07/31 17:07:41 INFO Executor: Running task 1.0 in stage 78.0 (TID 148)
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:41 INFO Executor: Finished task 0.0 in stage 78.0 (TID 147). 2366 bytes result sent to driver
19/07/31 17:07:41 INFO Executor: Finished task 2.0 in stage 78.0 (TID 149). 2371 bytes result sent to driver
19/07/31 17:07:41 INFO Executor: Finished task 3.0 in stage 78.0 (TID 150). 2353 bytes result sent to driver
19/07/31 17:07:41 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 147) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:07:41 INFO Executor: Finished task 1.0 in stage 78.0 (TID 148). 2304 bytes result sent to driver
19/07/31 17:07:41 INFO TaskSetManager: Finished task 2.0 in stage 78.0 (TID 149) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:07:41 INFO TaskSetManager: Finished task 3.0 in stage 78.0 (TID 150) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:07:41 INFO TaskSetManager: Finished task 1.0 in stage 78.0 (TID 148) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:07:41 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
19/07/31 17:07:41 INFO DAGScheduler: ResultStage 78 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:07:41 INFO DAGScheduler: Job 52 finished: collect at utils.scala:204, took 0.023861 s
19/07/31 17:07:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_193`) `dbplyr_194`
ORDER BY `date`) `dbplyr_195`) `dbplyr_196`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_197`) `dbplyr_198`
ORDER BY `date`) `dbplyr_199`) `dbplyr_200`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:41 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2794 - cust_prospect_ind.nullCount#2793) > 0)
19/07/31 17:07:41 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2799 - visit_device_type.nullCount#2798) > 0)
19/07/31 17:07:41 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#2792 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#2791))
19/07/31 17:07:41 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#2797 <= All Devices) && (All Devices <= visit_device_type.upperBound#2796))
19/07/31 17:07:41 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:41 INFO DAGScheduler: Got job 53 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:41 INFO DAGScheduler: Final stage: ResultStage 79 (collect at utils.scala:204)
19/07/31 17:07:41 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:41 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:41 INFO DAGScheduler: Submitting ResultStage 79 (MapPartitionsRDD[248] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:41 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 72.1 KB, free 909.8 MB)
19/07/31 17:07:41 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 30.4 KB, free 909.7 MB)
19/07/31 17:07:41 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 127.0.0.1:53949 (size: 30.4 KB, free: 911.7 MB)
19/07/31 17:07:41 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 79 (MapPartitionsRDD[248] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:41 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks
19/07/31 17:07:41 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 151, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:41 INFO Executor: Running task 0.0 in stage 79.0 (TID 151)
19/07/31 17:07:41 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:41 INFO Executor: Finished task 0.0 in stage 79.0 (TID 151). 7542 bytes result sent to driver
19/07/31 17:07:41 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 151) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:07:41 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool 
19/07/31 17:07:41 INFO DAGScheduler: ResultStage 79 (collect at utils.scala:204) finished in 0.004 s
19/07/31 17:07:41 INFO DAGScheduler: Job 53 finished: collect at utils.scala:204, took 0.008476 s
19/07/31 17:07:41 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:41 INFO DAGScheduler: Registering RDD 249 (collect at utils.scala:204)
19/07/31 17:07:41 INFO DAGScheduler: Got job 54 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:41 INFO DAGScheduler: Final stage: ResultStage 81 (collect at utils.scala:204)
19/07/31 17:07:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 80)
19/07/31 17:07:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 80)
19/07/31 17:07:41 INFO DAGScheduler: Submitting ShuffleMapStage 80 (MapPartitionsRDD[249] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:41 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 74.5 KB, free 909.7 MB)
19/07/31 17:07:41 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 31.7 KB, free 909.6 MB)
19/07/31 17:07:41 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 127.0.0.1:53949 (size: 31.7 KB, free: 911.7 MB)
19/07/31 17:07:41 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 80 (MapPartitionsRDD[249] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:41 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks
19/07/31 17:07:41 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 152, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:41 INFO Executor: Running task 0.0 in stage 80.0 (TID 152)
19/07/31 17:07:41 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:41 INFO Executor: Finished task 0.0 in stage 80.0 (TID 152). 1687 bytes result sent to driver
19/07/31 17:07:41 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 152) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:07:41 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
19/07/31 17:07:41 INFO DAGScheduler: ShuffleMapStage 80 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:07:41 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:41 INFO DAGScheduler: running: Set()
19/07/31 17:07:41 INFO DAGScheduler: waiting: Set(ResultStage 81)
19/07/31 17:07:41 INFO DAGScheduler: failed: Set()
19/07/31 17:07:41 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[252] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:41 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 16.8 KB, free 909.6 MB)
19/07/31 17:07:41 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.6 MB)
19/07/31 17:07:41 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:07:41 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:41 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 81 (MapPartitionsRDD[252] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:41 INFO TaskSchedulerImpl: Adding task set 81.0 with 4 tasks
19/07/31 17:07:41 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 153, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:41 INFO TaskSetManager: Starting task 1.0 in stage 81.0 (TID 154, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:41 INFO TaskSetManager: Starting task 2.0 in stage 81.0 (TID 155, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:41 INFO TaskSetManager: Starting task 3.0 in stage 81.0 (TID 156, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:41 INFO Executor: Running task 1.0 in stage 81.0 (TID 154)
19/07/31 17:07:41 INFO Executor: Running task 2.0 in stage 81.0 (TID 155)
19/07/31 17:07:41 INFO Executor: Running task 0.0 in stage 81.0 (TID 153)
19/07/31 17:07:41 INFO Executor: Running task 3.0 in stage 81.0 (TID 156)
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:41 INFO Executor: Finished task 0.0 in stage 81.0 (TID 153). 2382 bytes result sent to driver
19/07/31 17:07:41 INFO Executor: Finished task 2.0 in stage 81.0 (TID 155). 2390 bytes result sent to driver
19/07/31 17:07:41 INFO Executor: Finished task 3.0 in stage 81.0 (TID 156). 2319 bytes result sent to driver
19/07/31 17:07:41 INFO Executor: Finished task 1.0 in stage 81.0 (TID 154). 2403 bytes result sent to driver
19/07/31 17:07:41 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 153) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:07:41 INFO TaskSetManager: Finished task 2.0 in stage 81.0 (TID 155) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:07:41 INFO TaskSetManager: Finished task 3.0 in stage 81.0 (TID 156) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:07:41 INFO TaskSetManager: Finished task 1.0 in stage 81.0 (TID 154) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:07:41 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
19/07/31 17:07:41 INFO DAGScheduler: ResultStage 81 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:07:41 INFO DAGScheduler: Job 54 finished: collect at utils.scala:204, took 0.020206 s
19/07/31 17:07:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_201`) `dbplyr_202`
ORDER BY `date`) `dbplyr_203`) `dbplyr_204`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_205`) `dbplyr_206`
ORDER BY `date`) `dbplyr_207`) `dbplyr_208`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:41 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:41 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:41 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2892 - cust_prospect_ind.nullCount#2891) > 0)
19/07/31 17:07:41 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2897 - visit_device_type.nullCount#2896) > 0)
19/07/31 17:07:41 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#2890 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#2889))
19/07/31 17:07:41 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#2895 <= All Devices) && (All Devices <= visit_device_type.upperBound#2894))
19/07/31 17:07:41 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:41 INFO DAGScheduler: Got job 55 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:41 INFO DAGScheduler: Final stage: ResultStage 82 (collect at utils.scala:204)
19/07/31 17:07:41 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:41 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:41 INFO DAGScheduler: Submitting ResultStage 82 (MapPartitionsRDD[257] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:41 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 72.1 KB, free 909.5 MB)
19/07/31 17:07:41 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.5 MB)
19/07/31 17:07:41 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.6 MB)
19/07/31 17:07:41 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 82 (MapPartitionsRDD[257] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:41 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks
19/07/31 17:07:41 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 157, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:41 INFO Executor: Running task 0.0 in stage 82.0 (TID 157)
19/07/31 17:07:41 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:41 INFO Executor: Finished task 0.0 in stage 82.0 (TID 157). 7542 bytes result sent to driver
19/07/31 17:07:41 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 157) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:07:41 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
19/07/31 17:07:41 INFO DAGScheduler: ResultStage 82 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:07:41 INFO DAGScheduler: Job 55 finished: collect at utils.scala:204, took 0.017053 s
19/07/31 17:07:41 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:41 INFO DAGScheduler: Registering RDD 258 (collect at utils.scala:204)
19/07/31 17:07:41 INFO DAGScheduler: Got job 56 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:41 INFO DAGScheduler: Final stage: ResultStage 84 (collect at utils.scala:204)
19/07/31 17:07:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 83)
19/07/31 17:07:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 83)
19/07/31 17:07:41 INFO DAGScheduler: Submitting ShuffleMapStage 83 (MapPartitionsRDD[258] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:41 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 74.5 KB, free 909.4 MB)
19/07/31 17:07:41 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.4 MB)
19/07/31 17:07:41 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.6 MB)
19/07/31 17:07:41 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 83 (MapPartitionsRDD[258] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:41 INFO TaskSchedulerImpl: Adding task set 83.0 with 1 tasks
19/07/31 17:07:41 INFO TaskSetManager: Starting task 0.0 in stage 83.0 (TID 158, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:41 INFO Executor: Running task 0.0 in stage 83.0 (TID 158)
19/07/31 17:07:41 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:41 INFO Executor: Finished task 0.0 in stage 83.0 (TID 158). 1687 bytes result sent to driver
19/07/31 17:07:41 INFO TaskSetManager: Finished task 0.0 in stage 83.0 (TID 158) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:07:41 INFO TaskSchedulerImpl: Removed TaskSet 83.0, whose tasks have all completed, from pool 
19/07/31 17:07:41 INFO DAGScheduler: ShuffleMapStage 83 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:07:41 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:41 INFO DAGScheduler: running: Set()
19/07/31 17:07:41 INFO DAGScheduler: waiting: Set(ResultStage 84)
19/07/31 17:07:41 INFO DAGScheduler: failed: Set()
19/07/31 17:07:41 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[261] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:41 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 16.8 KB, free 909.4 MB)
19/07/31 17:07:41 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.4 MB)
19/07/31 17:07:41 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.6 MB)
19/07/31 17:07:41 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:41 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 84 (MapPartitionsRDD[261] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:41 INFO TaskSchedulerImpl: Adding task set 84.0 with 4 tasks
19/07/31 17:07:41 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 159, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:41 INFO TaskSetManager: Starting task 1.0 in stage 84.0 (TID 160, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:41 INFO TaskSetManager: Starting task 2.0 in stage 84.0 (TID 161, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:41 INFO TaskSetManager: Starting task 3.0 in stage 84.0 (TID 162, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:41 INFO Executor: Running task 0.0 in stage 84.0 (TID 159)
19/07/31 17:07:41 INFO Executor: Running task 3.0 in stage 84.0 (TID 162)
19/07/31 17:07:41 INFO Executor: Running task 1.0 in stage 84.0 (TID 160)
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:41 INFO Executor: Running task 2.0 in stage 84.0 (TID 161)
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:41 INFO Executor: Finished task 0.0 in stage 84.0 (TID 159). 2382 bytes result sent to driver
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/07/31 17:07:41 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 159) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:41 INFO Executor: Finished task 1.0 in stage 84.0 (TID 160). 2403 bytes result sent to driver
19/07/31 17:07:41 INFO Executor: Finished task 3.0 in stage 84.0 (TID 162). 2362 bytes result sent to driver
19/07/31 17:07:41 INFO Executor: Finished task 2.0 in stage 84.0 (TID 161). 2390 bytes result sent to driver
19/07/31 17:07:41 INFO TaskSetManager: Finished task 1.0 in stage 84.0 (TID 160) in 7 ms on localhost (executor driver) (2/4)
19/07/31 17:07:41 INFO TaskSetManager: Finished task 3.0 in stage 84.0 (TID 162) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:07:41 INFO TaskSetManager: Finished task 2.0 in stage 84.0 (TID 161) in 7 ms on localhost (executor driver) (4/4)
19/07/31 17:07:41 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
19/07/31 17:07:41 INFO DAGScheduler: ResultStage 84 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:07:41 INFO DAGScheduler: Job 56 finished: collect at utils.scala:204, took 0.028261 s
19/07/31 17:07:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_209`) `dbplyr_210`
ORDER BY `date`) `dbplyr_211`) `dbplyr_212`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Mobile Phone"))
19/07/31 17:07:42 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:42 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_213`) `dbplyr_214`
ORDER BY `date`) `dbplyr_215`) `dbplyr_216`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Mobile Phone"))
19/07/31 17:07:42 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:42 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:42 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2990 - cust_prospect_ind.nullCount#2989) > 0)
19/07/31 17:07:42 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2995 - visit_device_type.nullCount#2994) > 0)
19/07/31 17:07:42 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#2988 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#2987))
19/07/31 17:07:42 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#2993 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#2992))
19/07/31 17:07:42 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:42 INFO DAGScheduler: Got job 57 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:42 INFO DAGScheduler: Final stage: ResultStage 85 (collect at utils.scala:204)
19/07/31 17:07:42 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:42 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:42 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[266] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:42 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 72.1 KB, free 909.3 MB)
19/07/31 17:07:42 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 30.4 KB, free 909.3 MB)
19/07/31 17:07:42 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 127.0.0.1:53949 (size: 30.4 KB, free: 911.6 MB)
19/07/31 17:07:42 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[266] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:42 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks
19/07/31 17:07:42 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 163, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:42 INFO Executor: Running task 0.0 in stage 85.0 (TID 163)
19/07/31 17:07:42 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:42 INFO Executor: Finished task 0.0 in stage 85.0 (TID 163). 6979 bytes result sent to driver
19/07/31 17:07:42 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 163) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:07:42 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
19/07/31 17:07:42 INFO DAGScheduler: ResultStage 85 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:07:42 INFO DAGScheduler: Job 57 finished: collect at utils.scala:204, took 0.012809 s
19/07/31 17:07:42 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:42 INFO DAGScheduler: Registering RDD 267 (collect at utils.scala:204)
19/07/31 17:07:42 INFO DAGScheduler: Got job 58 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:42 INFO DAGScheduler: Final stage: ResultStage 87 (collect at utils.scala:204)
19/07/31 17:07:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 86)
19/07/31 17:07:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 86)
19/07/31 17:07:42 INFO DAGScheduler: Submitting ShuffleMapStage 86 (MapPartitionsRDD[267] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:42 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 74.5 KB, free 909.2 MB)
19/07/31 17:07:42 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 31.7 KB, free 909.2 MB)
19/07/31 17:07:42 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 127.0.0.1:53949 (size: 31.7 KB, free: 911.5 MB)
19/07/31 17:07:42 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 86 (MapPartitionsRDD[267] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:42 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks
19/07/31 17:07:42 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 164, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:42 INFO Executor: Running task 0.0 in stage 86.0 (TID 164)
19/07/31 17:07:42 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:42 INFO Executor: Finished task 0.0 in stage 86.0 (TID 164). 1687 bytes result sent to driver
19/07/31 17:07:42 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 164) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:07:42 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
19/07/31 17:07:42 INFO DAGScheduler: ShuffleMapStage 86 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:07:42 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:42 INFO DAGScheduler: running: Set()
19/07/31 17:07:42 INFO DAGScheduler: waiting: Set(ResultStage 87)
19/07/31 17:07:42 INFO DAGScheduler: failed: Set()
19/07/31 17:07:42 INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[270] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:42 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 16.8 KB, free 909.2 MB)
19/07/31 17:07:42 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.2 MB)
19/07/31 17:07:42 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.5 MB)
19/07/31 17:07:42 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:42 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 87 (MapPartitionsRDD[270] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:42 INFO TaskSchedulerImpl: Adding task set 87.0 with 4 tasks
19/07/31 17:07:42 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 165, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:42 INFO TaskSetManager: Starting task 1.0 in stage 87.0 (TID 166, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:42 INFO TaskSetManager: Starting task 2.0 in stage 87.0 (TID 167, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:42 INFO TaskSetManager: Starting task 3.0 in stage 87.0 (TID 168, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:42 INFO Executor: Running task 0.0 in stage 87.0 (TID 165)
19/07/31 17:07:42 INFO Executor: Running task 1.0 in stage 87.0 (TID 166)
19/07/31 17:07:42 INFO Executor: Running task 2.0 in stage 87.0 (TID 167)
19/07/31 17:07:42 INFO Executor: Running task 3.0 in stage 87.0 (TID 168)
19/07/31 17:07:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:42 INFO Executor: Finished task 0.0 in stage 87.0 (TID 165). 2373 bytes result sent to driver
19/07/31 17:07:42 INFO Executor: Finished task 2.0 in stage 87.0 (TID 167). 2384 bytes result sent to driver
19/07/31 17:07:42 INFO Executor: Finished task 1.0 in stage 87.0 (TID 166). 2370 bytes result sent to driver
19/07/31 17:07:42 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 165) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:07:42 INFO TaskSetManager: Finished task 1.0 in stage 87.0 (TID 166) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:07:42 INFO TaskSetManager: Finished task 2.0 in stage 87.0 (TID 167) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:07:42 INFO Executor: Finished task 3.0 in stage 87.0 (TID 168). 2353 bytes result sent to driver
19/07/31 17:07:42 INFO TaskSetManager: Finished task 3.0 in stage 87.0 (TID 168) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:07:42 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool 
19/07/31 17:07:42 INFO DAGScheduler: ResultStage 87 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:07:42 INFO DAGScheduler: Job 58 finished: collect at utils.scala:204, took 0.023900 s
19/07/31 17:07:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_217`) `dbplyr_218`
ORDER BY `date`) `dbplyr_219`) `dbplyr_220`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:42 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:42 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_221`) `dbplyr_222`
ORDER BY `date`) `dbplyr_223`) `dbplyr_224`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:42 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:42 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:42 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3088 - cust_prospect_ind.nullCount#3087) > 0)
19/07/31 17:07:42 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3093 - visit_device_type.nullCount#3092) > 0)
19/07/31 17:07:42 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#3086 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#3085))
19/07/31 17:07:42 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#3091 <= All Devices) && (All Devices <= visit_device_type.upperBound#3090))
19/07/31 17:07:42 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:42 INFO DAGScheduler: Got job 59 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:42 INFO DAGScheduler: Final stage: ResultStage 88 (collect at utils.scala:204)
19/07/31 17:07:42 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:42 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:42 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[275] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:42 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 72.1 KB, free 909.1 MB)
19/07/31 17:07:42 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 30.4 KB, free 909.1 MB)
19/07/31 17:07:42 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 127.0.0.1:53949 (size: 30.4 KB, free: 911.5 MB)
19/07/31 17:07:42 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[275] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:42 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks
19/07/31 17:07:42 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 169, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:42 INFO Executor: Running task 0.0 in stage 88.0 (TID 169)
19/07/31 17:07:42 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:42 INFO Executor: Finished task 0.0 in stage 88.0 (TID 169). 7542 bytes result sent to driver
19/07/31 17:07:42 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 169) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:07:42 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
19/07/31 17:07:42 INFO DAGScheduler: ResultStage 88 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:07:42 INFO DAGScheduler: Job 59 finished: collect at utils.scala:204, took 0.012219 s
19/07/31 17:07:42 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:42 INFO DAGScheduler: Registering RDD 276 (collect at utils.scala:204)
19/07/31 17:07:42 INFO DAGScheduler: Got job 60 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:42 INFO DAGScheduler: Final stage: ResultStage 90 (collect at utils.scala:204)
19/07/31 17:07:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 89)
19/07/31 17:07:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 89)
19/07/31 17:07:42 INFO DAGScheduler: Submitting ShuffleMapStage 89 (MapPartitionsRDD[276] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:42 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 74.5 KB, free 909.0 MB)
19/07/31 17:07:42 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.0 MB)
19/07/31 17:07:42 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.5 MB)
19/07/31 17:07:42 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 89 (MapPartitionsRDD[276] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:42 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks
19/07/31 17:07:42 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 170, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:42 INFO Executor: Running task 0.0 in stage 89.0 (TID 170)
19/07/31 17:07:42 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:42 INFO Executor: Finished task 0.0 in stage 89.0 (TID 170). 1687 bytes result sent to driver
19/07/31 17:07:42 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 170) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:07:42 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
19/07/31 17:07:42 INFO DAGScheduler: ShuffleMapStage 89 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:07:42 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:42 INFO DAGScheduler: running: Set()
19/07/31 17:07:42 INFO DAGScheduler: waiting: Set(ResultStage 90)
19/07/31 17:07:42 INFO DAGScheduler: failed: Set()
19/07/31 17:07:42 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[279] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:42 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 16.8 KB, free 908.9 MB)
19/07/31 17:07:42 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 8.0 KB, free 908.9 MB)
19/07/31 17:07:42 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.5 MB)
19/07/31 17:07:42 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:42 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 90 (MapPartitionsRDD[279] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:42 INFO TaskSchedulerImpl: Adding task set 90.0 with 4 tasks
19/07/31 17:07:42 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 171, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:42 INFO TaskSetManager: Starting task 1.0 in stage 90.0 (TID 172, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:42 INFO TaskSetManager: Starting task 2.0 in stage 90.0 (TID 173, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:42 INFO TaskSetManager: Starting task 3.0 in stage 90.0 (TID 174, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:42 INFO Executor: Running task 0.0 in stage 90.0 (TID 171)
19/07/31 17:07:42 INFO Executor: Running task 2.0 in stage 90.0 (TID 173)
19/07/31 17:07:42 INFO Executor: Running task 3.0 in stage 90.0 (TID 174)
19/07/31 17:07:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:42 INFO Executor: Finished task 3.0 in stage 90.0 (TID 174). 2319 bytes result sent to driver
19/07/31 17:07:42 INFO Executor: Running task 1.0 in stage 90.0 (TID 172)
19/07/31 17:07:42 INFO TaskSetManager: Finished task 3.0 in stage 90.0 (TID 174) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:07:42 INFO Executor: Finished task 0.0 in stage 90.0 (TID 171). 2382 bytes result sent to driver
19/07/31 17:07:42 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 171) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:07:42 INFO Executor: Finished task 2.0 in stage 90.0 (TID 173). 2390 bytes result sent to driver
19/07/31 17:07:42 INFO TaskSetManager: Finished task 2.0 in stage 90.0 (TID 173) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:07:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:42 INFO Executor: Finished task 1.0 in stage 90.0 (TID 172). 2403 bytes result sent to driver
19/07/31 17:07:42 INFO TaskSetManager: Finished task 1.0 in stage 90.0 (TID 172) in 9 ms on localhost (executor driver) (4/4)
19/07/31 17:07:42 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
19/07/31 17:07:42 INFO DAGScheduler: ResultStage 90 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:07:42 INFO DAGScheduler: Job 60 finished: collect at utils.scala:204, took 0.028695 s
19/07/31 17:07:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_225`) `dbplyr_226`
ORDER BY `date`) `dbplyr_227`) `dbplyr_228`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:42 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:42 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_229`) `dbplyr_230`
ORDER BY `date`) `dbplyr_231`) `dbplyr_232`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:42 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:42 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:42 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3186 - cust_prospect_ind.nullCount#3185) > 0)
19/07/31 17:07:42 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3191 - visit_device_type.nullCount#3190) > 0)
19/07/31 17:07:42 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#3184 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#3183))
19/07/31 17:07:42 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#3189 <= All Devices) && (All Devices <= visit_device_type.upperBound#3188))
19/07/31 17:07:43 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:43 INFO DAGScheduler: Got job 61 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:43 INFO DAGScheduler: Final stage: ResultStage 91 (collect at utils.scala:204)
19/07/31 17:07:43 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:43 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:43 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[284] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:43 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 72.1 KB, free 908.9 MB)
19/07/31 17:07:43 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 30.5 KB, free 908.8 MB)
19/07/31 17:07:43 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.4 MB)
19/07/31 17:07:43 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[284] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:43 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks
19/07/31 17:07:43 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 175, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:43 INFO Executor: Running task 0.0 in stage 91.0 (TID 175)
19/07/31 17:07:43 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:43 INFO Executor: Finished task 0.0 in stage 91.0 (TID 175). 7542 bytes result sent to driver
19/07/31 17:07:43 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 175) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:07:43 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
19/07/31 17:07:43 INFO DAGScheduler: ResultStage 91 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:07:43 INFO DAGScheduler: Job 61 finished: collect at utils.scala:204, took 0.010664 s
19/07/31 17:07:43 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:43 INFO DAGScheduler: Registering RDD 285 (collect at utils.scala:204)
19/07/31 17:07:43 INFO DAGScheduler: Got job 62 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:43 INFO DAGScheduler: Final stage: ResultStage 93 (collect at utils.scala:204)
19/07/31 17:07:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 92)
19/07/31 17:07:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 92)
19/07/31 17:07:43 INFO DAGScheduler: Submitting ShuffleMapStage 92 (MapPartitionsRDD[285] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:43 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 74.5 KB, free 908.8 MB)
19/07/31 17:07:43 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 31.8 KB, free 908.7 MB)
19/07/31 17:07:43 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.4 MB)
19/07/31 17:07:43 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 92 (MapPartitionsRDD[285] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:43 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks
19/07/31 17:07:43 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 176, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:43 INFO Executor: Running task 0.0 in stage 92.0 (TID 176)
19/07/31 17:07:43 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:43 INFO Executor: Finished task 0.0 in stage 92.0 (TID 176). 1687 bytes result sent to driver
19/07/31 17:07:43 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 176) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:07:43 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
19/07/31 17:07:43 INFO DAGScheduler: ShuffleMapStage 92 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:07:43 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:43 INFO DAGScheduler: running: Set()
19/07/31 17:07:43 INFO DAGScheduler: waiting: Set(ResultStage 93)
19/07/31 17:07:43 INFO DAGScheduler: failed: Set()
19/07/31 17:07:43 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[288] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:43 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 16.8 KB, free 908.7 MB)
19/07/31 17:07:43 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 8.0 KB, free 908.7 MB)
19/07/31 17:07:43 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.4 MB)
19/07/31 17:07:43 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:43 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 93 (MapPartitionsRDD[288] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:43 INFO TaskSchedulerImpl: Adding task set 93.0 with 4 tasks
19/07/31 17:07:43 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 177, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:43 INFO TaskSetManager: Starting task 1.0 in stage 93.0 (TID 178, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:43 INFO TaskSetManager: Starting task 2.0 in stage 93.0 (TID 179, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:43 INFO TaskSetManager: Starting task 3.0 in stage 93.0 (TID 180, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:43 INFO Executor: Running task 2.0 in stage 93.0 (TID 179)
19/07/31 17:07:43 INFO Executor: Running task 3.0 in stage 93.0 (TID 180)
19/07/31 17:07:43 INFO Executor: Running task 1.0 in stage 93.0 (TID 178)
19/07/31 17:07:43 INFO Executor: Running task 0.0 in stage 93.0 (TID 177)
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:43 INFO Executor: Finished task 3.0 in stage 93.0 (TID 180). 2362 bytes result sent to driver
19/07/31 17:07:43 INFO Executor: Finished task 0.0 in stage 93.0 (TID 177). 2382 bytes result sent to driver
19/07/31 17:07:43 INFO Executor: Finished task 1.0 in stage 93.0 (TID 178). 2403 bytes result sent to driver
19/07/31 17:07:43 INFO TaskSetManager: Finished task 3.0 in stage 93.0 (TID 180) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:07:43 INFO TaskSetManager: Finished task 1.0 in stage 93.0 (TID 178) in 4 ms on localhost (executor driver) (2/4)
19/07/31 17:07:43 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 177) in 4 ms on localhost (executor driver) (3/4)
19/07/31 17:07:43 INFO Executor: Finished task 2.0 in stage 93.0 (TID 179). 2390 bytes result sent to driver
19/07/31 17:07:43 INFO TaskSetManager: Finished task 2.0 in stage 93.0 (TID 179) in 4 ms on localhost (executor driver) (4/4)
19/07/31 17:07:43 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
19/07/31 17:07:43 INFO DAGScheduler: ResultStage 93 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:07:43 INFO DAGScheduler: Job 62 finished: collect at utils.scala:204, took 0.020580 s
19/07/31 17:07:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_233`) `dbplyr_234`
ORDER BY `date`) `dbplyr_235`) `dbplyr_236`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 17:07:43 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:43 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_237`) `dbplyr_238`
ORDER BY `date`) `dbplyr_239`) `dbplyr_240`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 17:07:43 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:43 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:43 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3284 - cust_prospect_ind.nullCount#3283) > 0)
19/07/31 17:07:43 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3289 - visit_device_type.nullCount#3288) > 0)
19/07/31 17:07:43 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#3282 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#3281))
19/07/31 17:07:43 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#3287 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#3286))
19/07/31 17:07:43 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:43 INFO DAGScheduler: Got job 63 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:43 INFO DAGScheduler: Final stage: ResultStage 94 (collect at utils.scala:204)
19/07/31 17:07:43 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:43 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:43 INFO DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[293] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:43 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 72.1 KB, free 908.6 MB)
19/07/31 17:07:43 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 30.4 KB, free 908.6 MB)
19/07/31 17:07:43 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 127.0.0.1:53949 (size: 30.4 KB, free: 911.4 MB)
19/07/31 17:07:43 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[293] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:43 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks
19/07/31 17:07:43 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 181, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:43 INFO Executor: Running task 0.0 in stage 94.0 (TID 181)
19/07/31 17:07:43 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:43 INFO Executor: Finished task 0.0 in stage 94.0 (TID 181). 7542 bytes result sent to driver
19/07/31 17:07:43 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 181) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:07:43 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
19/07/31 17:07:43 INFO DAGScheduler: ResultStage 94 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:07:43 INFO DAGScheduler: Job 63 finished: collect at utils.scala:204, took 0.011926 s
19/07/31 17:07:43 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:43 INFO DAGScheduler: Registering RDD 294 (collect at utils.scala:204)
19/07/31 17:07:43 INFO DAGScheduler: Got job 64 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:43 INFO DAGScheduler: Final stage: ResultStage 96 (collect at utils.scala:204)
19/07/31 17:07:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 95)
19/07/31 17:07:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 95)
19/07/31 17:07:43 INFO DAGScheduler: Submitting ShuffleMapStage 95 (MapPartitionsRDD[294] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:43 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 74.6 KB, free 908.5 MB)
19/07/31 17:07:43 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 31.7 KB, free 908.5 MB)
19/07/31 17:07:43 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 127.0.0.1:53949 (size: 31.7 KB, free: 911.3 MB)
19/07/31 17:07:43 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 95 (MapPartitionsRDD[294] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:43 INFO TaskSchedulerImpl: Adding task set 95.0 with 1 tasks
19/07/31 17:07:43 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 182, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:43 INFO Executor: Running task 0.0 in stage 95.0 (TID 182)
19/07/31 17:07:43 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:43 INFO Executor: Finished task 0.0 in stage 95.0 (TID 182). 1687 bytes result sent to driver
19/07/31 17:07:43 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 182) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:07:43 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
19/07/31 17:07:43 INFO DAGScheduler: ShuffleMapStage 95 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:07:43 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:43 INFO DAGScheduler: running: Set()
19/07/31 17:07:43 INFO DAGScheduler: waiting: Set(ResultStage 96)
19/07/31 17:07:43 INFO DAGScheduler: failed: Set()
19/07/31 17:07:43 INFO DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[297] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:43 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 16.8 KB, free 908.5 MB)
19/07/31 17:07:43 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 8.1 KB, free 908.5 MB)
19/07/31 17:07:43 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 127.0.0.1:53949 (size: 8.1 KB, free: 911.3 MB)
19/07/31 17:07:43 INFO SparkContext: Created broadcast 99 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:43 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 96 (MapPartitionsRDD[297] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:43 INFO TaskSchedulerImpl: Adding task set 96.0 with 4 tasks
19/07/31 17:07:43 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 183, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:43 INFO TaskSetManager: Starting task 1.0 in stage 96.0 (TID 184, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:43 INFO TaskSetManager: Starting task 2.0 in stage 96.0 (TID 185, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:43 INFO TaskSetManager: Starting task 3.0 in stage 96.0 (TID 186, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:43 INFO Executor: Running task 2.0 in stage 96.0 (TID 185)
19/07/31 17:07:43 INFO Executor: Running task 1.0 in stage 96.0 (TID 184)
19/07/31 17:07:43 INFO Executor: Running task 3.0 in stage 96.0 (TID 186)
19/07/31 17:07:43 INFO Executor: Running task 0.0 in stage 96.0 (TID 183)
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:43 INFO Executor: Finished task 2.0 in stage 96.0 (TID 185). 2377 bytes result sent to driver
19/07/31 17:07:43 INFO Executor: Finished task 0.0 in stage 96.0 (TID 183). 2377 bytes result sent to driver
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
19/07/31 17:07:43 INFO Executor: Finished task 3.0 in stage 96.0 (TID 186). 2356 bytes result sent to driver
19/07/31 17:07:43 INFO TaskSetManager: Finished task 2.0 in stage 96.0 (TID 185) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:07:43 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 183) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:07:43 INFO TaskSetManager: Finished task 3.0 in stage 96.0 (TID 186) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:07:43 INFO Executor: Finished task 1.0 in stage 96.0 (TID 184). 2382 bytes result sent to driver
19/07/31 17:07:43 INFO TaskSetManager: Finished task 1.0 in stage 96.0 (TID 184) in 7 ms on localhost (executor driver) (4/4)
19/07/31 17:07:43 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool 
19/07/31 17:07:43 INFO DAGScheduler: ResultStage 96 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:07:43 INFO DAGScheduler: Job 64 finished: collect at utils.scala:204, took 0.031901 s
19/07/31 17:07:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_241`) `dbplyr_242`
ORDER BY `date`) `dbplyr_243`) `dbplyr_244`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:43 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:43 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_245`) `dbplyr_246`
ORDER BY `date`) `dbplyr_247`) `dbplyr_248`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:43 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:43 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:43 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3382 - cust_prospect_ind.nullCount#3381) > 0)
19/07/31 17:07:43 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3387 - visit_device_type.nullCount#3386) > 0)
19/07/31 17:07:43 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#3380 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#3379))
19/07/31 17:07:43 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#3385 <= All Devices) && (All Devices <= visit_device_type.upperBound#3384))
19/07/31 17:07:43 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:43 INFO DAGScheduler: Got job 65 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:43 INFO DAGScheduler: Final stage: ResultStage 97 (collect at utils.scala:204)
19/07/31 17:07:43 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:43 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:43 INFO DAGScheduler: Submitting ResultStage 97 (MapPartitionsRDD[302] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:43 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 72.1 KB, free 908.4 MB)
19/07/31 17:07:43 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 30.5 KB, free 908.4 MB)
19/07/31 17:07:43 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.3 MB)
19/07/31 17:07:43 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 97 (MapPartitionsRDD[302] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:43 INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks
19/07/31 17:07:43 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 187, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:43 INFO Executor: Running task 0.0 in stage 97.0 (TID 187)
19/07/31 17:07:43 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:43 INFO Executor: Finished task 0.0 in stage 97.0 (TID 187). 7542 bytes result sent to driver
19/07/31 17:07:43 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 187) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:07:43 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
19/07/31 17:07:43 INFO DAGScheduler: ResultStage 97 (collect at utils.scala:204) finished in 0.004 s
19/07/31 17:07:43 INFO DAGScheduler: Job 65 finished: collect at utils.scala:204, took 0.010256 s
19/07/31 17:07:43 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:43 INFO DAGScheduler: Registering RDD 303 (collect at utils.scala:204)
19/07/31 17:07:43 INFO DAGScheduler: Got job 66 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:43 INFO DAGScheduler: Final stage: ResultStage 99 (collect at utils.scala:204)
19/07/31 17:07:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 98)
19/07/31 17:07:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 98)
19/07/31 17:07:43 INFO DAGScheduler: Submitting ShuffleMapStage 98 (MapPartitionsRDD[303] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:43 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 74.5 KB, free 908.3 MB)
19/07/31 17:07:43 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 31.8 KB, free 908.3 MB)
19/07/31 17:07:43 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.3 MB)
19/07/31 17:07:43 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 98 (MapPartitionsRDD[303] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:43 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks
19/07/31 17:07:43 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 188, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:43 INFO Executor: Running task 0.0 in stage 98.0 (TID 188)
19/07/31 17:07:43 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:43 INFO Executor: Finished task 0.0 in stage 98.0 (TID 188). 1687 bytes result sent to driver
19/07/31 17:07:43 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 188) in 12 ms on localhost (executor driver) (1/1)
19/07/31 17:07:43 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
19/07/31 17:07:43 INFO DAGScheduler: ShuffleMapStage 98 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:07:43 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:43 INFO DAGScheduler: running: Set()
19/07/31 17:07:43 INFO DAGScheduler: waiting: Set(ResultStage 99)
19/07/31 17:07:43 INFO DAGScheduler: failed: Set()
19/07/31 17:07:43 INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[306] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:43 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 16.8 KB, free 908.3 MB)
19/07/31 17:07:43 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 8.0 KB, free 908.3 MB)
19/07/31 17:07:43 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.2 MB)
19/07/31 17:07:43 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:43 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 99 (MapPartitionsRDD[306] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:43 INFO TaskSchedulerImpl: Adding task set 99.0 with 4 tasks
19/07/31 17:07:43 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 189, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:43 INFO TaskSetManager: Starting task 1.0 in stage 99.0 (TID 190, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:43 INFO TaskSetManager: Starting task 2.0 in stage 99.0 (TID 191, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:43 INFO TaskSetManager: Starting task 3.0 in stage 99.0 (TID 192, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:43 INFO Executor: Running task 1.0 in stage 99.0 (TID 190)
19/07/31 17:07:43 INFO Executor: Running task 0.0 in stage 99.0 (TID 189)
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:43 INFO Executor: Running task 2.0 in stage 99.0 (TID 191)
19/07/31 17:07:43 INFO Executor: Running task 3.0 in stage 99.0 (TID 192)
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:43 INFO Executor: Finished task 3.0 in stage 99.0 (TID 192). 2362 bytes result sent to driver
19/07/31 17:07:43 INFO Executor: Finished task 2.0 in stage 99.0 (TID 191). 2390 bytes result sent to driver
19/07/31 17:07:43 INFO TaskSetManager: Finished task 3.0 in stage 99.0 (TID 192) in 7 ms on localhost (executor driver) (1/4)
19/07/31 17:07:43 INFO Executor: Finished task 1.0 in stage 99.0 (TID 190). 2403 bytes result sent to driver
19/07/31 17:07:43 INFO Executor: Finished task 0.0 in stage 99.0 (TID 189). 2382 bytes result sent to driver
19/07/31 17:07:43 INFO TaskSetManager: Finished task 2.0 in stage 99.0 (TID 191) in 9 ms on localhost (executor driver) (2/4)
19/07/31 17:07:43 INFO TaskSetManager: Finished task 1.0 in stage 99.0 (TID 190) in 9 ms on localhost (executor driver) (3/4)
19/07/31 17:07:43 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 189) in 10 ms on localhost (executor driver) (4/4)
19/07/31 17:07:43 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
19/07/31 17:07:43 INFO DAGScheduler: ResultStage 99 (collect at utils.scala:204) finished in 0.011 s
19/07/31 17:07:43 INFO DAGScheduler: Job 66 finished: collect at utils.scala:204, took 0.036546 s
19/07/31 17:07:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_249`) `dbplyr_250`
ORDER BY `date`) `dbplyr_251`) `dbplyr_252`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:43 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:43 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_253`) `dbplyr_254`
ORDER BY `date`) `dbplyr_255`) `dbplyr_256`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:43 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:43 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:43 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3480 - cust_prospect_ind.nullCount#3479) > 0)
19/07/31 17:07:43 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3485 - visit_device_type.nullCount#3484) > 0)
19/07/31 17:07:43 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#3478 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#3477))
19/07/31 17:07:43 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#3483 <= All Devices) && (All Devices <= visit_device_type.upperBound#3482))
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1694
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1783
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1939
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2102
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1778
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1776
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1862
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1861
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2099
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2747
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.3 MB)
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.3 MB)
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1942
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2585
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2666
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 911.3 MB)
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 911.3 MB)
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1943
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2104
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2587
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 911.4 MB)
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 127.0.0.1:53949 in memory (size: 31.7 KB, free: 911.4 MB)
19/07/31 17:07:43 INFO ContextCleaner: Cleaned shuffle 31
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2100
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2427
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2103
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2430
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2429
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 911.4 MB)
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2107
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1944
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 911.4 MB)
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 911.5 MB)
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1940
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2591
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1859
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 127.0.0.1:53949 in memory (size: 30.4 KB, free: 911.5 MB)
19/07/31 17:07:43 INFO ContextCleaner: Cleaned shuffle 29
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1938
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2424
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2586
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.5 MB)
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1779
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2342
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2423
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2589
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 911.5 MB)
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1775
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1781
19/07/31 17:07:43 INFO ContextCleaner: Cleaned shuffle 21
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 911.6 MB)
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2428
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.6 MB)
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 127.0.0.1:53949 in memory (size: 31.7 KB, free: 911.6 MB)
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1864
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.6 MB)
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.6 MB)
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 911.7 MB)
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 911.7 MB)
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1858
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 127.0.0.1:53949 in memory (size: 30.4 KB, free: 911.7 MB)
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2105
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 127.0.0.1:53949 in memory (size: 30.4 KB, free: 911.8 MB)
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2592
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 127.0.0.1:53949 in memory (size: 30.4 KB, free: 911.8 MB)
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1941
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1780
19/07/31 17:07:43 INFO ContextCleaner: Cleaned shuffle 25
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1937
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2431
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2593
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2106
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2588
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1777
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:07:43 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 127.0.0.1:53949 in memory (size: 30.4 KB, free: 911.8 MB)
19/07/31 17:07:43 INFO DAGScheduler: Got job 67 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:43 INFO DAGScheduler: Final stage: ResultStage 100 (collect at utils.scala:204)
19/07/31 17:07:43 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:43 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:07:43 INFO DAGScheduler: Submitting ResultStage 100 (MapPartitionsRDD[311] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 127.0.0.1:53949 in memory (size: 31.7 KB, free: 911.9 MB)
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2426
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:07:43 INFO ContextCleaner: Cleaned shuffle 22
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 127.0.0.1:53949 in memory (size: 31.7 KB, free: 911.9 MB)
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2590
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1782
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 127.0.0.1:53949 in memory (size: 30.4 KB, free: 912.0 MB)
19/07/31 17:07:43 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 72.1 KB, free 910.5 MB)
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1863
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:07:43 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.6 MB)
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:07:43 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.9 MB)
19/07/31 17:07:43 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 127.0.0.1:53949 in memory (size: 31.7 KB, free: 912.0 MB)
19/07/31 17:07:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 100 (MapPartitionsRDD[311] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:43 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:07:43 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 193, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:43 INFO Executor: Running task 0.0 in stage 100.0 (TID 193)
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:07:43 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1856
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2018
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1945
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2504
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1860
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 2101
19/07/31 17:07:43 INFO ContextCleaner: Cleaned accumulator 1857
19/07/31 17:07:44 INFO ContextCleaner: Cleaned accumulator 2425
19/07/31 17:07:44 INFO ContextCleaner: Cleaned shuffle 23
19/07/31 17:07:44 INFO ContextCleaner: Cleaned accumulator 2180
19/07/31 17:07:44 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 127.0.0.1:53949 in memory (size: 30.4 KB, free: 912.1 MB)
19/07/31 17:07:44 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 127.0.0.1:53949 in memory (size: 8.1 KB, free: 912.1 MB)
19/07/31 17:07:44 INFO ContextCleaner: Cleaned accumulator 2261
19/07/31 17:07:44 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 912.1 MB)
19/07/31 17:07:44 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:07:44 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:44 INFO Executor: Finished task 0.0 in stage 100.0 (TID 193). 7542 bytes result sent to driver
19/07/31 17:07:44 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 193) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:07:44 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
19/07/31 17:07:44 INFO DAGScheduler: ResultStage 100 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:07:44 INFO DAGScheduler: Job 67 finished: collect at utils.scala:204, took 0.012379 s
19/07/31 17:07:44 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:44 INFO DAGScheduler: Registering RDD 312 (collect at utils.scala:204)
19/07/31 17:07:44 INFO DAGScheduler: Got job 68 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:44 INFO DAGScheduler: Final stage: ResultStage 102 (collect at utils.scala:204)
19/07/31 17:07:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 101)
19/07/31 17:07:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 101)
19/07/31 17:07:44 INFO DAGScheduler: Submitting ShuffleMapStage 101 (MapPartitionsRDD[312] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:44 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 74.5 KB, free 911.1 MB)
19/07/31 17:07:44 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.0 MB)
19/07/31 17:07:44 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 912.1 MB)
19/07/31 17:07:44 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 101 (MapPartitionsRDD[312] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:44 INFO TaskSchedulerImpl: Adding task set 101.0 with 1 tasks
19/07/31 17:07:44 INFO TaskSetManager: Starting task 0.0 in stage 101.0 (TID 194, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:44 INFO Executor: Running task 0.0 in stage 101.0 (TID 194)
19/07/31 17:07:44 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:44 INFO Executor: Finished task 0.0 in stage 101.0 (TID 194). 1687 bytes result sent to driver
19/07/31 17:07:44 INFO TaskSetManager: Finished task 0.0 in stage 101.0 (TID 194) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:07:44 INFO TaskSchedulerImpl: Removed TaskSet 101.0, whose tasks have all completed, from pool 
19/07/31 17:07:44 INFO DAGScheduler: ShuffleMapStage 101 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:07:44 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:44 INFO DAGScheduler: running: Set()
19/07/31 17:07:44 INFO DAGScheduler: waiting: Set(ResultStage 102)
19/07/31 17:07:44 INFO DAGScheduler: failed: Set()
19/07/31 17:07:44 INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[315] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:44 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 16.8 KB, free 911.0 MB)
19/07/31 17:07:44 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.0 MB)
19/07/31 17:07:44 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:07:44 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:44 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 102 (MapPartitionsRDD[315] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:44 INFO TaskSchedulerImpl: Adding task set 102.0 with 4 tasks
19/07/31 17:07:44 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 195, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:44 INFO TaskSetManager: Starting task 1.0 in stage 102.0 (TID 196, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:44 INFO TaskSetManager: Starting task 2.0 in stage 102.0 (TID 197, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:44 INFO TaskSetManager: Starting task 3.0 in stage 102.0 (TID 198, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:44 INFO Executor: Running task 1.0 in stage 102.0 (TID 196)
19/07/31 17:07:44 INFO Executor: Running task 0.0 in stage 102.0 (TID 195)
19/07/31 17:07:44 INFO Executor: Running task 2.0 in stage 102.0 (TID 197)
19/07/31 17:07:44 INFO Executor: Running task 3.0 in stage 102.0 (TID 198)
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:44 INFO Executor: Finished task 3.0 in stage 102.0 (TID 198). 2362 bytes result sent to driver
19/07/31 17:07:44 INFO Executor: Finished task 1.0 in stage 102.0 (TID 196). 2403 bytes result sent to driver
19/07/31 17:07:44 INFO Executor: Finished task 2.0 in stage 102.0 (TID 197). 2390 bytes result sent to driver
19/07/31 17:07:44 INFO TaskSetManager: Finished task 3.0 in stage 102.0 (TID 198) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:07:44 INFO TaskSetManager: Finished task 1.0 in stage 102.0 (TID 196) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:07:44 INFO TaskSetManager: Finished task 2.0 in stage 102.0 (TID 197) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:44 INFO Executor: Finished task 0.0 in stage 102.0 (TID 195). 2382 bytes result sent to driver
19/07/31 17:07:44 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 195) in 9 ms on localhost (executor driver) (4/4)
19/07/31 17:07:44 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
19/07/31 17:07:44 INFO DAGScheduler: ResultStage 102 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:07:44 INFO DAGScheduler: Job 68 finished: collect at utils.scala:204, took 0.027186 s
19/07/31 17:07:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_257`) `dbplyr_258`
ORDER BY `date`) `dbplyr_259`) `dbplyr_260`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Desktop"))
19/07/31 17:07:44 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:44 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_261`) `dbplyr_262`
ORDER BY `date`) `dbplyr_263`) `dbplyr_264`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Desktop"))
19/07/31 17:07:44 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:44 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:44 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3578 - cust_prospect_ind.nullCount#3577) > 0)
19/07/31 17:07:44 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3583 - visit_device_type.nullCount#3582) > 0)
19/07/31 17:07:44 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#3576 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#3575))
19/07/31 17:07:44 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#3581 <= Desktop) && (Desktop <= visit_device_type.upperBound#3580))
19/07/31 17:07:44 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:44 INFO DAGScheduler: Got job 69 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:44 INFO DAGScheduler: Final stage: ResultStage 103 (collect at utils.scala:204)
19/07/31 17:07:44 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:44 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:44 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[320] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:44 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 72.1 KB, free 910.9 MB)
19/07/31 17:07:44 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.9 MB)
19/07/31 17:07:44 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 127.0.0.1:53949 (size: 30.4 KB, free: 912.0 MB)
19/07/31 17:07:44 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[320] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:44 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks
19/07/31 17:07:44 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 199, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:44 INFO Executor: Running task 0.0 in stage 103.0 (TID 199)
19/07/31 17:07:44 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:44 INFO Executor: Finished task 0.0 in stage 103.0 (TID 199). 6512 bytes result sent to driver
19/07/31 17:07:44 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 199) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:07:44 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
19/07/31 17:07:44 INFO DAGScheduler: ResultStage 103 (collect at utils.scala:204) finished in 0.004 s
19/07/31 17:07:44 INFO DAGScheduler: Job 69 finished: collect at utils.scala:204, took 0.008331 s
19/07/31 17:07:44 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:44 INFO DAGScheduler: Registering RDD 321 (collect at utils.scala:204)
19/07/31 17:07:44 INFO DAGScheduler: Got job 70 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:44 INFO DAGScheduler: Final stage: ResultStage 105 (collect at utils.scala:204)
19/07/31 17:07:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 104)
19/07/31 17:07:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 104)
19/07/31 17:07:44 INFO DAGScheduler: Submitting ShuffleMapStage 104 (MapPartitionsRDD[321] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:44 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 74.5 KB, free 910.8 MB)
19/07/31 17:07:44 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.8 MB)
19/07/31 17:07:44 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 127.0.0.1:53949 (size: 31.7 KB, free: 912.0 MB)
19/07/31 17:07:44 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 104 (MapPartitionsRDD[321] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:44 INFO TaskSchedulerImpl: Adding task set 104.0 with 1 tasks
19/07/31 17:07:44 INFO TaskSetManager: Starting task 0.0 in stage 104.0 (TID 200, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:44 INFO Executor: Running task 0.0 in stage 104.0 (TID 200)
19/07/31 17:07:44 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:44 INFO Executor: Finished task 0.0 in stage 104.0 (TID 200). 1687 bytes result sent to driver
19/07/31 17:07:44 INFO TaskSetManager: Finished task 0.0 in stage 104.0 (TID 200) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:07:44 INFO TaskSchedulerImpl: Removed TaskSet 104.0, whose tasks have all completed, from pool 
19/07/31 17:07:44 INFO DAGScheduler: ShuffleMapStage 104 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:07:44 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:44 INFO DAGScheduler: running: Set()
19/07/31 17:07:44 INFO DAGScheduler: waiting: Set(ResultStage 105)
19/07/31 17:07:44 INFO DAGScheduler: failed: Set()
19/07/31 17:07:44 INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[324] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:44 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 16.8 KB, free 910.8 MB)
19/07/31 17:07:44 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.8 MB)
19/07/31 17:07:44 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:07:44 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:44 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 105 (MapPartitionsRDD[324] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:44 INFO TaskSchedulerImpl: Adding task set 105.0 with 4 tasks
19/07/31 17:07:44 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 201, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:44 INFO TaskSetManager: Starting task 1.0 in stage 105.0 (TID 202, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:44 INFO TaskSetManager: Starting task 2.0 in stage 105.0 (TID 203, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:44 INFO TaskSetManager: Starting task 3.0 in stage 105.0 (TID 204, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:44 INFO Executor: Running task 0.0 in stage 105.0 (TID 201)
19/07/31 17:07:44 INFO Executor: Running task 3.0 in stage 105.0 (TID 204)
19/07/31 17:07:44 INFO Executor: Running task 1.0 in stage 105.0 (TID 202)
19/07/31 17:07:44 INFO Executor: Running task 2.0 in stage 105.0 (TID 203)
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:44 INFO Executor: Finished task 0.0 in stage 105.0 (TID 201). 2367 bytes result sent to driver
19/07/31 17:07:44 INFO Executor: Finished task 1.0 in stage 105.0 (TID 202). 2350 bytes result sent to driver
19/07/31 17:07:44 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 201) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:07:44 INFO TaskSetManager: Finished task 1.0 in stage 105.0 (TID 202) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:07:44 INFO Executor: Finished task 3.0 in stage 105.0 (TID 204). 2357 bytes result sent to driver
19/07/31 17:07:44 INFO TaskSetManager: Finished task 3.0 in stage 105.0 (TID 204) in 4 ms on localhost (executor driver) (3/4)
19/07/31 17:07:44 INFO Executor: Finished task 2.0 in stage 105.0 (TID 203). 2368 bytes result sent to driver
19/07/31 17:07:44 INFO TaskSetManager: Finished task 2.0 in stage 105.0 (TID 203) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:07:44 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
19/07/31 17:07:44 INFO DAGScheduler: ResultStage 105 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:07:44 INFO DAGScheduler: Job 70 finished: collect at utils.scala:204, took 0.020355 s
19/07/31 17:07:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_265`) `dbplyr_266`
ORDER BY `date`) `dbplyr_267`) `dbplyr_268`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:44 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:44 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_269`) `dbplyr_270`
ORDER BY `date`) `dbplyr_271`) `dbplyr_272`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:44 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:44 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:44 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3676 - cust_prospect_ind.nullCount#3675) > 0)
19/07/31 17:07:44 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3681 - visit_device_type.nullCount#3680) > 0)
19/07/31 17:07:44 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#3674 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#3673))
19/07/31 17:07:44 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#3679 <= All Devices) && (All Devices <= visit_device_type.upperBound#3678))
19/07/31 17:07:44 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:44 INFO DAGScheduler: Got job 71 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:44 INFO DAGScheduler: Final stage: ResultStage 106 (collect at utils.scala:204)
19/07/31 17:07:44 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:44 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:44 INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[329] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:44 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 72.1 KB, free 910.7 MB)
19/07/31 17:07:44 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.7 MB)
19/07/31 17:07:44 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:07:44 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[329] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:44 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks
19/07/31 17:07:44 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 205, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:44 INFO Executor: Running task 0.0 in stage 106.0 (TID 205)
19/07/31 17:07:44 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:44 INFO Executor: Finished task 0.0 in stage 106.0 (TID 205). 7542 bytes result sent to driver
19/07/31 17:07:44 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 205) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:07:44 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
19/07/31 17:07:44 INFO DAGScheduler: ResultStage 106 (collect at utils.scala:204) finished in 0.004 s
19/07/31 17:07:44 INFO DAGScheduler: Job 71 finished: collect at utils.scala:204, took 0.007135 s
19/07/31 17:07:44 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:44 INFO DAGScheduler: Registering RDD 330 (collect at utils.scala:204)
19/07/31 17:07:44 INFO DAGScheduler: Got job 72 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:44 INFO DAGScheduler: Final stage: ResultStage 108 (collect at utils.scala:204)
19/07/31 17:07:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 107)
19/07/31 17:07:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 107)
19/07/31 17:07:44 INFO DAGScheduler: Submitting ShuffleMapStage 107 (MapPartitionsRDD[330] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:44 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 74.5 KB, free 910.6 MB)
19/07/31 17:07:44 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.6 MB)
19/07/31 17:07:44 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.9 MB)
19/07/31 17:07:44 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 107 (MapPartitionsRDD[330] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:44 INFO TaskSchedulerImpl: Adding task set 107.0 with 1 tasks
19/07/31 17:07:44 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 206, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:44 INFO Executor: Running task 0.0 in stage 107.0 (TID 206)
19/07/31 17:07:44 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:44 INFO Executor: Finished task 0.0 in stage 107.0 (TID 206). 1687 bytes result sent to driver
19/07/31 17:07:44 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 206) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:07:44 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
19/07/31 17:07:44 INFO DAGScheduler: ShuffleMapStage 107 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:07:44 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:44 INFO DAGScheduler: running: Set()
19/07/31 17:07:44 INFO DAGScheduler: waiting: Set(ResultStage 108)
19/07/31 17:07:44 INFO DAGScheduler: failed: Set()
19/07/31 17:07:44 INFO DAGScheduler: Submitting ResultStage 108 (MapPartitionsRDD[333] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:44 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 16.8 KB, free 910.6 MB)
19/07/31 17:07:44 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.6 MB)
19/07/31 17:07:44 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:07:44 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:44 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 108 (MapPartitionsRDD[333] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:44 INFO TaskSchedulerImpl: Adding task set 108.0 with 4 tasks
19/07/31 17:07:44 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 207, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:44 INFO TaskSetManager: Starting task 1.0 in stage 108.0 (TID 208, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:44 INFO TaskSetManager: Starting task 2.0 in stage 108.0 (TID 209, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:44 INFO TaskSetManager: Starting task 3.0 in stage 108.0 (TID 210, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:44 INFO Executor: Running task 1.0 in stage 108.0 (TID 208)
19/07/31 17:07:44 INFO Executor: Running task 3.0 in stage 108.0 (TID 210)
19/07/31 17:07:44 INFO Executor: Running task 0.0 in stage 108.0 (TID 207)
19/07/31 17:07:44 INFO Executor: Running task 2.0 in stage 108.0 (TID 209)
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:44 INFO Executor: Finished task 3.0 in stage 108.0 (TID 210). 2362 bytes result sent to driver
19/07/31 17:07:44 INFO Executor: Finished task 2.0 in stage 108.0 (TID 209). 2390 bytes result sent to driver
19/07/31 17:07:44 INFO Executor: Finished task 0.0 in stage 108.0 (TID 207). 2382 bytes result sent to driver
19/07/31 17:07:44 INFO TaskSetManager: Finished task 3.0 in stage 108.0 (TID 210) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:07:44 INFO TaskSetManager: Finished task 2.0 in stage 108.0 (TID 209) in 4 ms on localhost (executor driver) (2/4)
19/07/31 17:07:44 INFO Executor: Finished task 1.0 in stage 108.0 (TID 208). 2403 bytes result sent to driver
19/07/31 17:07:44 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 207) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:07:44 INFO TaskSetManager: Finished task 1.0 in stage 108.0 (TID 208) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:07:44 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool 
19/07/31 17:07:44 INFO DAGScheduler: ResultStage 108 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:07:44 INFO DAGScheduler: Job 72 finished: collect at utils.scala:204, took 0.018099 s
19/07/31 17:07:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_273`) `dbplyr_274`
ORDER BY `date`) `dbplyr_275`) `dbplyr_276`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:44 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:44 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_277`) `dbplyr_278`
ORDER BY `date`) `dbplyr_279`) `dbplyr_280`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:44 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:44 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:44 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3774 - cust_prospect_ind.nullCount#3773) > 0)
19/07/31 17:07:44 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3779 - visit_device_type.nullCount#3778) > 0)
19/07/31 17:07:44 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#3772 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#3771))
19/07/31 17:07:44 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#3777 <= All Devices) && (All Devices <= visit_device_type.upperBound#3776))
19/07/31 17:07:44 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:44 INFO DAGScheduler: Got job 73 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:44 INFO DAGScheduler: Final stage: ResultStage 109 (collect at utils.scala:204)
19/07/31 17:07:44 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:44 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:44 INFO DAGScheduler: Submitting ResultStage 109 (MapPartitionsRDD[338] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:44 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 72.1 KB, free 910.5 MB)
19/07/31 17:07:44 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.5 MB)
19/07/31 17:07:44 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 127.0.0.1:53949 (size: 30.4 KB, free: 911.9 MB)
19/07/31 17:07:44 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 109 (MapPartitionsRDD[338] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:44 INFO TaskSchedulerImpl: Adding task set 109.0 with 1 tasks
19/07/31 17:07:44 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 211, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:44 INFO Executor: Running task 0.0 in stage 109.0 (TID 211)
19/07/31 17:07:44 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:44 INFO Executor: Finished task 0.0 in stage 109.0 (TID 211). 7542 bytes result sent to driver
19/07/31 17:07:44 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 211) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:07:44 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool 
19/07/31 17:07:44 INFO DAGScheduler: ResultStage 109 (collect at utils.scala:204) finished in 0.004 s
19/07/31 17:07:44 INFO DAGScheduler: Job 73 finished: collect at utils.scala:204, took 0.008345 s
19/07/31 17:07:44 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:44 INFO DAGScheduler: Registering RDD 339 (collect at utils.scala:204)
19/07/31 17:07:44 INFO DAGScheduler: Got job 74 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:44 INFO DAGScheduler: Final stage: ResultStage 111 (collect at utils.scala:204)
19/07/31 17:07:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 110)
19/07/31 17:07:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 110)
19/07/31 17:07:44 INFO DAGScheduler: Submitting ShuffleMapStage 110 (MapPartitionsRDD[339] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:44 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 74.5 KB, free 910.4 MB)
19/07/31 17:07:44 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.4 MB)
19/07/31 17:07:44 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 127.0.0.1:53949 (size: 31.7 KB, free: 911.9 MB)
19/07/31 17:07:44 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 110 (MapPartitionsRDD[339] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:44 INFO TaskSchedulerImpl: Adding task set 110.0 with 1 tasks
19/07/31 17:07:44 INFO TaskSetManager: Starting task 0.0 in stage 110.0 (TID 212, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:44 INFO Executor: Running task 0.0 in stage 110.0 (TID 212)
19/07/31 17:07:44 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:44 INFO Executor: Finished task 0.0 in stage 110.0 (TID 212). 1687 bytes result sent to driver
19/07/31 17:07:44 INFO TaskSetManager: Finished task 0.0 in stage 110.0 (TID 212) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:07:44 INFO TaskSchedulerImpl: Removed TaskSet 110.0, whose tasks have all completed, from pool 
19/07/31 17:07:44 INFO DAGScheduler: ShuffleMapStage 110 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:07:44 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:44 INFO DAGScheduler: running: Set()
19/07/31 17:07:44 INFO DAGScheduler: waiting: Set(ResultStage 111)
19/07/31 17:07:44 INFO DAGScheduler: failed: Set()
19/07/31 17:07:44 INFO DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[342] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:44 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 16.8 KB, free 910.3 MB)
19/07/31 17:07:44 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.3 MB)
19/07/31 17:07:44 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:07:44 INFO SparkContext: Created broadcast 114 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:44 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 111 (MapPartitionsRDD[342] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:44 INFO TaskSchedulerImpl: Adding task set 111.0 with 4 tasks
19/07/31 17:07:44 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 213, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:44 INFO TaskSetManager: Starting task 1.0 in stage 111.0 (TID 214, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:44 INFO TaskSetManager: Starting task 2.0 in stage 111.0 (TID 215, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:44 INFO TaskSetManager: Starting task 3.0 in stage 111.0 (TID 216, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:44 INFO Executor: Running task 0.0 in stage 111.0 (TID 213)
19/07/31 17:07:44 INFO Executor: Running task 2.0 in stage 111.0 (TID 215)
19/07/31 17:07:44 INFO Executor: Running task 3.0 in stage 111.0 (TID 216)
19/07/31 17:07:44 INFO Executor: Running task 1.0 in stage 111.0 (TID 214)
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:44 INFO Executor: Finished task 0.0 in stage 111.0 (TID 213). 2382 bytes result sent to driver
19/07/31 17:07:44 INFO Executor: Finished task 3.0 in stage 111.0 (TID 216). 2362 bytes result sent to driver
19/07/31 17:07:44 INFO Executor: Finished task 2.0 in stage 111.0 (TID 215). 2390 bytes result sent to driver
19/07/31 17:07:44 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 213) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:07:44 INFO TaskSetManager: Finished task 3.0 in stage 111.0 (TID 216) in 4 ms on localhost (executor driver) (2/4)
19/07/31 17:07:44 INFO TaskSetManager: Finished task 2.0 in stage 111.0 (TID 215) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:07:44 INFO Executor: Finished task 1.0 in stage 111.0 (TID 214). 2403 bytes result sent to driver
19/07/31 17:07:44 INFO TaskSetManager: Finished task 1.0 in stage 111.0 (TID 214) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:07:44 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool 
19/07/31 17:07:44 INFO DAGScheduler: ResultStage 111 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:07:44 INFO DAGScheduler: Job 74 finished: collect at utils.scala:204, took 0.019297 s
19/07/31 17:07:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_281`) `dbplyr_282`
ORDER BY `date`) `dbplyr_283`) `dbplyr_284`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Desktop"))
19/07/31 17:07:44 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:44 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_285`) `dbplyr_286`
ORDER BY `date`) `dbplyr_287`) `dbplyr_288`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Desktop"))
19/07/31 17:07:45 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:45 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:45 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3872 - cust_prospect_ind.nullCount#3871) > 0)
19/07/31 17:07:45 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3877 - visit_device_type.nullCount#3876) > 0)
19/07/31 17:07:45 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#3870 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#3869))
19/07/31 17:07:45 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#3875 <= Desktop) && (Desktop <= visit_device_type.upperBound#3874))
19/07/31 17:07:45 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:45 INFO DAGScheduler: Got job 75 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:45 INFO DAGScheduler: Final stage: ResultStage 112 (collect at utils.scala:204)
19/07/31 17:07:45 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:45 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:45 INFO DAGScheduler: Submitting ResultStage 112 (MapPartitionsRDD[347] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:45 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 72.1 KB, free 910.3 MB)
19/07/31 17:07:45 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.2 MB)
19/07/31 17:07:45 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:07:45 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 112 (MapPartitionsRDD[347] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:45 INFO TaskSchedulerImpl: Adding task set 112.0 with 1 tasks
19/07/31 17:07:45 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 217, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:45 INFO Executor: Running task 0.0 in stage 112.0 (TID 217)
19/07/31 17:07:45 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:45 INFO Executor: Finished task 0.0 in stage 112.0 (TID 217). 6512 bytes result sent to driver
19/07/31 17:07:45 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 217) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:07:45 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool 
19/07/31 17:07:45 INFO DAGScheduler: ResultStage 112 (collect at utils.scala:204) finished in 0.004 s
19/07/31 17:07:45 INFO DAGScheduler: Job 75 finished: collect at utils.scala:204, took 0.007816 s
19/07/31 17:07:45 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:45 INFO DAGScheduler: Registering RDD 348 (collect at utils.scala:204)
19/07/31 17:07:45 INFO DAGScheduler: Got job 76 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:45 INFO DAGScheduler: Final stage: ResultStage 114 (collect at utils.scala:204)
19/07/31 17:07:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 113)
19/07/31 17:07:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 113)
19/07/31 17:07:45 INFO DAGScheduler: Submitting ShuffleMapStage 113 (MapPartitionsRDD[348] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:45 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 74.5 KB, free 910.2 MB)
19/07/31 17:07:45 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.1 MB)
19/07/31 17:07:45 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:07:45 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 113 (MapPartitionsRDD[348] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:45 INFO TaskSchedulerImpl: Adding task set 113.0 with 1 tasks
19/07/31 17:07:45 INFO TaskSetManager: Starting task 0.0 in stage 113.0 (TID 218, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:45 INFO Executor: Running task 0.0 in stage 113.0 (TID 218)
19/07/31 17:07:45 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:45 INFO Executor: Finished task 0.0 in stage 113.0 (TID 218). 1687 bytes result sent to driver
19/07/31 17:07:45 INFO TaskSetManager: Finished task 0.0 in stage 113.0 (TID 218) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:07:45 INFO TaskSchedulerImpl: Removed TaskSet 113.0, whose tasks have all completed, from pool 
19/07/31 17:07:45 INFO DAGScheduler: ShuffleMapStage 113 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:07:45 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:45 INFO DAGScheduler: running: Set()
19/07/31 17:07:45 INFO DAGScheduler: waiting: Set(ResultStage 114)
19/07/31 17:07:45 INFO DAGScheduler: failed: Set()
19/07/31 17:07:45 INFO DAGScheduler: Submitting ResultStage 114 (MapPartitionsRDD[351] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:45 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 16.8 KB, free 910.1 MB)
19/07/31 17:07:45 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.1 MB)
19/07/31 17:07:45 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:07:45 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:45 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 114 (MapPartitionsRDD[351] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:45 INFO TaskSchedulerImpl: Adding task set 114.0 with 4 tasks
19/07/31 17:07:45 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 219, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:45 INFO TaskSetManager: Starting task 1.0 in stage 114.0 (TID 220, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:45 INFO TaskSetManager: Starting task 2.0 in stage 114.0 (TID 221, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:45 INFO TaskSetManager: Starting task 3.0 in stage 114.0 (TID 222, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:45 INFO Executor: Running task 0.0 in stage 114.0 (TID 219)
19/07/31 17:07:45 INFO Executor: Running task 1.0 in stage 114.0 (TID 220)
19/07/31 17:07:45 INFO Executor: Running task 2.0 in stage 114.0 (TID 221)
19/07/31 17:07:45 INFO Executor: Running task 3.0 in stage 114.0 (TID 222)
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/07/31 17:07:45 INFO Executor: Finished task 2.0 in stage 114.0 (TID 221). 2373 bytes result sent to driver
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:45 INFO Executor: Finished task 0.0 in stage 114.0 (TID 219). 2369 bytes result sent to driver
19/07/31 17:07:45 INFO Executor: Finished task 3.0 in stage 114.0 (TID 222). 2359 bytes result sent to driver
19/07/31 17:07:45 INFO TaskSetManager: Finished task 2.0 in stage 114.0 (TID 221) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:07:45 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 219) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:07:45 INFO Executor: Finished task 1.0 in stage 114.0 (TID 220). 2351 bytes result sent to driver
19/07/31 17:07:45 INFO TaskSetManager: Finished task 3.0 in stage 114.0 (TID 222) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:07:45 INFO TaskSetManager: Finished task 1.0 in stage 114.0 (TID 220) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:07:45 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool 
19/07/31 17:07:45 INFO DAGScheduler: ResultStage 114 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:07:45 INFO DAGScheduler: Job 76 finished: collect at utils.scala:204, took 0.019913 s
19/07/31 17:07:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_289`) `dbplyr_290`
ORDER BY `date`) `dbplyr_291`) `dbplyr_292`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:45 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:45 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_293`) `dbplyr_294`
ORDER BY `date`) `dbplyr_295`) `dbplyr_296`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:45 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:45 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:45 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#3970 - cust_prospect_ind.nullCount#3969) > 0)
19/07/31 17:07:45 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#3975 - visit_device_type.nullCount#3974) > 0)
19/07/31 17:07:45 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#3968 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#3967))
19/07/31 17:07:45 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#3973 <= All Devices) && (All Devices <= visit_device_type.upperBound#3972))
19/07/31 17:07:45 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:45 INFO DAGScheduler: Got job 77 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:45 INFO DAGScheduler: Final stage: ResultStage 115 (collect at utils.scala:204)
19/07/31 17:07:45 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:45 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:45 INFO DAGScheduler: Submitting ResultStage 115 (MapPartitionsRDD[356] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:45 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 72.1 KB, free 910.0 MB)
19/07/31 17:07:45 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.0 MB)
19/07/31 17:07:45 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:07:45 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 115 (MapPartitionsRDD[356] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:45 INFO TaskSchedulerImpl: Adding task set 115.0 with 1 tasks
19/07/31 17:07:45 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 223, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:45 INFO Executor: Running task 0.0 in stage 115.0 (TID 223)
19/07/31 17:07:45 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:45 INFO Executor: Finished task 0.0 in stage 115.0 (TID 223). 7542 bytes result sent to driver
19/07/31 17:07:45 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 223) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:07:45 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool 
19/07/31 17:07:45 INFO DAGScheduler: ResultStage 115 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:07:45 INFO DAGScheduler: Job 77 finished: collect at utils.scala:204, took 0.009487 s
19/07/31 17:07:45 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:45 INFO DAGScheduler: Registering RDD 357 (collect at utils.scala:204)
19/07/31 17:07:45 INFO DAGScheduler: Got job 78 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:45 INFO DAGScheduler: Final stage: ResultStage 117 (collect at utils.scala:204)
19/07/31 17:07:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 116)
19/07/31 17:07:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 116)
19/07/31 17:07:45 INFO DAGScheduler: Submitting ShuffleMapStage 116 (MapPartitionsRDD[357] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:45 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 74.5 KB, free 909.9 MB)
19/07/31 17:07:45 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.9 MB)
19/07/31 17:07:45 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.7 MB)
19/07/31 17:07:45 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 116 (MapPartitionsRDD[357] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:45 INFO TaskSchedulerImpl: Adding task set 116.0 with 1 tasks
19/07/31 17:07:45 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 224, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:45 INFO Executor: Running task 0.0 in stage 116.0 (TID 224)
19/07/31 17:07:45 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:45 INFO Executor: Finished task 0.0 in stage 116.0 (TID 224). 1687 bytes result sent to driver
19/07/31 17:07:45 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 224) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:07:45 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool 
19/07/31 17:07:45 INFO DAGScheduler: ShuffleMapStage 116 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:07:45 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:45 INFO DAGScheduler: running: Set()
19/07/31 17:07:45 INFO DAGScheduler: waiting: Set(ResultStage 117)
19/07/31 17:07:45 INFO DAGScheduler: failed: Set()
19/07/31 17:07:45 INFO DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[360] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:45 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 16.8 KB, free 909.9 MB)
19/07/31 17:07:45 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.9 MB)
19/07/31 17:07:45 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:07:45 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:45 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 117 (MapPartitionsRDD[360] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:45 INFO TaskSchedulerImpl: Adding task set 117.0 with 4 tasks
19/07/31 17:07:45 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 225, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:45 INFO TaskSetManager: Starting task 1.0 in stage 117.0 (TID 226, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:45 INFO TaskSetManager: Starting task 2.0 in stage 117.0 (TID 227, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:45 INFO TaskSetManager: Starting task 3.0 in stage 117.0 (TID 228, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:45 INFO Executor: Running task 0.0 in stage 117.0 (TID 225)
19/07/31 17:07:45 INFO Executor: Running task 1.0 in stage 117.0 (TID 226)
19/07/31 17:07:45 INFO Executor: Running task 3.0 in stage 117.0 (TID 228)
19/07/31 17:07:45 INFO Executor: Running task 2.0 in stage 117.0 (TID 227)
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:45 INFO Executor: Finished task 3.0 in stage 117.0 (TID 228). 2362 bytes result sent to driver
19/07/31 17:07:45 INFO Executor: Finished task 2.0 in stage 117.0 (TID 227). 2390 bytes result sent to driver
19/07/31 17:07:45 INFO Executor: Finished task 0.0 in stage 117.0 (TID 225). 2382 bytes result sent to driver
19/07/31 17:07:45 INFO TaskSetManager: Finished task 3.0 in stage 117.0 (TID 228) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:07:45 INFO TaskSetManager: Finished task 2.0 in stage 117.0 (TID 227) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:07:45 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 225) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:45 INFO Executor: Finished task 1.0 in stage 117.0 (TID 226). 2403 bytes result sent to driver
19/07/31 17:07:45 INFO TaskSetManager: Finished task 1.0 in stage 117.0 (TID 226) in 7 ms on localhost (executor driver) (4/4)
19/07/31 17:07:45 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool 
19/07/31 17:07:45 INFO DAGScheduler: ResultStage 117 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:07:45 INFO DAGScheduler: Job 78 finished: collect at utils.scala:204, took 0.025910 s
19/07/31 17:07:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_297`) `dbplyr_298`
ORDER BY `date`) `dbplyr_299`) `dbplyr_300`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:45 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:45 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_301`) `dbplyr_302`
ORDER BY `date`) `dbplyr_303`) `dbplyr_304`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:45 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:45 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:45 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4068 - cust_prospect_ind.nullCount#4067) > 0)
19/07/31 17:07:45 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4073 - visit_device_type.nullCount#4072) > 0)
19/07/31 17:07:45 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4066 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4065))
19/07/31 17:07:45 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4071 <= All Devices) && (All Devices <= visit_device_type.upperBound#4070))
19/07/31 17:07:45 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:45 INFO DAGScheduler: Got job 79 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:45 INFO DAGScheduler: Final stage: ResultStage 118 (collect at utils.scala:204)
19/07/31 17:07:45 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:45 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:45 INFO DAGScheduler: Submitting ResultStage 118 (MapPartitionsRDD[365] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:45 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 72.1 KB, free 909.8 MB)
19/07/31 17:07:45 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 30.4 KB, free 909.8 MB)
19/07/31 17:07:45 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 127.0.0.1:53949 (size: 30.4 KB, free: 911.7 MB)
19/07/31 17:07:45 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 118 (MapPartitionsRDD[365] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:45 INFO TaskSchedulerImpl: Adding task set 118.0 with 1 tasks
19/07/31 17:07:45 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 229, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:45 INFO Executor: Running task 0.0 in stage 118.0 (TID 229)
19/07/31 17:07:45 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:45 INFO Executor: Finished task 0.0 in stage 118.0 (TID 229). 7542 bytes result sent to driver
19/07/31 17:07:45 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 229) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:07:45 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool 
19/07/31 17:07:45 INFO DAGScheduler: ResultStage 118 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:07:45 INFO DAGScheduler: Job 79 finished: collect at utils.scala:204, took 0.011971 s
19/07/31 17:07:45 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:45 INFO DAGScheduler: Registering RDD 366 (collect at utils.scala:204)
19/07/31 17:07:45 INFO DAGScheduler: Got job 80 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:45 INFO DAGScheduler: Final stage: ResultStage 120 (collect at utils.scala:204)
19/07/31 17:07:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 119)
19/07/31 17:07:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 119)
19/07/31 17:07:45 INFO DAGScheduler: Submitting ShuffleMapStage 119 (MapPartitionsRDD[366] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:45 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 74.5 KB, free 909.7 MB)
19/07/31 17:07:45 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 31.7 KB, free 909.7 MB)
19/07/31 17:07:45 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 127.0.0.1:53949 (size: 31.7 KB, free: 911.7 MB)
19/07/31 17:07:45 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 119 (MapPartitionsRDD[366] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:45 INFO TaskSchedulerImpl: Adding task set 119.0 with 1 tasks
19/07/31 17:07:45 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 230, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:45 INFO Executor: Running task 0.0 in stage 119.0 (TID 230)
19/07/31 17:07:45 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:45 INFO Executor: Finished task 0.0 in stage 119.0 (TID 230). 1687 bytes result sent to driver
19/07/31 17:07:45 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 230) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:07:45 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
19/07/31 17:07:45 INFO DAGScheduler: ShuffleMapStage 119 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:07:45 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:45 INFO DAGScheduler: running: Set()
19/07/31 17:07:45 INFO DAGScheduler: waiting: Set(ResultStage 120)
19/07/31 17:07:45 INFO DAGScheduler: failed: Set()
19/07/31 17:07:45 INFO DAGScheduler: Submitting ResultStage 120 (MapPartitionsRDD[369] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:45 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 16.8 KB, free 909.7 MB)
19/07/31 17:07:45 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.6 MB)
19/07/31 17:07:45 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:07:45 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:45 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 120 (MapPartitionsRDD[369] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:45 INFO TaskSchedulerImpl: Adding task set 120.0 with 4 tasks
19/07/31 17:07:45 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 231, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:45 INFO TaskSetManager: Starting task 1.0 in stage 120.0 (TID 232, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:45 INFO TaskSetManager: Starting task 2.0 in stage 120.0 (TID 233, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:45 INFO TaskSetManager: Starting task 3.0 in stage 120.0 (TID 234, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:45 INFO Executor: Running task 1.0 in stage 120.0 (TID 232)
19/07/31 17:07:45 INFO Executor: Running task 0.0 in stage 120.0 (TID 231)
19/07/31 17:07:45 INFO Executor: Running task 2.0 in stage 120.0 (TID 233)
19/07/31 17:07:45 INFO Executor: Running task 3.0 in stage 120.0 (TID 234)
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:45 INFO Executor: Finished task 3.0 in stage 120.0 (TID 234). 2362 bytes result sent to driver
19/07/31 17:07:45 INFO Executor: Finished task 2.0 in stage 120.0 (TID 233). 2390 bytes result sent to driver
19/07/31 17:07:45 INFO Executor: Finished task 1.0 in stage 120.0 (TID 232). 2403 bytes result sent to driver
19/07/31 17:07:45 INFO Executor: Finished task 0.0 in stage 120.0 (TID 231). 2382 bytes result sent to driver
19/07/31 17:07:45 INFO TaskSetManager: Finished task 2.0 in stage 120.0 (TID 233) in 7 ms on localhost (executor driver) (1/4)
19/07/31 17:07:45 INFO TaskSetManager: Finished task 1.0 in stage 120.0 (TID 232) in 7 ms on localhost (executor driver) (2/4)
19/07/31 17:07:45 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 231) in 8 ms on localhost (executor driver) (3/4)
19/07/31 17:07:45 INFO TaskSetManager: Finished task 3.0 in stage 120.0 (TID 234) in 8 ms on localhost (executor driver) (4/4)
19/07/31 17:07:45 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool 
19/07/31 17:07:45 INFO DAGScheduler: ResultStage 120 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:07:45 INFO DAGScheduler: Job 80 finished: collect at utils.scala:204, took 0.027108 s
19/07/31 17:07:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_305`) `dbplyr_306`
ORDER BY `date`) `dbplyr_307`) `dbplyr_308`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Desktop"))
19/07/31 17:07:46 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_309`) `dbplyr_310`
ORDER BY `date`) `dbplyr_311`) `dbplyr_312`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Desktop"))
19/07/31 17:07:46 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:46 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4166 - cust_prospect_ind.nullCount#4165) > 0)
19/07/31 17:07:46 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4171 - visit_device_type.nullCount#4170) > 0)
19/07/31 17:07:46 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#4164 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#4163))
19/07/31 17:07:46 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#4169 <= Desktop) && (Desktop <= visit_device_type.upperBound#4168))
19/07/31 17:07:46 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:46 INFO DAGScheduler: Got job 81 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:46 INFO DAGScheduler: Final stage: ResultStage 121 (collect at utils.scala:204)
19/07/31 17:07:46 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:46 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:46 INFO DAGScheduler: Submitting ResultStage 121 (MapPartitionsRDD[374] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:46 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 72.1 KB, free 909.6 MB)
19/07/31 17:07:46 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.5 MB)
19/07/31 17:07:46 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.6 MB)
19/07/31 17:07:46 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 121 (MapPartitionsRDD[374] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:46 INFO TaskSchedulerImpl: Adding task set 121.0 with 1 tasks
19/07/31 17:07:46 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 235, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:46 INFO Executor: Running task 0.0 in stage 121.0 (TID 235)
19/07/31 17:07:46 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:46 INFO Executor: Finished task 0.0 in stage 121.0 (TID 235). 7068 bytes result sent to driver
19/07/31 17:07:46 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 235) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:07:46 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool 
19/07/31 17:07:46 INFO DAGScheduler: ResultStage 121 (collect at utils.scala:204) finished in 0.004 s
19/07/31 17:07:46 INFO DAGScheduler: Job 81 finished: collect at utils.scala:204, took 0.008198 s
19/07/31 17:07:46 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:46 INFO DAGScheduler: Registering RDD 375 (collect at utils.scala:204)
19/07/31 17:07:46 INFO DAGScheduler: Got job 82 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:46 INFO DAGScheduler: Final stage: ResultStage 123 (collect at utils.scala:204)
19/07/31 17:07:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 122)
19/07/31 17:07:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 122)
19/07/31 17:07:46 INFO DAGScheduler: Submitting ShuffleMapStage 122 (MapPartitionsRDD[375] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:46 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 74.5 KB, free 909.5 MB)
19/07/31 17:07:46 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.4 MB)
19/07/31 17:07:46 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.6 MB)
19/07/31 17:07:46 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 122 (MapPartitionsRDD[375] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:46 INFO TaskSchedulerImpl: Adding task set 122.0 with 1 tasks
19/07/31 17:07:46 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 236, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:46 INFO Executor: Running task 0.0 in stage 122.0 (TID 236)
19/07/31 17:07:46 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:46 INFO Executor: Finished task 0.0 in stage 122.0 (TID 236). 1687 bytes result sent to driver
19/07/31 17:07:46 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 236) in 82 ms on localhost (executor driver) (1/1)
19/07/31 17:07:46 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool 
19/07/31 17:07:46 INFO DAGScheduler: ShuffleMapStage 122 (collect at utils.scala:204) finished in 0.083 s
19/07/31 17:07:46 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:46 INFO DAGScheduler: running: Set()
19/07/31 17:07:46 INFO DAGScheduler: waiting: Set(ResultStage 123)
19/07/31 17:07:46 INFO DAGScheduler: failed: Set()
19/07/31 17:07:46 INFO DAGScheduler: Submitting ResultStage 123 (MapPartitionsRDD[378] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:46 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 16.8 KB, free 909.4 MB)
19/07/31 17:07:46 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 8.1 KB, free 909.4 MB)
19/07/31 17:07:46 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 127.0.0.1:53949 (size: 8.1 KB, free: 911.6 MB)
19/07/31 17:07:46 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:46 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 123 (MapPartitionsRDD[378] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:46 INFO TaskSchedulerImpl: Adding task set 123.0 with 4 tasks
19/07/31 17:07:46 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 237, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:46 INFO TaskSetManager: Starting task 1.0 in stage 123.0 (TID 238, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:46 INFO TaskSetManager: Starting task 2.0 in stage 123.0 (TID 239, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:46 INFO TaskSetManager: Starting task 3.0 in stage 123.0 (TID 240, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:46 INFO Executor: Running task 0.0 in stage 123.0 (TID 237)
19/07/31 17:07:46 INFO Executor: Running task 2.0 in stage 123.0 (TID 239)
19/07/31 17:07:46 INFO Executor: Running task 3.0 in stage 123.0 (TID 240)
19/07/31 17:07:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:46 INFO Executor: Running task 1.0 in stage 123.0 (TID 238)
19/07/31 17:07:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:46 INFO Executor: Finished task 0.0 in stage 123.0 (TID 237). 2396 bytes result sent to driver
19/07/31 17:07:46 INFO Executor: Finished task 2.0 in stage 123.0 (TID 239). 2391 bytes result sent to driver
19/07/31 17:07:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:46 INFO Executor: Finished task 3.0 in stage 123.0 (TID 240). 2371 bytes result sent to driver
19/07/31 17:07:46 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 237) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:07:46 INFO TaskSetManager: Finished task 2.0 in stage 123.0 (TID 239) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:07:46 INFO TaskSetManager: Finished task 3.0 in stage 123.0 (TID 240) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:07:46 INFO Executor: Finished task 1.0 in stage 123.0 (TID 238). 2389 bytes result sent to driver
19/07/31 17:07:46 INFO TaskSetManager: Finished task 1.0 in stage 123.0 (TID 238) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:07:46 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool 
19/07/31 17:07:46 INFO DAGScheduler: ResultStage 123 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:07:46 INFO DAGScheduler: Job 82 finished: collect at utils.scala:204, took 0.099293 s
19/07/31 17:07:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_313`) `dbplyr_314`
ORDER BY `date`) `dbplyr_315`) `dbplyr_316`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:46 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_317`) `dbplyr_318`
ORDER BY `date`) `dbplyr_319`) `dbplyr_320`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:46 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:46 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4264 - cust_prospect_ind.nullCount#4263) > 0)
19/07/31 17:07:46 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4269 - visit_device_type.nullCount#4268) > 0)
19/07/31 17:07:46 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4262 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4261))
19/07/31 17:07:46 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4267 <= All Devices) && (All Devices <= visit_device_type.upperBound#4266))
19/07/31 17:07:46 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:46 INFO DAGScheduler: Got job 83 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:46 INFO DAGScheduler: Final stage: ResultStage 124 (collect at utils.scala:204)
19/07/31 17:07:46 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:46 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:46 INFO DAGScheduler: Submitting ResultStage 124 (MapPartitionsRDD[383] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:46 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 72.1 KB, free 909.3 MB)
19/07/31 17:07:46 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 30.4 KB, free 909.3 MB)
19/07/31 17:07:46 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 127.0.0.1:53949 (size: 30.4 KB, free: 911.6 MB)
19/07/31 17:07:46 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 124 (MapPartitionsRDD[383] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:46 INFO TaskSchedulerImpl: Adding task set 124.0 with 1 tasks
19/07/31 17:07:46 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 241, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:46 INFO Executor: Running task 0.0 in stage 124.0 (TID 241)
19/07/31 17:07:46 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:46 INFO Executor: Finished task 0.0 in stage 124.0 (TID 241). 7542 bytes result sent to driver
19/07/31 17:07:46 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 241) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:07:46 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool 
19/07/31 17:07:46 INFO DAGScheduler: ResultStage 124 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:07:46 INFO DAGScheduler: Job 83 finished: collect at utils.scala:204, took 0.012626 s
19/07/31 17:07:46 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:46 INFO DAGScheduler: Registering RDD 384 (collect at utils.scala:204)
19/07/31 17:07:46 INFO DAGScheduler: Got job 84 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:46 INFO DAGScheduler: Final stage: ResultStage 126 (collect at utils.scala:204)
19/07/31 17:07:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 125)
19/07/31 17:07:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 125)
19/07/31 17:07:46 INFO DAGScheduler: Submitting ShuffleMapStage 125 (MapPartitionsRDD[384] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:46 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 74.5 KB, free 909.2 MB)
19/07/31 17:07:46 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.2 MB)
19/07/31 17:07:46 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.5 MB)
19/07/31 17:07:46 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 125 (MapPartitionsRDD[384] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:46 INFO TaskSchedulerImpl: Adding task set 125.0 with 1 tasks
19/07/31 17:07:46 INFO TaskSetManager: Starting task 0.0 in stage 125.0 (TID 242, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:46 INFO Executor: Running task 0.0 in stage 125.0 (TID 242)
19/07/31 17:07:46 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:46 INFO Executor: Finished task 0.0 in stage 125.0 (TID 242). 1687 bytes result sent to driver
19/07/31 17:07:46 INFO TaskSetManager: Finished task 0.0 in stage 125.0 (TID 242) in 12 ms on localhost (executor driver) (1/1)
19/07/31 17:07:46 INFO TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool 
19/07/31 17:07:46 INFO DAGScheduler: ShuffleMapStage 125 (collect at utils.scala:204) finished in 0.014 s
19/07/31 17:07:46 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:46 INFO DAGScheduler: running: Set()
19/07/31 17:07:46 INFO DAGScheduler: waiting: Set(ResultStage 126)
19/07/31 17:07:46 INFO DAGScheduler: failed: Set()
19/07/31 17:07:46 INFO DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[387] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:46 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 16.8 KB, free 909.2 MB)
19/07/31 17:07:46 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.2 MB)
19/07/31 17:07:46 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.5 MB)
19/07/31 17:07:46 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:46 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 126 (MapPartitionsRDD[387] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:46 INFO TaskSchedulerImpl: Adding task set 126.0 with 4 tasks
19/07/31 17:07:46 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 243, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:46 INFO TaskSetManager: Starting task 1.0 in stage 126.0 (TID 244, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:46 INFO TaskSetManager: Starting task 2.0 in stage 126.0 (TID 245, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:46 INFO TaskSetManager: Starting task 3.0 in stage 126.0 (TID 246, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:46 INFO Executor: Running task 0.0 in stage 126.0 (TID 243)
19/07/31 17:07:46 INFO Executor: Running task 1.0 in stage 126.0 (TID 244)
19/07/31 17:07:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:46 INFO Executor: Finished task 1.0 in stage 126.0 (TID 244). 2403 bytes result sent to driver
19/07/31 17:07:46 INFO Executor: Running task 2.0 in stage 126.0 (TID 245)
19/07/31 17:07:46 INFO Executor: Finished task 0.0 in stage 126.0 (TID 243). 2382 bytes result sent to driver
19/07/31 17:07:46 INFO Executor: Running task 3.0 in stage 126.0 (TID 246)
19/07/31 17:07:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:46 INFO Executor: Finished task 3.0 in stage 126.0 (TID 246). 2362 bytes result sent to driver
19/07/31 17:07:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:46 INFO Executor: Finished task 2.0 in stage 126.0 (TID 245). 2390 bytes result sent to driver
19/07/31 17:07:46 INFO TaskSetManager: Finished task 1.0 in stage 126.0 (TID 244) in 20 ms on localhost (executor driver) (1/4)
19/07/31 17:07:46 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 243) in 20 ms on localhost (executor driver) (2/4)
19/07/31 17:07:46 INFO TaskSetManager: Finished task 3.0 in stage 126.0 (TID 246) in 20 ms on localhost (executor driver) (3/4)
19/07/31 17:07:46 INFO TaskSetManager: Finished task 2.0 in stage 126.0 (TID 245) in 21 ms on localhost (executor driver) (4/4)
19/07/31 17:07:46 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool 
19/07/31 17:07:46 INFO DAGScheduler: ResultStage 126 (collect at utils.scala:204) finished in 0.040 s
19/07/31 17:07:46 INFO DAGScheduler: Job 84 finished: collect at utils.scala:204, took 0.065771 s
19/07/31 17:07:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_321`) `dbplyr_322`
ORDER BY `date`) `dbplyr_323`) `dbplyr_324`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:46 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:46 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_325`) `dbplyr_326`
ORDER BY `date`) `dbplyr_327`) `dbplyr_328`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:47 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:47 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:47 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4362 - cust_prospect_ind.nullCount#4361) > 0)
19/07/31 17:07:47 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4367 - visit_device_type.nullCount#4366) > 0)
19/07/31 17:07:47 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4360 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4359))
19/07/31 17:07:47 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4365 <= All Devices) && (All Devices <= visit_device_type.upperBound#4364))
19/07/31 17:07:47 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:47 INFO DAGScheduler: Got job 85 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:47 INFO DAGScheduler: Final stage: ResultStage 127 (collect at utils.scala:204)
19/07/31 17:07:47 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:47 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:47 INFO DAGScheduler: Submitting ResultStage 127 (MapPartitionsRDD[392] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:47 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 72.1 KB, free 909.1 MB)
19/07/31 17:07:47 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.1 MB)
19/07/31 17:07:47 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.5 MB)
19/07/31 17:07:47 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 127 (MapPartitionsRDD[392] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:47 INFO TaskSchedulerImpl: Adding task set 127.0 with 1 tasks
19/07/31 17:07:47 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 247, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:47 INFO Executor: Running task 0.0 in stage 127.0 (TID 247)
19/07/31 17:07:47 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:47 INFO Executor: Finished task 0.0 in stage 127.0 (TID 247). 7542 bytes result sent to driver
19/07/31 17:07:47 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 247) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:07:47 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool 
19/07/31 17:07:47 INFO DAGScheduler: ResultStage 127 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:07:47 INFO DAGScheduler: Job 85 finished: collect at utils.scala:204, took 0.009814 s
19/07/31 17:07:47 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:47 INFO DAGScheduler: Registering RDD 393 (collect at utils.scala:204)
19/07/31 17:07:47 INFO DAGScheduler: Got job 86 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:47 INFO DAGScheduler: Final stage: ResultStage 129 (collect at utils.scala:204)
19/07/31 17:07:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 128)
19/07/31 17:07:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 128)
19/07/31 17:07:47 INFO DAGScheduler: Submitting ShuffleMapStage 128 (MapPartitionsRDD[393] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:47 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 74.5 KB, free 909.0 MB)
19/07/31 17:07:47 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.0 MB)
19/07/31 17:07:47 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.5 MB)
19/07/31 17:07:47 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 128 (MapPartitionsRDD[393] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:47 INFO TaskSchedulerImpl: Adding task set 128.0 with 1 tasks
19/07/31 17:07:47 INFO TaskSetManager: Starting task 0.0 in stage 128.0 (TID 248, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:47 INFO Executor: Running task 0.0 in stage 128.0 (TID 248)
19/07/31 17:07:47 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:47 INFO Executor: Finished task 0.0 in stage 128.0 (TID 248). 1687 bytes result sent to driver
19/07/31 17:07:47 INFO TaskSetManager: Finished task 0.0 in stage 128.0 (TID 248) in 11 ms on localhost (executor driver) (1/1)
19/07/31 17:07:47 INFO TaskSchedulerImpl: Removed TaskSet 128.0, whose tasks have all completed, from pool 
19/07/31 17:07:47 INFO DAGScheduler: ShuffleMapStage 128 (collect at utils.scala:204) finished in 0.011 s
19/07/31 17:07:47 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:47 INFO DAGScheduler: running: Set()
19/07/31 17:07:47 INFO DAGScheduler: waiting: Set(ResultStage 129)
19/07/31 17:07:47 INFO DAGScheduler: failed: Set()
19/07/31 17:07:47 INFO DAGScheduler: Submitting ResultStage 129 (MapPartitionsRDD[396] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:47 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 16.8 KB, free 909.0 MB)
19/07/31 17:07:47 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.0 MB)
19/07/31 17:07:47 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.5 MB)
19/07/31 17:07:47 INFO SparkContext: Created broadcast 132 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:47 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 129 (MapPartitionsRDD[396] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:47 INFO TaskSchedulerImpl: Adding task set 129.0 with 4 tasks
19/07/31 17:07:47 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 249, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:47 INFO TaskSetManager: Starting task 1.0 in stage 129.0 (TID 250, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:47 INFO TaskSetManager: Starting task 2.0 in stage 129.0 (TID 251, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:47 INFO TaskSetManager: Starting task 3.0 in stage 129.0 (TID 252, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:47 INFO Executor: Running task 0.0 in stage 129.0 (TID 249)
19/07/31 17:07:47 INFO Executor: Running task 2.0 in stage 129.0 (TID 251)
19/07/31 17:07:47 INFO Executor: Running task 1.0 in stage 129.0 (TID 250)
19/07/31 17:07:47 INFO Executor: Running task 3.0 in stage 129.0 (TID 252)
19/07/31 17:07:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:47 INFO Executor: Finished task 1.0 in stage 129.0 (TID 250). 2403 bytes result sent to driver
19/07/31 17:07:47 INFO Executor: Finished task 3.0 in stage 129.0 (TID 252). 2362 bytes result sent to driver
19/07/31 17:07:47 INFO TaskSetManager: Finished task 1.0 in stage 129.0 (TID 250) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:07:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:47 INFO TaskSetManager: Finished task 3.0 in stage 129.0 (TID 252) in 4 ms on localhost (executor driver) (2/4)
19/07/31 17:07:47 INFO Executor: Finished task 2.0 in stage 129.0 (TID 251). 2390 bytes result sent to driver
19/07/31 17:07:47 INFO TaskSetManager: Finished task 2.0 in stage 129.0 (TID 251) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:07:47 INFO Executor: Finished task 0.0 in stage 129.0 (TID 249). 2382 bytes result sent to driver
19/07/31 17:07:47 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 249) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:07:47 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool 
19/07/31 17:07:47 INFO DAGScheduler: ResultStage 129 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:07:47 INFO DAGScheduler: Job 86 finished: collect at utils.scala:204, took 0.027135 s
19/07/31 17:07:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_329`) `dbplyr_330`
ORDER BY `date`) `dbplyr_331`) `dbplyr_332`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Tablet"))
19/07/31 17:07:47 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:47 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_333`) `dbplyr_334`
ORDER BY `date`) `dbplyr_335`) `dbplyr_336`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Tablet"))
19/07/31 17:07:47 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:47 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:47 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4460 - cust_prospect_ind.nullCount#4459) > 0)
19/07/31 17:07:47 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4465 - visit_device_type.nullCount#4464) > 0)
19/07/31 17:07:47 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#4458 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#4457))
19/07/31 17:07:47 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#4463 <= Tablet) && (Tablet <= visit_device_type.upperBound#4462))
19/07/31 17:07:47 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:47 INFO DAGScheduler: Got job 87 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:47 INFO DAGScheduler: Final stage: ResultStage 130 (collect at utils.scala:204)
19/07/31 17:07:47 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:47 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:47 INFO DAGScheduler: Submitting ResultStage 130 (MapPartitionsRDD[401] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:47 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 72.1 KB, free 908.9 MB)
19/07/31 17:07:47 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 30.5 KB, free 908.9 MB)
19/07/31 17:07:47 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.4 MB)
19/07/31 17:07:47 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 130 (MapPartitionsRDD[401] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:47 INFO TaskSchedulerImpl: Adding task set 130.0 with 1 tasks
19/07/31 17:07:47 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 253, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:47 INFO Executor: Running task 0.0 in stage 130.0 (TID 253)
19/07/31 17:07:47 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:47 INFO Executor: Finished task 0.0 in stage 130.0 (TID 253). 6512 bytes result sent to driver
19/07/31 17:07:47 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 253) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:07:47 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool 
19/07/31 17:07:47 INFO DAGScheduler: ResultStage 130 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:07:47 INFO DAGScheduler: Job 87 finished: collect at utils.scala:204, took 0.012074 s
19/07/31 17:07:47 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:47 INFO DAGScheduler: Registering RDD 402 (collect at utils.scala:204)
19/07/31 17:07:47 INFO DAGScheduler: Got job 88 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:47 INFO DAGScheduler: Final stage: ResultStage 132 (collect at utils.scala:204)
19/07/31 17:07:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 131)
19/07/31 17:07:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 131)
19/07/31 17:07:47 INFO DAGScheduler: Submitting ShuffleMapStage 131 (MapPartitionsRDD[402] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:47 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 74.5 KB, free 908.8 MB)
19/07/31 17:07:47 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 31.8 KB, free 908.8 MB)
19/07/31 17:07:47 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.4 MB)
19/07/31 17:07:47 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 131 (MapPartitionsRDD[402] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:47 INFO TaskSchedulerImpl: Adding task set 131.0 with 1 tasks
19/07/31 17:07:47 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 254, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:47 INFO Executor: Running task 0.0 in stage 131.0 (TID 254)
19/07/31 17:07:47 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:47 INFO Executor: Finished task 0.0 in stage 131.0 (TID 254). 1687 bytes result sent to driver
19/07/31 17:07:47 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 254) in 11 ms on localhost (executor driver) (1/1)
19/07/31 17:07:47 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool 
19/07/31 17:07:47 INFO DAGScheduler: ShuffleMapStage 131 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:07:47 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:47 INFO DAGScheduler: running: Set()
19/07/31 17:07:47 INFO DAGScheduler: waiting: Set(ResultStage 132)
19/07/31 17:07:47 INFO DAGScheduler: failed: Set()
19/07/31 17:07:47 INFO DAGScheduler: Submitting ResultStage 132 (MapPartitionsRDD[405] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:47 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 16.8 KB, free 908.7 MB)
19/07/31 17:07:47 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 8.0 KB, free 908.7 MB)
19/07/31 17:07:47 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.4 MB)
19/07/31 17:07:47 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:47 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 132 (MapPartitionsRDD[405] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:47 INFO TaskSchedulerImpl: Adding task set 132.0 with 4 tasks
19/07/31 17:07:47 INFO TaskSetManager: Starting task 0.0 in stage 132.0 (TID 255, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:47 INFO TaskSetManager: Starting task 1.0 in stage 132.0 (TID 256, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:47 INFO TaskSetManager: Starting task 2.0 in stage 132.0 (TID 257, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:47 INFO TaskSetManager: Starting task 3.0 in stage 132.0 (TID 258, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:47 INFO Executor: Running task 2.0 in stage 132.0 (TID 257)
19/07/31 17:07:47 INFO Executor: Running task 3.0 in stage 132.0 (TID 258)
19/07/31 17:07:47 INFO Executor: Running task 1.0 in stage 132.0 (TID 256)
19/07/31 17:07:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:47 INFO Executor: Running task 0.0 in stage 132.0 (TID 255)
19/07/31 17:07:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:47 INFO Executor: Finished task 1.0 in stage 132.0 (TID 256). 2340 bytes result sent to driver
19/07/31 17:07:47 INFO Executor: Finished task 2.0 in stage 132.0 (TID 257). 2362 bytes result sent to driver
19/07/31 17:07:47 INFO Executor: Finished task 3.0 in stage 132.0 (TID 258). 2336 bytes result sent to driver
19/07/31 17:07:47 INFO TaskSetManager: Finished task 1.0 in stage 132.0 (TID 256) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:07:47 INFO TaskSetManager: Finished task 3.0 in stage 132.0 (TID 258) in 4 ms on localhost (executor driver) (2/4)
19/07/31 17:07:47 INFO TaskSetManager: Finished task 2.0 in stage 132.0 (TID 257) in 4 ms on localhost (executor driver) (3/4)
19/07/31 17:07:47 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:47 INFO Executor: Finished task 0.0 in stage 132.0 (TID 255). 2357 bytes result sent to driver
19/07/31 17:07:47 INFO TaskSetManager: Finished task 0.0 in stage 132.0 (TID 255) in 7 ms on localhost (executor driver) (4/4)
19/07/31 17:07:47 INFO TaskSchedulerImpl: Removed TaskSet 132.0, whose tasks have all completed, from pool 
19/07/31 17:07:47 INFO DAGScheduler: ResultStage 132 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:07:47 INFO DAGScheduler: Job 88 finished: collect at utils.scala:204, took 0.029164 s
19/07/31 17:07:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_337`) `dbplyr_338`
ORDER BY `date`) `dbplyr_339`) `dbplyr_340`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:47 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:47 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:47 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_341`) `dbplyr_342`
ORDER BY `date`) `dbplyr_343`) `dbplyr_344`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:47 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:47 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:47 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4558 - cust_prospect_ind.nullCount#4557) > 0)
19/07/31 17:07:47 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4563 - visit_device_type.nullCount#4562) > 0)
19/07/31 17:07:47 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4556 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4555))
19/07/31 17:07:47 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4561 <= All Devices) && (All Devices <= visit_device_type.upperBound#4560))
19/07/31 17:07:47 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:47 INFO DAGScheduler: Got job 89 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:47 INFO DAGScheduler: Final stage: ResultStage 133 (collect at utils.scala:204)
19/07/31 17:07:47 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:47 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:47 INFO DAGScheduler: Submitting ResultStage 133 (MapPartitionsRDD[410] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:47 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 72.1 KB, free 908.7 MB)
19/07/31 17:07:47 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 30.4 KB, free 908.6 MB)
19/07/31 17:07:48 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 127.0.0.1:53949 (size: 30.4 KB, free: 911.4 MB)
19/07/31 17:07:48 INFO SparkContext: Created broadcast 136 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 133 (MapPartitionsRDD[410] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:48 INFO TaskSchedulerImpl: Adding task set 133.0 with 1 tasks
19/07/31 17:07:48 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 259, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:48 INFO Executor: Running task 0.0 in stage 133.0 (TID 259)
19/07/31 17:07:48 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:48 INFO Executor: Finished task 0.0 in stage 133.0 (TID 259). 7542 bytes result sent to driver
19/07/31 17:07:48 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 259) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:07:48 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool 
19/07/31 17:07:48 INFO DAGScheduler: ResultStage 133 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:07:48 INFO DAGScheduler: Job 89 finished: collect at utils.scala:204, took 0.016667 s
19/07/31 17:07:48 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:48 INFO DAGScheduler: Registering RDD 411 (collect at utils.scala:204)
19/07/31 17:07:48 INFO DAGScheduler: Got job 90 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:48 INFO DAGScheduler: Final stage: ResultStage 135 (collect at utils.scala:204)
19/07/31 17:07:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 134)
19/07/31 17:07:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 134)
19/07/31 17:07:48 INFO DAGScheduler: Submitting ShuffleMapStage 134 (MapPartitionsRDD[411] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:48 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 74.5 KB, free 908.6 MB)
19/07/31 17:07:48 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 31.7 KB, free 908.5 MB)
19/07/31 17:07:48 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 127.0.0.1:53949 (size: 31.7 KB, free: 911.3 MB)
19/07/31 17:07:48 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 134 (MapPartitionsRDD[411] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:48 INFO TaskSchedulerImpl: Adding task set 134.0 with 1 tasks
19/07/31 17:07:48 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 260, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:48 INFO Executor: Running task 0.0 in stage 134.0 (TID 260)
19/07/31 17:07:48 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:48 INFO Executor: Finished task 0.0 in stage 134.0 (TID 260). 1687 bytes result sent to driver
19/07/31 17:07:48 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 260) in 26 ms on localhost (executor driver) (1/1)
19/07/31 17:07:48 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool 
19/07/31 17:07:48 INFO DAGScheduler: ShuffleMapStage 134 (collect at utils.scala:204) finished in 0.026 s
19/07/31 17:07:48 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:48 INFO DAGScheduler: running: Set()
19/07/31 17:07:48 INFO DAGScheduler: waiting: Set(ResultStage 135)
19/07/31 17:07:48 INFO DAGScheduler: failed: Set()
19/07/31 17:07:48 INFO DAGScheduler: Submitting ResultStage 135 (MapPartitionsRDD[414] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:48 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 16.8 KB, free 908.5 MB)
19/07/31 17:07:48 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 8.0 KB, free 908.5 MB)
19/07/31 17:07:48 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.3 MB)
19/07/31 17:07:48 INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:48 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 135 (MapPartitionsRDD[414] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:48 INFO TaskSchedulerImpl: Adding task set 135.0 with 4 tasks
19/07/31 17:07:48 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 261, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:48 INFO TaskSetManager: Starting task 1.0 in stage 135.0 (TID 262, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:48 INFO TaskSetManager: Starting task 2.0 in stage 135.0 (TID 263, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:48 INFO TaskSetManager: Starting task 3.0 in stage 135.0 (TID 264, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:48 INFO Executor: Running task 1.0 in stage 135.0 (TID 262)
19/07/31 17:07:48 INFO Executor: Running task 2.0 in stage 135.0 (TID 263)
19/07/31 17:07:48 INFO Executor: Running task 3.0 in stage 135.0 (TID 264)
19/07/31 17:07:48 INFO Executor: Running task 0.0 in stage 135.0 (TID 261)
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:48 INFO Executor: Finished task 2.0 in stage 135.0 (TID 263). 2390 bytes result sent to driver
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/07/31 17:07:48 INFO Executor: Finished task 1.0 in stage 135.0 (TID 262). 2403 bytes result sent to driver
19/07/31 17:07:48 INFO Executor: Finished task 0.0 in stage 135.0 (TID 261). 2382 bytes result sent to driver
19/07/31 17:07:48 INFO TaskSetManager: Finished task 2.0 in stage 135.0 (TID 263) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:07:48 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 261) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:07:48 INFO TaskSetManager: Finished task 1.0 in stage 135.0 (TID 262) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:07:48 INFO Executor: Finished task 3.0 in stage 135.0 (TID 264). 2362 bytes result sent to driver
19/07/31 17:07:48 INFO TaskSetManager: Finished task 3.0 in stage 135.0 (TID 264) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:07:48 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool 
19/07/31 17:07:48 INFO DAGScheduler: ResultStage 135 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:07:48 INFO DAGScheduler: Job 90 finished: collect at utils.scala:204, took 0.041368 s
19/07/31 17:07:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_345`) `dbplyr_346`
ORDER BY `date`) `dbplyr_347`) `dbplyr_348`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:48 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:48 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_349`) `dbplyr_350`
ORDER BY `date`) `dbplyr_351`) `dbplyr_352`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:48 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:48 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:48 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4656 - cust_prospect_ind.nullCount#4655) > 0)
19/07/31 17:07:48 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4661 - visit_device_type.nullCount#4660) > 0)
19/07/31 17:07:48 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4654 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4653))
19/07/31 17:07:48 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4659 <= All Devices) && (All Devices <= visit_device_type.upperBound#4658))
19/07/31 17:07:48 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:48 INFO DAGScheduler: Got job 91 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:48 INFO DAGScheduler: Final stage: ResultStage 136 (collect at utils.scala:204)
19/07/31 17:07:48 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:48 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:48 INFO DAGScheduler: Submitting ResultStage 136 (MapPartitionsRDD[419] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:48 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 72.1 KB, free 908.4 MB)
19/07/31 17:07:48 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 30.5 KB, free 908.4 MB)
19/07/31 17:07:48 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.3 MB)
19/07/31 17:07:48 INFO SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 136 (MapPartitionsRDD[419] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:48 INFO TaskSchedulerImpl: Adding task set 136.0 with 1 tasks
19/07/31 17:07:48 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 265, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:48 INFO Executor: Running task 0.0 in stage 136.0 (TID 265)
19/07/31 17:07:48 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:48 INFO Executor: Finished task 0.0 in stage 136.0 (TID 265). 7542 bytes result sent to driver
19/07/31 17:07:48 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 265) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:07:48 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool 
19/07/31 17:07:48 INFO DAGScheduler: ResultStage 136 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:07:48 INFO DAGScheduler: Job 91 finished: collect at utils.scala:204, took 0.011208 s
19/07/31 17:07:48 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:48 INFO DAGScheduler: Registering RDD 420 (collect at utils.scala:204)
19/07/31 17:07:48 INFO DAGScheduler: Got job 92 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:48 INFO DAGScheduler: Final stage: ResultStage 138 (collect at utils.scala:204)
19/07/31 17:07:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 137)
19/07/31 17:07:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 137)
19/07/31 17:07:48 INFO DAGScheduler: Submitting ShuffleMapStage 137 (MapPartitionsRDD[420] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:48 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 74.5 KB, free 908.3 MB)
19/07/31 17:07:48 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 31.8 KB, free 908.3 MB)
19/07/31 17:07:48 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.3 MB)
19/07/31 17:07:48 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 137 (MapPartitionsRDD[420] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:48 INFO TaskSchedulerImpl: Adding task set 137.0 with 1 tasks
19/07/31 17:07:48 INFO TaskSetManager: Starting task 0.0 in stage 137.0 (TID 266, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:48 INFO Executor: Running task 0.0 in stage 137.0 (TID 266)
19/07/31 17:07:48 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:48 INFO Executor: Finished task 0.0 in stage 137.0 (TID 266). 1687 bytes result sent to driver
19/07/31 17:07:48 INFO TaskSetManager: Finished task 0.0 in stage 137.0 (TID 266) in 13 ms on localhost (executor driver) (1/1)
19/07/31 17:07:48 INFO TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool 
19/07/31 17:07:48 INFO DAGScheduler: ShuffleMapStage 137 (collect at utils.scala:204) finished in 0.014 s
19/07/31 17:07:48 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:48 INFO DAGScheduler: running: Set()
19/07/31 17:07:48 INFO DAGScheduler: waiting: Set(ResultStage 138)
19/07/31 17:07:48 INFO DAGScheduler: failed: Set()
19/07/31 17:07:48 INFO DAGScheduler: Submitting ResultStage 138 (MapPartitionsRDD[423] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:48 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 16.8 KB, free 908.3 MB)
19/07/31 17:07:48 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 8.0 KB, free 908.3 MB)
19/07/31 17:07:48 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.3 MB)
19/07/31 17:07:48 INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:48 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 138 (MapPartitionsRDD[423] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:48 INFO TaskSchedulerImpl: Adding task set 138.0 with 4 tasks
19/07/31 17:07:48 INFO TaskSetManager: Starting task 0.0 in stage 138.0 (TID 267, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:48 INFO TaskSetManager: Starting task 1.0 in stage 138.0 (TID 268, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:48 INFO TaskSetManager: Starting task 2.0 in stage 138.0 (TID 269, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:48 INFO TaskSetManager: Starting task 3.0 in stage 138.0 (TID 270, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:48 INFO Executor: Running task 1.0 in stage 138.0 (TID 268)
19/07/31 17:07:48 INFO Executor: Running task 2.0 in stage 138.0 (TID 269)
19/07/31 17:07:48 INFO Executor: Running task 3.0 in stage 138.0 (TID 270)
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:48 INFO Executor: Finished task 1.0 in stage 138.0 (TID 268). 2403 bytes result sent to driver
19/07/31 17:07:48 INFO Executor: Running task 0.0 in stage 138.0 (TID 267)
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:48 INFO Executor: Finished task 2.0 in stage 138.0 (TID 269). 2433 bytes result sent to driver
19/07/31 17:07:48 INFO Executor: Finished task 3.0 in stage 138.0 (TID 270). 2362 bytes result sent to driver
19/07/31 17:07:48 INFO TaskSetManager: Finished task 1.0 in stage 138.0 (TID 268) in 13 ms on localhost (executor driver) (1/4)
19/07/31 17:07:48 INFO TaskSetManager: Finished task 2.0 in stage 138.0 (TID 269) in 12 ms on localhost (executor driver) (2/4)
19/07/31 17:07:48 INFO TaskSetManager: Finished task 3.0 in stage 138.0 (TID 270) in 13 ms on localhost (executor driver) (3/4)
19/07/31 17:07:48 INFO Executor: Finished task 0.0 in stage 138.0 (TID 267). 2382 bytes result sent to driver
19/07/31 17:07:48 INFO TaskSetManager: Finished task 0.0 in stage 138.0 (TID 267) in 15 ms on localhost (executor driver) (4/4)
19/07/31 17:07:48 INFO TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool 
19/07/31 17:07:48 INFO DAGScheduler: ResultStage 138 (collect at utils.scala:204) finished in 0.015 s
19/07/31 17:07:48 INFO DAGScheduler: Job 92 finished: collect at utils.scala:204, took 0.039059 s
19/07/31 17:07:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_353`) `dbplyr_354`
ORDER BY `date`) `dbplyr_355`) `dbplyr_356`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Tablet"))
19/07/31 17:07:48 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:48 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_357`) `dbplyr_358`
ORDER BY `date`) `dbplyr_359`) `dbplyr_360`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Tablet"))
19/07/31 17:07:48 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:48 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:48 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4754 - cust_prospect_ind.nullCount#4753) > 0)
19/07/31 17:07:48 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4759 - visit_device_type.nullCount#4758) > 0)
19/07/31 17:07:48 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#4752 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#4751))
19/07/31 17:07:48 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#4757 <= Tablet) && (Tablet <= visit_device_type.upperBound#4756))
19/07/31 17:07:48 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:48 INFO DAGScheduler: Got job 93 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:48 INFO DAGScheduler: Final stage: ResultStage 139 (collect at utils.scala:204)
19/07/31 17:07:48 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:48 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:48 INFO DAGScheduler: Submitting ResultStage 139 (MapPartitionsRDD[428] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:48 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 72.1 KB, free 908.2 MB)
19/07/31 17:07:48 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 30.5 KB, free 908.2 MB)
19/07/31 17:07:48 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.2 MB)
19/07/31 17:07:48 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 139 (MapPartitionsRDD[428] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:48 INFO TaskSchedulerImpl: Adding task set 139.0 with 1 tasks
19/07/31 17:07:48 INFO TaskSetManager: Starting task 0.0 in stage 139.0 (TID 271, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:48 INFO Executor: Running task 0.0 in stage 139.0 (TID 271)
19/07/31 17:07:48 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:48 INFO Executor: Finished task 0.0 in stage 139.0 (TID 271). 6512 bytes result sent to driver
19/07/31 17:07:48 INFO TaskSetManager: Finished task 0.0 in stage 139.0 (TID 271) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:07:48 INFO TaskSchedulerImpl: Removed TaskSet 139.0, whose tasks have all completed, from pool 
19/07/31 17:07:48 INFO DAGScheduler: ResultStage 139 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:07:48 INFO DAGScheduler: Job 93 finished: collect at utils.scala:204, took 0.015552 s
19/07/31 17:07:48 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:48 INFO DAGScheduler: Registering RDD 429 (collect at utils.scala:204)
19/07/31 17:07:48 INFO DAGScheduler: Got job 94 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:48 INFO DAGScheduler: Final stage: ResultStage 141 (collect at utils.scala:204)
19/07/31 17:07:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 140)
19/07/31 17:07:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 140)
19/07/31 17:07:48 INFO DAGScheduler: Submitting ShuffleMapStage 140 (MapPartitionsRDD[429] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:48 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 74.5 KB, free 908.1 MB)
19/07/31 17:07:48 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 31.8 KB, free 908.1 MB)
19/07/31 17:07:48 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.2 MB)
19/07/31 17:07:48 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 140 (MapPartitionsRDD[429] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:48 INFO TaskSchedulerImpl: Adding task set 140.0 with 1 tasks
19/07/31 17:07:48 INFO TaskSetManager: Starting task 0.0 in stage 140.0 (TID 272, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:48 INFO Executor: Running task 0.0 in stage 140.0 (TID 272)
19/07/31 17:07:48 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:48 INFO Executor: Finished task 0.0 in stage 140.0 (TID 272). 1687 bytes result sent to driver
19/07/31 17:07:48 INFO TaskSetManager: Finished task 0.0 in stage 140.0 (TID 272) in 13 ms on localhost (executor driver) (1/1)
19/07/31 17:07:48 INFO TaskSchedulerImpl: Removed TaskSet 140.0, whose tasks have all completed, from pool 
19/07/31 17:07:48 INFO DAGScheduler: ShuffleMapStage 140 (collect at utils.scala:204) finished in 0.013 s
19/07/31 17:07:48 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:48 INFO DAGScheduler: running: Set()
19/07/31 17:07:48 INFO DAGScheduler: waiting: Set(ResultStage 141)
19/07/31 17:07:48 INFO DAGScheduler: failed: Set()
19/07/31 17:07:48 INFO DAGScheduler: Submitting ResultStage 141 (MapPartitionsRDD[432] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:48 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 16.8 KB, free 908.1 MB)
19/07/31 17:07:48 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 8.0 KB, free 908.0 MB)
19/07/31 17:07:48 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.2 MB)
19/07/31 17:07:48 INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:48 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 141 (MapPartitionsRDD[432] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:48 INFO TaskSchedulerImpl: Adding task set 141.0 with 4 tasks
19/07/31 17:07:48 INFO TaskSetManager: Starting task 0.0 in stage 141.0 (TID 273, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:48 INFO TaskSetManager: Starting task 1.0 in stage 141.0 (TID 274, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:48 INFO TaskSetManager: Starting task 2.0 in stage 141.0 (TID 275, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:48 INFO TaskSetManager: Starting task 3.0 in stage 141.0 (TID 276, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:48 INFO Executor: Running task 1.0 in stage 141.0 (TID 274)
19/07/31 17:07:48 INFO Executor: Running task 0.0 in stage 141.0 (TID 273)
19/07/31 17:07:48 INFO Executor: Running task 2.0 in stage 141.0 (TID 275)
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:48 INFO Executor: Running task 3.0 in stage 141.0 (TID 276)
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:48 INFO Executor: Finished task 0.0 in stage 141.0 (TID 273). 2385 bytes result sent to driver
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:48 INFO Executor: Finished task 2.0 in stage 141.0 (TID 275). 2360 bytes result sent to driver
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:48 INFO TaskSetManager: Finished task 0.0 in stage 141.0 (TID 273) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:07:48 INFO TaskSetManager: Finished task 2.0 in stage 141.0 (TID 275) in 4 ms on localhost (executor driver) (2/4)
19/07/31 17:07:48 INFO Executor: Finished task 3.0 in stage 141.0 (TID 276). 2346 bytes result sent to driver
19/07/31 17:07:48 INFO Executor: Finished task 1.0 in stage 141.0 (TID 274). 2337 bytes result sent to driver
19/07/31 17:07:48 INFO TaskSetManager: Finished task 3.0 in stage 141.0 (TID 276) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:07:48 INFO TaskSetManager: Finished task 1.0 in stage 141.0 (TID 274) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:07:48 INFO TaskSchedulerImpl: Removed TaskSet 141.0, whose tasks have all completed, from pool 
19/07/31 17:07:48 INFO DAGScheduler: ResultStage 141 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:07:48 INFO DAGScheduler: Job 94 finished: collect at utils.scala:204, took 0.030748 s
19/07/31 17:07:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_361`) `dbplyr_362`
ORDER BY `date`) `dbplyr_363`) `dbplyr_364`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:49 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:49 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_365`) `dbplyr_366`
ORDER BY `date`) `dbplyr_367`) `dbplyr_368`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:49 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:49 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 911.2 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2834
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2995
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3645
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2991
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 127.0.0.1:53949 in memory (size: 8.1 KB, free: 911.2 MB)
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_144_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.2 MB)
19/07/31 17:07:49 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4852 - cust_prospect_ind.nullCount#4851) > 0)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3321
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3071
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 911.3 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3078
19/07/31 17:07:49 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4857 - visit_device_type.nullCount#4856) > 0)
19/07/31 17:07:49 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4850 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4849))
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 127.0.0.1:53949 in memory (size: 31.7 KB, free: 911.3 MB)
19/07/31 17:07:49 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4855 <= All Devices) && (All Devices <= visit_device_type.upperBound#4854))
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2833
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 127.0.0.1:53949 in memory (size: 30.4 KB, free: 911.3 MB)
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 911.4 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3395
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3075
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.4 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3159
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3721
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_139_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 911.4 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3316
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3156
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 911.4 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2914
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.4 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2910
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 911.5 MB)
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 911.5 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3155
19/07/31 17:07:49 INFO ContextCleaner: Cleaned shuffle 38
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2992
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 911.5 MB)
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 911.6 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2828
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2990
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 911.6 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3807
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.6 MB)
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 911.6 MB)
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.6 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3157
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3152
19/07/31 17:07:49 INFO ContextCleaner: Cleaned shuffle 35
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3318
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3317
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3319
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 127.0.0.1:53949 in memory (size: 31.7 KB, free: 911.7 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3808
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 911.7 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3802
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3801
19/07/31 17:07:49 INFO ContextCleaner: Cleaned shuffle 46
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3726
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2997
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3154
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2829
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2916
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3160
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2832
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3077
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3803
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3557
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3723
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2996
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2830
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3724
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3314
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3076
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2912
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3074
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3315
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 911.7 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2994
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2915
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2911
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2909
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3805
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2993
19/07/31 17:07:49 INFO ContextCleaner: Cleaned shuffle 40
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3073
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 127.0.0.1:53949 in memory (size: 30.4 KB, free: 911.8 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2836
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3720
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3643
19/07/31 17:07:49 INFO ContextCleaner: Cleaned shuffle 44
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3641
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3072
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3320
19/07/31 17:07:49 INFO ContextCleaner: Cleaned shuffle 45
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 127.0.0.1:53949 in memory (size: 31.7 KB, free: 911.9 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3722
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 911.9 MB)
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 911.9 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3158
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 127.0.0.1:53949 in memory (size: 30.4 KB, free: 912.0 MB)
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 127.0.0.1:53949 in memory (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3233
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3644
19/07/31 17:07:49 INFO ContextCleaner: Cleaned shuffle 34
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2835
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3639
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3727
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3638
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3806
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3804
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3079
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2998
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3725
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3640
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 127.0.0.1:53949 in memory (size: 30.4 KB, free: 912.0 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3800
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3642
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3153
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned shuffle 33
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2831
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 127.0.0.1:53949 in memory (size: 30.4 KB, free: 912.1 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned shuffle 36
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2917
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 127.0.0.1:53949 in memory (size: 30.5 KB, free: 912.1 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 2913
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3646
19/07/31 17:07:49 INFO ContextCleaner: Cleaned shuffle 37
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 127.0.0.1:53949 in memory (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:07:49 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 127.0.0.1:53949 in memory (size: 31.7 KB, free: 912.1 MB)
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3719
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3476
19/07/31 17:07:49 INFO ContextCleaner: Cleaned accumulator 3322
19/07/31 17:07:49 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:49 INFO DAGScheduler: Got job 95 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:49 INFO DAGScheduler: Final stage: ResultStage 142 (collect at utils.scala:204)
19/07/31 17:07:49 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:49 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:49 INFO DAGScheduler: Submitting ResultStage 142 (MapPartitionsRDD[437] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:49 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 72.1 KB, free 911.2 MB)
19/07/31 17:07:49 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.1 MB)
19/07/31 17:07:49 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 127.0.0.1:53949 (size: 30.4 KB, free: 912.1 MB)
19/07/31 17:07:49 INFO SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 142 (MapPartitionsRDD[437] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:49 INFO TaskSchedulerImpl: Adding task set 142.0 with 1 tasks
19/07/31 17:07:49 INFO TaskSetManager: Starting task 0.0 in stage 142.0 (TID 277, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:49 INFO Executor: Running task 0.0 in stage 142.0 (TID 277)
19/07/31 17:07:49 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:49 INFO Executor: Finished task 0.0 in stage 142.0 (TID 277). 7542 bytes result sent to driver
19/07/31 17:07:49 INFO TaskSetManager: Finished task 0.0 in stage 142.0 (TID 277) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:07:49 INFO TaskSchedulerImpl: Removed TaskSet 142.0, whose tasks have all completed, from pool 
19/07/31 17:07:49 INFO DAGScheduler: ResultStage 142 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:07:49 INFO DAGScheduler: Job 95 finished: collect at utils.scala:204, took 0.012858 s
19/07/31 17:07:49 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:49 INFO DAGScheduler: Registering RDD 438 (collect at utils.scala:204)
19/07/31 17:07:49 INFO DAGScheduler: Got job 96 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:49 INFO DAGScheduler: Final stage: ResultStage 144 (collect at utils.scala:204)
19/07/31 17:07:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 143)
19/07/31 17:07:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 143)
19/07/31 17:07:49 INFO DAGScheduler: Submitting ShuffleMapStage 143 (MapPartitionsRDD[438] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:49 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 74.5 KB, free 911.1 MB)
19/07/31 17:07:49 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 31.7 KB, free 911.0 MB)
19/07/31 17:07:49 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 127.0.0.1:53949 (size: 31.7 KB, free: 912.1 MB)
19/07/31 17:07:49 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 143 (MapPartitionsRDD[438] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:49 INFO TaskSchedulerImpl: Adding task set 143.0 with 1 tasks
19/07/31 17:07:49 INFO TaskSetManager: Starting task 0.0 in stage 143.0 (TID 278, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:49 INFO Executor: Running task 0.0 in stage 143.0 (TID 278)
19/07/31 17:07:49 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:49 INFO Executor: Finished task 0.0 in stage 143.0 (TID 278). 1687 bytes result sent to driver
19/07/31 17:07:49 INFO TaskSetManager: Finished task 0.0 in stage 143.0 (TID 278) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:07:49 INFO TaskSchedulerImpl: Removed TaskSet 143.0, whose tasks have all completed, from pool 
19/07/31 17:07:49 INFO DAGScheduler: ShuffleMapStage 143 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:07:49 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:49 INFO DAGScheduler: running: Set()
19/07/31 17:07:49 INFO DAGScheduler: waiting: Set(ResultStage 144)
19/07/31 17:07:49 INFO DAGScheduler: failed: Set()
19/07/31 17:07:49 INFO DAGScheduler: Submitting ResultStage 144 (MapPartitionsRDD[441] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:49 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 16.8 KB, free 911.0 MB)
19/07/31 17:07:49 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.0 MB)
19/07/31 17:07:49 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:07:49 INFO SparkContext: Created broadcast 147 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:49 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 144 (MapPartitionsRDD[441] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:49 INFO TaskSchedulerImpl: Adding task set 144.0 with 4 tasks
19/07/31 17:07:49 INFO TaskSetManager: Starting task 0.0 in stage 144.0 (TID 279, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:49 INFO TaskSetManager: Starting task 1.0 in stage 144.0 (TID 280, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:49 INFO TaskSetManager: Starting task 2.0 in stage 144.0 (TID 281, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:49 INFO TaskSetManager: Starting task 3.0 in stage 144.0 (TID 282, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:49 INFO Executor: Running task 0.0 in stage 144.0 (TID 279)
19/07/31 17:07:49 INFO Executor: Running task 3.0 in stage 144.0 (TID 282)
19/07/31 17:07:49 INFO Executor: Running task 1.0 in stage 144.0 (TID 280)
19/07/31 17:07:49 INFO Executor: Running task 2.0 in stage 144.0 (TID 281)
19/07/31 17:07:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:49 INFO Executor: Finished task 2.0 in stage 144.0 (TID 281). 2390 bytes result sent to driver
19/07/31 17:07:49 INFO Executor: Finished task 0.0 in stage 144.0 (TID 279). 2382 bytes result sent to driver
19/07/31 17:07:49 INFO Executor: Finished task 3.0 in stage 144.0 (TID 282). 2362 bytes result sent to driver
19/07/31 17:07:49 INFO TaskSetManager: Finished task 2.0 in stage 144.0 (TID 281) in 6 ms on localhost (executor driver) (1/4)
19/07/31 17:07:49 INFO Executor: Finished task 1.0 in stage 144.0 (TID 280). 2403 bytes result sent to driver
19/07/31 17:07:49 INFO TaskSetManager: Finished task 0.0 in stage 144.0 (TID 279) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:07:49 INFO TaskSetManager: Finished task 3.0 in stage 144.0 (TID 282) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:07:49 INFO TaskSetManager: Finished task 1.0 in stage 144.0 (TID 280) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:07:49 INFO TaskSchedulerImpl: Removed TaskSet 144.0, whose tasks have all completed, from pool 
19/07/31 17:07:49 INFO DAGScheduler: ResultStage 144 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:07:49 INFO DAGScheduler: Job 96 finished: collect at utils.scala:204, took 0.024424 s
19/07/31 17:07:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_369`) `dbplyr_370`
ORDER BY `date`) `dbplyr_371`) `dbplyr_372`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:49 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:49 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:49 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_373`) `dbplyr_374`
ORDER BY `date`) `dbplyr_375`) `dbplyr_376`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:49 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:49 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:49 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#4950 - cust_prospect_ind.nullCount#4949) > 0)
19/07/31 17:07:49 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#4955 - visit_device_type.nullCount#4954) > 0)
19/07/31 17:07:49 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#4948 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#4947))
19/07/31 17:07:49 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#4953 <= All Devices) && (All Devices <= visit_device_type.upperBound#4952))
19/07/31 17:07:49 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:49 INFO DAGScheduler: Got job 97 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:49 INFO DAGScheduler: Final stage: ResultStage 145 (collect at utils.scala:204)
19/07/31 17:07:49 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:49 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:49 INFO DAGScheduler: Submitting ResultStage 145 (MapPartitionsRDD[446] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:49 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 72.1 KB, free 910.9 MB)
19/07/31 17:07:49 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.9 MB)
19/07/31 17:07:49 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:07:49 INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 145 (MapPartitionsRDD[446] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:49 INFO TaskSchedulerImpl: Adding task set 145.0 with 1 tasks
19/07/31 17:07:49 INFO TaskSetManager: Starting task 0.0 in stage 145.0 (TID 283, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:49 INFO Executor: Running task 0.0 in stage 145.0 (TID 283)
19/07/31 17:07:49 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:49 INFO Executor: Finished task 0.0 in stage 145.0 (TID 283). 7542 bytes result sent to driver
19/07/31 17:07:49 INFO TaskSetManager: Finished task 0.0 in stage 145.0 (TID 283) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:07:49 INFO TaskSchedulerImpl: Removed TaskSet 145.0, whose tasks have all completed, from pool 
19/07/31 17:07:49 INFO DAGScheduler: ResultStage 145 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:07:49 INFO DAGScheduler: Job 97 finished: collect at utils.scala:204, took 0.011187 s
19/07/31 17:07:49 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:49 INFO DAGScheduler: Registering RDD 447 (collect at utils.scala:204)
19/07/31 17:07:49 INFO DAGScheduler: Got job 98 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:49 INFO DAGScheduler: Final stage: ResultStage 147 (collect at utils.scala:204)
19/07/31 17:07:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 146)
19/07/31 17:07:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 146)
19/07/31 17:07:49 INFO DAGScheduler: Submitting ShuffleMapStage 146 (MapPartitionsRDD[447] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:49 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 74.5 KB, free 910.8 MB)
19/07/31 17:07:49 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.8 MB)
19/07/31 17:07:49 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:07:49 INFO SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 146 (MapPartitionsRDD[447] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:49 INFO TaskSchedulerImpl: Adding task set 146.0 with 1 tasks
19/07/31 17:07:49 INFO TaskSetManager: Starting task 0.0 in stage 146.0 (TID 284, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:49 INFO Executor: Running task 0.0 in stage 146.0 (TID 284)
19/07/31 17:07:49 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:49 INFO Executor: Finished task 0.0 in stage 146.0 (TID 284). 1687 bytes result sent to driver
19/07/31 17:07:49 INFO TaskSetManager: Finished task 0.0 in stage 146.0 (TID 284) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:07:49 INFO TaskSchedulerImpl: Removed TaskSet 146.0, whose tasks have all completed, from pool 
19/07/31 17:07:49 INFO DAGScheduler: ShuffleMapStage 146 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:07:49 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:49 INFO DAGScheduler: running: Set()
19/07/31 17:07:49 INFO DAGScheduler: waiting: Set(ResultStage 147)
19/07/31 17:07:49 INFO DAGScheduler: failed: Set()
19/07/31 17:07:49 INFO DAGScheduler: Submitting ResultStage 147 (MapPartitionsRDD[450] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:49 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 16.8 KB, free 910.8 MB)
19/07/31 17:07:49 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.8 MB)
19/07/31 17:07:49 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:07:49 INFO SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:49 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 147 (MapPartitionsRDD[450] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:49 INFO TaskSchedulerImpl: Adding task set 147.0 with 4 tasks
19/07/31 17:07:49 INFO TaskSetManager: Starting task 0.0 in stage 147.0 (TID 285, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:49 INFO TaskSetManager: Starting task 1.0 in stage 147.0 (TID 286, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:49 INFO TaskSetManager: Starting task 2.0 in stage 147.0 (TID 287, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:49 INFO TaskSetManager: Starting task 3.0 in stage 147.0 (TID 288, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:49 INFO Executor: Running task 2.0 in stage 147.0 (TID 287)
19/07/31 17:07:49 INFO Executor: Running task 0.0 in stage 147.0 (TID 285)
19/07/31 17:07:49 INFO Executor: Running task 1.0 in stage 147.0 (TID 286)
19/07/31 17:07:49 INFO Executor: Running task 3.0 in stage 147.0 (TID 288)
19/07/31 17:07:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:49 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:49 INFO Executor: Finished task 0.0 in stage 147.0 (TID 285). 2382 bytes result sent to driver
19/07/31 17:07:49 INFO Executor: Finished task 3.0 in stage 147.0 (TID 288). 2362 bytes result sent to driver
19/07/31 17:07:49 INFO Executor: Finished task 1.0 in stage 147.0 (TID 286). 2403 bytes result sent to driver
19/07/31 17:07:49 INFO Executor: Finished task 2.0 in stage 147.0 (TID 287). 2390 bytes result sent to driver
19/07/31 17:07:49 INFO TaskSetManager: Finished task 0.0 in stage 147.0 (TID 285) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:07:49 INFO TaskSetManager: Finished task 3.0 in stage 147.0 (TID 288) in 4 ms on localhost (executor driver) (2/4)
19/07/31 17:07:49 INFO TaskSetManager: Finished task 2.0 in stage 147.0 (TID 287) in 4 ms on localhost (executor driver) (3/4)
19/07/31 17:07:49 INFO TaskSetManager: Finished task 1.0 in stage 147.0 (TID 286) in 4 ms on localhost (executor driver) (4/4)
19/07/31 17:07:49 INFO TaskSchedulerImpl: Removed TaskSet 147.0, whose tasks have all completed, from pool 
19/07/31 17:07:49 INFO DAGScheduler: ResultStage 147 (collect at utils.scala:204) finished in 0.004 s
19/07/31 17:07:49 INFO DAGScheduler: Job 98 finished: collect at utils.scala:204, took 0.020246 s
19/07/31 17:07:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_377`) `dbplyr_378`
ORDER BY `date`) `dbplyr_379`) `dbplyr_380`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Tablet"))
19/07/31 17:07:50 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:50 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_381`) `dbplyr_382`
ORDER BY `date`) `dbplyr_383`) `dbplyr_384`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Tablet"))
19/07/31 17:07:50 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:50 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:50 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#5048 - cust_prospect_ind.nullCount#5047) > 0)
19/07/31 17:07:50 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#5053 - visit_device_type.nullCount#5052) > 0)
19/07/31 17:07:50 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#5046 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#5045))
19/07/31 17:07:50 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#5051 <= Tablet) && (Tablet <= visit_device_type.upperBound#5050))
19/07/31 17:07:50 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:50 INFO DAGScheduler: Got job 99 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:50 INFO DAGScheduler: Final stage: ResultStage 148 (collect at utils.scala:204)
19/07/31 17:07:50 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:50 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:50 INFO DAGScheduler: Submitting ResultStage 148 (MapPartitionsRDD[455] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:50 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 72.1 KB, free 910.7 MB)
19/07/31 17:07:50 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.7 MB)
19/07/31 17:07:50 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 127.0.0.1:53949 (size: 30.4 KB, free: 912.0 MB)
19/07/31 17:07:50 INFO SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 148 (MapPartitionsRDD[455] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:50 INFO TaskSchedulerImpl: Adding task set 148.0 with 1 tasks
19/07/31 17:07:50 INFO TaskSetManager: Starting task 0.0 in stage 148.0 (TID 289, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:50 INFO Executor: Running task 0.0 in stage 148.0 (TID 289)
19/07/31 17:07:50 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:50 INFO Executor: Finished task 0.0 in stage 148.0 (TID 289). 7068 bytes result sent to driver
19/07/31 17:07:50 INFO TaskSetManager: Finished task 0.0 in stage 148.0 (TID 289) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:07:50 INFO TaskSchedulerImpl: Removed TaskSet 148.0, whose tasks have all completed, from pool 
19/07/31 17:07:50 INFO DAGScheduler: ResultStage 148 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:07:50 INFO DAGScheduler: Job 99 finished: collect at utils.scala:204, took 0.020066 s
19/07/31 17:07:50 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:50 INFO DAGScheduler: Registering RDD 456 (collect at utils.scala:204)
19/07/31 17:07:50 INFO DAGScheduler: Got job 100 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:50 INFO DAGScheduler: Final stage: ResultStage 150 (collect at utils.scala:204)
19/07/31 17:07:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 149)
19/07/31 17:07:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 149)
19/07/31 17:07:50 INFO DAGScheduler: Submitting ShuffleMapStage 149 (MapPartitionsRDD[456] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:50 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 74.5 KB, free 910.6 MB)
19/07/31 17:07:50 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.6 MB)
19/07/31 17:07:50 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.9 MB)
19/07/31 17:07:50 INFO SparkContext: Created broadcast 152 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 149 (MapPartitionsRDD[456] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:50 INFO TaskSchedulerImpl: Adding task set 149.0 with 1 tasks
19/07/31 17:07:50 INFO TaskSetManager: Starting task 0.0 in stage 149.0 (TID 290, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:50 INFO Executor: Running task 0.0 in stage 149.0 (TID 290)
19/07/31 17:07:50 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:50 INFO Executor: Finished task 0.0 in stage 149.0 (TID 290). 1687 bytes result sent to driver
19/07/31 17:07:50 INFO TaskSetManager: Finished task 0.0 in stage 149.0 (TID 290) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:07:50 INFO TaskSchedulerImpl: Removed TaskSet 149.0, whose tasks have all completed, from pool 
19/07/31 17:07:50 INFO DAGScheduler: ShuffleMapStage 149 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:07:50 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:50 INFO DAGScheduler: running: Set()
19/07/31 17:07:50 INFO DAGScheduler: waiting: Set(ResultStage 150)
19/07/31 17:07:50 INFO DAGScheduler: failed: Set()
19/07/31 17:07:50 INFO DAGScheduler: Submitting ResultStage 150 (MapPartitionsRDD[459] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:50 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 16.8 KB, free 910.6 MB)
19/07/31 17:07:50 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.6 MB)
19/07/31 17:07:50 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:07:50 INFO SparkContext: Created broadcast 153 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:50 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 150 (MapPartitionsRDD[459] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:50 INFO TaskSchedulerImpl: Adding task set 150.0 with 4 tasks
19/07/31 17:07:50 INFO TaskSetManager: Starting task 0.0 in stage 150.0 (TID 291, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:50 INFO TaskSetManager: Starting task 1.0 in stage 150.0 (TID 292, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:50 INFO TaskSetManager: Starting task 2.0 in stage 150.0 (TID 293, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:50 INFO TaskSetManager: Starting task 3.0 in stage 150.0 (TID 294, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:50 INFO Executor: Running task 0.0 in stage 150.0 (TID 291)
19/07/31 17:07:50 INFO Executor: Running task 3.0 in stage 150.0 (TID 294)
19/07/31 17:07:50 INFO Executor: Running task 1.0 in stage 150.0 (TID 292)
19/07/31 17:07:50 INFO Executor: Running task 2.0 in stage 150.0 (TID 293)
19/07/31 17:07:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:50 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:50 INFO Executor: Finished task 0.0 in stage 150.0 (TID 291). 2376 bytes result sent to driver
19/07/31 17:07:50 INFO Executor: Finished task 1.0 in stage 150.0 (TID 292). 2381 bytes result sent to driver
19/07/31 17:07:50 INFO Executor: Finished task 2.0 in stage 150.0 (TID 293). 2379 bytes result sent to driver
19/07/31 17:07:50 INFO Executor: Finished task 3.0 in stage 150.0 (TID 294). 2357 bytes result sent to driver
19/07/31 17:07:50 INFO TaskSetManager: Finished task 0.0 in stage 150.0 (TID 291) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:07:50 INFO TaskSetManager: Finished task 2.0 in stage 150.0 (TID 293) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:07:50 INFO TaskSetManager: Finished task 1.0 in stage 150.0 (TID 292) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:07:50 INFO TaskSetManager: Finished task 3.0 in stage 150.0 (TID 294) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:07:50 INFO TaskSchedulerImpl: Removed TaskSet 150.0, whose tasks have all completed, from pool 
19/07/31 17:07:50 INFO DAGScheduler: ResultStage 150 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:07:50 INFO DAGScheduler: Job 100 finished: collect at utils.scala:204, took 0.024814 s
19/07/31 17:07:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_385`) `dbplyr_386`
ORDER BY `date`) `dbplyr_387`) `dbplyr_388`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:50 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:50 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_389`) `dbplyr_390`
ORDER BY `date`) `dbplyr_391`) `dbplyr_392`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:51 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:51 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:51 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#5146 - cust_prospect_ind.nullCount#5145) > 0)
19/07/31 17:07:51 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#5151 - visit_device_type.nullCount#5150) > 0)
19/07/31 17:07:51 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#5144 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#5143))
19/07/31 17:07:51 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#5149 <= All Devices) && (All Devices <= visit_device_type.upperBound#5148))
19/07/31 17:07:51 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:51 INFO DAGScheduler: Got job 101 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:51 INFO DAGScheduler: Final stage: ResultStage 151 (collect at utils.scala:204)
19/07/31 17:07:51 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:51 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:51 INFO DAGScheduler: Submitting ResultStage 151 (MapPartitionsRDD[464] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:51 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 72.1 KB, free 910.5 MB)
19/07/31 17:07:51 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.5 MB)
19/07/31 17:07:51 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.9 MB)
19/07/31 17:07:51 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 151 (MapPartitionsRDD[464] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:51 INFO TaskSchedulerImpl: Adding task set 151.0 with 1 tasks
19/07/31 17:07:51 INFO TaskSetManager: Starting task 0.0 in stage 151.0 (TID 295, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:51 INFO Executor: Running task 0.0 in stage 151.0 (TID 295)
19/07/31 17:07:51 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:51 INFO Executor: Finished task 0.0 in stage 151.0 (TID 295). 7542 bytes result sent to driver
19/07/31 17:07:51 INFO TaskSetManager: Finished task 0.0 in stage 151.0 (TID 295) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:07:51 INFO TaskSchedulerImpl: Removed TaskSet 151.0, whose tasks have all completed, from pool 
19/07/31 17:07:51 INFO DAGScheduler: ResultStage 151 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:07:51 INFO DAGScheduler: Job 101 finished: collect at utils.scala:204, took 0.011939 s
19/07/31 17:07:51 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:51 INFO DAGScheduler: Registering RDD 465 (collect at utils.scala:204)
19/07/31 17:07:51 INFO DAGScheduler: Got job 102 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:51 INFO DAGScheduler: Final stage: ResultStage 153 (collect at utils.scala:204)
19/07/31 17:07:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 152)
19/07/31 17:07:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 152)
19/07/31 17:07:51 INFO DAGScheduler: Submitting ShuffleMapStage 152 (MapPartitionsRDD[465] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:51 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 74.5 KB, free 910.4 MB)
19/07/31 17:07:51 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.4 MB)
19/07/31 17:07:51 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.9 MB)
19/07/31 17:07:51 INFO SparkContext: Created broadcast 155 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 152 (MapPartitionsRDD[465] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:51 INFO TaskSchedulerImpl: Adding task set 152.0 with 1 tasks
19/07/31 17:07:51 INFO TaskSetManager: Starting task 0.0 in stage 152.0 (TID 296, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:51 INFO Executor: Running task 0.0 in stage 152.0 (TID 296)
19/07/31 17:07:51 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:51 INFO Executor: Finished task 0.0 in stage 152.0 (TID 296). 1687 bytes result sent to driver
19/07/31 17:07:51 INFO TaskSetManager: Finished task 0.0 in stage 152.0 (TID 296) in 11 ms on localhost (executor driver) (1/1)
19/07/31 17:07:51 INFO TaskSchedulerImpl: Removed TaskSet 152.0, whose tasks have all completed, from pool 
19/07/31 17:07:51 INFO DAGScheduler: ShuffleMapStage 152 (collect at utils.scala:204) finished in 0.011 s
19/07/31 17:07:51 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:51 INFO DAGScheduler: running: Set()
19/07/31 17:07:51 INFO DAGScheduler: waiting: Set(ResultStage 153)
19/07/31 17:07:51 INFO DAGScheduler: failed: Set()
19/07/31 17:07:51 INFO DAGScheduler: Submitting ResultStage 153 (MapPartitionsRDD[468] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:51 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 16.8 KB, free 910.3 MB)
19/07/31 17:07:51 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.3 MB)
19/07/31 17:07:51 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:07:51 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:51 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 153 (MapPartitionsRDD[468] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:51 INFO TaskSchedulerImpl: Adding task set 153.0 with 4 tasks
19/07/31 17:07:51 INFO TaskSetManager: Starting task 0.0 in stage 153.0 (TID 297, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:51 INFO TaskSetManager: Starting task 1.0 in stage 153.0 (TID 298, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:51 INFO TaskSetManager: Starting task 2.0 in stage 153.0 (TID 299, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:51 INFO TaskSetManager: Starting task 3.0 in stage 153.0 (TID 300, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:51 INFO Executor: Running task 1.0 in stage 153.0 (TID 298)
19/07/31 17:07:51 INFO Executor: Running task 0.0 in stage 153.0 (TID 297)
19/07/31 17:07:51 INFO Executor: Running task 2.0 in stage 153.0 (TID 299)
19/07/31 17:07:51 INFO Executor: Running task 3.0 in stage 153.0 (TID 300)
19/07/31 17:07:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:51 INFO Executor: Finished task 3.0 in stage 153.0 (TID 300). 2362 bytes result sent to driver
19/07/31 17:07:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:51 INFO Executor: Finished task 1.0 in stage 153.0 (TID 298). 2403 bytes result sent to driver
19/07/31 17:07:51 INFO TaskSetManager: Finished task 3.0 in stage 153.0 (TID 300) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:07:51 INFO TaskSetManager: Finished task 1.0 in stage 153.0 (TID 298) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:07:51 INFO Executor: Finished task 2.0 in stage 153.0 (TID 299). 2390 bytes result sent to driver
19/07/31 17:07:51 INFO Executor: Finished task 0.0 in stage 153.0 (TID 297). 2382 bytes result sent to driver
19/07/31 17:07:51 INFO TaskSetManager: Finished task 2.0 in stage 153.0 (TID 299) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:07:51 INFO TaskSetManager: Finished task 0.0 in stage 153.0 (TID 297) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:07:51 INFO TaskSchedulerImpl: Removed TaskSet 153.0, whose tasks have all completed, from pool 
19/07/31 17:07:51 INFO DAGScheduler: ResultStage 153 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:07:51 INFO DAGScheduler: Job 102 finished: collect at utils.scala:204, took 0.026144 s
19/07/31 17:07:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_393`) `dbplyr_394`
ORDER BY `date`) `dbplyr_395`) `dbplyr_396`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:51 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:51 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_397`) `dbplyr_398`
ORDER BY `date`) `dbplyr_399`) `dbplyr_400`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:07:51 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:51 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:51 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#5244 - cust_prospect_ind.nullCount#5243) > 0)
19/07/31 17:07:51 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#5249 - visit_device_type.nullCount#5248) > 0)
19/07/31 17:07:51 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#5242 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#5241))
19/07/31 17:07:51 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#5247 <= All Devices) && (All Devices <= visit_device_type.upperBound#5246))
19/07/31 17:07:51 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:51 INFO DAGScheduler: Got job 103 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:51 INFO DAGScheduler: Final stage: ResultStage 154 (collect at utils.scala:204)
19/07/31 17:07:51 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:51 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:51 INFO DAGScheduler: Submitting ResultStage 154 (MapPartitionsRDD[473] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:51 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 72.1 KB, free 910.3 MB)
19/07/31 17:07:51 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.2 MB)
19/07/31 17:07:51 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 127.0.0.1:53949 (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:07:51 INFO SparkContext: Created broadcast 157 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 154 (MapPartitionsRDD[473] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:51 INFO TaskSchedulerImpl: Adding task set 154.0 with 1 tasks
19/07/31 17:07:51 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 301, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:07:51 INFO Executor: Running task 0.0 in stage 154.0 (TID 301)
19/07/31 17:07:51 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:51 INFO Executor: Finished task 0.0 in stage 154.0 (TID 301). 7542 bytes result sent to driver
19/07/31 17:07:51 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 301) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:07:51 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool 
19/07/31 17:07:51 INFO DAGScheduler: ResultStage 154 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:07:51 INFO DAGScheduler: Job 103 finished: collect at utils.scala:204, took 0.009760 s
19/07/31 17:07:51 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:51 INFO DAGScheduler: Registering RDD 474 (collect at utils.scala:204)
19/07/31 17:07:51 INFO DAGScheduler: Got job 104 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:07:51 INFO DAGScheduler: Final stage: ResultStage 156 (collect at utils.scala:204)
19/07/31 17:07:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 155)
19/07/31 17:07:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 155)
19/07/31 17:07:51 INFO DAGScheduler: Submitting ShuffleMapStage 155 (MapPartitionsRDD[474] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:51 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 74.5 KB, free 910.2 MB)
19/07/31 17:07:51 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.1 MB)
19/07/31 17:07:51 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 127.0.0.1:53949 (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:07:51 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 155 (MapPartitionsRDD[474] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:51 INFO TaskSchedulerImpl: Adding task set 155.0 with 1 tasks
19/07/31 17:07:51 INFO TaskSetManager: Starting task 0.0 in stage 155.0 (TID 302, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:07:51 INFO Executor: Running task 0.0 in stage 155.0 (TID 302)
19/07/31 17:07:51 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:07:51 INFO Executor: Finished task 0.0 in stage 155.0 (TID 302). 1687 bytes result sent to driver
19/07/31 17:07:51 INFO TaskSetManager: Finished task 0.0 in stage 155.0 (TID 302) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:07:51 INFO TaskSchedulerImpl: Removed TaskSet 155.0, whose tasks have all completed, from pool 
19/07/31 17:07:51 INFO DAGScheduler: ShuffleMapStage 155 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:07:51 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:51 INFO DAGScheduler: running: Set()
19/07/31 17:07:51 INFO DAGScheduler: waiting: Set(ResultStage 156)
19/07/31 17:07:51 INFO DAGScheduler: failed: Set()
19/07/31 17:07:51 INFO DAGScheduler: Submitting ResultStage 156 (MapPartitionsRDD[477] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:51 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 16.8 KB, free 910.1 MB)
19/07/31 17:07:51 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.1 MB)
19/07/31 17:07:51 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on 127.0.0.1:53949 (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:07:51 INFO SparkContext: Created broadcast 159 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:51 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 156 (MapPartitionsRDD[477] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:07:51 INFO TaskSchedulerImpl: Adding task set 156.0 with 4 tasks
19/07/31 17:07:51 INFO TaskSetManager: Starting task 0.0 in stage 156.0 (TID 303, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:51 INFO TaskSetManager: Starting task 1.0 in stage 156.0 (TID 304, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:07:51 INFO TaskSetManager: Starting task 2.0 in stage 156.0 (TID 305, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:07:51 INFO TaskSetManager: Starting task 3.0 in stage 156.0 (TID 306, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:07:51 INFO Executor: Running task 0.0 in stage 156.0 (TID 303)
19/07/31 17:07:51 INFO Executor: Running task 1.0 in stage 156.0 (TID 304)
19/07/31 17:07:51 INFO Executor: Running task 3.0 in stage 156.0 (TID 306)
19/07/31 17:07:51 INFO Executor: Running task 2.0 in stage 156.0 (TID 305)
19/07/31 17:07:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:51 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:51 INFO Executor: Finished task 3.0 in stage 156.0 (TID 306). 2362 bytes result sent to driver
19/07/31 17:07:51 INFO Executor: Finished task 2.0 in stage 156.0 (TID 305). 2390 bytes result sent to driver
19/07/31 17:07:51 INFO Executor: Finished task 1.0 in stage 156.0 (TID 304). 2403 bytes result sent to driver
19/07/31 17:07:51 INFO TaskSetManager: Finished task 2.0 in stage 156.0 (TID 305) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:07:51 INFO Executor: Finished task 0.0 in stage 156.0 (TID 303). 2382 bytes result sent to driver
19/07/31 17:07:51 INFO TaskSetManager: Finished task 1.0 in stage 156.0 (TID 304) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:07:51 INFO TaskSetManager: Finished task 3.0 in stage 156.0 (TID 306) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:07:51 INFO TaskSetManager: Finished task 0.0 in stage 156.0 (TID 303) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:07:51 INFO TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool 
19/07/31 17:07:51 INFO DAGScheduler: ResultStage 156 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:07:51 INFO DAGScheduler: Job 104 finished: collect at utils.scala:204, took 0.024102 s
19/07/31 17:07:51 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 17:07:51 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:51 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:51 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:51 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:51 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 17:07:51 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 17:07:51 INFO CodeGenerator: Code generated in 13.981142 ms
19/07/31 17:07:51 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 17:07:51 INFO DAGScheduler: Got job 105 (collect at utils.scala:44) with 1 output partitions
19/07/31 17:07:51 INFO DAGScheduler: Final stage: ResultStage 157 (collect at utils.scala:44)
19/07/31 17:07:51 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:51 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:51 INFO DAGScheduler: Submitting ResultStage 157 (MapPartitionsRDD[482] at map at utils.scala:41), which has no missing parents
19/07/31 17:07:51 INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 6.3 KB, free 910.1 MB)
19/07/31 17:07:51 INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 3.5 KB, free 910.1 MB)
19/07/31 17:07:51 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on 127.0.0.1:53949 (size: 3.5 KB, free: 911.8 MB)
19/07/31 17:07:51 INFO SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 157 (MapPartitionsRDD[482] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:51 INFO TaskSchedulerImpl: Adding task set 157.0 with 1 tasks
19/07/31 17:07:51 INFO TaskSetManager: Starting task 0.0 in stage 157.0 (TID 307, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 17:07:51 INFO Executor: Running task 0.0 in stage 157.0 (TID 307)
19/07/31 17:07:51 INFO Executor: Finished task 0.0 in stage 157.0 (TID 307). 1007 bytes result sent to driver
19/07/31 17:07:51 INFO TaskSetManager: Finished task 0.0 in stage 157.0 (TID 307) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:07:51 INFO TaskSchedulerImpl: Removed TaskSet 157.0, whose tasks have all completed, from pool 
19/07/31 17:07:51 INFO DAGScheduler: ResultStage 157 (collect at utils.scala:44) finished in 0.006 s
19/07/31 17:07:51 INFO DAGScheduler: Job 105 finished: collect at utils.scala:44, took 0.023600 s
19/07/31 17:07:51 INFO SparkSqlParser: Parsing command: result
19/07/31 17:07:51 INFO SparkSqlParser: Parsing command: CACHE TABLE `result`
19/07/31 17:07:51 INFO SparkSqlParser: Parsing command: `result`
19/07/31 17:07:52 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 17:07:52 INFO DAGScheduler: Registering RDD 490 (sql at <unknown>:0)
19/07/31 17:07:52 INFO DAGScheduler: Got job 106 (sql at <unknown>:0) with 1 output partitions
19/07/31 17:07:52 INFO DAGScheduler: Final stage: ResultStage 159 (sql at <unknown>:0)
19/07/31 17:07:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 158)
19/07/31 17:07:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 158)
19/07/31 17:07:52 INFO DAGScheduler: Submitting ShuffleMapStage 158 (MapPartitionsRDD[490] at sql at <unknown>:0), which has no missing parents
19/07/31 17:07:52 INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 19.5 KB, free 910.1 MB)
19/07/31 17:07:52 INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 8.6 KB, free 910.1 MB)
19/07/31 17:07:52 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on 127.0.0.1:53949 (size: 8.6 KB, free: 911.8 MB)
19/07/31 17:07:52 INFO SparkContext: Created broadcast 161 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 158 (MapPartitionsRDD[490] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:52 INFO TaskSchedulerImpl: Adding task set 158.0 with 1 tasks
19/07/31 17:07:52 INFO TaskSetManager: Starting task 0.0 in stage 158.0 (TID 308, localhost, executor driver, partition 0, PROCESS_LOCAL, 15044 bytes)
19/07/31 17:07:52 INFO Executor: Running task 0.0 in stage 158.0 (TID 308)
19/07/31 17:07:52 INFO CodeGenerator: Code generated in 10.895989 ms
19/07/31 17:07:52 INFO CodeGenerator: Code generated in 42.456016 ms
19/07/31 17:07:52 INFO MemoryStore: Block rdd_487_0 stored as values in memory (estimated size 8.5 KB, free 910.1 MB)
19/07/31 17:07:52 INFO BlockManagerInfo: Added rdd_487_0 in memory on 127.0.0.1:53949 (size: 8.5 KB, free: 911.8 MB)
19/07/31 17:07:52 INFO Executor: Finished task 0.0 in stage 158.0 (TID 308). 2285 bytes result sent to driver
19/07/31 17:07:52 INFO TaskSetManager: Finished task 0.0 in stage 158.0 (TID 308) in 80 ms on localhost (executor driver) (1/1)
19/07/31 17:07:52 INFO TaskSchedulerImpl: Removed TaskSet 158.0, whose tasks have all completed, from pool 
19/07/31 17:07:52 INFO DAGScheduler: ShuffleMapStage 158 (sql at <unknown>:0) finished in 0.080 s
19/07/31 17:07:52 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:52 INFO DAGScheduler: running: Set()
19/07/31 17:07:52 INFO DAGScheduler: waiting: Set(ResultStage 159)
19/07/31 17:07:52 INFO DAGScheduler: failed: Set()
19/07/31 17:07:52 INFO DAGScheduler: Submitting ResultStage 159 (MapPartitionsRDD[493] at sql at <unknown>:0), which has no missing parents
19/07/31 17:07:52 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 7.0 KB, free 910.0 MB)
19/07/31 17:07:52 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.0 MB)
19/07/31 17:07:52 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on 127.0.0.1:53949 (size: 3.7 KB, free: 911.8 MB)
19/07/31 17:07:52 INFO SparkContext: Created broadcast 162 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 159 (MapPartitionsRDD[493] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:52 INFO TaskSchedulerImpl: Adding task set 159.0 with 1 tasks
19/07/31 17:07:52 INFO TaskSetManager: Starting task 0.0 in stage 159.0 (TID 309, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:52 INFO Executor: Running task 0.0 in stage 159.0 (TID 309)
19/07/31 17:07:52 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:07:52 INFO Executor: Finished task 0.0 in stage 159.0 (TID 309). 1581 bytes result sent to driver
19/07/31 17:07:52 INFO TaskSetManager: Finished task 0.0 in stage 159.0 (TID 309) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:07:52 INFO TaskSchedulerImpl: Removed TaskSet 159.0, whose tasks have all completed, from pool 
19/07/31 17:07:52 INFO DAGScheduler: ResultStage 159 (sql at <unknown>:0) finished in 0.004 s
19/07/31 17:07:52 INFO DAGScheduler: Job 106 finished: sql at <unknown>:0, took 0.108800 s
19/07/31 17:07:52 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `result`
19/07/31 17:07:52 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:07:52 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:07:52 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:07:52 INFO DAGScheduler: Registering RDD 496 (collect at utils.scala:204)
19/07/31 17:07:52 INFO DAGScheduler: Got job 107 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:07:52 INFO DAGScheduler: Final stage: ResultStage 161 (collect at utils.scala:204)
19/07/31 17:07:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 160)
19/07/31 17:07:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 160)
19/07/31 17:07:52 INFO DAGScheduler: Submitting ShuffleMapStage 160 (MapPartitionsRDD[496] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:52 INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 19.5 KB, free 910.0 MB)
19/07/31 17:07:52 INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 8.6 KB, free 910.0 MB)
19/07/31 17:07:52 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on 127.0.0.1:53949 (size: 8.6 KB, free: 911.8 MB)
19/07/31 17:07:52 INFO SparkContext: Created broadcast 163 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 160 (MapPartitionsRDD[496] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:52 INFO TaskSchedulerImpl: Adding task set 160.0 with 1 tasks
19/07/31 17:07:52 INFO TaskSetManager: Starting task 0.0 in stage 160.0 (TID 310, localhost, executor driver, partition 0, PROCESS_LOCAL, 15044 bytes)
19/07/31 17:07:52 INFO Executor: Running task 0.0 in stage 160.0 (TID 310)
19/07/31 17:07:52 INFO BlockManager: Found block rdd_487_0 locally
19/07/31 17:07:52 INFO Executor: Finished task 0.0 in stage 160.0 (TID 310). 1690 bytes result sent to driver
19/07/31 17:07:52 INFO TaskSetManager: Finished task 0.0 in stage 160.0 (TID 310) in 13 ms on localhost (executor driver) (1/1)
19/07/31 17:07:52 INFO TaskSchedulerImpl: Removed TaskSet 160.0, whose tasks have all completed, from pool 
19/07/31 17:07:52 INFO DAGScheduler: ShuffleMapStage 160 (collect at utils.scala:204) finished in 0.013 s
19/07/31 17:07:52 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:07:52 INFO DAGScheduler: running: Set()
19/07/31 17:07:52 INFO DAGScheduler: waiting: Set(ResultStage 161)
19/07/31 17:07:52 INFO DAGScheduler: failed: Set()
19/07/31 17:07:52 INFO DAGScheduler: Submitting ResultStage 161 (MapPartitionsRDD[499] at collect at utils.scala:204), which has no missing parents
19/07/31 17:07:52 INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 7.0 KB, free 910.0 MB)
19/07/31 17:07:52 INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.0 MB)
19/07/31 17:07:52 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on 127.0.0.1:53949 (size: 3.7 KB, free: 911.8 MB)
19/07/31 17:07:52 INFO SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 161 (MapPartitionsRDD[499] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:52 INFO TaskSchedulerImpl: Adding task set 161.0 with 1 tasks
19/07/31 17:07:52 INFO TaskSetManager: Starting task 0.0 in stage 161.0 (TID 311, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:07:52 INFO Executor: Running task 0.0 in stage 161.0 (TID 311)
19/07/31 17:07:52 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:07:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:07:52 INFO Executor: Finished task 0.0 in stage 161.0 (TID 311). 1581 bytes result sent to driver
19/07/31 17:07:52 INFO TaskSetManager: Finished task 0.0 in stage 161.0 (TID 311) in 3 ms on localhost (executor driver) (1/1)
19/07/31 17:07:52 INFO TaskSchedulerImpl: Removed TaskSet 161.0, whose tasks have all completed, from pool 
19/07/31 17:07:52 INFO DAGScheduler: ResultStage 161 (collect at utils.scala:204) finished in 0.003 s
19/07/31 17:07:52 INFO DAGScheduler: Job 107 finished: collect at utils.scala:204, took 0.032270 s
19/07/31 17:07:52 INFO SparkSqlParser: Parsing command: SELECT *
FROM `result` AS `zzz2`
WHERE (0 = 1)
19/07/31 17:07:52 INFO SparkSqlParser: Parsing command: SELECT *
FROM `result`
19/07/31 17:07:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 17:07:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 17:07:52 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 17:07:52 INFO DAGScheduler: Got job 108 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 17:07:52 INFO DAGScheduler: Final stage: ResultStage 162 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 17:07:52 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:07:52 INFO DAGScheduler: Missing parents: List()
19/07/31 17:07:52 INFO DAGScheduler: Submitting ResultStage 162 (MapPartitionsRDD[500] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 17:07:52 INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 90.4 KB, free 909.9 MB)
19/07/31 17:07:52 INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 35.0 KB, free 909.9 MB)
19/07/31 17:07:52 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on 127.0.0.1:53949 (size: 35.0 KB, free: 911.7 MB)
19/07/31 17:07:52 INFO SparkContext: Created broadcast 165 from broadcast at DAGScheduler.scala:1006
19/07/31 17:07:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 162 (MapPartitionsRDD[500] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:07:52 INFO TaskSchedulerImpl: Adding task set 162.0 with 1 tasks
19/07/31 17:07:52 INFO TaskSetManager: Starting task 0.0 in stage 162.0 (TID 312, localhost, executor driver, partition 0, PROCESS_LOCAL, 15055 bytes)
19/07/31 17:07:52 INFO Executor: Running task 0.0 in stage 162.0 (TID 312)
19/07/31 17:07:52 INFO BlockManager: Found block rdd_487_0 locally
19/07/31 17:07:52 INFO CodeGenerator: Code generated in 16.49069 ms
19/07/31 17:07:52 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 17:07:52 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 17:07:52 INFO FileOutputCommitter: Saved output of task 'attempt_20190731170752_0162_m_000000_0' to file:/Users/6jncnk4f/Desktop/anomaly/forecast_result/_temporary/0/task_20190731170752_0162_m_000000
19/07/31 17:07:52 INFO SparkHadoopMapRedUtil: attempt_20190731170752_0162_m_000000_0: Committed
19/07/31 17:07:52 INFO Executor: Finished task 0.0 in stage 162.0 (TID 312). 1576 bytes result sent to driver
19/07/31 17:07:52 INFO TaskSetManager: Finished task 0.0 in stage 162.0 (TID 312) in 115 ms on localhost (executor driver) (1/1)
19/07/31 17:07:52 INFO TaskSchedulerImpl: Removed TaskSet 162.0, whose tasks have all completed, from pool 
19/07/31 17:07:52 INFO DAGScheduler: ResultStage 162 (csv at NativeMethodAccessorImpl.java:0) finished in 0.115 s
19/07/31 17:07:52 INFO DAGScheduler: Job 108 finished: csv at NativeMethodAccessorImpl.java:0, took 0.141172 s
19/07/31 17:07:52 INFO FileFormatWriter: Job null committed.
19/07/31 17:07:53 INFO SparkContext: Invoking stop() from shutdown hook
19/07/31 17:07:53 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
19/07/31 17:07:53 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/07/31 17:07:53 INFO MemoryStore: MemoryStore cleared
19/07/31 17:07:53 INFO BlockManager: BlockManager stopped
19/07/31 17:07:53 INFO BlockManagerMaster: BlockManagerMaster stopped
19/07/31 17:07:53 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/07/31 17:07:53 INFO SparkContext: Successfully stopped SparkContext
19/07/31 17:07:53 INFO ShutdownHookManager: Shutdown hook called
19/07/31 17:07:53 INFO ShutdownHookManager: Deleting directory /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-3ab3356b-cfa2-49f9-a98e-d760fb07ca60
19/07/31 17:10:48 INFO SparkContext: Running Spark version 2.2.0
19/07/31 17:10:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/07/31 17:10:49 INFO SparkContext: Submitted application: sparklyr
19/07/31 17:10:49 INFO SecurityManager: Changing view acls to: 6jncnk4f
19/07/31 17:10:49 INFO SecurityManager: Changing modify acls to: 6jncnk4f
19/07/31 17:10:49 INFO SecurityManager: Changing view acls groups to: 
19/07/31 17:10:49 INFO SecurityManager: Changing modify acls groups to: 
19/07/31 17:10:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(6jncnk4f); groups with view permissions: Set(); users  with modify permissions: Set(6jncnk4f); groups with modify permissions: Set()
19/07/31 17:10:49 INFO Utils: Successfully started service 'sparkDriver' on port 54056.
19/07/31 17:10:49 INFO SparkEnv: Registering MapOutputTracker
19/07/31 17:10:49 INFO SparkEnv: Registering BlockManagerMaster
19/07/31 17:10:49 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/07/31 17:10:49 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/07/31 17:10:49 INFO DiskBlockManager: Created local directory at /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/blockmgr-f01f725c-0ec9-475d-af60-aa920c5f187b
19/07/31 17:10:49 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/07/31 17:10:49 INFO SparkEnv: Registering OutputCommitCoordinator
19/07/31 17:10:49 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/07/31 17:10:49 INFO Utils: Successfully started service 'SparkUI' on port 4041.
19/07/31 17:10:49 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
19/07/31 17:10:49 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:54056/jars/sparklyr-2.0-2.11.jar with timestamp 1564607449761
19/07/31 17:10:49 INFO Executor: Starting executor ID driver on host localhost
19/07/31 17:10:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54057.
19/07/31 17:10:49 INFO NettyBlockTransferService: Server created on 127.0.0.1:54057
19/07/31 17:10:49 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/07/31 17:10:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 54057, None)
19/07/31 17:10:49 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:54057 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 54057, None)
19/07/31 17:10:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 54057, None)
19/07/31 17:10:49 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 54057, None)
19/07/31 17:10:50 INFO SharedState: loading hive config file: file:/Users/6jncnk4f/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/07/31 17:10:50 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse').
19/07/31 17:10:50 INFO SharedState: Warehouse path is 'file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse'.
19/07/31 17:10:50 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/07/31 17:10:51 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/07/31 17:10:51 INFO ObjectStore: ObjectStore, initialize called
19/07/31 17:10:51 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/07/31 17:10:51 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/07/31 17:10:52 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/07/31 17:10:53 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:10:53 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:10:53 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:10:53 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:10:53 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/07/31 17:10:53 INFO ObjectStore: Initialized ObjectStore
19/07/31 17:10:53 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/07/31 17:10:53 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/07/31 17:10:53 INFO HiveMetaStore: Added admin role in metastore
19/07/31 17:10:53 INFO HiveMetaStore: Added public role in metastore
19/07/31 17:10:54 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/07/31 17:10:54 INFO HiveMetaStore: 0: get_all_databases
19/07/31 17:10:54 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_all_databases	
19/07/31 17:10:54 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/07/31 17:10:54 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/07/31 17:10:54 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:10:54 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/64763f2d-5f5d-41e4-8f9e-9d97f24fe0b2_resources
19/07/31 17:10:54 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/64763f2d-5f5d-41e4-8f9e-9d97f24fe0b2
19/07/31 17:10:54 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/64763f2d-5f5d-41e4-8f9e-9d97f24fe0b2
19/07/31 17:10:54 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/64763f2d-5f5d-41e4-8f9e-9d97f24fe0b2/_tmp_space.db
19/07/31 17:10:54 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 17:10:54 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:10:54 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:10:54 INFO HiveMetaStore: 0: get_database: global_temp
19/07/31 17:10:54 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/07/31 17:10:54 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/07/31 17:10:54 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/e607eb66-ef00-492f-8ddd-cdcf5aaea67a_resources
19/07/31 17:10:54 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/e607eb66-ef00-492f-8ddd-cdcf5aaea67a
19/07/31 17:10:54 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/e607eb66-ef00-492f-8ddd-cdcf5aaea67a
19/07/31 17:10:54 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/e607eb66-ef00-492f-8ddd-cdcf5aaea67a/_tmp_space.db
19/07/31 17:10:54 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 17:10:54 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/07/31 17:10:55 INFO SparkContext: Invoking stop() from shutdown hook
19/07/31 17:10:55 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
19/07/31 17:10:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/07/31 17:10:55 INFO MemoryStore: MemoryStore cleared
19/07/31 17:10:55 INFO BlockManager: BlockManager stopped
19/07/31 17:10:55 INFO BlockManagerMaster: BlockManagerMaster stopped
19/07/31 17:10:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/07/31 17:10:55 INFO SparkContext: Successfully stopped SparkContext
19/07/31 17:10:55 INFO ShutdownHookManager: Shutdown hook called
19/07/31 17:10:55 INFO ShutdownHookManager: Deleting directory /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-f98b650b-8ef8-4e26-888b-66975e7f443c
19/07/31 17:12:14 INFO SparkContext: Running Spark version 2.2.0
19/07/31 17:12:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/07/31 17:12:14 INFO SparkContext: Submitted application: sparklyr
19/07/31 17:12:14 INFO SecurityManager: Changing view acls to: 6jncnk4f
19/07/31 17:12:14 INFO SecurityManager: Changing modify acls to: 6jncnk4f
19/07/31 17:12:14 INFO SecurityManager: Changing view acls groups to: 
19/07/31 17:12:14 INFO SecurityManager: Changing modify acls groups to: 
19/07/31 17:12:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(6jncnk4f); groups with view permissions: Set(); users  with modify permissions: Set(6jncnk4f); groups with modify permissions: Set()
19/07/31 17:12:14 INFO Utils: Successfully started service 'sparkDriver' on port 54088.
19/07/31 17:12:15 INFO SparkEnv: Registering MapOutputTracker
19/07/31 17:12:15 INFO SparkEnv: Registering BlockManagerMaster
19/07/31 17:12:15 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/07/31 17:12:15 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/07/31 17:12:15 INFO DiskBlockManager: Created local directory at /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/blockmgr-f00272b4-d0af-4f7c-86c6-476400b4a14b
19/07/31 17:12:15 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/07/31 17:12:15 INFO SparkEnv: Registering OutputCommitCoordinator
19/07/31 17:12:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/07/31 17:12:15 INFO Utils: Successfully started service 'SparkUI' on port 4041.
19/07/31 17:12:15 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
19/07/31 17:12:15 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:54088/jars/sparklyr-2.0-2.11.jar with timestamp 1564607535349
19/07/31 17:12:15 INFO Executor: Starting executor ID driver on host localhost
19/07/31 17:12:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54089.
19/07/31 17:12:15 INFO NettyBlockTransferService: Server created on 127.0.0.1:54089
19/07/31 17:12:15 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/07/31 17:12:15 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 54089, None)
19/07/31 17:12:15 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:54089 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 54089, None)
19/07/31 17:12:15 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 54089, None)
19/07/31 17:12:15 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 54089, None)
19/07/31 17:12:15 INFO SharedState: loading hive config file: file:/Users/6jncnk4f/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/07/31 17:12:15 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse').
19/07/31 17:12:15 INFO SharedState: Warehouse path is 'file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse'.
19/07/31 17:12:16 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/07/31 17:12:16 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/07/31 17:12:16 INFO ObjectStore: ObjectStore, initialize called
19/07/31 17:12:16 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/07/31 17:12:16 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/07/31 17:12:18 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/07/31 17:12:18 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:12:18 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:12:19 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:12:19 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:12:19 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/07/31 17:12:19 INFO ObjectStore: Initialized ObjectStore
19/07/31 17:12:19 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/07/31 17:12:19 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/07/31 17:12:19 INFO HiveMetaStore: Added admin role in metastore
19/07/31 17:12:19 INFO HiveMetaStore: Added public role in metastore
19/07/31 17:12:19 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/07/31 17:12:19 INFO HiveMetaStore: 0: get_all_databases
19/07/31 17:12:19 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_all_databases	
19/07/31 17:12:19 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/07/31 17:12:19 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/07/31 17:12:19 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:12:19 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/e66fee45-9edc-4a44-b36c-b2009997d659_resources
19/07/31 17:12:19 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/e66fee45-9edc-4a44-b36c-b2009997d659
19/07/31 17:12:19 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/e66fee45-9edc-4a44-b36c-b2009997d659
19/07/31 17:12:19 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/e66fee45-9edc-4a44-b36c-b2009997d659/_tmp_space.db
19/07/31 17:12:19 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 17:12:20 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:20 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:20 INFO HiveMetaStore: 0: get_database: global_temp
19/07/31 17:12:20 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/07/31 17:12:20 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/07/31 17:12:20 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/9c5fc776-063a-4fc5-9016-5b6ec45a6874_resources
19/07/31 17:12:20 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/9c5fc776-063a-4fc5-9016-5b6ec45a6874
19/07/31 17:12:20 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/9c5fc776-063a-4fc5-9016-5b6ec45a6874
19/07/31 17:12:20 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/9c5fc776-063a-4fc5-9016-5b6ec45a6874/_tmp_space.db
19/07/31 17:12:20 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 17:12:20 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/07/31 17:12:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 17:12:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:21 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 17:12:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 17:12:21 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 17:12:21 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/07/31 17:12:21 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/07/31 17:12:21 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:21 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:21 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/07/31 17:12:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/07/31 17:12:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/07/31 17:12:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:54089 (size: 3.4 KB, free: 912.3 MB)
19/07/31 17:12:22 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/07/31 17:12:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/07/31 17:12:22 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/07/31 17:12:22 INFO Executor: Fetching spark://127.0.0.1:54088/jars/sparklyr-2.0-2.11.jar with timestamp 1564607535349
19/07/31 17:12:22 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:54088 after 12 ms (0 ms spent in bootstraps)
19/07/31 17:12:22 INFO Utils: Fetching spark://127.0.0.1:54088/jars/sparklyr-2.0-2.11.jar to /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-414747aa-b4b2-4b50-a440-dd74a5115d37/userFiles-e08c8d02-ffbd-4094-9dd5-00810fad1a6b/fetchFileTemp6138732170310682155.tmp
19/07/31 17:12:22 INFO Executor: Adding file:/private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-414747aa-b4b2-4b50-a440-dd74a5115d37/userFiles-e08c8d02-ffbd-4094-9dd5-00810fad1a6b/sparklyr-2.0-2.11.jar to class loader
19/07/31 17:12:22 INFO CodeGenerator: Code generated in 165.715421 ms
19/07/31 17:12:22 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
19/07/31 17:12:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 397 ms on localhost (executor driver) (1/1)
19/07/31 17:12:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/07/31 17:12:22 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.413 s
19/07/31 17:12:22 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0.581480 s
19/07/31 17:12:22 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 17:12:22 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#10)) > 0)
19/07/31 17:12:22 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 17:12:22 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 17:12:22 INFO CodeGenerator: Code generated in 12.961537 ms
19/07/31 17:12:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 281.2 KB, free 912.0 MB)
19/07/31 17:12:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.8 KB, free 912.0 MB)
19/07/31 17:12:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:54089 (size: 23.8 KB, free: 912.3 MB)
19/07/31 17:12:22 INFO SparkContext: Created broadcast 1 from csv at NativeMethodAccessorImpl.java:0
19/07/31 17:12:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 17:12:23 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 17:12:23 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 17:12:23 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 17:12:23 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:23 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:23 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 17:12:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 912.0 MB)
19/07/31 17:12:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 912.0 MB)
19/07/31 17:12:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:54089 (size: 4.3 KB, free: 912.3 MB)
19/07/31 17:12:23 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:23 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/07/31 17:12:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:12:23 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/07/31 17:12:23 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 17:12:23 INFO CodeGenerator: Code generated in 7.798008 ms
19/07/31 17:12:23 INFO ContextCleaner: Cleaned accumulator 0
19/07/31 17:12:23 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:54089 in memory (size: 3.4 KB, free: 912.3 MB)
19/07/31 17:12:23 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1480 bytes result sent to driver
19/07/31 17:12:23 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 220 ms on localhost (executor driver) (1/1)
19/07/31 17:12:23 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/07/31 17:12:23 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0.220 s
19/07/31 17:12:23 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0.235225 s
19/07/31 17:12:23 INFO CodeGenerator: Code generated in 6.76069 ms
19/07/31 17:12:23 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 17:12:23 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 17:12:23 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 17:12:23 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 17:12:23 INFO CodeGenerator: Code generated in 6.593883 ms
19/07/31 17:12:23 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 281.2 KB, free 911.7 MB)
19/07/31 17:12:23 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.7 MB)
19/07/31 17:12:23 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:54089 (size: 23.8 KB, free: 912.2 MB)
19/07/31 17:12:23 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:0
19/07/31 17:12:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 17:12:23 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 17:12:23 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 17:12:23 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 17:12:23 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:23 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:23 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 17:12:23 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.8 KB, free 911.7 MB)
19/07/31 17:12:23 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.7 MB)
19/07/31 17:12:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:54089 (size: 8.6 KB, free: 912.2 MB)
19/07/31 17:12:23 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/07/31 17:12:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:12:23 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/07/31 17:12:23 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 17:12:23 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1627 bytes result sent to driver
19/07/31 17:12:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 72 ms on localhost (executor driver) (1/1)
19/07/31 17:12:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/07/31 17:12:23 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.072 s
19/07/31 17:12:23 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.079461 s
19/07/31 17:12:23 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 17:12:23 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:23 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:23 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:23 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 17:12:23 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 17:12:23 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 17:12:23 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 17:12:23 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 17:12:23 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 17:12:23 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 17:12:23 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 17:12:23 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 17:12:23 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 282.3 KB, free 911.4 MB)
19/07/31 17:12:23 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.4 MB)
19/07/31 17:12:23 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:54089 (size: 24.0 KB, free: 912.2 MB)
19/07/31 17:12:23 INFO SparkContext: Created broadcast 5 from sql at NativeMethodAccessorImpl.java:0
19/07/31 17:12:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 17:12:23 INFO CodeGenerator: Code generated in 8.846619 ms
19/07/31 17:12:23 INFO CodeGenerator: Code generated in 9.721904 ms
19/07/31 17:12:23 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 17:12:23 INFO DAGScheduler: Registering RDD 18 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 17:12:23 INFO DAGScheduler: Got job 3 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 17:12:23 INFO DAGScheduler: Final stage: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 17:12:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/07/31 17:12:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/07/31 17:12:23 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 17:12:23 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 26.3 KB, free 911.3 MB)
19/07/31 17:12:23 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.8 KB, free 911.3 MB)
19/07/31 17:12:23 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:54089 (size: 11.8 KB, free: 912.2 MB)
19/07/31 17:12:23 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:23 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/07/31 17:12:23 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:12:23 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/07/31 17:12:23 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 17:12:23 INFO CodeGenerator: Code generated in 15.280128 ms
19/07/31 17:12:23 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 48.9 KB, free 911.3 MB)
19/07/31 17:12:23 INFO BlockManagerInfo: Added rdd_15_0 in memory on 127.0.0.1:54089 (size: 48.9 KB, free: 912.2 MB)
19/07/31 17:12:23 INFO CodeGenerator: Code generated in 3.656091 ms
19/07/31 17:12:23 INFO CodeGenerator: Code generated in 15.646427 ms
19/07/31 17:12:23 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2504 bytes result sent to driver
19/07/31 17:12:23 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 199 ms on localhost (executor driver) (1/1)
19/07/31 17:12:23 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/07/31 17:12:23 INFO DAGScheduler: ShuffleMapStage 3 (sql at NativeMethodAccessorImpl.java:0) finished in 0.202 s
19/07/31 17:12:23 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:12:23 INFO DAGScheduler: running: Set()
19/07/31 17:12:23 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/07/31 17:12:23 INFO DAGScheduler: failed: Set()
19/07/31 17:12:24 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 17:12:24 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 911.3 MB)
19/07/31 17:12:24 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.3 MB)
19/07/31 17:12:24 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:54089 (size: 3.7 KB, free: 912.2 MB)
19/07/31 17:12:24 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:24 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/07/31 17:12:24 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:12:24 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/07/31 17:12:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
19/07/31 17:12:24 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1624 bytes result sent to driver
19/07/31 17:12:24 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 33 ms on localhost (executor driver) (1/1)
19/07/31 17:12:24 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/07/31 17:12:24 INFO DAGScheduler: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0) finished in 0.034 s
19/07/31 17:12:24 INFO DAGScheduler: Job 3 finished: sql at NativeMethodAccessorImpl.java:0, took 0.282612 s
19/07/31 17:12:24 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 17:12:24 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:24 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:24 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:24 INFO DAGScheduler: Registering RDD 24 (collect at utils.scala:204)
19/07/31 17:12:24 INFO DAGScheduler: Got job 4 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:12:24 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
19/07/31 17:12:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/07/31 17:12:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/07/31 17:12:24 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:24 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 26.3 KB, free 911.2 MB)
19/07/31 17:12:24 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.9 KB, free 911.2 MB)
19/07/31 17:12:24 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:54089 (size: 11.9 KB, free: 912.1 MB)
19/07/31 17:12:24 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:24 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/07/31 17:12:24 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:12:24 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/07/31 17:12:24 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:24 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1780 bytes result sent to driver
19/07/31 17:12:24 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 11 ms on localhost (executor driver) (1/1)
19/07/31 17:12:24 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/07/31 17:12:24 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:12:24 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:12:24 INFO DAGScheduler: running: Set()
19/07/31 17:12:24 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/07/31 17:12:24 INFO DAGScheduler: failed: Set()
19/07/31 17:12:24 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:24 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 911.2 MB)
19/07/31 17:12:24 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.2 MB)
19/07/31 17:12:24 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:54089 (size: 3.7 KB, free: 912.1 MB)
19/07/31 17:12:24 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:24 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/07/31 17:12:24 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:12:24 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/07/31 17:12:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:24 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1581 bytes result sent to driver
19/07/31 17:12:24 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:12:24 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/07/31 17:12:24 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:12:24 INFO DAGScheduler: Job 4 finished: collect at utils.scala:204, took 0.034145 s
19/07/31 17:12:24 INFO CodeGenerator: Code generated in 5.674739 ms
19/07/31 17:12:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz1`
WHERE (0 = 1)
19/07/31 17:12:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_001`) `dbplyr_002`
ORDER BY `date`) `dbplyr_003`) `dbplyr_004`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:12:24 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:24 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_005`) `dbplyr_006`
ORDER BY `date`) `dbplyr_007`) `dbplyr_008`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:12:24 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:24 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:24 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#442 - cust_prospect_ind.nullCount#441) > 0)
19/07/31 17:12:24 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#447 - visit_device_type.nullCount#446) > 0)
19/07/31 17:12:24 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#440 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#439))
19/07/31 17:12:24 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#445 <= All Devices) && (All Devices <= visit_device_type.upperBound#444))
19/07/31 17:12:24 INFO CodeGenerator: Code generated in 16.081112 ms
19/07/31 17:12:24 INFO CodeGenerator: Code generated in 14.994347 ms
19/07/31 17:12:24 INFO CodeGenerator: Code generated in 7.036883 ms
19/07/31 17:12:24 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:24 INFO DAGScheduler: Got job 5 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:12:24 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:204)
19/07/31 17:12:24 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:24 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:24 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[32] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:24 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 72.1 KB, free 911.2 MB)
19/07/31 17:12:24 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.1 MB)
19/07/31 17:12:24 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:54089 (size: 30.4 KB, free: 912.1 MB)
19/07/31 17:12:24 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:24 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/07/31 17:12:24 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:12:24 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
19/07/31 17:12:24 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:24 INFO CodeGenerator: Code generated in 7.59647 ms
19/07/31 17:12:24 INFO CodeGenerator: Code generated in 10.995028 ms
19/07/31 17:12:24 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 7585 bytes result sent to driver
19/07/31 17:12:24 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 47 ms on localhost (executor driver) (1/1)
19/07/31 17:12:24 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/07/31 17:12:24 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:204) finished in 0.048 s
19/07/31 17:12:24 INFO DAGScheduler: Job 5 finished: collect at utils.scala:204, took 0.057195 s
19/07/31 17:12:24 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:24 INFO DAGScheduler: Registering RDD 33 (collect at utils.scala:204)
19/07/31 17:12:24 INFO DAGScheduler: Got job 6 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:12:24 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:204)
19/07/31 17:12:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
19/07/31 17:12:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
19/07/31 17:12:24 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[33] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:24 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 74.5 KB, free 911.1 MB)
19/07/31 17:12:24 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 31.7 KB, free 911.0 MB)
19/07/31 17:12:24 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:54089 (size: 31.7 KB, free: 912.1 MB)
19/07/31 17:12:24 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[33] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:24 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/07/31 17:12:24 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:12:24 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
19/07/31 17:12:24 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:24 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1730 bytes result sent to driver
19/07/31 17:12:24 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 21 ms on localhost (executor driver) (1/1)
19/07/31 17:12:24 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/07/31 17:12:24 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:204) finished in 0.022 s
19/07/31 17:12:24 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:12:24 INFO DAGScheduler: running: Set()
19/07/31 17:12:24 INFO DAGScheduler: waiting: Set(ResultStage 9)
19/07/31 17:12:24 INFO DAGScheduler: failed: Set()
19/07/31 17:12:24 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[36] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:24 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 16.8 KB, free 911.0 MB)
19/07/31 17:12:24 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.0 MB)
19/07/31 17:12:24 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:54089 (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:12:24 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:24 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 9 (MapPartitionsRDD[36] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:12:24 INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks
19/07/31 17:12:24 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:12:24 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 10, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:12:24 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 11, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:12:24 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 12, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:12:24 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
19/07/31 17:12:24 INFO Executor: Running task 1.0 in stage 9.0 (TID 10)
19/07/31 17:12:24 INFO Executor: Running task 2.0 in stage 9.0 (TID 11)
19/07/31 17:12:24 INFO Executor: Running task 3.0 in stage 9.0 (TID 12)
19/07/31 17:12:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:24 INFO CodeGenerator: Code generated in 5.675461 ms
19/07/31 17:12:24 INFO Executor: Finished task 3.0 in stage 9.0 (TID 12). 2362 bytes result sent to driver
19/07/31 17:12:24 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2382 bytes result sent to driver
19/07/31 17:12:24 INFO Executor: Finished task 1.0 in stage 9.0 (TID 10). 2403 bytes result sent to driver
19/07/31 17:12:24 INFO Executor: Finished task 2.0 in stage 9.0 (TID 11). 2390 bytes result sent to driver
19/07/31 17:12:24 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 12) in 45 ms on localhost (executor driver) (1/4)
19/07/31 17:12:24 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 11) in 45 ms on localhost (executor driver) (2/4)
19/07/31 17:12:24 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 10) in 46 ms on localhost (executor driver) (3/4)
19/07/31 17:12:24 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 46 ms on localhost (executor driver) (4/4)
19/07/31 17:12:24 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/07/31 17:12:24 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:204) finished in 0.046 s
19/07/31 17:12:24 INFO DAGScheduler: Job 6 finished: collect at utils.scala:204, took 0.086967 s
19/07/31 17:12:24 INFO CodeGenerator: Code generated in 16.478076 ms
19/07/31 17:12:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_009`) `dbplyr_010`
ORDER BY `date`) `dbplyr_011`) `dbplyr_012`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:12:25 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_013`) `dbplyr_014`
ORDER BY `date`) `dbplyr_015`) `dbplyr_016`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:12:25 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:25 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#540 - cust_prospect_ind.nullCount#539) > 0)
19/07/31 17:12:25 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#545 - visit_device_type.nullCount#544) > 0)
19/07/31 17:12:25 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#538 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#537))
19/07/31 17:12:25 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#543 <= All Devices) && (All Devices <= visit_device_type.upperBound#542))
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 116
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 181
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 178
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 177
19/07/31 17:12:25 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:54089 in memory (size: 30.4 KB, free: 912.1 MB)
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 118
19/07/31 17:12:25 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:54089 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 17:12:25 INFO ContextCleaner: Cleaned shuffle 0
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 179
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 176
19/07/31 17:12:25 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:54089 in memory (size: 8.6 KB, free: 912.1 MB)
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 180
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 117
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 122
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 123
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 182
19/07/31 17:12:25 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:54089 in memory (size: 11.8 KB, free: 912.1 MB)
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 121
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 184
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 125
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 119
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 115
19/07/31 17:12:25 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:54089 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 186
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 236
19/07/31 17:12:25 INFO ContextCleaner: Cleaned shuffle 1
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 187
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 126
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 317
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 114
19/07/31 17:12:25 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:54089 in memory (size: 11.9 KB, free: 912.1 MB)
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 120
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 175
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 183
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 124
19/07/31 17:12:25 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:54089 in memory (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:12:25 INFO ContextCleaner: Cleaned accumulator 185
19/07/31 17:12:25 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:54089 in memory (size: 31.7 KB, free: 912.2 MB)
19/07/31 17:12:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:25 INFO DAGScheduler: Got job 7 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:12:25 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:204)
19/07/31 17:12:25 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:25 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:25 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[41] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:25 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 72.1 KB, free 911.3 MB)
19/07/31 17:12:25 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 30.5 KB, free 911.2 MB)
19/07/31 17:12:25 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:54089 (size: 30.5 KB, free: 912.1 MB)
19/07/31 17:12:25 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[41] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:25 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/07/31 17:12:25 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:12:25 INFO Executor: Running task 0.0 in stage 10.0 (TID 13)
19/07/31 17:12:25 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:25 INFO Executor: Finished task 0.0 in stage 10.0 (TID 13). 7542 bytes result sent to driver
19/07/31 17:12:25 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 13) in 11 ms on localhost (executor driver) (1/1)
19/07/31 17:12:25 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/07/31 17:12:25 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:12:25 INFO DAGScheduler: Job 7 finished: collect at utils.scala:204, took 0.021085 s
19/07/31 17:12:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:25 INFO DAGScheduler: Registering RDD 42 (collect at utils.scala:204)
19/07/31 17:12:25 INFO DAGScheduler: Got job 8 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:12:25 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:204)
19/07/31 17:12:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
19/07/31 17:12:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
19/07/31 17:12:25 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[42] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:25 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 74.5 KB, free 911.2 MB)
19/07/31 17:12:25 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.1 MB)
19/07/31 17:12:25 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:54089 (size: 31.8 KB, free: 912.1 MB)
19/07/31 17:12:25 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[42] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:25 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/07/31 17:12:25 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:12:25 INFO Executor: Running task 0.0 in stage 11.0 (TID 14)
19/07/31 17:12:25 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:25 INFO Executor: Finished task 0.0 in stage 11.0 (TID 14). 1687 bytes result sent to driver
19/07/31 17:12:25 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 14) in 15 ms on localhost (executor driver) (1/1)
19/07/31 17:12:25 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/07/31 17:12:25 INFO DAGScheduler: ShuffleMapStage 11 (collect at utils.scala:204) finished in 0.016 s
19/07/31 17:12:25 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:12:25 INFO DAGScheduler: running: Set()
19/07/31 17:12:25 INFO DAGScheduler: waiting: Set(ResultStage 12)
19/07/31 17:12:25 INFO DAGScheduler: failed: Set()
19/07/31 17:12:25 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[45] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:25 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 16.8 KB, free 911.1 MB)
19/07/31 17:12:25 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.1 MB)
19/07/31 17:12:25 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:54089 (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:12:25 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:25 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 12 (MapPartitionsRDD[45] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:12:25 INFO TaskSchedulerImpl: Adding task set 12.0 with 4 tasks
19/07/31 17:12:25 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 15, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:12:25 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 16, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:12:25 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 17, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:12:25 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 18, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:12:25 INFO Executor: Running task 1.0 in stage 12.0 (TID 16)
19/07/31 17:12:25 INFO Executor: Running task 3.0 in stage 12.0 (TID 18)
19/07/31 17:12:25 INFO Executor: Running task 0.0 in stage 12.0 (TID 15)
19/07/31 17:12:25 INFO Executor: Running task 2.0 in stage 12.0 (TID 17)
19/07/31 17:12:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:12:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:12:25 INFO Executor: Finished task 2.0 in stage 12.0 (TID 17). 2390 bytes result sent to driver
19/07/31 17:12:25 INFO Executor: Finished task 0.0 in stage 12.0 (TID 15). 2382 bytes result sent to driver
19/07/31 17:12:25 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 17) in 9 ms on localhost (executor driver) (1/4)
19/07/31 17:12:25 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 15) in 11 ms on localhost (executor driver) (2/4)
19/07/31 17:12:25 INFO Executor: Finished task 3.0 in stage 12.0 (TID 18). 2362 bytes result sent to driver
19/07/31 17:12:25 INFO Executor: Finished task 1.0 in stage 12.0 (TID 16). 2403 bytes result sent to driver
19/07/31 17:12:25 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 18) in 10 ms on localhost (executor driver) (3/4)
19/07/31 17:12:25 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 16) in 11 ms on localhost (executor driver) (4/4)
19/07/31 17:12:25 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/07/31 17:12:25 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:12:25 INFO DAGScheduler: Job 8 finished: collect at utils.scala:204, took 0.042752 s
19/07/31 17:12:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_017`) `dbplyr_018`
ORDER BY `date`) `dbplyr_019`) `dbplyr_020`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:12:25 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_021`) `dbplyr_022`
ORDER BY `date`) `dbplyr_023`) `dbplyr_024`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:12:25 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:25 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#638 - cust_prospect_ind.nullCount#637) > 0)
19/07/31 17:12:25 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#643 - visit_device_type.nullCount#642) > 0)
19/07/31 17:12:25 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#636 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#635))
19/07/31 17:12:25 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#641 <= All Devices) && (All Devices <= visit_device_type.upperBound#640))
19/07/31 17:12:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:25 INFO DAGScheduler: Got job 9 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:12:25 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:204)
19/07/31 17:12:25 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:25 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:25 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[50] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:25 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 72.1 KB, free 911.0 MB)
19/07/31 17:12:25 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 30.5 KB, free 911.0 MB)
19/07/31 17:12:25 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:54089 (size: 30.5 KB, free: 912.1 MB)
19/07/31 17:12:25 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[50] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:25 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/07/31 17:12:25 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:12:25 INFO Executor: Running task 0.0 in stage 13.0 (TID 19)
19/07/31 17:12:25 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:25 INFO Executor: Finished task 0.0 in stage 13.0 (TID 19). 7542 bytes result sent to driver
19/07/31 17:12:25 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 19) in 14 ms on localhost (executor driver) (1/1)
19/07/31 17:12:25 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/07/31 17:12:25 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:204) finished in 0.014 s
19/07/31 17:12:25 INFO DAGScheduler: Job 9 finished: collect at utils.scala:204, took 0.022578 s
19/07/31 17:12:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:25 INFO DAGScheduler: Registering RDD 51 (collect at utils.scala:204)
19/07/31 17:12:25 INFO DAGScheduler: Got job 10 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:12:25 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:204)
19/07/31 17:12:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
19/07/31 17:12:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
19/07/31 17:12:25 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[51] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:25 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 74.5 KB, free 910.9 MB)
19/07/31 17:12:25 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.9 MB)
19/07/31 17:12:25 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:54089 (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:12:25 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[51] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:25 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/07/31 17:12:25 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:12:25 INFO Executor: Running task 0.0 in stage 14.0 (TID 20)
19/07/31 17:12:25 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:25 INFO Executor: Finished task 0.0 in stage 14.0 (TID 20). 1687 bytes result sent to driver
19/07/31 17:12:25 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 20) in 13 ms on localhost (executor driver) (1/1)
19/07/31 17:12:25 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/07/31 17:12:25 INFO DAGScheduler: ShuffleMapStage 14 (collect at utils.scala:204) finished in 0.014 s
19/07/31 17:12:25 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:12:25 INFO DAGScheduler: running: Set()
19/07/31 17:12:25 INFO DAGScheduler: waiting: Set(ResultStage 15)
19/07/31 17:12:25 INFO DAGScheduler: failed: Set()
19/07/31 17:12:25 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[54] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:25 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 16.8 KB, free 910.9 MB)
19/07/31 17:12:25 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.9 MB)
19/07/31 17:12:25 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:54089 (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:12:25 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:25 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:12:25 INFO TaskSchedulerImpl: Adding task set 15.0 with 4 tasks
19/07/31 17:12:25 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 21, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:12:25 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 22, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:12:25 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 23, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:12:25 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 24, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:12:25 INFO Executor: Running task 0.0 in stage 15.0 (TID 21)
19/07/31 17:12:25 INFO Executor: Running task 1.0 in stage 15.0 (TID 22)
19/07/31 17:12:25 INFO Executor: Running task 3.0 in stage 15.0 (TID 24)
19/07/31 17:12:25 INFO Executor: Running task 2.0 in stage 15.0 (TID 23)
19/07/31 17:12:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:12:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:12:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:25 INFO Executor: Finished task 3.0 in stage 15.0 (TID 24). 2362 bytes result sent to driver
19/07/31 17:12:25 INFO Executor: Finished task 1.0 in stage 15.0 (TID 22). 2403 bytes result sent to driver
19/07/31 17:12:25 INFO Executor: Finished task 2.0 in stage 15.0 (TID 23). 2390 bytes result sent to driver
19/07/31 17:12:25 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 24) in 6 ms on localhost (executor driver) (1/4)
19/07/31 17:12:25 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 22) in 7 ms on localhost (executor driver) (2/4)
19/07/31 17:12:25 INFO Executor: Finished task 0.0 in stage 15.0 (TID 21). 2382 bytes result sent to driver
19/07/31 17:12:25 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 23) in 8 ms on localhost (executor driver) (3/4)
19/07/31 17:12:25 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 21) in 8 ms on localhost (executor driver) (4/4)
19/07/31 17:12:25 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/07/31 17:12:25 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:12:25 INFO DAGScheduler: Job 10 finished: collect at utils.scala:204, took 0.037015 s
19/07/31 17:12:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_025`) `dbplyr_026`
ORDER BY `date`) `dbplyr_027`) `dbplyr_028`
WHERE ((`customer` = "All Visitors") AND (`device` = "Mobile Phone"))
19/07/31 17:12:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_029`) `dbplyr_030`
ORDER BY `date`) `dbplyr_031`) `dbplyr_032`
WHERE ((`customer` = "All Visitors") AND (`device` = "Mobile Phone"))
19/07/31 17:12:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:26 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#736 - cust_prospect_ind.nullCount#735) > 0)
19/07/31 17:12:26 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#741 - visit_device_type.nullCount#740) > 0)
19/07/31 17:12:26 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#734 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#733))
19/07/31 17:12:26 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#739 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#738))
19/07/31 17:12:26 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:26 INFO DAGScheduler: Got job 11 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:12:26 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:204)
19/07/31 17:12:26 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:26 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:26 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[59] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:26 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 72.1 KB, free 910.8 MB)
19/07/31 17:12:26 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.8 MB)
19/07/31 17:12:26 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:54089 (size: 30.4 KB, free: 912.0 MB)
19/07/31 17:12:26 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[59] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:26 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/07/31 17:12:26 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:12:26 INFO Executor: Running task 0.0 in stage 16.0 (TID 25)
19/07/31 17:12:26 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:26 INFO Executor: Finished task 0.0 in stage 16.0 (TID 25). 7542 bytes result sent to driver
19/07/31 17:12:26 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 25) in 10 ms on localhost (executor driver) (1/1)
19/07/31 17:12:26 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/07/31 17:12:26 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:12:26 INFO DAGScheduler: Job 11 finished: collect at utils.scala:204, took 0.017596 s
19/07/31 17:12:26 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:26 INFO DAGScheduler: Registering RDD 60 (collect at utils.scala:204)
19/07/31 17:12:26 INFO DAGScheduler: Got job 12 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:12:26 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:204)
19/07/31 17:12:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
19/07/31 17:12:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
19/07/31 17:12:26 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[60] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:26 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 74.6 KB, free 910.7 MB)
19/07/31 17:12:26 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.7 MB)
19/07/31 17:12:26 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:54089 (size: 31.7 KB, free: 912.0 MB)
19/07/31 17:12:26 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[60] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:26 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
19/07/31 17:12:26 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:12:26 INFO Executor: Running task 0.0 in stage 17.0 (TID 26)
19/07/31 17:12:26 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:26 INFO Executor: Finished task 0.0 in stage 17.0 (TID 26). 1687 bytes result sent to driver
19/07/31 17:12:26 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 26) in 14 ms on localhost (executor driver) (1/1)
19/07/31 17:12:26 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/07/31 17:12:26 INFO DAGScheduler: ShuffleMapStage 17 (collect at utils.scala:204) finished in 0.014 s
19/07/31 17:12:26 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:12:26 INFO DAGScheduler: running: Set()
19/07/31 17:12:26 INFO DAGScheduler: waiting: Set(ResultStage 18)
19/07/31 17:12:26 INFO DAGScheduler: failed: Set()
19/07/31 17:12:26 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[63] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:26 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 16.8 KB, free 910.7 MB)
19/07/31 17:12:26 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.7 MB)
19/07/31 17:12:26 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:54089 (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:12:26 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 18 (MapPartitionsRDD[63] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:12:26 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks
19/07/31 17:12:26 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 27, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:12:26 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 28, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:12:26 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 29, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:12:26 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 30, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:12:26 INFO Executor: Running task 1.0 in stage 18.0 (TID 28)
19/07/31 17:12:26 INFO Executor: Running task 0.0 in stage 18.0 (TID 27)
19/07/31 17:12:26 INFO Executor: Running task 3.0 in stage 18.0 (TID 30)
19/07/31 17:12:26 INFO Executor: Running task 2.0 in stage 18.0 (TID 29)
19/07/31 17:12:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:26 INFO Executor: Finished task 2.0 in stage 18.0 (TID 29). 2372 bytes result sent to driver
19/07/31 17:12:26 INFO Executor: Finished task 1.0 in stage 18.0 (TID 28). 2383 bytes result sent to driver
19/07/31 17:12:26 INFO Executor: Finished task 3.0 in stage 18.0 (TID 30). 2358 bytes result sent to driver
19/07/31 17:12:26 INFO Executor: Finished task 0.0 in stage 18.0 (TID 27). 2385 bytes result sent to driver
19/07/31 17:12:26 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 30) in 7 ms on localhost (executor driver) (1/4)
19/07/31 17:12:26 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 28) in 7 ms on localhost (executor driver) (2/4)
19/07/31 17:12:26 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 29) in 7 ms on localhost (executor driver) (3/4)
19/07/31 17:12:26 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 27) in 8 ms on localhost (executor driver) (4/4)
19/07/31 17:12:26 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/07/31 17:12:26 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:12:26 INFO DAGScheduler: Job 12 finished: collect at utils.scala:204, took 0.035118 s
19/07/31 17:12:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_033`) `dbplyr_034`
ORDER BY `date`) `dbplyr_035`) `dbplyr_036`
WHERE ((`customer` = "All Visitors") AND (`device` = "Desktop"))
19/07/31 17:12:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_037`) `dbplyr_038`
ORDER BY `date`) `dbplyr_039`) `dbplyr_040`
WHERE ((`customer` = "All Visitors") AND (`device` = "Desktop"))
19/07/31 17:12:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:26 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#834 - cust_prospect_ind.nullCount#833) > 0)
19/07/31 17:12:26 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#839 - visit_device_type.nullCount#838) > 0)
19/07/31 17:12:26 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#832 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#831))
19/07/31 17:12:26 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#837 <= Desktop) && (Desktop <= visit_device_type.upperBound#836))
19/07/31 17:12:26 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:26 INFO DAGScheduler: Got job 13 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:12:26 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:204)
19/07/31 17:12:26 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:26 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:26 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[68] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:26 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 72.1 KB, free 910.6 MB)
19/07/31 17:12:26 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.6 MB)
19/07/31 17:12:26 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:54089 (size: 30.5 KB, free: 911.9 MB)
19/07/31 17:12:26 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[68] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:26 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/07/31 17:12:26 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:12:26 INFO Executor: Running task 0.0 in stage 19.0 (TID 31)
19/07/31 17:12:26 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:26 INFO Executor: Finished task 0.0 in stage 19.0 (TID 31). 7068 bytes result sent to driver
19/07/31 17:12:26 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 31) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:12:26 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/07/31 17:12:26 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:12:26 INFO DAGScheduler: Job 13 finished: collect at utils.scala:204, took 0.016192 s
19/07/31 17:12:26 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:26 INFO DAGScheduler: Registering RDD 69 (collect at utils.scala:204)
19/07/31 17:12:26 INFO DAGScheduler: Got job 14 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:12:26 INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:204)
19/07/31 17:12:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
19/07/31 17:12:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
19/07/31 17:12:26 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[69] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:26 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 74.5 KB, free 910.5 MB)
19/07/31 17:12:26 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.5 MB)
19/07/31 17:12:26 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:54089 (size: 31.8 KB, free: 911.9 MB)
19/07/31 17:12:26 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[69] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:26 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/07/31 17:12:26 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:12:26 INFO Executor: Running task 0.0 in stage 20.0 (TID 32)
19/07/31 17:12:26 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:26 INFO Executor: Finished task 0.0 in stage 20.0 (TID 32). 1687 bytes result sent to driver
19/07/31 17:12:26 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 32) in 12 ms on localhost (executor driver) (1/1)
19/07/31 17:12:26 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/07/31 17:12:26 INFO DAGScheduler: ShuffleMapStage 20 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:12:26 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:12:26 INFO DAGScheduler: running: Set()
19/07/31 17:12:26 INFO DAGScheduler: waiting: Set(ResultStage 21)
19/07/31 17:12:26 INFO DAGScheduler: failed: Set()
19/07/31 17:12:26 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[72] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:26 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 16.8 KB, free 910.4 MB)
19/07/31 17:12:26 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.4 MB)
19/07/31 17:12:26 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:54089 (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:12:26 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:26 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 21 (MapPartitionsRDD[72] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:12:26 INFO TaskSchedulerImpl: Adding task set 21.0 with 4 tasks
19/07/31 17:12:26 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 33, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:12:26 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 34, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:12:26 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 35, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:12:26 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 36, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:12:26 INFO Executor: Running task 0.0 in stage 21.0 (TID 33)
19/07/31 17:12:26 INFO Executor: Running task 1.0 in stage 21.0 (TID 34)
19/07/31 17:12:26 INFO Executor: Running task 3.0 in stage 21.0 (TID 36)
19/07/31 17:12:26 INFO Executor: Running task 2.0 in stage 21.0 (TID 35)
19/07/31 17:12:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:26 INFO Executor: Finished task 0.0 in stage 21.0 (TID 33). 2381 bytes result sent to driver
19/07/31 17:12:26 INFO Executor: Finished task 3.0 in stage 21.0 (TID 36). 2356 bytes result sent to driver
19/07/31 17:12:26 INFO Executor: Finished task 1.0 in stage 21.0 (TID 34). 2385 bytes result sent to driver
19/07/31 17:12:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:26 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 33) in 7 ms on localhost (executor driver) (1/4)
19/07/31 17:12:26 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 34) in 7 ms on localhost (executor driver) (2/4)
19/07/31 17:12:26 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 36) in 7 ms on localhost (executor driver) (3/4)
19/07/31 17:12:26 INFO Executor: Finished task 2.0 in stage 21.0 (TID 35). 2380 bytes result sent to driver
19/07/31 17:12:26 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 35) in 10 ms on localhost (executor driver) (4/4)
19/07/31 17:12:26 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/07/31 17:12:26 INFO DAGScheduler: ResultStage 21 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:12:26 INFO DAGScheduler: Job 14 finished: collect at utils.scala:204, took 0.033546 s
19/07/31 17:12:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_041`) `dbplyr_042`
ORDER BY `date`) `dbplyr_043`) `dbplyr_044`
WHERE ((`customer` = "All Visitors") AND (`device` = "Tablet"))
19/07/31 17:12:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_045`) `dbplyr_046`
ORDER BY `date`) `dbplyr_047`) `dbplyr_048`
WHERE ((`customer` = "All Visitors") AND (`device` = "Tablet"))
19/07/31 17:12:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:26 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#932 - cust_prospect_ind.nullCount#931) > 0)
19/07/31 17:12:26 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#937 - visit_device_type.nullCount#936) > 0)
19/07/31 17:12:26 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#930 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#929))
19/07/31 17:12:26 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#935 <= Tablet) && (Tablet <= visit_device_type.upperBound#934))
19/07/31 17:12:27 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:27 INFO DAGScheduler: Got job 15 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:12:27 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:204)
19/07/31 17:12:27 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:27 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:27 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[77] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:27 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 72.1 KB, free 910.4 MB)
19/07/31 17:12:27 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.3 MB)
19/07/31 17:12:27 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:54089 (size: 30.4 KB, free: 911.9 MB)
19/07/31 17:12:27 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[77] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:27 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
19/07/31 17:12:27 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:12:27 INFO Executor: Running task 0.0 in stage 22.0 (TID 37)
19/07/31 17:12:27 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:27 INFO Executor: Finished task 0.0 in stage 22.0 (TID 37). 7068 bytes result sent to driver
19/07/31 17:12:27 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 37) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:12:27 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/07/31 17:12:27 INFO DAGScheduler: ResultStage 22 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:12:27 INFO DAGScheduler: Job 15 finished: collect at utils.scala:204, took 0.015955 s
19/07/31 17:12:27 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:27 INFO DAGScheduler: Registering RDD 78 (collect at utils.scala:204)
19/07/31 17:12:27 INFO DAGScheduler: Got job 16 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:12:27 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:204)
19/07/31 17:12:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
19/07/31 17:12:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 23)
19/07/31 17:12:27 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[78] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:27 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 74.5 KB, free 910.3 MB)
19/07/31 17:12:27 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.2 MB)
19/07/31 17:12:27 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:54089 (size: 31.7 KB, free: 911.8 MB)
19/07/31 17:12:27 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[78] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:27 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
19/07/31 17:12:27 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:12:27 INFO Executor: Running task 0.0 in stage 23.0 (TID 38)
19/07/31 17:12:27 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:27 INFO Executor: Finished task 0.0 in stage 23.0 (TID 38). 1687 bytes result sent to driver
19/07/31 17:12:27 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 38) in 12 ms on localhost (executor driver) (1/1)
19/07/31 17:12:27 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
19/07/31 17:12:27 INFO DAGScheduler: ShuffleMapStage 23 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:12:27 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:12:27 INFO DAGScheduler: running: Set()
19/07/31 17:12:27 INFO DAGScheduler: waiting: Set(ResultStage 24)
19/07/31 17:12:27 INFO DAGScheduler: failed: Set()
19/07/31 17:12:27 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[81] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:27 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 16.8 KB, free 910.2 MB)
19/07/31 17:12:27 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.2 MB)
19/07/31 17:12:27 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:54089 (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:12:27 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[81] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:12:27 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks
19/07/31 17:12:27 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 39, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:12:27 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 40, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:12:27 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 41, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:12:27 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 42, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:12:27 INFO Executor: Running task 0.0 in stage 24.0 (TID 39)
19/07/31 17:12:27 INFO Executor: Running task 3.0 in stage 24.0 (TID 42)
19/07/31 17:12:27 INFO Executor: Running task 1.0 in stage 24.0 (TID 40)
19/07/31 17:12:27 INFO Executor: Running task 2.0 in stage 24.0 (TID 41)
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:27 INFO Executor: Finished task 2.0 in stage 24.0 (TID 41). 2362 bytes result sent to driver
19/07/31 17:12:27 INFO Executor: Finished task 1.0 in stage 24.0 (TID 40). 2361 bytes result sent to driver
19/07/31 17:12:27 INFO Executor: Finished task 0.0 in stage 24.0 (TID 39). 2363 bytes result sent to driver
19/07/31 17:12:27 INFO Executor: Finished task 3.0 in stage 24.0 (TID 42). 2337 bytes result sent to driver
19/07/31 17:12:27 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 41) in 7 ms on localhost (executor driver) (1/4)
19/07/31 17:12:27 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 40) in 7 ms on localhost (executor driver) (2/4)
19/07/31 17:12:27 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 39) in 7 ms on localhost (executor driver) (3/4)
19/07/31 17:12:27 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 42) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:12:27 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
19/07/31 17:12:27 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:12:27 INFO DAGScheduler: Job 16 finished: collect at utils.scala:204, took 0.031676 s
19/07/31 17:12:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_049`) `dbplyr_050`
ORDER BY `date`) `dbplyr_051`) `dbplyr_052`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "All Devices"))
19/07/31 17:12:27 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:27 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_053`) `dbplyr_054`
ORDER BY `date`) `dbplyr_055`) `dbplyr_056`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "All Devices"))
19/07/31 17:12:27 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:27 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:27 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1030 - cust_prospect_ind.nullCount#1029) > 0)
19/07/31 17:12:27 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1035 - visit_device_type.nullCount#1034) > 0)
19/07/31 17:12:27 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#1028 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#1027))
19/07/31 17:12:27 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#1033 <= All Devices) && (All Devices <= visit_device_type.upperBound#1032))
19/07/31 17:12:27 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:27 INFO DAGScheduler: Got job 17 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:12:27 INFO DAGScheduler: Final stage: ResultStage 25 (collect at utils.scala:204)
19/07/31 17:12:27 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:27 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:27 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[86] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:27 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 72.1 KB, free 910.1 MB)
19/07/31 17:12:27 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.1 MB)
19/07/31 17:12:27 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:54089 (size: 30.4 KB, free: 911.8 MB)
19/07/31 17:12:27 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[86] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:27 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
19/07/31 17:12:27 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:12:27 INFO Executor: Running task 0.0 in stage 25.0 (TID 43)
19/07/31 17:12:27 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:27 INFO Executor: Finished task 0.0 in stage 25.0 (TID 43). 6979 bytes result sent to driver
19/07/31 17:12:27 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 43) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:12:27 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
19/07/31 17:12:27 INFO DAGScheduler: ResultStage 25 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:12:27 INFO DAGScheduler: Job 17 finished: collect at utils.scala:204, took 0.015562 s
19/07/31 17:12:27 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:27 INFO DAGScheduler: Registering RDD 87 (collect at utils.scala:204)
19/07/31 17:12:27 INFO DAGScheduler: Got job 18 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:12:27 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:204)
19/07/31 17:12:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
19/07/31 17:12:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 26)
19/07/31 17:12:27 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[87] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:27 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 74.5 KB, free 910.0 MB)
19/07/31 17:12:27 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.0 MB)
19/07/31 17:12:27 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:54089 (size: 31.7 KB, free: 911.8 MB)
19/07/31 17:12:27 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[87] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:27 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
19/07/31 17:12:27 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:12:27 INFO Executor: Running task 0.0 in stage 26.0 (TID 44)
19/07/31 17:12:27 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:27 INFO Executor: Finished task 0.0 in stage 26.0 (TID 44). 1687 bytes result sent to driver
19/07/31 17:12:27 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 44) in 14 ms on localhost (executor driver) (1/1)
19/07/31 17:12:27 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
19/07/31 17:12:27 INFO DAGScheduler: ShuffleMapStage 26 (collect at utils.scala:204) finished in 0.015 s
19/07/31 17:12:27 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:12:27 INFO DAGScheduler: running: Set()
19/07/31 17:12:27 INFO DAGScheduler: waiting: Set(ResultStage 27)
19/07/31 17:12:27 INFO DAGScheduler: failed: Set()
19/07/31 17:12:27 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[90] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:27 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 16.8 KB, free 910.0 MB)
19/07/31 17:12:27 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.0 MB)
19/07/31 17:12:27 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:54089 (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:12:27 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 27 (MapPartitionsRDD[90] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:12:27 INFO TaskSchedulerImpl: Adding task set 27.0 with 4 tasks
19/07/31 17:12:27 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 45, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:12:27 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 46, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:12:27 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 47, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:12:27 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 48, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:12:27 INFO Executor: Running task 0.0 in stage 27.0 (TID 45)
19/07/31 17:12:27 INFO Executor: Running task 2.0 in stage 27.0 (TID 47)
19/07/31 17:12:27 INFO Executor: Running task 1.0 in stage 27.0 (TID 46)
19/07/31 17:12:27 INFO Executor: Running task 3.0 in stage 27.0 (TID 48)
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:27 INFO Executor: Finished task 3.0 in stage 27.0 (TID 48). 2353 bytes result sent to driver
19/07/31 17:12:27 INFO Executor: Finished task 0.0 in stage 27.0 (TID 45). 2377 bytes result sent to driver
19/07/31 17:12:27 INFO Executor: Finished task 2.0 in stage 27.0 (TID 47). 2378 bytes result sent to driver
19/07/31 17:12:27 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 48) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:12:27 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 45) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:12:27 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 47) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:12:27 INFO Executor: Finished task 1.0 in stage 27.0 (TID 46). 2359 bytes result sent to driver
19/07/31 17:12:27 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 46) in 7 ms on localhost (executor driver) (4/4)
19/07/31 17:12:27 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
19/07/31 17:12:27 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:12:27 INFO DAGScheduler: Job 18 finished: collect at utils.scala:204, took 0.032286 s
19/07/31 17:12:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_057`) `dbplyr_058`
ORDER BY `date`) `dbplyr_059`) `dbplyr_060`
WHERE ((`customer` = "PROSPECT") AND (`device` = "All Devices"))
19/07/31 17:12:27 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:27 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_061`) `dbplyr_062`
ORDER BY `date`) `dbplyr_063`) `dbplyr_064`
WHERE ((`customer` = "PROSPECT") AND (`device` = "All Devices"))
19/07/31 17:12:27 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:27 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:27 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1128 - cust_prospect_ind.nullCount#1127) > 0)
19/07/31 17:12:27 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1133 - visit_device_type.nullCount#1132) > 0)
19/07/31 17:12:27 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#1126 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#1125))
19/07/31 17:12:27 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#1131 <= All Devices) && (All Devices <= visit_device_type.upperBound#1130))
19/07/31 17:12:27 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:27 INFO DAGScheduler: Got job 19 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:12:27 INFO DAGScheduler: Final stage: ResultStage 28 (collect at utils.scala:204)
19/07/31 17:12:27 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:27 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:27 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[95] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:27 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 72.1 KB, free 909.9 MB)
19/07/31 17:12:27 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.9 MB)
19/07/31 17:12:27 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:54089 (size: 30.5 KB, free: 911.7 MB)
19/07/31 17:12:27 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[95] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:27 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
19/07/31 17:12:27 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:12:27 INFO Executor: Running task 0.0 in stage 28.0 (TID 49)
19/07/31 17:12:27 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:27 INFO Executor: Finished task 0.0 in stage 28.0 (TID 49). 6979 bytes result sent to driver
19/07/31 17:12:27 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 49) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:12:27 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
19/07/31 17:12:27 INFO DAGScheduler: ResultStage 28 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:12:27 INFO DAGScheduler: Job 19 finished: collect at utils.scala:204, took 0.018822 s
19/07/31 17:12:27 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:27 INFO DAGScheduler: Registering RDD 96 (collect at utils.scala:204)
19/07/31 17:12:27 INFO DAGScheduler: Got job 20 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:12:27 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:204)
19/07/31 17:12:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
19/07/31 17:12:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 29)
19/07/31 17:12:27 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[96] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:27 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 74.5 KB, free 909.8 MB)
19/07/31 17:12:27 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.8 MB)
19/07/31 17:12:27 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:54089 (size: 31.8 KB, free: 911.7 MB)
19/07/31 17:12:27 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[96] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:27 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
19/07/31 17:12:27 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:12:27 INFO Executor: Running task 0.0 in stage 29.0 (TID 50)
19/07/31 17:12:27 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:27 INFO Executor: Finished task 0.0 in stage 29.0 (TID 50). 1687 bytes result sent to driver
19/07/31 17:12:27 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 50) in 10 ms on localhost (executor driver) (1/1)
19/07/31 17:12:27 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
19/07/31 17:12:27 INFO DAGScheduler: ShuffleMapStage 29 (collect at utils.scala:204) finished in 0.011 s
19/07/31 17:12:27 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:12:27 INFO DAGScheduler: running: Set()
19/07/31 17:12:27 INFO DAGScheduler: waiting: Set(ResultStage 30)
19/07/31 17:12:27 INFO DAGScheduler: failed: Set()
19/07/31 17:12:27 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[99] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:27 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 16.8 KB, free 909.8 MB)
19/07/31 17:12:27 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.7 MB)
19/07/31 17:12:27 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:54089 (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:12:27 INFO ContextCleaner: Cleaned shuffle 6
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 487
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 641
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 323
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 321
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 404
19/07/31 17:12:27 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 724
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 722
19/07/31 17:12:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 30 (MapPartitionsRDD[99] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:12:27 INFO TaskSchedulerImpl: Adding task set 30.0 with 4 tasks
19/07/31 17:12:27 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 51, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:12:27 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:54089 in memory (size: 30.5 KB, free: 911.7 MB)
19/07/31 17:12:27 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 52, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:12:27 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 53, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:12:27 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 54, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:12:27 INFO Executor: Running task 0.0 in stage 30.0 (TID 51)
19/07/31 17:12:27 INFO Executor: Running task 2.0 in stage 30.0 (TID 53)
19/07/31 17:12:27 INFO Executor: Running task 3.0 in stage 30.0 (TID 54)
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:27 INFO Executor: Running task 1.0 in stage 30.0 (TID 52)
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 803
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 239
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:27 INFO Executor: Finished task 2.0 in stage 30.0 (TID 53). 2391 bytes result sent to driver
19/07/31 17:12:27 INFO Executor: Finished task 1.0 in stage 30.0 (TID 52). 2357 bytes result sent to driver
19/07/31 17:12:27 INFO Executor: Finished task 0.0 in stage 30.0 (TID 51). 2383 bytes result sent to driver
19/07/31 17:12:27 INFO Executor: Finished task 3.0 in stage 30.0 (TID 54). 2369 bytes result sent to driver
19/07/31 17:12:27 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:54089 in memory (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:12:27 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 52) in 8 ms on localhost (executor driver) (1/4)
19/07/31 17:12:27 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 53) in 8 ms on localhost (executor driver) (2/4)
19/07/31 17:12:27 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 51) in 8 ms on localhost (executor driver) (3/4)
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 402
19/07/31 17:12:27 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 54) in 8 ms on localhost (executor driver) (4/4)
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 322
19/07/31 17:12:27 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
19/07/31 17:12:27 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:12:27 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:54089 in memory (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:12:27 INFO DAGScheduler: Job 20 finished: collect at utils.scala:204, took 0.040891 s
19/07/31 17:12:27 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:54089 in memory (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 646
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 244
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 400
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 237
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 482
19/07/31 17:12:27 INFO ContextCleaner: Cleaned shuffle 2
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 642
19/07/31 17:12:27 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:54089 in memory (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 485
19/07/31 17:12:27 INFO ContextCleaner: Cleaned shuffle 8
19/07/31 17:12:27 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:54089 in memory (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 319
19/07/31 17:12:27 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:54089 in memory (size: 31.7 KB, free: 911.8 MB)
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 563
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 649
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 401
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 728
19/07/31 17:12:27 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:54089 in memory (size: 30.4 KB, free: 911.9 MB)
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 320
19/07/31 17:12:27 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:54089 in memory (size: 30.5 KB, free: 911.9 MB)
19/07/31 17:12:27 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:54089 in memory (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 565
19/07/31 17:12:27 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:54089 in memory (size: 30.5 KB, free: 911.9 MB)
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 241
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 729
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 645
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 240
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 567
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 243
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 566
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 730
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 648
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 242
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 399
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 568
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 725
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 483
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 723
19/07/31 17:12:27 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:54089 in memory (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:12:27 INFO ContextCleaner: Cleaned shuffle 7
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 325
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 643
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 561
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 480
19/07/31 17:12:27 INFO ContextCleaner: Cleaned shuffle 5
19/07/31 17:12:27 INFO ContextCleaner: Cleaned shuffle 3
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 726
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 484
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 405
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 564
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 644
19/07/31 17:12:27 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:54089 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:12:27 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:54089 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 324
19/07/31 17:12:27 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:54089 in memory (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 403
19/07/31 17:12:27 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:54089 in memory (size: 30.4 KB, free: 912.0 MB)
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 479
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 398
19/07/31 17:12:27 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:54089 in memory (size: 31.7 KB, free: 912.1 MB)
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 562
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 560
19/07/31 17:12:27 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:54089 in memory (size: 30.4 KB, free: 912.1 MB)
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 647
19/07/31 17:12:27 INFO ContextCleaner: Cleaned shuffle 4
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 486
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 481
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 318
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 406
19/07/31 17:12:27 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:54089 in memory (size: 31.7 KB, free: 912.1 MB)
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 238
19/07/31 17:12:27 INFO ContextCleaner: Cleaned accumulator 727
19/07/31 17:12:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_065`) `dbplyr_066`
ORDER BY `date`) `dbplyr_067`) `dbplyr_068`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "All Devices"))
19/07/31 17:12:28 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:28 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_069`) `dbplyr_070`
ORDER BY `date`) `dbplyr_071`) `dbplyr_072`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "All Devices"))
19/07/31 17:12:28 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:28 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:28 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1226 - cust_prospect_ind.nullCount#1225) > 0)
19/07/31 17:12:28 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1231 - visit_device_type.nullCount#1230) > 0)
19/07/31 17:12:28 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#1224 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#1223))
19/07/31 17:12:28 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#1229 <= All Devices) && (All Devices <= visit_device_type.upperBound#1228))
19/07/31 17:12:28 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:28 INFO DAGScheduler: Got job 21 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:12:28 INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:204)
19/07/31 17:12:28 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:28 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:28 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[104] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:28 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 72.1 KB, free 911.1 MB)
19/07/31 17:12:28 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.1 MB)
19/07/31 17:12:28 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:54089 (size: 30.4 KB, free: 912.1 MB)
19/07/31 17:12:28 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[104] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:28 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
19/07/31 17:12:28 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:12:28 INFO Executor: Running task 0.0 in stage 31.0 (TID 55)
19/07/31 17:12:28 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:28 INFO Executor: Finished task 0.0 in stage 31.0 (TID 55). 7542 bytes result sent to driver
19/07/31 17:12:28 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 55) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:12:28 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
19/07/31 17:12:28 INFO DAGScheduler: ResultStage 31 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:12:28 INFO DAGScheduler: Job 21 finished: collect at utils.scala:204, took 0.014334 s
19/07/31 17:12:28 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:28 INFO DAGScheduler: Registering RDD 105 (collect at utils.scala:204)
19/07/31 17:12:28 INFO DAGScheduler: Got job 22 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:12:28 INFO DAGScheduler: Final stage: ResultStage 33 (collect at utils.scala:204)
19/07/31 17:12:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)
19/07/31 17:12:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 32)
19/07/31 17:12:28 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[105] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:28 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 74.5 KB, free 911.0 MB)
19/07/31 17:12:28 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 31.7 KB, free 911.0 MB)
19/07/31 17:12:28 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:54089 (size: 31.7 KB, free: 912.1 MB)
19/07/31 17:12:28 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[105] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:28 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
19/07/31 17:12:28 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:12:28 INFO Executor: Running task 0.0 in stage 32.0 (TID 56)
19/07/31 17:12:28 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:28 INFO Executor: Finished task 0.0 in stage 32.0 (TID 56). 1687 bytes result sent to driver
19/07/31 17:12:28 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 56) in 10 ms on localhost (executor driver) (1/1)
19/07/31 17:12:28 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
19/07/31 17:12:28 INFO DAGScheduler: ShuffleMapStage 32 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:12:28 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:12:28 INFO DAGScheduler: running: Set()
19/07/31 17:12:28 INFO DAGScheduler: waiting: Set(ResultStage 33)
19/07/31 17:12:28 INFO DAGScheduler: failed: Set()
19/07/31 17:12:28 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[108] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:28 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 16.8 KB, free 911.0 MB)
19/07/31 17:12:28 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.0 MB)
19/07/31 17:12:28 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:54089 (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:12:28 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:28 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 33 (MapPartitionsRDD[108] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:12:28 INFO TaskSchedulerImpl: Adding task set 33.0 with 4 tasks
19/07/31 17:12:28 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 57, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:12:28 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 58, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:12:28 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 59, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:12:28 INFO TaskSetManager: Starting task 3.0 in stage 33.0 (TID 60, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:12:28 INFO Executor: Running task 0.0 in stage 33.0 (TID 57)
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:28 INFO Executor: Running task 1.0 in stage 33.0 (TID 58)
19/07/31 17:12:28 INFO Executor: Running task 2.0 in stage 33.0 (TID 59)
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:28 INFO Executor: Running task 3.0 in stage 33.0 (TID 60)
19/07/31 17:12:28 INFO Executor: Finished task 2.0 in stage 33.0 (TID 59). 2386 bytes result sent to driver
19/07/31 17:12:28 INFO Executor: Finished task 0.0 in stage 33.0 (TID 57). 2386 bytes result sent to driver
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:28 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 59) in 10 ms on localhost (executor driver) (1/4)
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/07/31 17:12:28 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 57) in 10 ms on localhost (executor driver) (2/4)
19/07/31 17:12:28 INFO Executor: Finished task 3.0 in stage 33.0 (TID 60). 2374 bytes result sent to driver
19/07/31 17:12:28 INFO TaskSetManager: Finished task 3.0 in stage 33.0 (TID 60) in 10 ms on localhost (executor driver) (3/4)
19/07/31 17:12:28 INFO Executor: Finished task 1.0 in stage 33.0 (TID 58). 2392 bytes result sent to driver
19/07/31 17:12:28 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 58) in 13 ms on localhost (executor driver) (4/4)
19/07/31 17:12:28 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
19/07/31 17:12:28 INFO DAGScheduler: ResultStage 33 (collect at utils.scala:204) finished in 0.013 s
19/07/31 17:12:28 INFO DAGScheduler: Job 22 finished: collect at utils.scala:204, took 0.033582 s
19/07/31 17:12:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_073`) `dbplyr_074`
ORDER BY `date`) `dbplyr_075`) `dbplyr_076`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Mobile Phone"))
19/07/31 17:12:28 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:28 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_077`) `dbplyr_078`
ORDER BY `date`) `dbplyr_079`) `dbplyr_080`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Mobile Phone"))
19/07/31 17:12:28 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:28 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:28 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1324 - cust_prospect_ind.nullCount#1323) > 0)
19/07/31 17:12:28 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1329 - visit_device_type.nullCount#1328) > 0)
19/07/31 17:12:28 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#1322 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#1321))
19/07/31 17:12:28 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#1327 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#1326))
19/07/31 17:12:28 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:28 INFO DAGScheduler: Got job 23 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:12:28 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:204)
19/07/31 17:12:28 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:28 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:28 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[113] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:28 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 72.1 KB, free 910.9 MB)
19/07/31 17:12:28 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.9 MB)
19/07/31 17:12:28 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:54089 (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:12:28 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[113] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:28 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
19/07/31 17:12:28 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:12:28 INFO Executor: Running task 0.0 in stage 34.0 (TID 61)
19/07/31 17:12:28 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:28 INFO Executor: Finished task 0.0 in stage 34.0 (TID 61). 6979 bytes result sent to driver
19/07/31 17:12:28 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 61) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:12:28 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
19/07/31 17:12:28 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:12:28 INFO DAGScheduler: Job 23 finished: collect at utils.scala:204, took 0.013238 s
19/07/31 17:12:28 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:28 INFO DAGScheduler: Registering RDD 114 (collect at utils.scala:204)
19/07/31 17:12:28 INFO DAGScheduler: Got job 24 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:12:28 INFO DAGScheduler: Final stage: ResultStage 36 (collect at utils.scala:204)
19/07/31 17:12:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
19/07/31 17:12:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 35)
19/07/31 17:12:28 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[114] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:28 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 74.5 KB, free 910.8 MB)
19/07/31 17:12:28 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.8 MB)
19/07/31 17:12:28 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:54089 (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:12:28 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[114] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:28 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
19/07/31 17:12:28 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:12:28 INFO Executor: Running task 0.0 in stage 35.0 (TID 62)
19/07/31 17:12:28 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:28 INFO Executor: Finished task 0.0 in stage 35.0 (TID 62). 1687 bytes result sent to driver
19/07/31 17:12:28 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 62) in 11 ms on localhost (executor driver) (1/1)
19/07/31 17:12:28 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
19/07/31 17:12:28 INFO DAGScheduler: ShuffleMapStage 35 (collect at utils.scala:204) finished in 0.011 s
19/07/31 17:12:28 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:12:28 INFO DAGScheduler: running: Set()
19/07/31 17:12:28 INFO DAGScheduler: waiting: Set(ResultStage 36)
19/07/31 17:12:28 INFO DAGScheduler: failed: Set()
19/07/31 17:12:28 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[117] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:28 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 16.8 KB, free 910.8 MB)
19/07/31 17:12:28 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 8.1 KB, free 910.8 MB)
19/07/31 17:12:28 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:54089 (size: 8.1 KB, free: 912.0 MB)
19/07/31 17:12:28 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:28 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 36 (MapPartitionsRDD[117] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:12:28 INFO TaskSchedulerImpl: Adding task set 36.0 with 4 tasks
19/07/31 17:12:28 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 63, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:12:28 INFO TaskSetManager: Starting task 1.0 in stage 36.0 (TID 64, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:12:28 INFO TaskSetManager: Starting task 2.0 in stage 36.0 (TID 65, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:12:28 INFO TaskSetManager: Starting task 3.0 in stage 36.0 (TID 66, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:12:28 INFO Executor: Running task 1.0 in stage 36.0 (TID 64)
19/07/31 17:12:28 INFO Executor: Running task 0.0 in stage 36.0 (TID 63)
19/07/31 17:12:28 INFO Executor: Running task 2.0 in stage 36.0 (TID 65)
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:28 INFO Executor: Running task 3.0 in stage 36.0 (TID 66)
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:28 INFO Executor: Finished task 0.0 in stage 36.0 (TID 63). 2366 bytes result sent to driver
19/07/31 17:12:28 INFO Executor: Finished task 1.0 in stage 36.0 (TID 64). 2347 bytes result sent to driver
19/07/31 17:12:28 INFO Executor: Finished task 3.0 in stage 36.0 (TID 66). 2353 bytes result sent to driver
19/07/31 17:12:28 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 63) in 7 ms on localhost (executor driver) (1/4)
19/07/31 17:12:28 INFO TaskSetManager: Finished task 3.0 in stage 36.0 (TID 66) in 7 ms on localhost (executor driver) (2/4)
19/07/31 17:12:28 INFO Executor: Finished task 2.0 in stage 36.0 (TID 65). 2371 bytes result sent to driver
19/07/31 17:12:28 INFO TaskSetManager: Finished task 1.0 in stage 36.0 (TID 64) in 7 ms on localhost (executor driver) (3/4)
19/07/31 17:12:28 INFO TaskSetManager: Finished task 2.0 in stage 36.0 (TID 65) in 7 ms on localhost (executor driver) (4/4)
19/07/31 17:12:28 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
19/07/31 17:12:28 INFO DAGScheduler: ResultStage 36 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:12:28 INFO DAGScheduler: Job 24 finished: collect at utils.scala:204, took 0.030081 s
19/07/31 17:12:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_081`) `dbplyr_082`
ORDER BY `date`) `dbplyr_083`) `dbplyr_084`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Mobile Phone"))
19/07/31 17:12:28 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:28 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_085`) `dbplyr_086`
ORDER BY `date`) `dbplyr_087`) `dbplyr_088`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Mobile Phone"))
19/07/31 17:12:28 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:28 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:28 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1422 - cust_prospect_ind.nullCount#1421) > 0)
19/07/31 17:12:28 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1427 - visit_device_type.nullCount#1426) > 0)
19/07/31 17:12:28 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#1420 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#1419))
19/07/31 17:12:28 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#1425 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#1424))
19/07/31 17:12:28 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:28 INFO DAGScheduler: Got job 25 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:12:28 INFO DAGScheduler: Final stage: ResultStage 37 (collect at utils.scala:204)
19/07/31 17:12:28 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:28 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:28 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[122] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:28 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 72.1 KB, free 910.7 MB)
19/07/31 17:12:28 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.7 MB)
19/07/31 17:12:28 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:54089 (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:12:28 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[122] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:28 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
19/07/31 17:12:28 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:12:28 INFO Executor: Running task 0.0 in stage 37.0 (TID 67)
19/07/31 17:12:28 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:28 INFO Executor: Finished task 0.0 in stage 37.0 (TID 67). 6979 bytes result sent to driver
19/07/31 17:12:28 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 67) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:12:28 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
19/07/31 17:12:28 INFO DAGScheduler: ResultStage 37 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:12:28 INFO DAGScheduler: Job 25 finished: collect at utils.scala:204, took 0.015581 s
19/07/31 17:12:28 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:28 INFO DAGScheduler: Registering RDD 123 (collect at utils.scala:204)
19/07/31 17:12:28 INFO DAGScheduler: Got job 26 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:12:28 INFO DAGScheduler: Final stage: ResultStage 39 (collect at utils.scala:204)
19/07/31 17:12:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)
19/07/31 17:12:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 38)
19/07/31 17:12:28 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[123] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:28 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 74.5 KB, free 910.6 MB)
19/07/31 17:12:28 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.6 MB)
19/07/31 17:12:28 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:54089 (size: 31.8 KB, free: 911.9 MB)
19/07/31 17:12:28 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[123] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:28 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
19/07/31 17:12:28 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:12:28 INFO Executor: Running task 0.0 in stage 38.0 (TID 68)
19/07/31 17:12:28 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:28 INFO Executor: Finished task 0.0 in stage 38.0 (TID 68). 1687 bytes result sent to driver
19/07/31 17:12:28 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 68) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:12:28 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
19/07/31 17:12:28 INFO DAGScheduler: ShuffleMapStage 38 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:12:28 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:12:28 INFO DAGScheduler: running: Set()
19/07/31 17:12:28 INFO DAGScheduler: waiting: Set(ResultStage 39)
19/07/31 17:12:28 INFO DAGScheduler: failed: Set()
19/07/31 17:12:28 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[126] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:28 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 16.8 KB, free 910.5 MB)
19/07/31 17:12:28 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.5 MB)
19/07/31 17:12:28 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:54089 (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:12:28 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:28 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 39 (MapPartitionsRDD[126] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:12:28 INFO TaskSchedulerImpl: Adding task set 39.0 with 4 tasks
19/07/31 17:12:28 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 69, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:12:28 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 70, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:12:28 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 71, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:12:28 INFO TaskSetManager: Starting task 3.0 in stage 39.0 (TID 72, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:12:28 INFO Executor: Running task 0.0 in stage 39.0 (TID 69)
19/07/31 17:12:28 INFO Executor: Running task 1.0 in stage 39.0 (TID 70)
19/07/31 17:12:28 INFO Executor: Running task 2.0 in stage 39.0 (TID 71)
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:28 INFO Executor: Running task 3.0 in stage 39.0 (TID 72)
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:28 INFO Executor: Finished task 2.0 in stage 39.0 (TID 71). 2384 bytes result sent to driver
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:28 INFO Executor: Finished task 1.0 in stage 39.0 (TID 70). 2370 bytes result sent to driver
19/07/31 17:12:28 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 71) in 6 ms on localhost (executor driver) (1/4)
19/07/31 17:12:28 INFO Executor: Finished task 0.0 in stage 39.0 (TID 69). 2373 bytes result sent to driver
19/07/31 17:12:28 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 70) in 8 ms on localhost (executor driver) (2/4)
19/07/31 17:12:28 INFO Executor: Finished task 3.0 in stage 39.0 (TID 72). 2353 bytes result sent to driver
19/07/31 17:12:28 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 69) in 8 ms on localhost (executor driver) (3/4)
19/07/31 17:12:28 INFO TaskSetManager: Finished task 3.0 in stage 39.0 (TID 72) in 8 ms on localhost (executor driver) (4/4)
19/07/31 17:12:28 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
19/07/31 17:12:28 INFO DAGScheduler: ResultStage 39 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:12:28 INFO DAGScheduler: Job 26 finished: collect at utils.scala:204, took 0.028278 s
19/07/31 17:12:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_089`) `dbplyr_090`
ORDER BY `date`) `dbplyr_091`) `dbplyr_092`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 17:12:29 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:29 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_093`) `dbplyr_094`
ORDER BY `date`) `dbplyr_095`) `dbplyr_096`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 17:12:29 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:29 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:29 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1520 - cust_prospect_ind.nullCount#1519) > 0)
19/07/31 17:12:29 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1525 - visit_device_type.nullCount#1524) > 0)
19/07/31 17:12:29 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#1518 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#1517))
19/07/31 17:12:29 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#1523 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#1522))
19/07/31 17:12:29 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:29 INFO DAGScheduler: Got job 27 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:12:29 INFO DAGScheduler: Final stage: ResultStage 40 (collect at utils.scala:204)
19/07/31 17:12:29 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:29 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:29 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[131] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:29 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 72.1 KB, free 910.5 MB)
19/07/31 17:12:29 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.4 MB)
19/07/31 17:12:29 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:54089 (size: 30.4 KB, free: 911.9 MB)
19/07/31 17:12:29 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[131] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:29 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
19/07/31 17:12:29 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:12:29 INFO Executor: Running task 0.0 in stage 40.0 (TID 73)
19/07/31 17:12:29 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:29 INFO Executor: Finished task 0.0 in stage 40.0 (TID 73). 7542 bytes result sent to driver
19/07/31 17:12:29 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 73) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:12:29 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
19/07/31 17:12:29 INFO DAGScheduler: ResultStage 40 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:12:29 INFO DAGScheduler: Job 27 finished: collect at utils.scala:204, took 0.015009 s
19/07/31 17:12:29 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:29 INFO DAGScheduler: Registering RDD 132 (collect at utils.scala:204)
19/07/31 17:12:29 INFO DAGScheduler: Got job 28 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:12:29 INFO DAGScheduler: Final stage: ResultStage 42 (collect at utils.scala:204)
19/07/31 17:12:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
19/07/31 17:12:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
19/07/31 17:12:29 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[132] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:29 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 74.6 KB, free 910.4 MB)
19/07/31 17:12:29 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.3 MB)
19/07/31 17:12:29 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:54089 (size: 31.7 KB, free: 911.9 MB)
19/07/31 17:12:29 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[132] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:29 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
19/07/31 17:12:29 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 74, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:12:29 INFO Executor: Running task 0.0 in stage 41.0 (TID 74)
19/07/31 17:12:29 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:29 INFO Executor: Finished task 0.0 in stage 41.0 (TID 74). 1687 bytes result sent to driver
19/07/31 17:12:29 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 74) in 11 ms on localhost (executor driver) (1/1)
19/07/31 17:12:29 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
19/07/31 17:12:29 INFO DAGScheduler: ShuffleMapStage 41 (collect at utils.scala:204) finished in 0.011 s
19/07/31 17:12:29 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:12:29 INFO DAGScheduler: running: Set()
19/07/31 17:12:29 INFO DAGScheduler: waiting: Set(ResultStage 42)
19/07/31 17:12:29 INFO DAGScheduler: failed: Set()
19/07/31 17:12:29 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[135] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:29 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 16.8 KB, free 910.3 MB)
19/07/31 17:12:29 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.3 MB)
19/07/31 17:12:29 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:54089 (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:12:29 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 42 (MapPartitionsRDD[135] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:12:29 INFO TaskSchedulerImpl: Adding task set 42.0 with 4 tasks
19/07/31 17:12:29 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 75, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:12:29 INFO TaskSetManager: Starting task 1.0 in stage 42.0 (TID 76, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:12:29 INFO TaskSetManager: Starting task 2.0 in stage 42.0 (TID 77, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:12:29 INFO TaskSetManager: Starting task 3.0 in stage 42.0 (TID 78, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:12:29 INFO Executor: Running task 2.0 in stage 42.0 (TID 77)
19/07/31 17:12:29 INFO Executor: Running task 3.0 in stage 42.0 (TID 78)
19/07/31 17:12:29 INFO Executor: Running task 0.0 in stage 42.0 (TID 75)
19/07/31 17:12:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:29 INFO Executor: Running task 1.0 in stage 42.0 (TID 76)
19/07/31 17:12:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:12:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:12:29 INFO Executor: Finished task 2.0 in stage 42.0 (TID 77). 2377 bytes result sent to driver
19/07/31 17:12:29 INFO Executor: Finished task 3.0 in stage 42.0 (TID 78). 2356 bytes result sent to driver
19/07/31 17:12:29 INFO Executor: Finished task 0.0 in stage 42.0 (TID 75). 2334 bytes result sent to driver
19/07/31 17:12:29 INFO TaskSetManager: Finished task 2.0 in stage 42.0 (TID 77) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:12:29 INFO TaskSetManager: Finished task 3.0 in stage 42.0 (TID 78) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:12:29 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 75) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:12:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:29 INFO Executor: Finished task 1.0 in stage 42.0 (TID 76). 2382 bytes result sent to driver
19/07/31 17:12:29 INFO TaskSetManager: Finished task 1.0 in stage 42.0 (TID 76) in 9 ms on localhost (executor driver) (4/4)
19/07/31 17:12:29 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
19/07/31 17:12:29 INFO DAGScheduler: ResultStage 42 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:12:29 INFO DAGScheduler: Job 28 finished: collect at utils.scala:204, took 0.031176 s
19/07/31 17:12:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_097`) `dbplyr_098`
ORDER BY `date`) `dbplyr_099`) `dbplyr_100`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Desktop"))
19/07/31 17:12:29 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:29 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_101`) `dbplyr_102`
ORDER BY `date`) `dbplyr_103`) `dbplyr_104`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Desktop"))
19/07/31 17:12:29 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:29 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:29 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1618 - cust_prospect_ind.nullCount#1617) > 0)
19/07/31 17:12:29 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1623 - visit_device_type.nullCount#1622) > 0)
19/07/31 17:12:29 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#1616 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#1615))
19/07/31 17:12:29 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#1621 <= Desktop) && (Desktop <= visit_device_type.upperBound#1620))
19/07/31 17:12:29 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:29 INFO DAGScheduler: Got job 29 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:12:29 INFO DAGScheduler: Final stage: ResultStage 43 (collect at utils.scala:204)
19/07/31 17:12:29 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:29 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:29 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[140] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:29 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 72.1 KB, free 910.2 MB)
19/07/31 17:12:29 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.2 MB)
19/07/31 17:12:29 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:54089 (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:12:29 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[140] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:29 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
19/07/31 17:12:29 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 79, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:12:29 INFO Executor: Running task 0.0 in stage 43.0 (TID 79)
19/07/31 17:12:29 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:29 INFO Executor: Finished task 0.0 in stage 43.0 (TID 79). 6512 bytes result sent to driver
19/07/31 17:12:29 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 79) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:12:29 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
19/07/31 17:12:29 INFO DAGScheduler: ResultStage 43 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:12:29 INFO DAGScheduler: Job 29 finished: collect at utils.scala:204, took 0.010888 s
19/07/31 17:12:29 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:29 INFO DAGScheduler: Registering RDD 141 (collect at utils.scala:204)
19/07/31 17:12:29 INFO DAGScheduler: Got job 30 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:12:29 INFO DAGScheduler: Final stage: ResultStage 45 (collect at utils.scala:204)
19/07/31 17:12:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
19/07/31 17:12:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 44)
19/07/31 17:12:29 INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[141] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:29 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 74.5 KB, free 910.1 MB)
19/07/31 17:12:29 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.1 MB)
19/07/31 17:12:29 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:54089 (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:12:29 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[141] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:29 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
19/07/31 17:12:29 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 80, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:12:29 INFO Executor: Running task 0.0 in stage 44.0 (TID 80)
19/07/31 17:12:29 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:29 INFO Executor: Finished task 0.0 in stage 44.0 (TID 80). 1687 bytes result sent to driver
19/07/31 17:12:29 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 80) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:12:29 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
19/07/31 17:12:29 INFO DAGScheduler: ShuffleMapStage 44 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:12:29 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:12:29 INFO DAGScheduler: running: Set()
19/07/31 17:12:29 INFO DAGScheduler: waiting: Set(ResultStage 45)
19/07/31 17:12:29 INFO DAGScheduler: failed: Set()
19/07/31 17:12:29 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[144] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:29 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 16.8 KB, free 910.1 MB)
19/07/31 17:12:29 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.1 MB)
19/07/31 17:12:29 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:54089 (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:12:29 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 45 (MapPartitionsRDD[144] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:12:29 INFO TaskSchedulerImpl: Adding task set 45.0 with 4 tasks
19/07/31 17:12:29 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 81, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:12:29 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 82, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:12:29 INFO TaskSetManager: Starting task 2.0 in stage 45.0 (TID 83, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:12:29 INFO TaskSetManager: Starting task 3.0 in stage 45.0 (TID 84, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:12:29 INFO Executor: Running task 0.0 in stage 45.0 (TID 81)
19/07/31 17:12:29 INFO Executor: Running task 3.0 in stage 45.0 (TID 84)
19/07/31 17:12:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:12:29 INFO Executor: Running task 1.0 in stage 45.0 (TID 82)
19/07/31 17:12:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:12:29 INFO Executor: Running task 2.0 in stage 45.0 (TID 83)
19/07/31 17:12:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:29 INFO Executor: Finished task 0.0 in stage 45.0 (TID 81). 2367 bytes result sent to driver
19/07/31 17:12:29 INFO Executor: Finished task 3.0 in stage 45.0 (TID 84). 2357 bytes result sent to driver
19/07/31 17:12:29 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 81) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:12:29 INFO TaskSetManager: Finished task 3.0 in stage 45.0 (TID 84) in 4 ms on localhost (executor driver) (2/4)
19/07/31 17:12:29 INFO Executor: Finished task 1.0 in stage 45.0 (TID 82). 2350 bytes result sent to driver
19/07/31 17:12:29 INFO Executor: Finished task 2.0 in stage 45.0 (TID 83). 2368 bytes result sent to driver
19/07/31 17:12:29 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 82) in 7 ms on localhost (executor driver) (3/4)
19/07/31 17:12:29 INFO TaskSetManager: Finished task 2.0 in stage 45.0 (TID 83) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:12:29 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
19/07/31 17:12:29 INFO DAGScheduler: ResultStage 45 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:12:29 INFO DAGScheduler: Job 30 finished: collect at utils.scala:204, took 0.023934 s
19/07/31 17:12:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_105`) `dbplyr_106`
ORDER BY `date`) `dbplyr_107`) `dbplyr_108`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Desktop"))
19/07/31 17:12:29 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:29 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_109`) `dbplyr_110`
ORDER BY `date`) `dbplyr_111`) `dbplyr_112`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Desktop"))
19/07/31 17:12:29 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:29 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:29 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1716 - cust_prospect_ind.nullCount#1715) > 0)
19/07/31 17:12:29 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1721 - visit_device_type.nullCount#1720) > 0)
19/07/31 17:12:29 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#1714 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#1713))
19/07/31 17:12:29 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#1719 <= Desktop) && (Desktop <= visit_device_type.upperBound#1718))
19/07/31 17:12:29 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:29 INFO DAGScheduler: Got job 31 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:12:29 INFO DAGScheduler: Final stage: ResultStage 46 (collect at utils.scala:204)
19/07/31 17:12:29 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:29 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:29 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[149] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:29 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 72.1 KB, free 910.0 MB)
19/07/31 17:12:29 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.0 MB)
19/07/31 17:12:29 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:54089 (size: 30.4 KB, free: 911.8 MB)
19/07/31 17:12:29 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[149] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:29 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
19/07/31 17:12:29 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:12:29 INFO Executor: Running task 0.0 in stage 46.0 (TID 85)
19/07/31 17:12:29 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:29 INFO Executor: Finished task 0.0 in stage 46.0 (TID 85). 6512 bytes result sent to driver
19/07/31 17:12:29 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 85) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:12:29 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
19/07/31 17:12:29 INFO DAGScheduler: ResultStage 46 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:12:29 INFO DAGScheduler: Job 31 finished: collect at utils.scala:204, took 0.011482 s
19/07/31 17:12:29 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:29 INFO DAGScheduler: Registering RDD 150 (collect at utils.scala:204)
19/07/31 17:12:29 INFO DAGScheduler: Got job 32 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:12:29 INFO DAGScheduler: Final stage: ResultStage 48 (collect at utils.scala:204)
19/07/31 17:12:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
19/07/31 17:12:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 47)
19/07/31 17:12:29 INFO DAGScheduler: Submitting ShuffleMapStage 47 (MapPartitionsRDD[150] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:29 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 74.5 KB, free 909.9 MB)
19/07/31 17:12:29 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 31.7 KB, free 909.9 MB)
19/07/31 17:12:29 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:54089 (size: 31.7 KB, free: 911.7 MB)
19/07/31 17:12:29 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[150] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:29 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
19/07/31 17:12:29 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:12:29 INFO Executor: Running task 0.0 in stage 47.0 (TID 86)
19/07/31 17:12:29 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:29 INFO Executor: Finished task 0.0 in stage 47.0 (TID 86). 1687 bytes result sent to driver
19/07/31 17:12:29 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 86) in 10 ms on localhost (executor driver) (1/1)
19/07/31 17:12:29 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
19/07/31 17:12:29 INFO DAGScheduler: ShuffleMapStage 47 (collect at utils.scala:204) finished in 0.011 s
19/07/31 17:12:29 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:12:29 INFO DAGScheduler: running: Set()
19/07/31 17:12:29 INFO DAGScheduler: waiting: Set(ResultStage 48)
19/07/31 17:12:29 INFO DAGScheduler: failed: Set()
19/07/31 17:12:29 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[153] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:29 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 16.8 KB, free 909.9 MB)
19/07/31 17:12:30 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.8 MB)
19/07/31 17:12:30 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:54089 (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:12:30 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:30 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 48 (MapPartitionsRDD[153] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:12:30 INFO TaskSchedulerImpl: Adding task set 48.0 with 4 tasks
19/07/31 17:12:30 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 87, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:12:30 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 88, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:12:30 INFO TaskSetManager: Starting task 2.0 in stage 48.0 (TID 89, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:12:30 INFO TaskSetManager: Starting task 3.0 in stage 48.0 (TID 90, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:12:30 INFO Executor: Running task 1.0 in stage 48.0 (TID 88)
19/07/31 17:12:30 INFO Executor: Running task 0.0 in stage 48.0 (TID 87)
19/07/31 17:12:30 INFO Executor: Running task 2.0 in stage 48.0 (TID 89)
19/07/31 17:12:30 INFO Executor: Running task 3.0 in stage 48.0 (TID 90)
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:30 INFO Executor: Finished task 1.0 in stage 48.0 (TID 88). 2308 bytes result sent to driver
19/07/31 17:12:30 INFO Executor: Finished task 2.0 in stage 48.0 (TID 89). 2330 bytes result sent to driver
19/07/31 17:12:30 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 88) in 4 ms on localhost (executor driver) (1/4)
19/07/31 17:12:30 INFO TaskSetManager: Finished task 2.0 in stage 48.0 (TID 89) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:12:30 INFO Executor: Finished task 3.0 in stage 48.0 (TID 90). 2316 bytes result sent to driver
19/07/31 17:12:30 INFO Executor: Finished task 0.0 in stage 48.0 (TID 87). 2326 bytes result sent to driver
19/07/31 17:12:30 INFO TaskSetManager: Finished task 3.0 in stage 48.0 (TID 90) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:12:30 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 87) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:12:30 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
19/07/31 17:12:30 INFO DAGScheduler: ResultStage 48 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:12:30 INFO DAGScheduler: Job 32 finished: collect at utils.scala:204, took 0.030056 s
19/07/31 17:12:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_113`) `dbplyr_114`
ORDER BY `date`) `dbplyr_115`) `dbplyr_116`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Desktop"))
19/07/31 17:12:30 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:30 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_117`) `dbplyr_118`
ORDER BY `date`) `dbplyr_119`) `dbplyr_120`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Desktop"))
19/07/31 17:12:30 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:30 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:30 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1814 - cust_prospect_ind.nullCount#1813) > 0)
19/07/31 17:12:30 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1819 - visit_device_type.nullCount#1818) > 0)
19/07/31 17:12:30 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#1812 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#1811))
19/07/31 17:12:30 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#1817 <= Desktop) && (Desktop <= visit_device_type.upperBound#1816))
19/07/31 17:12:30 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:30 INFO DAGScheduler: Got job 33 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:12:30 INFO DAGScheduler: Final stage: ResultStage 49 (collect at utils.scala:204)
19/07/31 17:12:30 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:30 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:30 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[158] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:30 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 72.1 KB, free 909.8 MB)
19/07/31 17:12:30 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.7 MB)
19/07/31 17:12:30 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:54089 (size: 30.5 KB, free: 911.7 MB)
19/07/31 17:12:30 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[158] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:30 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
19/07/31 17:12:30 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 91, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:12:30 INFO Executor: Running task 0.0 in stage 49.0 (TID 91)
19/07/31 17:12:30 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:30 INFO Executor: Finished task 0.0 in stage 49.0 (TID 91). 7068 bytes result sent to driver
19/07/31 17:12:30 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 91) in 14 ms on localhost (executor driver) (1/1)
19/07/31 17:12:30 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
19/07/31 17:12:30 INFO DAGScheduler: ResultStage 49 (collect at utils.scala:204) finished in 0.016 s
19/07/31 17:12:30 INFO DAGScheduler: Job 33 finished: collect at utils.scala:204, took 0.034544 s
19/07/31 17:12:30 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:30 INFO DAGScheduler: Registering RDD 159 (collect at utils.scala:204)
19/07/31 17:12:30 INFO DAGScheduler: Got job 34 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:12:30 INFO DAGScheduler: Final stage: ResultStage 51 (collect at utils.scala:204)
19/07/31 17:12:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
19/07/31 17:12:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 50)
19/07/31 17:12:30 INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[159] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:30 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 74.5 KB, free 909.7 MB)
19/07/31 17:12:30 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.6 MB)
19/07/31 17:12:30 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:54089 (size: 31.8 KB, free: 911.7 MB)
19/07/31 17:12:30 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[159] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:30 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
19/07/31 17:12:30 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:12:30 INFO Executor: Running task 0.0 in stage 50.0 (TID 92)
19/07/31 17:12:30 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:30 INFO Executor: Finished task 0.0 in stage 50.0 (TID 92). 1687 bytes result sent to driver
19/07/31 17:12:30 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 92) in 14 ms on localhost (executor driver) (1/1)
19/07/31 17:12:30 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
19/07/31 17:12:30 INFO DAGScheduler: ShuffleMapStage 50 (collect at utils.scala:204) finished in 0.015 s
19/07/31 17:12:30 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:12:30 INFO DAGScheduler: running: Set()
19/07/31 17:12:30 INFO DAGScheduler: waiting: Set(ResultStage 51)
19/07/31 17:12:30 INFO DAGScheduler: failed: Set()
19/07/31 17:12:30 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[162] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:30 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 16.8 KB, free 909.6 MB)
19/07/31 17:12:30 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 8.1 KB, free 909.6 MB)
19/07/31 17:12:30 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:54089 (size: 8.1 KB, free: 911.7 MB)
19/07/31 17:12:30 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:30 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 51 (MapPartitionsRDD[162] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:12:30 INFO TaskSchedulerImpl: Adding task set 51.0 with 4 tasks
19/07/31 17:12:30 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 93, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:12:30 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 94, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:12:30 INFO TaskSetManager: Starting task 2.0 in stage 51.0 (TID 95, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:12:30 INFO TaskSetManager: Starting task 3.0 in stage 51.0 (TID 96, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:12:30 INFO Executor: Running task 2.0 in stage 51.0 (TID 95)
19/07/31 17:12:30 INFO Executor: Running task 1.0 in stage 51.0 (TID 94)
19/07/31 17:12:30 INFO Executor: Running task 3.0 in stage 51.0 (TID 96)
19/07/31 17:12:30 INFO Executor: Running task 0.0 in stage 51.0 (TID 93)
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:30 INFO Executor: Finished task 2.0 in stage 51.0 (TID 95). 2391 bytes result sent to driver
19/07/31 17:12:30 INFO Executor: Finished task 3.0 in stage 51.0 (TID 96). 2371 bytes result sent to driver
19/07/31 17:12:30 INFO TaskSetManager: Finished task 2.0 in stage 51.0 (TID 95) in 6 ms on localhost (executor driver) (1/4)
19/07/31 17:12:30 INFO TaskSetManager: Finished task 3.0 in stage 51.0 (TID 96) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:12:30 INFO Executor: Finished task 1.0 in stage 51.0 (TID 94). 2389 bytes result sent to driver
19/07/31 17:12:30 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 94) in 7 ms on localhost (executor driver) (3/4)
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:30 INFO Executor: Finished task 0.0 in stage 51.0 (TID 93). 2396 bytes result sent to driver
19/07/31 17:12:30 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 93) in 10 ms on localhost (executor driver) (4/4)
19/07/31 17:12:30 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
19/07/31 17:12:30 INFO DAGScheduler: ResultStage 51 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:12:30 INFO DAGScheduler: Job 34 finished: collect at utils.scala:204, took 0.039782 s
19/07/31 17:12:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_121`) `dbplyr_122`
ORDER BY `date`) `dbplyr_123`) `dbplyr_124`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Tablet"))
19/07/31 17:12:30 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:30 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_125`) `dbplyr_126`
ORDER BY `date`) `dbplyr_127`) `dbplyr_128`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Tablet"))
19/07/31 17:12:30 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:30 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:30 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1912 - cust_prospect_ind.nullCount#1911) > 0)
19/07/31 17:12:30 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1917 - visit_device_type.nullCount#1916) > 0)
19/07/31 17:12:30 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#1910 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#1909))
19/07/31 17:12:30 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#1915 <= Tablet) && (Tablet <= visit_device_type.upperBound#1914))
19/07/31 17:12:30 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:30 INFO DAGScheduler: Got job 35 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:12:30 INFO DAGScheduler: Final stage: ResultStage 52 (collect at utils.scala:204)
19/07/31 17:12:30 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:30 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:30 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[167] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:30 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 72.1 KB, free 909.5 MB)
19/07/31 17:12:30 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.5 MB)
19/07/31 17:12:30 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:54089 (size: 30.5 KB, free: 911.6 MB)
19/07/31 17:12:30 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[167] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:30 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
19/07/31 17:12:30 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:12:30 INFO Executor: Running task 0.0 in stage 52.0 (TID 97)
19/07/31 17:12:30 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:30 INFO Executor: Finished task 0.0 in stage 52.0 (TID 97). 6512 bytes result sent to driver
19/07/31 17:12:30 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 97) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:12:30 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
19/07/31 17:12:30 INFO DAGScheduler: ResultStage 52 (collect at utils.scala:204) finished in 0.004 s
19/07/31 17:12:30 INFO DAGScheduler: Job 35 finished: collect at utils.scala:204, took 0.011857 s
19/07/31 17:12:30 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:30 INFO DAGScheduler: Registering RDD 168 (collect at utils.scala:204)
19/07/31 17:12:30 INFO DAGScheduler: Got job 36 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:12:30 INFO DAGScheduler: Final stage: ResultStage 54 (collect at utils.scala:204)
19/07/31 17:12:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 53)
19/07/31 17:12:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 53)
19/07/31 17:12:30 INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[168] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:30 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 74.5 KB, free 909.4 MB)
19/07/31 17:12:30 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.4 MB)
19/07/31 17:12:30 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:54089 (size: 31.8 KB, free: 911.6 MB)
19/07/31 17:12:30 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[168] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:30 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
19/07/31 17:12:30 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 98, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:12:30 INFO Executor: Running task 0.0 in stage 53.0 (TID 98)
19/07/31 17:12:30 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:30 INFO Executor: Finished task 0.0 in stage 53.0 (TID 98). 1687 bytes result sent to driver
19/07/31 17:12:30 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 98) in 10 ms on localhost (executor driver) (1/1)
19/07/31 17:12:30 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
19/07/31 17:12:30 INFO DAGScheduler: ShuffleMapStage 53 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:12:30 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:12:30 INFO DAGScheduler: running: Set()
19/07/31 17:12:30 INFO DAGScheduler: waiting: Set(ResultStage 54)
19/07/31 17:12:30 INFO DAGScheduler: failed: Set()
19/07/31 17:12:30 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[171] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:30 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 16.8 KB, free 909.4 MB)
19/07/31 17:12:30 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.4 MB)
19/07/31 17:12:30 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:54089 (size: 8.0 KB, free: 911.6 MB)
19/07/31 17:12:30 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:30 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 54 (MapPartitionsRDD[171] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:12:30 INFO TaskSchedulerImpl: Adding task set 54.0 with 4 tasks
19/07/31 17:12:30 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 99, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:12:30 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 100, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:12:30 INFO TaskSetManager: Starting task 2.0 in stage 54.0 (TID 101, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:12:30 INFO TaskSetManager: Starting task 3.0 in stage 54.0 (TID 102, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:12:30 INFO Executor: Running task 0.0 in stage 54.0 (TID 99)
19/07/31 17:12:30 INFO Executor: Running task 1.0 in stage 54.0 (TID 100)
19/07/31 17:12:30 INFO Executor: Running task 3.0 in stage 54.0 (TID 102)
19/07/31 17:12:30 INFO Executor: Running task 2.0 in stage 54.0 (TID 101)
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:12:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:12:30 INFO Executor: Finished task 2.0 in stage 54.0 (TID 101). 2362 bytes result sent to driver
19/07/31 17:12:30 INFO Executor: Finished task 3.0 in stage 54.0 (TID 102). 2336 bytes result sent to driver
19/07/31 17:12:30 INFO Executor: Finished task 1.0 in stage 54.0 (TID 100). 2340 bytes result sent to driver
19/07/31 17:12:30 INFO Executor: Finished task 0.0 in stage 54.0 (TID 99). 2357 bytes result sent to driver
19/07/31 17:12:30 INFO TaskSetManager: Finished task 2.0 in stage 54.0 (TID 101) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:12:30 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 100) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:12:30 INFO TaskSetManager: Finished task 3.0 in stage 54.0 (TID 102) in 4 ms on localhost (executor driver) (3/4)
19/07/31 17:12:30 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 99) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:12:30 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
19/07/31 17:12:30 INFO DAGScheduler: ResultStage 54 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:12:30 INFO DAGScheduler: Job 36 finished: collect at utils.scala:204, took 0.029136 s
19/07/31 17:12:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_129`) `dbplyr_130`
ORDER BY `date`) `dbplyr_131`) `dbplyr_132`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Tablet"))
19/07/31 17:12:30 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:30 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_133`) `dbplyr_134`
ORDER BY `date`) `dbplyr_135`) `dbplyr_136`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Tablet"))
19/07/31 17:12:31 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:31 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:31 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2010 - cust_prospect_ind.nullCount#2009) > 0)
19/07/31 17:12:31 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2015 - visit_device_type.nullCount#2014) > 0)
19/07/31 17:12:31 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#2008 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#2007))
19/07/31 17:12:31 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#2013 <= Tablet) && (Tablet <= visit_device_type.upperBound#2012))
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1452
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 966
19/07/31 17:12:31 INFO ContextCleaner: Cleaned shuffle 10
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1457
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1293
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 127.0.0.1:54089 in memory (size: 8.0 KB, free: 911.6 MB)
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1453
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1216
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:54089 in memory (size: 30.5 KB, free: 911.6 MB)
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:54089 in memory (size: 30.5 KB, free: 911.7 MB)
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1456
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1132
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1459
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1134
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 808
19/07/31 17:12:31 INFO ContextCleaner: Cleaned shuffle 12
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:54089 in memory (size: 31.8 KB, free: 911.7 MB)
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:54089 in memory (size: 8.1 KB, free: 911.7 MB)
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1209
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1051
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:54089 in memory (size: 31.8 KB, free: 911.7 MB)
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1050
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1377
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1455
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 127.0.0.1:54089 in memory (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:12:31 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1047
19/07/31 17:12:31 INFO DAGScheduler: Got job 37 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:12:31 INFO DAGScheduler: Final stage: ResultStage 55 (collect at utils.scala:204)
19/07/31 17:12:31 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:31 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:54089 in memory (size: 31.7 KB, free: 911.8 MB)
19/07/31 17:12:31 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[176] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:31 INFO ContextCleaner: Cleaned shuffle 11
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 127.0.0.1:54089 in memory (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:12:31 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 72.1 KB, free 909.9 MB)
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 807
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 127.0.0.1:54089 in memory (size: 30.4 KB, free: 911.8 MB)
19/07/31 17:12:31 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.0 MB)
19/07/31 17:12:31 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:54089 (size: 30.4 KB, free: 911.8 MB)
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1054
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 885
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 968
19/07/31 17:12:31 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:54089 in memory (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:12:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[176] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:31 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1374
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 811
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1378
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 892
19/07/31 17:12:31 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 103, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:54089 in memory (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:12:31 INFO Executor: Running task 0.0 in stage 55.0 (TID 103)
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1053
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:54089 in memory (size: 30.4 KB, free: 911.8 MB)
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:54089 in memory (size: 30.4 KB, free: 911.9 MB)
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1210
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1048
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 805
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 967
19/07/31 17:12:31 INFO ContextCleaner: Cleaned shuffle 15
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1373
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 891
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1212
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1372
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1135
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 973
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 890
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:54089 in memory (size: 31.8 KB, free: 911.9 MB)
19/07/31 17:12:31 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:54089 in memory (size: 30.5 KB, free: 911.9 MB)
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1128
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1297
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 127.0.0.1:54089 in memory (size: 8.1 KB, free: 911.9 MB)
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1049
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1292
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1130
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:54089 in memory (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:12:31 INFO Executor: Finished task 0.0 in stage 55.0 (TID 103). 6512 bytes result sent to driver
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 971
19/07/31 17:12:31 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 103) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:12:31 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
19/07/31 17:12:31 INFO ContextCleaner: Cleaned shuffle 14
19/07/31 17:12:31 INFO DAGScheduler: ResultStage 55 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:12:31 INFO DAGScheduler: Job 37 finished: collect at utils.scala:204, took 0.013382 s
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 127.0.0.1:54089 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 804
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:54089 in memory (size: 31.7 KB, free: 912.0 MB)
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1129
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1454
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1370
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1458
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1133
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:54089 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1294
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1296
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1208
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1290
19/07/31 17:12:31 INFO ContextCleaner: Cleaned shuffle 13
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:54089 in memory (size: 31.7 KB, free: 912.0 MB)
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 884
19/07/31 17:12:31 INFO ContextCleaner: Cleaned shuffle 17
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1289
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1371
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:54089 in memory (size: 31.8 KB, free: 912.1 MB)
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 889
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1291
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1295
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 886
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:54089 in memory (size: 31.8 KB, free: 912.1 MB)
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 806
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:54089 in memory (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 972
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 969
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1046
19/07/31 17:12:31 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1052
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 810
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1131
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1213
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 809
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1211
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1532
19/07/31 17:12:31 INFO DAGScheduler: Registering RDD 177 (collect at utils.scala:204)
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1451
19/07/31 17:12:31 INFO DAGScheduler: Got job 38 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:12:31 INFO DAGScheduler: Final stage: ResultStage 57 (collect at utils.scala:204)
19/07/31 17:12:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
19/07/31 17:12:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 56)
19/07/31 17:12:31 INFO ContextCleaner: Cleaned shuffle 16
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 888
19/07/31 17:12:31 INFO DAGScheduler: Submitting ShuffleMapStage 56 (MapPartitionsRDD[177] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:31 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:54089 in memory (size: 30.5 KB, free: 912.1 MB)
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1375
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1215
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 970
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1214
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 965
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1127
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 1376
19/07/31 17:12:31 INFO ContextCleaner: Cleaned accumulator 887
19/07/31 17:12:31 INFO ContextCleaner: Cleaned shuffle 9
19/07/31 17:12:31 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 74.5 KB, free 911.2 MB)
19/07/31 17:12:31 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 31.7 KB, free 911.1 MB)
19/07/31 17:12:31 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:54089 (size: 31.7 KB, free: 912.1 MB)
19/07/31 17:12:31 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[177] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:31 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
19/07/31 17:12:31 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 104, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:12:31 INFO Executor: Running task 0.0 in stage 56.0 (TID 104)
19/07/31 17:12:31 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:31 INFO Executor: Finished task 0.0 in stage 56.0 (TID 104). 1687 bytes result sent to driver
19/07/31 17:12:31 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 104) in 36 ms on localhost (executor driver) (1/1)
19/07/31 17:12:31 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
19/07/31 17:12:31 INFO DAGScheduler: ShuffleMapStage 56 (collect at utils.scala:204) finished in 0.037 s
19/07/31 17:12:31 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:12:31 INFO DAGScheduler: running: Set()
19/07/31 17:12:31 INFO DAGScheduler: waiting: Set(ResultStage 57)
19/07/31 17:12:31 INFO DAGScheduler: failed: Set()
19/07/31 17:12:31 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[180] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:31 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 16.8 KB, free 911.1 MB)
19/07/31 17:12:31 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.1 MB)
19/07/31 17:12:31 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:54089 (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:12:31 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:31 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 57 (MapPartitionsRDD[180] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:12:31 INFO TaskSchedulerImpl: Adding task set 57.0 with 4 tasks
19/07/31 17:12:31 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 105, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:12:31 INFO TaskSetManager: Starting task 1.0 in stage 57.0 (TID 106, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:12:31 INFO TaskSetManager: Starting task 2.0 in stage 57.0 (TID 107, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:12:31 INFO TaskSetManager: Starting task 3.0 in stage 57.0 (TID 108, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:12:31 INFO Executor: Running task 1.0 in stage 57.0 (TID 106)
19/07/31 17:12:31 INFO Executor: Running task 2.0 in stage 57.0 (TID 107)
19/07/31 17:12:31 INFO Executor: Running task 3.0 in stage 57.0 (TID 108)
19/07/31 17:12:31 INFO Executor: Running task 0.0 in stage 57.0 (TID 105)
19/07/31 17:12:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:12:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:12:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:12:31 INFO Executor: Finished task 1.0 in stage 57.0 (TID 106). 2337 bytes result sent to driver
19/07/31 17:12:31 INFO Executor: Finished task 2.0 in stage 57.0 (TID 107). 2360 bytes result sent to driver
19/07/31 17:12:31 INFO Executor: Finished task 3.0 in stage 57.0 (TID 108). 2346 bytes result sent to driver
19/07/31 17:12:31 INFO TaskSetManager: Finished task 1.0 in stage 57.0 (TID 106) in 15 ms on localhost (executor driver) (1/4)
19/07/31 17:12:31 INFO TaskSetManager: Finished task 2.0 in stage 57.0 (TID 107) in 14 ms on localhost (executor driver) (2/4)
19/07/31 17:12:31 INFO TaskSetManager: Finished task 3.0 in stage 57.0 (TID 108) in 14 ms on localhost (executor driver) (3/4)
19/07/31 17:12:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:31 INFO Executor: Finished task 0.0 in stage 57.0 (TID 105). 2385 bytes result sent to driver
19/07/31 17:12:31 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 105) in 20 ms on localhost (executor driver) (4/4)
19/07/31 17:12:31 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
19/07/31 17:12:31 INFO DAGScheduler: ResultStage 57 (collect at utils.scala:204) finished in 0.020 s
19/07/31 17:12:31 INFO DAGScheduler: Job 38 finished: collect at utils.scala:204, took 0.075666 s
19/07/31 17:12:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_137`) `dbplyr_138`
ORDER BY `date`) `dbplyr_139`) `dbplyr_140`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Tablet"))
19/07/31 17:12:31 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:31 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_141`) `dbplyr_142`
ORDER BY `date`) `dbplyr_143`) `dbplyr_144`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Tablet"))
19/07/31 17:12:31 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:31 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:31 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#2108 - cust_prospect_ind.nullCount#2107) > 0)
19/07/31 17:12:31 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#2113 - visit_device_type.nullCount#2112) > 0)
19/07/31 17:12:31 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#2106 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#2105))
19/07/31 17:12:31 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#2111 <= Tablet) && (Tablet <= visit_device_type.upperBound#2110))
19/07/31 17:12:31 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:31 INFO DAGScheduler: Got job 39 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:12:31 INFO DAGScheduler: Final stage: ResultStage 58 (collect at utils.scala:204)
19/07/31 17:12:31 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:31 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:31 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[185] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:31 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 72.1 KB, free 911.0 MB)
19/07/31 17:12:31 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 30.5 KB, free 911.0 MB)
19/07/31 17:12:31 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:54089 (size: 30.5 KB, free: 912.1 MB)
19/07/31 17:12:31 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[185] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:31 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
19/07/31 17:12:31 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 109, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:12:31 INFO Executor: Running task 0.0 in stage 58.0 (TID 109)
19/07/31 17:12:31 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:31 INFO Executor: Finished task 0.0 in stage 58.0 (TID 109). 7068 bytes result sent to driver
19/07/31 17:12:31 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 109) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:12:31 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
19/07/31 17:12:31 INFO DAGScheduler: ResultStage 58 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:12:31 INFO DAGScheduler: Job 39 finished: collect at utils.scala:204, took 0.009802 s
19/07/31 17:12:31 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:31 INFO DAGScheduler: Registering RDD 186 (collect at utils.scala:204)
19/07/31 17:12:31 INFO DAGScheduler: Got job 40 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:12:31 INFO DAGScheduler: Final stage: ResultStage 60 (collect at utils.scala:204)
19/07/31 17:12:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
19/07/31 17:12:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 59)
19/07/31 17:12:31 INFO DAGScheduler: Submitting ShuffleMapStage 59 (MapPartitionsRDD[186] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:31 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 74.5 KB, free 910.9 MB)
19/07/31 17:12:31 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.9 MB)
19/07/31 17:12:31 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:54089 (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:12:31 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 59 (MapPartitionsRDD[186] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:31 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
19/07/31 17:12:31 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 110, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:12:31 INFO Executor: Running task 0.0 in stage 59.0 (TID 110)
19/07/31 17:12:31 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:12:31 INFO Executor: Finished task 0.0 in stage 59.0 (TID 110). 1687 bytes result sent to driver
19/07/31 17:12:31 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 110) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:12:31 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
19/07/31 17:12:31 INFO DAGScheduler: ShuffleMapStage 59 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:12:31 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:12:31 INFO DAGScheduler: running: Set()
19/07/31 17:12:31 INFO DAGScheduler: waiting: Set(ResultStage 60)
19/07/31 17:12:31 INFO DAGScheduler: failed: Set()
19/07/31 17:12:31 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[189] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:31 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 16.8 KB, free 910.9 MB)
19/07/31 17:12:31 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.9 MB)
19/07/31 17:12:31 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:54089 (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:12:31 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:31 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 60 (MapPartitionsRDD[189] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:12:31 INFO TaskSchedulerImpl: Adding task set 60.0 with 4 tasks
19/07/31 17:12:31 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 111, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:12:31 INFO TaskSetManager: Starting task 1.0 in stage 60.0 (TID 112, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:12:31 INFO TaskSetManager: Starting task 2.0 in stage 60.0 (TID 113, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:12:31 INFO TaskSetManager: Starting task 3.0 in stage 60.0 (TID 114, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:12:31 INFO Executor: Running task 0.0 in stage 60.0 (TID 111)
19/07/31 17:12:31 INFO Executor: Running task 2.0 in stage 60.0 (TID 113)
19/07/31 17:12:31 INFO Executor: Running task 3.0 in stage 60.0 (TID 114)
19/07/31 17:12:31 INFO Executor: Running task 1.0 in stage 60.0 (TID 112)
19/07/31 17:12:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/07/31 17:12:31 INFO Executor: Finished task 3.0 in stage 60.0 (TID 114). 2357 bytes result sent to driver
19/07/31 17:12:31 INFO Executor: Finished task 1.0 in stage 60.0 (TID 112). 2381 bytes result sent to driver
19/07/31 17:12:31 INFO Executor: Finished task 0.0 in stage 60.0 (TID 111). 2376 bytes result sent to driver
19/07/31 17:12:31 INFO TaskSetManager: Finished task 3.0 in stage 60.0 (TID 114) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:12:31 INFO TaskSetManager: Finished task 1.0 in stage 60.0 (TID 112) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:12:31 INFO Executor: Finished task 2.0 in stage 60.0 (TID 113). 2379 bytes result sent to driver
19/07/31 17:12:31 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 111) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:12:31 INFO TaskSetManager: Finished task 2.0 in stage 60.0 (TID 113) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:12:31 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
19/07/31 17:12:31 INFO DAGScheduler: ResultStage 60 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:12:31 INFO DAGScheduler: Job 40 finished: collect at utils.scala:204, took 0.024098 s
19/07/31 17:12:31 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 17:12:31 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:31 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:31 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:31 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:31 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 17:12:31 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 17:12:31 INFO CodeGenerator: Code generated in 5.075316 ms
19/07/31 17:12:31 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 17:12:31 INFO DAGScheduler: Got job 41 (collect at utils.scala:44) with 1 output partitions
19/07/31 17:12:31 INFO DAGScheduler: Final stage: ResultStage 61 (collect at utils.scala:44)
19/07/31 17:12:31 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:31 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:31 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[194] at map at utils.scala:41), which has no missing parents
19/07/31 17:12:31 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 6.3 KB, free 910.9 MB)
19/07/31 17:12:31 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 3.5 KB, free 910.9 MB)
19/07/31 17:12:31 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:54089 (size: 3.5 KB, free: 912.0 MB)
19/07/31 17:12:31 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[194] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:31 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
19/07/31 17:12:31 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 115, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 17:12:31 INFO Executor: Running task 0.0 in stage 61.0 (TID 115)
19/07/31 17:12:31 INFO Executor: Finished task 0.0 in stage 61.0 (TID 115). 964 bytes result sent to driver
19/07/31 17:12:31 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 115) in 3 ms on localhost (executor driver) (1/1)
19/07/31 17:12:31 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
19/07/31 17:12:31 INFO DAGScheduler: ResultStage 61 (collect at utils.scala:44) finished in 0.003 s
19/07/31 17:12:31 INFO DAGScheduler: Job 41 finished: collect at utils.scala:44, took 0.007731 s
19/07/31 17:12:31 INFO SparkSqlParser: Parsing command: result
19/07/31 17:12:31 INFO SparkSqlParser: Parsing command: CACHE TABLE `result`
19/07/31 17:12:31 INFO SparkSqlParser: Parsing command: `result`
19/07/31 17:12:31 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 17:12:31 INFO DAGScheduler: Registering RDD 202 (sql at <unknown>:0)
19/07/31 17:12:31 INFO DAGScheduler: Got job 42 (sql at <unknown>:0) with 1 output partitions
19/07/31 17:12:31 INFO DAGScheduler: Final stage: ResultStage 63 (sql at <unknown>:0)
19/07/31 17:12:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
19/07/31 17:12:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 62)
19/07/31 17:12:31 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[202] at sql at <unknown>:0), which has no missing parents
19/07/31 17:12:31 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 19.5 KB, free 910.9 MB)
19/07/31 17:12:31 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 8.6 KB, free 910.9 MB)
19/07/31 17:12:31 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:54089 (size: 8.6 KB, free: 912.0 MB)
19/07/31 17:12:31 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[202] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:31 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
19/07/31 17:12:31 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 116, localhost, executor driver, partition 0, PROCESS_LOCAL, 14596 bytes)
19/07/31 17:12:31 INFO Executor: Running task 0.0 in stage 62.0 (TID 116)
19/07/31 17:12:31 INFO CodeGenerator: Code generated in 7.641234 ms
19/07/31 17:12:31 INFO CodeGenerator: Code generated in 30.548427 ms
19/07/31 17:12:31 INFO MemoryStore: Block rdd_199_0 stored as values in memory (estimated size 8.8 KB, free 910.8 MB)
19/07/31 17:12:31 INFO BlockManagerInfo: Added rdd_199_0 in memory on 127.0.0.1:54089 (size: 8.8 KB, free: 912.0 MB)
19/07/31 17:12:31 INFO Executor: Finished task 0.0 in stage 62.0 (TID 116). 2285 bytes result sent to driver
19/07/31 17:12:31 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 116) in 64 ms on localhost (executor driver) (1/1)
19/07/31 17:12:31 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
19/07/31 17:12:31 INFO DAGScheduler: ShuffleMapStage 62 (sql at <unknown>:0) finished in 0.064 s
19/07/31 17:12:31 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:12:31 INFO DAGScheduler: running: Set()
19/07/31 17:12:31 INFO DAGScheduler: waiting: Set(ResultStage 63)
19/07/31 17:12:31 INFO DAGScheduler: failed: Set()
19/07/31 17:12:31 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[205] at sql at <unknown>:0), which has no missing parents
19/07/31 17:12:31 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 7.0 KB, free 910.8 MB)
19/07/31 17:12:31 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.8 MB)
19/07/31 17:12:31 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:54089 (size: 3.7 KB, free: 912.0 MB)
19/07/31 17:12:31 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[205] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:31 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
19/07/31 17:12:31 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 117, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:12:31 INFO Executor: Running task 0.0 in stage 63.0 (TID 117)
19/07/31 17:12:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:31 INFO Executor: Finished task 0.0 in stage 63.0 (TID 117). 1538 bytes result sent to driver
19/07/31 17:12:31 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 117) in 3 ms on localhost (executor driver) (1/1)
19/07/31 17:12:31 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
19/07/31 17:12:31 INFO DAGScheduler: ResultStage 63 (sql at <unknown>:0) finished in 0.004 s
19/07/31 17:12:31 INFO DAGScheduler: Job 42 finished: sql at <unknown>:0, took 0.077232 s
19/07/31 17:12:31 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `result`
19/07/31 17:12:31 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:12:31 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:12:31 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:12:31 INFO DAGScheduler: Registering RDD 208 (collect at utils.scala:204)
19/07/31 17:12:31 INFO DAGScheduler: Got job 43 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:12:31 INFO DAGScheduler: Final stage: ResultStage 65 (collect at utils.scala:204)
19/07/31 17:12:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 64)
19/07/31 17:12:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 64)
19/07/31 17:12:31 INFO DAGScheduler: Submitting ShuffleMapStage 64 (MapPartitionsRDD[208] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:31 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 19.5 KB, free 910.8 MB)
19/07/31 17:12:31 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 8.6 KB, free 910.8 MB)
19/07/31 17:12:31 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:54089 (size: 8.6 KB, free: 912.0 MB)
19/07/31 17:12:31 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[208] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:31 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
19/07/31 17:12:31 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 118, localhost, executor driver, partition 0, PROCESS_LOCAL, 14596 bytes)
19/07/31 17:12:31 INFO Executor: Running task 0.0 in stage 64.0 (TID 118)
19/07/31 17:12:31 INFO BlockManager: Found block rdd_199_0 locally
19/07/31 17:12:31 INFO Executor: Finished task 0.0 in stage 64.0 (TID 118). 1690 bytes result sent to driver
19/07/31 17:12:31 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 118) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:12:31 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
19/07/31 17:12:31 INFO DAGScheduler: ShuffleMapStage 64 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:12:31 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:12:31 INFO DAGScheduler: running: Set()
19/07/31 17:12:31 INFO DAGScheduler: waiting: Set(ResultStage 65)
19/07/31 17:12:31 INFO DAGScheduler: failed: Set()
19/07/31 17:12:31 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[211] at collect at utils.scala:204), which has no missing parents
19/07/31 17:12:31 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 7.0 KB, free 910.8 MB)
19/07/31 17:12:31 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 3.7 KB, free 910.8 MB)
19/07/31 17:12:31 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:54089 (size: 3.7 KB, free: 912.0 MB)
19/07/31 17:12:31 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[211] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:31 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
19/07/31 17:12:31 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 119, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:12:31 INFO Executor: Running task 0.0 in stage 65.0 (TID 119)
19/07/31 17:12:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:12:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:12:31 INFO Executor: Finished task 0.0 in stage 65.0 (TID 119). 1581 bytes result sent to driver
19/07/31 17:12:31 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 119) in 2 ms on localhost (executor driver) (1/1)
19/07/31 17:12:31 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
19/07/31 17:12:31 INFO DAGScheduler: ResultStage 65 (collect at utils.scala:204) finished in 0.003 s
19/07/31 17:12:31 INFO DAGScheduler: Job 43 finished: collect at utils.scala:204, took 0.015098 s
19/07/31 17:12:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `result` AS `zzz2`
WHERE (0 = 1)
19/07/31 17:12:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `result`
19/07/31 17:12:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 17:12:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 17:12:32 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 17:12:32 INFO DAGScheduler: Got job 44 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 17:12:32 INFO DAGScheduler: Final stage: ResultStage 66 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 17:12:32 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:12:32 INFO DAGScheduler: Missing parents: List()
19/07/31 17:12:32 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[212] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 17:12:32 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 90.4 KB, free 910.7 MB)
19/07/31 17:12:32 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 35.0 KB, free 910.7 MB)
19/07/31 17:12:32 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:54089 (size: 35.0 KB, free: 912.0 MB)
19/07/31 17:12:32 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1006
19/07/31 17:12:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[212] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:12:32 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
19/07/31 17:12:32 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 120, localhost, executor driver, partition 0, PROCESS_LOCAL, 14607 bytes)
19/07/31 17:12:32 INFO Executor: Running task 0.0 in stage 66.0 (TID 120)
19/07/31 17:12:32 INFO BlockManager: Found block rdd_199_0 locally
19/07/31 17:12:32 INFO CodeGenerator: Code generated in 14.056959 ms
19/07/31 17:12:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 17:12:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 17:12:32 INFO FileOutputCommitter: Saved output of task 'attempt_20190731171232_0066_m_000000_0' to file:/Users/6jncnk4f/Desktop/anomaly/forecast_result/_temporary/0/task_20190731171232_0066_m_000000
19/07/31 17:12:32 INFO SparkHadoopMapRedUtil: attempt_20190731171232_0066_m_000000_0: Committed
19/07/31 17:12:32 INFO Executor: Finished task 0.0 in stage 66.0 (TID 120). 1619 bytes result sent to driver
19/07/31 17:12:32 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 120) in 102 ms on localhost (executor driver) (1/1)
19/07/31 17:12:32 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
19/07/31 17:12:32 INFO DAGScheduler: ResultStage 66 (csv at NativeMethodAccessorImpl.java:0) finished in 0.102 s
19/07/31 17:12:32 INFO DAGScheduler: Job 44 finished: csv at NativeMethodAccessorImpl.java:0, took 0.118803 s
19/07/31 17:12:32 INFO FileFormatWriter: Job null committed.
19/07/31 17:12:33 INFO SparkContext: Invoking stop() from shutdown hook
19/07/31 17:12:33 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
19/07/31 17:12:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/07/31 17:12:33 INFO MemoryStore: MemoryStore cleared
19/07/31 17:12:33 INFO BlockManager: BlockManager stopped
19/07/31 17:12:33 INFO BlockManagerMaster: BlockManagerMaster stopped
19/07/31 17:12:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/07/31 17:12:33 INFO SparkContext: Successfully stopped SparkContext
19/07/31 17:12:33 INFO ShutdownHookManager: Shutdown hook called
19/07/31 17:12:33 INFO ShutdownHookManager: Deleting directory /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-414747aa-b4b2-4b50-a440-dd74a5115d37
19/07/31 17:14:07 INFO SparkContext: Running Spark version 2.2.0
19/07/31 17:14:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/07/31 17:14:07 INFO SparkContext: Submitted application: sparklyr
19/07/31 17:14:07 INFO SecurityManager: Changing view acls to: 6jncnk4f
19/07/31 17:14:07 INFO SecurityManager: Changing modify acls to: 6jncnk4f
19/07/31 17:14:07 INFO SecurityManager: Changing view acls groups to: 
19/07/31 17:14:07 INFO SecurityManager: Changing modify acls groups to: 
19/07/31 17:14:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(6jncnk4f); groups with view permissions: Set(); users  with modify permissions: Set(6jncnk4f); groups with modify permissions: Set()
19/07/31 17:14:07 INFO Utils: Successfully started service 'sparkDriver' on port 54131.
19/07/31 17:14:07 INFO SparkEnv: Registering MapOutputTracker
19/07/31 17:14:07 INFO SparkEnv: Registering BlockManagerMaster
19/07/31 17:14:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/07/31 17:14:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/07/31 17:14:07 INFO DiskBlockManager: Created local directory at /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/blockmgr-a955192d-0d25-4f5c-a79e-2740fed93ecd
19/07/31 17:14:07 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
19/07/31 17:14:07 INFO SparkEnv: Registering OutputCommitCoordinator
19/07/31 17:14:08 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
19/07/31 17:14:08 INFO Utils: Successfully started service 'SparkUI' on port 4041.
19/07/31 17:14:08 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
19/07/31 17:14:08 INFO SparkContext: Added JAR file:/Library/Frameworks/R.framework/Versions/3.5/Resources/library/sparklyr/java/sparklyr-2.0-2.11.jar at spark://127.0.0.1:54131/jars/sparklyr-2.0-2.11.jar with timestamp 1564607648140
19/07/31 17:14:08 INFO Executor: Starting executor ID driver on host localhost
19/07/31 17:14:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54132.
19/07/31 17:14:08 INFO NettyBlockTransferService: Server created on 127.0.0.1:54132
19/07/31 17:14:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/07/31 17:14:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 54132, None)
19/07/31 17:14:08 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:54132 with 912.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 54132, None)
19/07/31 17:14:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 54132, None)
19/07/31 17:14:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 54132, None)
19/07/31 17:14:08 INFO SharedState: loading hive config file: file:/Users/6jncnk4f/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml
19/07/31 17:14:08 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse').
19/07/31 17:14:08 INFO SharedState: Warehouse path is 'file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse'.
19/07/31 17:14:09 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
19/07/31 17:14:09 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
19/07/31 17:14:09 INFO ObjectStore: ObjectStore, initialize called
19/07/31 17:14:09 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
19/07/31 17:14:09 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
19/07/31 17:14:10 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
19/07/31 17:14:11 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:14:11 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:14:12 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:14:12 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:14:12 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
19/07/31 17:14:12 INFO ObjectStore: Initialized ObjectStore
19/07/31 17:14:12 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
19/07/31 17:14:12 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
19/07/31 17:14:12 INFO HiveMetaStore: Added admin role in metastore
19/07/31 17:14:12 INFO HiveMetaStore: Added public role in metastore
19/07/31 17:14:12 INFO HiveMetaStore: No user is added in admin role, since config is empty
19/07/31 17:14:12 INFO HiveMetaStore: 0: get_all_databases
19/07/31 17:14:12 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_all_databases	
19/07/31 17:14:12 INFO HiveMetaStore: 0: get_functions: db=default pat=*
19/07/31 17:14:12 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
19/07/31 17:14:12 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
19/07/31 17:14:12 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/5daced60-bf4d-4dc7-855c-a545caba9bdd_resources
19/07/31 17:14:12 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/5daced60-bf4d-4dc7-855c-a545caba9bdd
19/07/31 17:14:12 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/5daced60-bf4d-4dc7-855c-a545caba9bdd
19/07/31 17:14:12 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/5daced60-bf4d-4dc7-855c-a545caba9bdd/_tmp_space.db
19/07/31 17:14:12 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 17:14:12 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:12 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:12 INFO HiveMetaStore: 0: get_database: global_temp
19/07/31 17:14:12 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: global_temp	
19/07/31 17:14:12 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
19/07/31 17:14:12 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/13c94a88-dd4b-4096-b6e2-332d1931dea7_resources
19/07/31 17:14:12 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/13c94a88-dd4b-4096-b6e2-332d1931dea7
19/07/31 17:14:12 INFO SessionState: Created local directory: /var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/6jncnk4f/13c94a88-dd4b-4096-b6e2-332d1931dea7
19/07/31 17:14:12 INFO SessionState: Created HDFS directory: /tmp/hive/6jncnk4f/13c94a88-dd4b-4096-b6e2-332d1931dea7/_tmp_space.db
19/07/31 17:14:12 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/Users/6jncnk4f/Desktop/anomaly/spark-warehouse
19/07/31 17:14:12 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/07/31 17:14:13 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 17:14:14 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:14 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:14 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:14 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:14 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 17:14:14 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 17:14:14 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 17:14:14 INFO DAGScheduler: Got job 0 (collect at utils.scala:44) with 1 output partitions
19/07/31 17:14:14 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:44)
19/07/31 17:14:14 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:14:14 INFO DAGScheduler: Missing parents: List()
19/07/31 17:14:14 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents
19/07/31 17:14:14 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
19/07/31 17:14:14 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
19/07/31 17:14:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:54132 (size: 3.4 KB, free: 912.3 MB)
19/07/31 17:14:14 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:14 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/07/31 17:14:14 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4852 bytes)
19/07/31 17:14:14 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
19/07/31 17:14:14 INFO Executor: Fetching spark://127.0.0.1:54131/jars/sparklyr-2.0-2.11.jar with timestamp 1564607648140
19/07/31 17:14:14 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:54131 after 13 ms (0 ms spent in bootstraps)
19/07/31 17:14:14 INFO Utils: Fetching spark://127.0.0.1:54131/jars/sparklyr-2.0-2.11.jar to /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-8eca7bcc-7455-4eee-bf63-cb51a0c8af88/userFiles-0be3c395-7836-4043-91bf-ca36f9e703b5/fetchFileTemp1378784982529343463.tmp
19/07/31 17:14:14 INFO Executor: Adding file:/private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-8eca7bcc-7455-4eee-bf63-cb51a0c8af88/userFiles-0be3c395-7836-4043-91bf-ca36f9e703b5/sparklyr-2.0-2.11.jar to class loader
19/07/31 17:14:15 INFO CodeGenerator: Code generated in 173.024027 ms
19/07/31 17:14:15 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
19/07/31 17:14:15 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 480 ms on localhost (executor driver) (1/1)
19/07/31 17:14:15 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/07/31 17:14:15 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:44) finished in 0.496 s
19/07/31 17:14:15 INFO DAGScheduler: Job 0 finished: collect at utils.scala:44, took 0.622020 s
19/07/31 17:14:15 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 17:14:15 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#10)) > 0)
19/07/31 17:14:15 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 17:14:15 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 17:14:15 INFO CodeGenerator: Code generated in 14.730222 ms
19/07/31 17:14:15 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 281.2 KB, free 912.0 MB)
19/07/31 17:14:15 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.8 KB, free 912.0 MB)
19/07/31 17:14:15 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:54132 (size: 23.8 KB, free: 912.3 MB)
19/07/31 17:14:15 INFO SparkContext: Created broadcast 1 from csv at NativeMethodAccessorImpl.java:0
19/07/31 17:14:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 17:14:15 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 17:14:15 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 17:14:15 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 17:14:15 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:14:15 INFO DAGScheduler: Missing parents: List()
19/07/31 17:14:15 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 17:14:15 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 912.0 MB)
19/07/31 17:14:15 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 912.0 MB)
19/07/31 17:14:15 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:54132 (size: 4.3 KB, free: 912.3 MB)
19/07/31 17:14:15 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:15 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/07/31 17:14:15 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:14:15 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
19/07/31 17:14:15 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 17:14:15 INFO CodeGenerator: Code generated in 8.515585 ms
19/07/31 17:14:16 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:54132 in memory (size: 3.4 KB, free: 912.3 MB)
19/07/31 17:14:16 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1437 bytes result sent to driver
19/07/31 17:14:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 191 ms on localhost (executor driver) (1/1)
19/07/31 17:14:16 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/07/31 17:14:16 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0.192 s
19/07/31 17:14:16 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0.206555 s
19/07/31 17:14:16 INFO ContextCleaner: Cleaned accumulator 0
19/07/31 17:14:16 INFO CodeGenerator: Code generated in 7.279311 ms
19/07/31 17:14:16 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 17:14:16 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 17:14:16 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
19/07/31 17:14:16 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 17:14:16 INFO CodeGenerator: Code generated in 5.651841 ms
19/07/31 17:14:16 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 281.2 KB, free 911.7 MB)
19/07/31 17:14:16 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.8 KB, free 911.7 MB)
19/07/31 17:14:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:54132 (size: 23.8 KB, free: 912.2 MB)
19/07/31 17:14:16 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:0
19/07/31 17:14:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 17:14:16 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 17:14:16 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 17:14:16 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 17:14:16 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:14:16 INFO DAGScheduler: Missing parents: List()
19/07/31 17:14:16 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 17:14:16 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.8 KB, free 911.7 MB)
19/07/31 17:14:16 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 8.6 KB, free 911.7 MB)
19/07/31 17:14:16 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:54132 (size: 8.6 KB, free: 912.2 MB)
19/07/31 17:14:16 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:16 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
19/07/31 17:14:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:14:16 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
19/07/31 17:14:16 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 17:14:16 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1627 bytes result sent to driver
19/07/31 17:14:16 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 71 ms on localhost (executor driver) (1/1)
19/07/31 17:14:16 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
19/07/31 17:14:16 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.071 s
19/07/31 17:14:16 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.078008 s
19/07/31 17:14:16 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 17:14:16 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:16 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:16 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:16 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 17:14:16 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 17:14:16 INFO SparkSqlParser: Parsing command: anomaly_det_dashboard_shopper_conv
19/07/31 17:14:16 INFO SparkSqlParser: Parsing command: CACHE TABLE `anomaly_det_dashboard_shopper_conv`
19/07/31 17:14:16 INFO SparkSqlParser: Parsing command: `anomaly_det_dashboard_shopper_conv`
19/07/31 17:14:16 INFO FileSourceStrategy: Pruning directories with: 
19/07/31 17:14:16 INFO FileSourceStrategy: Post-Scan Filters: 
19/07/31 17:14:16 INFO FileSourceStrategy: Output Data Schema: struct<totalshoppertraffic_visitors: int, totalshoppertraffic_visits: int, digital_orders: int, aal_orders: int, eup_orders: int ... 12 more fields>
19/07/31 17:14:16 INFO FileSourceScanExec: Pushed Filters: 
19/07/31 17:14:16 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 282.3 KB, free 911.4 MB)
19/07/31 17:14:16 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 24.0 KB, free 911.4 MB)
19/07/31 17:14:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:54132 (size: 24.0 KB, free: 912.2 MB)
19/07/31 17:14:16 INFO SparkContext: Created broadcast 5 from sql at NativeMethodAccessorImpl.java:0
19/07/31 17:14:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/07/31 17:14:16 INFO CodeGenerator: Code generated in 8.870002 ms
19/07/31 17:14:16 INFO CodeGenerator: Code generated in 8.859981 ms
19/07/31 17:14:16 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
19/07/31 17:14:16 INFO DAGScheduler: Registering RDD 18 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 17:14:16 INFO DAGScheduler: Got job 3 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 17:14:16 INFO DAGScheduler: Final stage: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0)
19/07/31 17:14:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
19/07/31 17:14:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
19/07/31 17:14:16 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 17:14:16 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 26.3 KB, free 911.3 MB)
19/07/31 17:14:16 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 11.8 KB, free 911.3 MB)
19/07/31 17:14:16 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:54132 (size: 11.8 KB, free: 912.2 MB)
19/07/31 17:14:16 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[18] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:16 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
19/07/31 17:14:16 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:14:16 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
19/07/31 17:14:16 INFO FileScanRDD: Reading File path: file:///Users/6jncnk4f/Desktop/anomaly/anomaly_det_dashboard_shopper_conv.csv, range: 0-83862, partition values: [empty row]
19/07/31 17:14:16 INFO CodeGenerator: Code generated in 15.029109 ms
19/07/31 17:14:16 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 48.9 KB, free 911.3 MB)
19/07/31 17:14:16 INFO BlockManagerInfo: Added rdd_15_0 in memory on 127.0.0.1:54132 (size: 48.9 KB, free: 912.2 MB)
19/07/31 17:14:16 INFO CodeGenerator: Code generated in 3.487629 ms
19/07/31 17:14:16 INFO CodeGenerator: Code generated in 14.885366 ms
19/07/31 17:14:16 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2504 bytes result sent to driver
19/07/31 17:14:16 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 206 ms on localhost (executor driver) (1/1)
19/07/31 17:14:16 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
19/07/31 17:14:16 INFO DAGScheduler: ShuffleMapStage 3 (sql at NativeMethodAccessorImpl.java:0) finished in 0.207 s
19/07/31 17:14:16 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:14:16 INFO DAGScheduler: running: Set()
19/07/31 17:14:16 INFO DAGScheduler: waiting: Set(ResultStage 4)
19/07/31 17:14:16 INFO DAGScheduler: failed: Set()
19/07/31 17:14:16 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 17:14:16 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 911.3 MB)
19/07/31 17:14:16 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.3 MB)
19/07/31 17:14:16 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:54132 (size: 3.7 KB, free: 912.2 MB)
19/07/31 17:14:16 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[21] at sql at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:16 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
19/07/31 17:14:16 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:14:16 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
19/07/31 17:14:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
19/07/31 17:14:16 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1624 bytes result sent to driver
19/07/31 17:14:16 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 28 ms on localhost (executor driver) (1/1)
19/07/31 17:14:16 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
19/07/31 17:14:16 INFO DAGScheduler: ResultStage 4 (sql at NativeMethodAccessorImpl.java:0) finished in 0.030 s
19/07/31 17:14:16 INFO DAGScheduler: Job 3 finished: sql at NativeMethodAccessorImpl.java:0, took 0.279010 s
19/07/31 17:14:16 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM `anomaly_det_dashboard_shopper_conv`
19/07/31 17:14:16 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:16 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:16 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:16 INFO DAGScheduler: Registering RDD 24 (collect at utils.scala:204)
19/07/31 17:14:16 INFO DAGScheduler: Got job 4 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:14:16 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:204)
19/07/31 17:14:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
19/07/31 17:14:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
19/07/31 17:14:16 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:16 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 26.3 KB, free 911.2 MB)
19/07/31 17:14:16 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 11.9 KB, free 911.2 MB)
19/07/31 17:14:16 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:54132 (size: 11.9 KB, free: 912.1 MB)
19/07/31 17:14:16 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[24] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:16 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
19/07/31 17:14:16 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:14:16 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
19/07/31 17:14:16 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:16 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1780 bytes result sent to driver
19/07/31 17:14:16 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 23 ms on localhost (executor driver) (1/1)
19/07/31 17:14:16 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
19/07/31 17:14:16 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:204) finished in 0.024 s
19/07/31 17:14:16 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:14:16 INFO DAGScheduler: running: Set()
19/07/31 17:14:16 INFO DAGScheduler: waiting: Set(ResultStage 6)
19/07/31 17:14:16 INFO DAGScheduler: failed: Set()
19/07/31 17:14:16 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:16 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 911.2 MB)
19/07/31 17:14:16 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 911.2 MB)
19/07/31 17:14:16 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:54132 (size: 3.7 KB, free: 912.1 MB)
19/07/31 17:14:16 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:16 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
19/07/31 17:14:16 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:14:16 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
19/07/31 17:14:16 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:16 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1581 bytes result sent to driver
19/07/31 17:14:16 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 11 ms on localhost (executor driver) (1/1)
19/07/31 17:14:16 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
19/07/31 17:14:16 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:14:16 INFO DAGScheduler: Job 4 finished: collect at utils.scala:204, took 0.075625 s
19/07/31 17:14:17 INFO CodeGenerator: Code generated in 13.497379 ms
19/07/31 17:14:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `anomaly_det_dashboard_shopper_conv` AS `zzz1`
WHERE (0 = 1)
19/07/31 17:14:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_001`) `dbplyr_002`
ORDER BY `date`) `dbplyr_003`) `dbplyr_004`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:14:17 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:17 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_005`) `dbplyr_006`
ORDER BY `date`) `dbplyr_007`) `dbplyr_008`
WHERE ((`customer` = "All Visitors") AND (`device` = "All Devices"))
19/07/31 17:14:17 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:17 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:18 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#442 - cust_prospect_ind.nullCount#441) > 0)
19/07/31 17:14:18 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#447 - visit_device_type.nullCount#446) > 0)
19/07/31 17:14:18 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#440 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#439))
19/07/31 17:14:18 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#445 <= All Devices) && (All Devices <= visit_device_type.upperBound#444))
19/07/31 17:14:18 INFO CodeGenerator: Code generated in 38.93066 ms
19/07/31 17:14:18 INFO CodeGenerator: Code generated in 42.007051 ms
19/07/31 17:14:18 INFO CodeGenerator: Code generated in 16.68024 ms
19/07/31 17:14:18 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:18 INFO DAGScheduler: Got job 5 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:14:18 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:204)
19/07/31 17:14:18 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:14:18 INFO DAGScheduler: Missing parents: List()
19/07/31 17:14:18 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[32] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:18 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 72.1 KB, free 911.2 MB)
19/07/31 17:14:18 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.1 MB)
19/07/31 17:14:18 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:54132 (size: 30.4 KB, free: 912.1 MB)
19/07/31 17:14:18 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:18 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
19/07/31 17:14:18 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:14:18 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
19/07/31 17:14:18 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:18 INFO CodeGenerator: Code generated in 16.300627 ms
19/07/31 17:14:18 INFO CodeGenerator: Code generated in 27.180866 ms
19/07/31 17:14:18 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 7585 bytes result sent to driver
19/07/31 17:14:18 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 115 ms on localhost (executor driver) (1/1)
19/07/31 17:14:18 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
19/07/31 17:14:18 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:204) finished in 0.116 s
19/07/31 17:14:18 INFO DAGScheduler: Job 5 finished: collect at utils.scala:204, took 0.136192 s
19/07/31 17:14:18 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:18 INFO DAGScheduler: Registering RDD 33 (collect at utils.scala:204)
19/07/31 17:14:18 INFO DAGScheduler: Got job 6 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:14:18 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:204)
19/07/31 17:14:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
19/07/31 17:14:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
19/07/31 17:14:18 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[33] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:18 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 74.5 KB, free 911.1 MB)
19/07/31 17:14:18 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 31.7 KB, free 911.0 MB)
19/07/31 17:14:18 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:54132 (size: 31.7 KB, free: 912.1 MB)
19/07/31 17:14:18 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[33] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:18 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
19/07/31 17:14:18 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:14:18 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
19/07/31 17:14:18 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:18 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1687 bytes result sent to driver
19/07/31 17:14:18 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 49 ms on localhost (executor driver) (1/1)
19/07/31 17:14:18 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
19/07/31 17:14:18 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:204) finished in 0.051 s
19/07/31 17:14:18 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:14:18 INFO DAGScheduler: running: Set()
19/07/31 17:14:18 INFO DAGScheduler: waiting: Set(ResultStage 9)
19/07/31 17:14:18 INFO DAGScheduler: failed: Set()
19/07/31 17:14:18 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[36] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:18 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 16.8 KB, free 911.0 MB)
19/07/31 17:14:18 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.0 MB)
19/07/31 17:14:18 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:54132 (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:14:18 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:18 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 9 (MapPartitionsRDD[36] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:14:18 INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks
19/07/31 17:14:18 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:14:18 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 10, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:14:18 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 11, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:14:18 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 12, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:14:18 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
19/07/31 17:14:18 INFO Executor: Running task 2.0 in stage 9.0 (TID 11)
19/07/31 17:14:18 INFO Executor: Running task 3.0 in stage 9.0 (TID 12)
19/07/31 17:14:18 INFO Executor: Running task 1.0 in stage 9.0 (TID 10)
19/07/31 17:14:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:14:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/07/31 17:14:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:18 INFO CodeGenerator: Code generated in 10.715408 ms
19/07/31 17:14:18 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2382 bytes result sent to driver
19/07/31 17:14:18 INFO Executor: Finished task 1.0 in stage 9.0 (TID 10). 2403 bytes result sent to driver
19/07/31 17:14:18 INFO Executor: Finished task 2.0 in stage 9.0 (TID 11). 2390 bytes result sent to driver
19/07/31 17:14:18 INFO Executor: Finished task 3.0 in stage 9.0 (TID 12). 2362 bytes result sent to driver
19/07/31 17:14:18 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 97 ms on localhost (executor driver) (1/4)
19/07/31 17:14:18 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 10) in 96 ms on localhost (executor driver) (2/4)
19/07/31 17:14:18 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 12) in 96 ms on localhost (executor driver) (3/4)
19/07/31 17:14:18 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 11) in 96 ms on localhost (executor driver) (4/4)
19/07/31 17:14:18 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
19/07/31 17:14:18 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:204) finished in 0.100 s
19/07/31 17:14:18 INFO DAGScheduler: Job 6 finished: collect at utils.scala:204, took 0.189551 s
19/07/31 17:14:18 INFO CodeGenerator: Code generated in 23.614214 ms
19/07/31 17:14:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_009`) `dbplyr_010`
ORDER BY `date`) `dbplyr_011`) `dbplyr_012`
WHERE ((`customer` = "All Visitors") AND (`device` = "Mobile Phone"))
19/07/31 17:14:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_013`) `dbplyr_014`
ORDER BY `date`) `dbplyr_015`) `dbplyr_016`
WHERE ((`customer` = "All Visitors") AND (`device` = "Mobile Phone"))
19/07/31 17:14:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:21 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#540 - cust_prospect_ind.nullCount#539) > 0)
19/07/31 17:14:21 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#545 - visit_device_type.nullCount#544) > 0)
19/07/31 17:14:21 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#538 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#537))
19/07/31 17:14:21 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#543 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#542))
19/07/31 17:14:21 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:21 INFO DAGScheduler: Got job 7 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:14:21 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:204)
19/07/31 17:14:21 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:14:21 INFO DAGScheduler: Missing parents: List()
19/07/31 17:14:21 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[41] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:21 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 72.1 KB, free 910.9 MB)
19/07/31 17:14:21 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.9 MB)
19/07/31 17:14:21 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:54132 (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:14:21 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[41] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:21 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
19/07/31 17:14:21 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:14:21 INFO Executor: Running task 0.0 in stage 10.0 (TID 13)
19/07/31 17:14:21 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:21 INFO Executor: Finished task 0.0 in stage 10.0 (TID 13). 7585 bytes result sent to driver
19/07/31 17:14:21 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 13) in 14 ms on localhost (executor driver) (1/1)
19/07/31 17:14:21 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
19/07/31 17:14:21 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:204) finished in 0.014 s
19/07/31 17:14:21 INFO DAGScheduler: Job 7 finished: collect at utils.scala:204, took 0.024290 s
19/07/31 17:14:21 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:21 INFO DAGScheduler: Registering RDD 42 (collect at utils.scala:204)
19/07/31 17:14:21 INFO DAGScheduler: Got job 8 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:14:21 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:204)
19/07/31 17:14:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
19/07/31 17:14:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
19/07/31 17:14:21 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[42] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:21 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 74.6 KB, free 910.8 MB)
19/07/31 17:14:21 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.8 MB)
19/07/31 17:14:21 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:54132 (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:14:21 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[42] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:21 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
19/07/31 17:14:21 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:14:21 INFO Executor: Running task 0.0 in stage 11.0 (TID 14)
19/07/31 17:14:21 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:21 INFO Executor: Finished task 0.0 in stage 11.0 (TID 14). 1687 bytes result sent to driver
19/07/31 17:14:21 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 14) in 23 ms on localhost (executor driver) (1/1)
19/07/31 17:14:21 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
19/07/31 17:14:21 INFO DAGScheduler: ShuffleMapStage 11 (collect at utils.scala:204) finished in 0.024 s
19/07/31 17:14:21 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:14:21 INFO DAGScheduler: running: Set()
19/07/31 17:14:21 INFO DAGScheduler: waiting: Set(ResultStage 12)
19/07/31 17:14:21 INFO DAGScheduler: failed: Set()
19/07/31 17:14:21 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[45] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:21 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 16.8 KB, free 910.8 MB)
19/07/31 17:14:21 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.8 MB)
19/07/31 17:14:21 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:54132 (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:14:21 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:21 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 12 (MapPartitionsRDD[45] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:14:21 INFO TaskSchedulerImpl: Adding task set 12.0 with 4 tasks
19/07/31 17:14:21 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 15, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:14:21 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 16, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:14:21 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 17, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:14:21 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 18, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:14:21 INFO Executor: Running task 1.0 in stage 12.0 (TID 16)
19/07/31 17:14:21 INFO Executor: Running task 2.0 in stage 12.0 (TID 17)
19/07/31 17:14:21 INFO Executor: Running task 3.0 in stage 12.0 (TID 18)
19/07/31 17:14:21 INFO Executor: Running task 0.0 in stage 12.0 (TID 15)
19/07/31 17:14:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:21 INFO Executor: Finished task 2.0 in stage 12.0 (TID 17). 2372 bytes result sent to driver
19/07/31 17:14:21 INFO Executor: Finished task 1.0 in stage 12.0 (TID 16). 2383 bytes result sent to driver
19/07/31 17:14:21 INFO Executor: Finished task 3.0 in stage 12.0 (TID 18). 2358 bytes result sent to driver
19/07/31 17:14:21 INFO Executor: Finished task 0.0 in stage 12.0 (TID 15). 2385 bytes result sent to driver
19/07/31 17:14:21 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 17) in 8 ms on localhost (executor driver) (1/4)
19/07/31 17:14:21 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 18) in 8 ms on localhost (executor driver) (2/4)
19/07/31 17:14:21 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 16) in 8 ms on localhost (executor driver) (3/4)
19/07/31 17:14:21 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 15) in 9 ms on localhost (executor driver) (4/4)
19/07/31 17:14:21 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
19/07/31 17:14:21 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:14:21 INFO DAGScheduler: Job 8 finished: collect at utils.scala:204, took 0.057050 s
19/07/31 17:14:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_017`) `dbplyr_018`
ORDER BY `date`) `dbplyr_019`) `dbplyr_020`
WHERE ((`customer` = "All Visitors") AND (`device` = "Desktop"))
19/07/31 17:14:21 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:21 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_021`) `dbplyr_022`
ORDER BY `date`) `dbplyr_023`) `dbplyr_024`
WHERE ((`customer` = "All Visitors") AND (`device` = "Desktop"))
19/07/31 17:14:22 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:22 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:22 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#638 - cust_prospect_ind.nullCount#637) > 0)
19/07/31 17:14:22 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#643 - visit_device_type.nullCount#642) > 0)
19/07/31 17:14:22 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#636 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#635))
19/07/31 17:14:22 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#641 <= Desktop) && (Desktop <= visit_device_type.upperBound#640))
19/07/31 17:14:22 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:22 INFO DAGScheduler: Got job 9 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:14:22 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:204)
19/07/31 17:14:22 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:14:22 INFO DAGScheduler: Missing parents: List()
19/07/31 17:14:22 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[50] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:22 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:54132 in memory (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:14:22 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 72.1 KB, free 910.8 MB)
19/07/31 17:14:22 INFO ContextCleaner: Cleaned shuffle 0
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 119
19/07/31 17:14:22 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.8 MB)
19/07/31 17:14:22 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:54132 (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:14:22 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:22 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:54132 in memory (size: 11.8 KB, free: 912.0 MB)
19/07/31 17:14:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[50] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:22 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
19/07/31 17:14:22 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:54132 in memory (size: 8.6 KB, free: 912.0 MB)
19/07/31 17:14:22 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 186
19/07/31 17:14:22 INFO Executor: Running task 0.0 in stage 13.0 (TID 19)
19/07/31 17:14:22 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:54132 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:14:22 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:54132 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:14:22 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:54132 in memory (size: 31.8 KB, free: 912.1 MB)
19/07/31 17:14:22 INFO ContextCleaner: Cleaned shuffle 1
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 244
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 124
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 236
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 118
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 180
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 398
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 116
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 122
19/07/31 17:14:22 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:54132 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 17:14:22 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:54132 in memory (size: 31.7 KB, free: 912.1 MB)
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 126
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 237
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 176
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 115
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 179
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 243
19/07/31 17:14:22 INFO ContextCleaner: Cleaned shuffle 2
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 114
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 239
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 317
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 177
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 117
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 182
19/07/31 17:14:22 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 184
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 238
19/07/31 17:14:22 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:54132 in memory (size: 11.9 KB, free: 912.1 MB)
19/07/31 17:14:22 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:54132 in memory (size: 30.4 KB, free: 912.1 MB)
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 242
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 121
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 125
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 183
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 120
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 175
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 181
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 123
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 240
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 241
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 185
19/07/31 17:14:22 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:54132 in memory (size: 3.7 KB, free: 912.1 MB)
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 178
19/07/31 17:14:22 INFO ContextCleaner: Cleaned accumulator 187
19/07/31 17:14:22 INFO Executor: Finished task 0.0 in stage 13.0 (TID 19). 7068 bytes result sent to driver
19/07/31 17:14:22 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 19) in 12 ms on localhost (executor driver) (1/1)
19/07/31 17:14:22 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
19/07/31 17:14:22 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:14:22 INFO DAGScheduler: Job 9 finished: collect at utils.scala:204, took 0.034112 s
19/07/31 17:14:22 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:22 INFO DAGScheduler: Registering RDD 51 (collect at utils.scala:204)
19/07/31 17:14:22 INFO DAGScheduler: Got job 10 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:14:22 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:204)
19/07/31 17:14:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
19/07/31 17:14:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 14)
19/07/31 17:14:22 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[51] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:22 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 74.5 KB, free 911.2 MB)
19/07/31 17:14:22 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.1 MB)
19/07/31 17:14:22 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:54132 (size: 31.8 KB, free: 912.1 MB)
19/07/31 17:14:22 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[51] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:22 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
19/07/31 17:14:22 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:14:22 INFO Executor: Running task 0.0 in stage 14.0 (TID 20)
19/07/31 17:14:22 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:22 INFO Executor: Finished task 0.0 in stage 14.0 (TID 20). 1687 bytes result sent to driver
19/07/31 17:14:22 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 20) in 13 ms on localhost (executor driver) (1/1)
19/07/31 17:14:22 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
19/07/31 17:14:22 INFO DAGScheduler: ShuffleMapStage 14 (collect at utils.scala:204) finished in 0.014 s
19/07/31 17:14:22 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:14:22 INFO DAGScheduler: running: Set()
19/07/31 17:14:22 INFO DAGScheduler: waiting: Set(ResultStage 15)
19/07/31 17:14:22 INFO DAGScheduler: failed: Set()
19/07/31 17:14:22 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[54] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:22 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 16.8 KB, free 911.1 MB)
19/07/31 17:14:22 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.1 MB)
19/07/31 17:14:22 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:54132 (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:14:22 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:22 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 15 (MapPartitionsRDD[54] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:14:22 INFO TaskSchedulerImpl: Adding task set 15.0 with 4 tasks
19/07/31 17:14:22 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 21, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:14:22 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 22, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:14:22 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 23, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:14:22 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 24, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:14:22 INFO Executor: Running task 1.0 in stage 15.0 (TID 22)
19/07/31 17:14:22 INFO Executor: Running task 2.0 in stage 15.0 (TID 23)
19/07/31 17:14:22 INFO Executor: Running task 3.0 in stage 15.0 (TID 24)
19/07/31 17:14:22 INFO Executor: Running task 0.0 in stage 15.0 (TID 21)
19/07/31 17:14:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:14:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:14:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:14:22 INFO Executor: Finished task 1.0 in stage 15.0 (TID 22). 2385 bytes result sent to driver
19/07/31 17:14:22 INFO Executor: Finished task 2.0 in stage 15.0 (TID 23). 2380 bytes result sent to driver
19/07/31 17:14:22 INFO Executor: Finished task 3.0 in stage 15.0 (TID 24). 2356 bytes result sent to driver
19/07/31 17:14:22 INFO Executor: Finished task 0.0 in stage 15.0 (TID 21). 2381 bytes result sent to driver
19/07/31 17:14:22 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 22) in 9 ms on localhost (executor driver) (1/4)
19/07/31 17:14:22 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 24) in 8 ms on localhost (executor driver) (2/4)
19/07/31 17:14:22 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 23) in 8 ms on localhost (executor driver) (3/4)
19/07/31 17:14:22 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 21) in 9 ms on localhost (executor driver) (4/4)
19/07/31 17:14:22 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
19/07/31 17:14:22 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:14:22 INFO DAGScheduler: Job 10 finished: collect at utils.scala:204, took 0.036361 s
19/07/31 17:14:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_025`) `dbplyr_026`
ORDER BY `date`) `dbplyr_027`) `dbplyr_028`
WHERE ((`customer` = "All Visitors") AND (`device` = "Tablet"))
19/07/31 17:14:22 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:22 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_029`) `dbplyr_030`
ORDER BY `date`) `dbplyr_031`) `dbplyr_032`
WHERE ((`customer` = "All Visitors") AND (`device` = "Tablet"))
19/07/31 17:14:22 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:22 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:22 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#736 - cust_prospect_ind.nullCount#735) > 0)
19/07/31 17:14:22 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#741 - visit_device_type.nullCount#740) > 0)
19/07/31 17:14:22 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = All Visitors) generates partition filter: ((cust_prospect_ind.lowerBound#734 <= All Visitors) && (All Visitors <= cust_prospect_ind.upperBound#733))
19/07/31 17:14:22 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#739 <= Tablet) && (Tablet <= visit_device_type.upperBound#738))
19/07/31 17:14:22 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:22 INFO DAGScheduler: Got job 11 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:14:22 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:204)
19/07/31 17:14:22 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:14:22 INFO DAGScheduler: Missing parents: List()
19/07/31 17:14:22 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[59] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:23 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 72.1 KB, free 911.0 MB)
19/07/31 17:14:23 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.0 MB)
19/07/31 17:14:23 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:54132 (size: 30.4 KB, free: 912.1 MB)
19/07/31 17:14:23 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[59] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:23 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
19/07/31 17:14:23 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:14:23 INFO Executor: Running task 0.0 in stage 16.0 (TID 25)
19/07/31 17:14:23 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:23 INFO Executor: Finished task 0.0 in stage 16.0 (TID 25). 7068 bytes result sent to driver
19/07/31 17:14:23 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 25) in 10 ms on localhost (executor driver) (1/1)
19/07/31 17:14:23 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
19/07/31 17:14:23 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:204) finished in 0.011 s
19/07/31 17:14:23 INFO DAGScheduler: Job 11 finished: collect at utils.scala:204, took 0.019348 s
19/07/31 17:14:23 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:23 INFO DAGScheduler: Registering RDD 60 (collect at utils.scala:204)
19/07/31 17:14:23 INFO DAGScheduler: Got job 12 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:14:23 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:204)
19/07/31 17:14:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
19/07/31 17:14:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
19/07/31 17:14:23 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[60] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:23 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 74.5 KB, free 910.9 MB)
19/07/31 17:14:23 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.9 MB)
19/07/31 17:14:23 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:54132 (size: 31.7 KB, free: 912.0 MB)
19/07/31 17:14:23 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[60] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:23 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
19/07/31 17:14:23 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:14:23 INFO Executor: Running task 0.0 in stage 17.0 (TID 26)
19/07/31 17:14:23 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:23 INFO Executor: Finished task 0.0 in stage 17.0 (TID 26). 1687 bytes result sent to driver
19/07/31 17:14:23 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 26) in 14 ms on localhost (executor driver) (1/1)
19/07/31 17:14:23 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
19/07/31 17:14:23 INFO DAGScheduler: ShuffleMapStage 17 (collect at utils.scala:204) finished in 0.014 s
19/07/31 17:14:23 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:14:23 INFO DAGScheduler: running: Set()
19/07/31 17:14:23 INFO DAGScheduler: waiting: Set(ResultStage 18)
19/07/31 17:14:23 INFO DAGScheduler: failed: Set()
19/07/31 17:14:23 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[63] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:23 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 16.8 KB, free 910.9 MB)
19/07/31 17:14:23 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.9 MB)
19/07/31 17:14:23 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:54132 (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:14:23 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:23 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 18 (MapPartitionsRDD[63] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:14:23 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks
19/07/31 17:14:23 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 27, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:14:23 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 28, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:14:23 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 29, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:14:23 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 30, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:14:23 INFO Executor: Running task 0.0 in stage 18.0 (TID 27)
19/07/31 17:14:23 INFO Executor: Running task 1.0 in stage 18.0 (TID 28)
19/07/31 17:14:23 INFO Executor: Running task 2.0 in stage 18.0 (TID 29)
19/07/31 17:14:23 INFO Executor: Running task 3.0 in stage 18.0 (TID 30)
19/07/31 17:14:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:23 INFO Executor: Finished task 2.0 in stage 18.0 (TID 29). 2362 bytes result sent to driver
19/07/31 17:14:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:23 INFO Executor: Finished task 3.0 in stage 18.0 (TID 30). 2337 bytes result sent to driver
19/07/31 17:14:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:23 INFO Executor: Finished task 0.0 in stage 18.0 (TID 27). 2363 bytes result sent to driver
19/07/31 17:14:23 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 29) in 9 ms on localhost (executor driver) (1/4)
19/07/31 17:14:23 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 30) in 10 ms on localhost (executor driver) (2/4)
19/07/31 17:14:23 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 27) in 11 ms on localhost (executor driver) (3/4)
19/07/31 17:14:23 INFO Executor: Finished task 1.0 in stage 18.0 (TID 28). 2361 bytes result sent to driver
19/07/31 17:14:23 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 28) in 13 ms on localhost (executor driver) (4/4)
19/07/31 17:14:23 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
19/07/31 17:14:23 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:204) finished in 0.014 s
19/07/31 17:14:23 INFO DAGScheduler: Job 12 finished: collect at utils.scala:204, took 0.045770 s
19/07/31 17:14:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_033`) `dbplyr_034`
ORDER BY `date`) `dbplyr_035`) `dbplyr_036`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "All Devices"))
19/07/31 17:14:23 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:23 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_037`) `dbplyr_038`
ORDER BY `date`) `dbplyr_039`) `dbplyr_040`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "All Devices"))
19/07/31 17:14:23 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:23 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:23 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#834 - cust_prospect_ind.nullCount#833) > 0)
19/07/31 17:14:23 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#839 - visit_device_type.nullCount#838) > 0)
19/07/31 17:14:23 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#832 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#831))
19/07/31 17:14:23 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#837 <= All Devices) && (All Devices <= visit_device_type.upperBound#836))
19/07/31 17:14:23 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:23 INFO DAGScheduler: Got job 13 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:14:23 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:204)
19/07/31 17:14:23 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:14:23 INFO DAGScheduler: Missing parents: List()
19/07/31 17:14:23 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[68] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:23 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 72.1 KB, free 910.8 MB)
19/07/31 17:14:23 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.8 MB)
19/07/31 17:14:23 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:54132 (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:14:23 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[68] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:23 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
19/07/31 17:14:23 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:14:23 INFO Executor: Running task 0.0 in stage 19.0 (TID 31)
19/07/31 17:14:23 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:23 INFO Executor: Finished task 0.0 in stage 19.0 (TID 31). 6979 bytes result sent to driver
19/07/31 17:14:23 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 31) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:14:23 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
19/07/31 17:14:23 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:14:23 INFO DAGScheduler: Job 13 finished: collect at utils.scala:204, took 0.017522 s
19/07/31 17:14:23 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:23 INFO DAGScheduler: Registering RDD 69 (collect at utils.scala:204)
19/07/31 17:14:23 INFO DAGScheduler: Got job 14 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:14:23 INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:204)
19/07/31 17:14:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
19/07/31 17:14:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
19/07/31 17:14:23 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[69] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:23 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 74.5 KB, free 910.7 MB)
19/07/31 17:14:23 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.7 MB)
19/07/31 17:14:23 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:54132 (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:14:23 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[69] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:23 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
19/07/31 17:14:23 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 32, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:14:23 INFO Executor: Running task 0.0 in stage 20.0 (TID 32)
19/07/31 17:14:23 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:23 INFO Executor: Finished task 0.0 in stage 20.0 (TID 32). 1687 bytes result sent to driver
19/07/31 17:14:23 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 32) in 12 ms on localhost (executor driver) (1/1)
19/07/31 17:14:23 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
19/07/31 17:14:23 INFO DAGScheduler: ShuffleMapStage 20 (collect at utils.scala:204) finished in 0.015 s
19/07/31 17:14:23 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:14:23 INFO DAGScheduler: running: Set()
19/07/31 17:14:23 INFO DAGScheduler: waiting: Set(ResultStage 21)
19/07/31 17:14:23 INFO DAGScheduler: failed: Set()
19/07/31 17:14:23 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[72] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:23 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 16.8 KB, free 910.7 MB)
19/07/31 17:14:23 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.7 MB)
19/07/31 17:14:23 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:54132 (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:14:23 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:23 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 21 (MapPartitionsRDD[72] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:14:23 INFO TaskSchedulerImpl: Adding task set 21.0 with 4 tasks
19/07/31 17:14:23 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 33, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:14:23 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 34, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:14:23 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 35, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:14:23 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 36, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:14:23 INFO Executor: Running task 0.0 in stage 21.0 (TID 33)
19/07/31 17:14:23 INFO Executor: Running task 1.0 in stage 21.0 (TID 34)
19/07/31 17:14:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:23 INFO Executor: Running task 3.0 in stage 21.0 (TID 36)
19/07/31 17:14:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:23 INFO Executor: Running task 2.0 in stage 21.0 (TID 35)
19/07/31 17:14:23 INFO Executor: Finished task 3.0 in stage 21.0 (TID 36). 2353 bytes result sent to driver
19/07/31 17:14:23 INFO Executor: Finished task 1.0 in stage 21.0 (TID 34). 2359 bytes result sent to driver
19/07/31 17:14:23 INFO Executor: Finished task 0.0 in stage 21.0 (TID 33). 2377 bytes result sent to driver
19/07/31 17:14:23 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 36) in 11 ms on localhost (executor driver) (1/4)
19/07/31 17:14:23 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 34) in 12 ms on localhost (executor driver) (2/4)
19/07/31 17:14:23 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 33) in 12 ms on localhost (executor driver) (3/4)
19/07/31 17:14:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:23 INFO Executor: Finished task 2.0 in stage 21.0 (TID 35). 2421 bytes result sent to driver
19/07/31 17:14:23 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 35) in 16 ms on localhost (executor driver) (4/4)
19/07/31 17:14:23 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
19/07/31 17:14:23 INFO DAGScheduler: ResultStage 21 (collect at utils.scala:204) finished in 0.018 s
19/07/31 17:14:23 INFO DAGScheduler: Job 14 finished: collect at utils.scala:204, took 0.049254 s
19/07/31 17:14:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_041`) `dbplyr_042`
ORDER BY `date`) `dbplyr_043`) `dbplyr_044`
WHERE ((`customer` = "PROSPECT") AND (`device` = "All Devices"))
19/07/31 17:14:25 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_045`) `dbplyr_046`
ORDER BY `date`) `dbplyr_047`) `dbplyr_048`
WHERE ((`customer` = "PROSPECT") AND (`device` = "All Devices"))
19/07/31 17:14:25 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:25 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:25 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#932 - cust_prospect_ind.nullCount#931) > 0)
19/07/31 17:14:25 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#937 - visit_device_type.nullCount#936) > 0)
19/07/31 17:14:25 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#930 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#929))
19/07/31 17:14:25 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#935 <= All Devices) && (All Devices <= visit_device_type.upperBound#934))
19/07/31 17:14:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:25 INFO DAGScheduler: Got job 15 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:14:25 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:204)
19/07/31 17:14:25 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:14:25 INFO DAGScheduler: Missing parents: List()
19/07/31 17:14:25 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[77] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:25 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 72.1 KB, free 910.6 MB)
19/07/31 17:14:25 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.6 MB)
19/07/31 17:14:25 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:54132 (size: 30.4 KB, free: 911.9 MB)
19/07/31 17:14:25 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[77] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:25 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
19/07/31 17:14:25 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:14:25 INFO Executor: Running task 0.0 in stage 22.0 (TID 37)
19/07/31 17:14:25 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:25 INFO Executor: Finished task 0.0 in stage 22.0 (TID 37). 6979 bytes result sent to driver
19/07/31 17:14:25 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 37) in 17 ms on localhost (executor driver) (1/1)
19/07/31 17:14:25 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
19/07/31 17:14:25 INFO DAGScheduler: ResultStage 22 (collect at utils.scala:204) finished in 0.018 s
19/07/31 17:14:25 INFO DAGScheduler: Job 15 finished: collect at utils.scala:204, took 0.035040 s
19/07/31 17:14:25 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:25 INFO DAGScheduler: Registering RDD 78 (collect at utils.scala:204)
19/07/31 17:14:25 INFO DAGScheduler: Got job 16 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:14:25 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:204)
19/07/31 17:14:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
19/07/31 17:14:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 23)
19/07/31 17:14:25 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[78] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:25 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 74.5 KB, free 910.5 MB)
19/07/31 17:14:25 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.5 MB)
19/07/31 17:14:25 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:54132 (size: 31.8 KB, free: 911.9 MB)
19/07/31 17:14:25 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[78] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:25 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
19/07/31 17:14:25 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:14:25 INFO Executor: Running task 0.0 in stage 23.0 (TID 38)
19/07/31 17:14:25 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:25 INFO Executor: Finished task 0.0 in stage 23.0 (TID 38). 1687 bytes result sent to driver
19/07/31 17:14:25 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 38) in 40 ms on localhost (executor driver) (1/1)
19/07/31 17:14:25 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
19/07/31 17:14:25 INFO DAGScheduler: ShuffleMapStage 23 (collect at utils.scala:204) finished in 0.041 s
19/07/31 17:14:25 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:14:25 INFO DAGScheduler: running: Set()
19/07/31 17:14:25 INFO DAGScheduler: waiting: Set(ResultStage 24)
19/07/31 17:14:25 INFO DAGScheduler: failed: Set()
19/07/31 17:14:25 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[81] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:25 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 16.8 KB, free 910.4 MB)
19/07/31 17:14:25 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.4 MB)
19/07/31 17:14:25 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:54132 (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:14:25 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:25 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[81] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:14:25 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks
19/07/31 17:14:25 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 39, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:14:25 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 40, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:14:25 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 41, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:14:25 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 42, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:14:25 INFO Executor: Running task 0.0 in stage 24.0 (TID 39)
19/07/31 17:14:25 INFO Executor: Running task 1.0 in stage 24.0 (TID 40)
19/07/31 17:14:25 INFO Executor: Running task 2.0 in stage 24.0 (TID 41)
19/07/31 17:14:25 INFO Executor: Running task 3.0 in stage 24.0 (TID 42)
19/07/31 17:14:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:14:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:14:25 INFO Executor: Finished task 3.0 in stage 24.0 (TID 42). 2369 bytes result sent to driver
19/07/31 17:14:25 INFO Executor: Finished task 2.0 in stage 24.0 (TID 41). 2391 bytes result sent to driver
19/07/31 17:14:25 INFO Executor: Finished task 0.0 in stage 24.0 (TID 39). 2383 bytes result sent to driver
19/07/31 17:14:25 INFO Executor: Finished task 1.0 in stage 24.0 (TID 40). 2357 bytes result sent to driver
19/07/31 17:14:25 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 42) in 13 ms on localhost (executor driver) (1/4)
19/07/31 17:14:25 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 41) in 13 ms on localhost (executor driver) (2/4)
19/07/31 17:14:25 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 40) in 14 ms on localhost (executor driver) (3/4)
19/07/31 17:14:25 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 39) in 14 ms on localhost (executor driver) (4/4)
19/07/31 17:14:25 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
19/07/31 17:14:25 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:204) finished in 0.016 s
19/07/31 17:14:25 INFO DAGScheduler: Job 16 finished: collect at utils.scala:204, took 0.080916 s
19/07/31 17:14:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_049`) `dbplyr_050`
ORDER BY `date`) `dbplyr_051`) `dbplyr_052`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "All Devices"))
19/07/31 17:14:26 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:26 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_053`) `dbplyr_054`
ORDER BY `date`) `dbplyr_055`) `dbplyr_056`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "All Devices"))
19/07/31 17:14:27 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:27 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:27 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1030 - cust_prospect_ind.nullCount#1029) > 0)
19/07/31 17:14:27 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1035 - visit_device_type.nullCount#1034) > 0)
19/07/31 17:14:27 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#1028 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#1027))
19/07/31 17:14:27 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = All Devices) generates partition filter: ((visit_device_type.lowerBound#1033 <= All Devices) && (All Devices <= visit_device_type.upperBound#1032))
19/07/31 17:14:27 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:27 INFO DAGScheduler: Got job 17 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:14:27 INFO DAGScheduler: Final stage: ResultStage 25 (collect at utils.scala:204)
19/07/31 17:14:27 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:14:27 INFO DAGScheduler: Missing parents: List()
19/07/31 17:14:27 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[86] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:27 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 72.1 KB, free 910.4 MB)
19/07/31 17:14:27 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.3 MB)
19/07/31 17:14:27 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:54132 (size: 30.5 KB, free: 911.9 MB)
19/07/31 17:14:27 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[86] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:27 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
19/07/31 17:14:27 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:14:27 INFO Executor: Running task 0.0 in stage 25.0 (TID 43)
19/07/31 17:14:27 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:27 INFO Executor: Finished task 0.0 in stage 25.0 (TID 43). 7542 bytes result sent to driver
19/07/31 17:14:27 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 43) in 15 ms on localhost (executor driver) (1/1)
19/07/31 17:14:27 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
19/07/31 17:14:27 INFO DAGScheduler: ResultStage 25 (collect at utils.scala:204) finished in 0.017 s
19/07/31 17:14:27 INFO DAGScheduler: Job 17 finished: collect at utils.scala:204, took 0.034054 s
19/07/31 17:14:27 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:27 INFO DAGScheduler: Registering RDD 87 (collect at utils.scala:204)
19/07/31 17:14:27 INFO DAGScheduler: Got job 18 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:14:27 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:204)
19/07/31 17:14:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
19/07/31 17:14:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 26)
19/07/31 17:14:27 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[87] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:27 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 74.5 KB, free 910.3 MB)
19/07/31 17:14:27 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.2 MB)
19/07/31 17:14:27 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:54132 (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:14:27 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[87] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:27 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
19/07/31 17:14:27 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:14:27 INFO Executor: Running task 0.0 in stage 26.0 (TID 44)
19/07/31 17:14:27 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:27 INFO Executor: Finished task 0.0 in stage 26.0 (TID 44). 1687 bytes result sent to driver
19/07/31 17:14:27 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 44) in 23 ms on localhost (executor driver) (1/1)
19/07/31 17:14:27 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
19/07/31 17:14:27 INFO DAGScheduler: ShuffleMapStage 26 (collect at utils.scala:204) finished in 0.024 s
19/07/31 17:14:27 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:14:27 INFO DAGScheduler: running: Set()
19/07/31 17:14:27 INFO DAGScheduler: waiting: Set(ResultStage 27)
19/07/31 17:14:27 INFO DAGScheduler: failed: Set()
19/07/31 17:14:27 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[90] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:27 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 16.8 KB, free 910.2 MB)
19/07/31 17:14:27 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.2 MB)
19/07/31 17:14:27 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:54132 (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:14:27 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:27 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 27 (MapPartitionsRDD[90] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:14:27 INFO TaskSchedulerImpl: Adding task set 27.0 with 4 tasks
19/07/31 17:14:27 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 45, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:14:27 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 46, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:14:27 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 47, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:14:27 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 48, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:14:27 INFO Executor: Running task 2.0 in stage 27.0 (TID 47)
19/07/31 17:14:27 INFO Executor: Running task 0.0 in stage 27.0 (TID 45)
19/07/31 17:14:27 INFO Executor: Running task 1.0 in stage 27.0 (TID 46)
19/07/31 17:14:27 INFO Executor: Running task 3.0 in stage 27.0 (TID 48)
19/07/31 17:14:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:14:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:14:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:14:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:27 INFO Executor: Finished task 1.0 in stage 27.0 (TID 46). 2392 bytes result sent to driver
19/07/31 17:14:27 INFO Executor: Finished task 0.0 in stage 27.0 (TID 45). 2386 bytes result sent to driver
19/07/31 17:14:27 INFO Executor: Finished task 2.0 in stage 27.0 (TID 47). 2386 bytes result sent to driver
19/07/31 17:14:27 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 46) in 11 ms on localhost (executor driver) (1/4)
19/07/31 17:14:27 INFO Executor: Finished task 3.0 in stage 27.0 (TID 48). 2374 bytes result sent to driver
19/07/31 17:14:27 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 45) in 13 ms on localhost (executor driver) (2/4)
19/07/31 17:14:27 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 47) in 12 ms on localhost (executor driver) (3/4)
19/07/31 17:14:27 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 48) in 12 ms on localhost (executor driver) (4/4)
19/07/31 17:14:27 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
19/07/31 17:14:27 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:204) finished in 0.014 s
19/07/31 17:14:27 INFO DAGScheduler: Job 18 finished: collect at utils.scala:204, took 0.061122 s
19/07/31 17:14:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_057`) `dbplyr_058`
ORDER BY `date`) `dbplyr_059`) `dbplyr_060`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Mobile Phone"))
19/07/31 17:14:29 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:29 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_061`) `dbplyr_062`
ORDER BY `date`) `dbplyr_063`) `dbplyr_064`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Mobile Phone"))
19/07/31 17:14:29 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:29 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:29 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1128 - cust_prospect_ind.nullCount#1127) > 0)
19/07/31 17:14:29 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1133 - visit_device_type.nullCount#1132) > 0)
19/07/31 17:14:29 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#1126 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#1125))
19/07/31 17:14:29 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#1131 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#1130))
19/07/31 17:14:29 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:29 INFO DAGScheduler: Got job 19 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:14:29 INFO DAGScheduler: Final stage: ResultStage 28 (collect at utils.scala:204)
19/07/31 17:14:29 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:14:29 INFO DAGScheduler: Missing parents: List()
19/07/31 17:14:29 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[95] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:29 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 72.1 KB, free 910.1 MB)
19/07/31 17:14:29 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.1 MB)
19/07/31 17:14:29 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:54132 (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:14:29 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[95] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:29 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
19/07/31 17:14:29 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:14:29 INFO Executor: Running task 0.0 in stage 28.0 (TID 49)
19/07/31 17:14:29 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:29 INFO Executor: Finished task 0.0 in stage 28.0 (TID 49). 6979 bytes result sent to driver
19/07/31 17:14:29 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 49) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:14:29 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
19/07/31 17:14:29 INFO DAGScheduler: ResultStage 28 (collect at utils.scala:204) finished in 0.007 s
19/07/31 17:14:29 INFO DAGScheduler: Job 19 finished: collect at utils.scala:204, took 0.012566 s
19/07/31 17:14:29 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:29 INFO DAGScheduler: Registering RDD 96 (collect at utils.scala:204)
19/07/31 17:14:29 INFO DAGScheduler: Got job 20 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:14:29 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:204)
19/07/31 17:14:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
19/07/31 17:14:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 29)
19/07/31 17:14:29 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[96] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:29 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 74.5 KB, free 910.0 MB)
19/07/31 17:14:29 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.0 MB)
19/07/31 17:14:29 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:54132 (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:14:29 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[96] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:29 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
19/07/31 17:14:29 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:14:29 INFO Executor: Running task 0.0 in stage 29.0 (TID 50)
19/07/31 17:14:29 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:29 INFO Executor: Finished task 0.0 in stage 29.0 (TID 50). 1687 bytes result sent to driver
19/07/31 17:14:29 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 50) in 15 ms on localhost (executor driver) (1/1)
19/07/31 17:14:29 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
19/07/31 17:14:29 INFO DAGScheduler: ShuffleMapStage 29 (collect at utils.scala:204) finished in 0.016 s
19/07/31 17:14:29 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:14:29 INFO DAGScheduler: running: Set()
19/07/31 17:14:29 INFO DAGScheduler: waiting: Set(ResultStage 30)
19/07/31 17:14:29 INFO DAGScheduler: failed: Set()
19/07/31 17:14:29 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[99] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:29 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 16.8 KB, free 910.0 MB)
19/07/31 17:14:29 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.0 MB)
19/07/31 17:14:29 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:54132 (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:14:29 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:29 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 30 (MapPartitionsRDD[99] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:14:29 INFO TaskSchedulerImpl: Adding task set 30.0 with 4 tasks
19/07/31 17:14:29 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 51, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:14:29 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 52, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:14:29 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 53, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:14:29 INFO TaskSetManager: Starting task 3.0 in stage 30.0 (TID 54, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:14:29 INFO Executor: Running task 1.0 in stage 30.0 (TID 52)
19/07/31 17:14:29 INFO Executor: Running task 2.0 in stage 30.0 (TID 53)
19/07/31 17:14:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:29 INFO Executor: Running task 0.0 in stage 30.0 (TID 51)
19/07/31 17:14:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:29 INFO Executor: Finished task 1.0 in stage 30.0 (TID 52). 2347 bytes result sent to driver
19/07/31 17:14:29 INFO Executor: Running task 3.0 in stage 30.0 (TID 54)
19/07/31 17:14:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:29 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 52) in 9 ms on localhost (executor driver) (1/4)
19/07/31 17:14:29 INFO Executor: Finished task 2.0 in stage 30.0 (TID 53). 2371 bytes result sent to driver
19/07/31 17:14:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:29 INFO Executor: Finished task 3.0 in stage 30.0 (TID 54). 2353 bytes result sent to driver
19/07/31 17:14:29 INFO Executor: Finished task 0.0 in stage 30.0 (TID 51). 2366 bytes result sent to driver
19/07/31 17:14:29 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 53) in 14 ms on localhost (executor driver) (2/4)
19/07/31 17:14:29 INFO TaskSetManager: Finished task 3.0 in stage 30.0 (TID 54) in 14 ms on localhost (executor driver) (3/4)
19/07/31 17:14:29 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 51) in 14 ms on localhost (executor driver) (4/4)
19/07/31 17:14:29 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
19/07/31 17:14:29 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:204) finished in 0.015 s
19/07/31 17:14:29 INFO DAGScheduler: Job 20 finished: collect at utils.scala:204, took 0.043638 s
19/07/31 17:14:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_065`) `dbplyr_066`
ORDER BY `date`) `dbplyr_067`) `dbplyr_068`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Mobile Phone"))
19/07/31 17:14:30 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:30 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_069`) `dbplyr_070`
ORDER BY `date`) `dbplyr_071`) `dbplyr_072`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Mobile Phone"))
19/07/31 17:14:30 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:30 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:30 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1226 - cust_prospect_ind.nullCount#1225) > 0)
19/07/31 17:14:30 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1231 - visit_device_type.nullCount#1230) > 0)
19/07/31 17:14:30 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#1224 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#1223))
19/07/31 17:14:30 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#1229 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#1228))
19/07/31 17:14:30 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:30 INFO DAGScheduler: Got job 21 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:14:30 INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:204)
19/07/31 17:14:30 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:14:30 INFO DAGScheduler: Missing parents: List()
19/07/31 17:14:30 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[104] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:30 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 72.1 KB, free 909.9 MB)
19/07/31 17:14:30 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 30.4 KB, free 909.9 MB)
19/07/31 17:14:30 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:54132 (size: 30.4 KB, free: 911.7 MB)
19/07/31 17:14:30 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[104] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:30 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
19/07/31 17:14:30 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:14:30 INFO Executor: Running task 0.0 in stage 31.0 (TID 55)
19/07/31 17:14:30 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:30 INFO Executor: Finished task 0.0 in stage 31.0 (TID 55). 6979 bytes result sent to driver
19/07/31 17:14:30 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 55) in 8 ms on localhost (executor driver) (1/1)
19/07/31 17:14:30 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
19/07/31 17:14:30 INFO DAGScheduler: ResultStage 31 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:14:30 INFO DAGScheduler: Job 21 finished: collect at utils.scala:204, took 0.014821 s
19/07/31 17:14:30 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:30 INFO DAGScheduler: Registering RDD 105 (collect at utils.scala:204)
19/07/31 17:14:30 INFO DAGScheduler: Got job 22 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:14:30 INFO DAGScheduler: Final stage: ResultStage 33 (collect at utils.scala:204)
19/07/31 17:14:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)
19/07/31 17:14:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 32)
19/07/31 17:14:30 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[105] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:30 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 74.5 KB, free 909.8 MB)
19/07/31 17:14:30 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 31.7 KB, free 909.8 MB)
19/07/31 17:14:30 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:54132 (size: 31.7 KB, free: 911.7 MB)
19/07/31 17:14:30 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[105] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:30 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
19/07/31 17:14:30 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:14:30 INFO Executor: Running task 0.0 in stage 32.0 (TID 56)
19/07/31 17:14:30 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:30 INFO Executor: Finished task 0.0 in stage 32.0 (TID 56). 1687 bytes result sent to driver
19/07/31 17:14:30 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 56) in 10 ms on localhost (executor driver) (1/1)
19/07/31 17:14:30 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
19/07/31 17:14:30 INFO DAGScheduler: ShuffleMapStage 32 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:14:30 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:14:30 INFO DAGScheduler: running: Set()
19/07/31 17:14:30 INFO DAGScheduler: waiting: Set(ResultStage 33)
19/07/31 17:14:30 INFO DAGScheduler: failed: Set()
19/07/31 17:14:30 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[108] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:30 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 16.8 KB, free 909.8 MB)
19/07/31 17:14:30 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.7 MB)
19/07/31 17:14:30 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:54132 (size: 8.0 KB, free: 911.7 MB)
19/07/31 17:14:30 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:30 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 33 (MapPartitionsRDD[108] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:14:30 INFO TaskSchedulerImpl: Adding task set 33.0 with 4 tasks
19/07/31 17:14:30 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 57, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:14:30 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 58, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:14:30 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 59, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:14:30 INFO TaskSetManager: Starting task 3.0 in stage 33.0 (TID 60, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:14:30 INFO Executor: Running task 0.0 in stage 33.0 (TID 57)
19/07/31 17:14:30 INFO Executor: Running task 1.0 in stage 33.0 (TID 58)
19/07/31 17:14:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:30 INFO Executor: Running task 2.0 in stage 33.0 (TID 59)
19/07/31 17:14:30 INFO Executor: Finished task 1.0 in stage 33.0 (TID 58). 2370 bytes result sent to driver
19/07/31 17:14:30 INFO Executor: Running task 3.0 in stage 33.0 (TID 60)
19/07/31 17:14:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:14:30 INFO Executor: Finished task 0.0 in stage 33.0 (TID 57). 2373 bytes result sent to driver
19/07/31 17:14:30 INFO Executor: Finished task 2.0 in stage 33.0 (TID 59). 2384 bytes result sent to driver
19/07/31 17:14:30 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 58) in 9 ms on localhost (executor driver) (1/4)
19/07/31 17:14:30 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 57) in 9 ms on localhost (executor driver) (2/4)
19/07/31 17:14:30 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 59) in 9 ms on localhost (executor driver) (3/4)
19/07/31 17:14:30 INFO Executor: Finished task 3.0 in stage 33.0 (TID 60). 2353 bytes result sent to driver
19/07/31 17:14:30 INFO TaskSetManager: Finished task 3.0 in stage 33.0 (TID 60) in 10 ms on localhost (executor driver) (4/4)
19/07/31 17:14:30 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
19/07/31 17:14:30 INFO DAGScheduler: ResultStage 33 (collect at utils.scala:204) finished in 0.012 s
19/07/31 17:14:30 INFO DAGScheduler: Job 22 finished: collect at utils.scala:204, took 0.034799 s
19/07/31 17:14:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_073`) `dbplyr_074`
ORDER BY `date`) `dbplyr_075`) `dbplyr_076`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 17:14:30 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:30 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_077`) `dbplyr_078`
ORDER BY `date`) `dbplyr_079`) `dbplyr_080`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Mobile Phone"))
19/07/31 17:14:30 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:30 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:30 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1324 - cust_prospect_ind.nullCount#1323) > 0)
19/07/31 17:14:30 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1329 - visit_device_type.nullCount#1328) > 0)
19/07/31 17:14:30 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#1322 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#1321))
19/07/31 17:14:30 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Mobile Phone) generates partition filter: ((visit_device_type.lowerBound#1327 <= Mobile Phone) && (Mobile Phone <= visit_device_type.upperBound#1326))
19/07/31 17:14:30 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:30 INFO DAGScheduler: Got job 23 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:14:30 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:204)
19/07/31 17:14:30 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:14:30 INFO DAGScheduler: Missing parents: List()
19/07/31 17:14:30 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[113] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:30 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 72.1 KB, free 909.7 MB)
19/07/31 17:14:30 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 30.5 KB, free 909.6 MB)
19/07/31 17:14:30 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:54132 (size: 30.5 KB, free: 911.7 MB)
19/07/31 17:14:30 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[113] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:30 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
19/07/31 17:14:30 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:14:30 INFO Executor: Running task 0.0 in stage 34.0 (TID 61)
19/07/31 17:14:30 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:30 INFO Executor: Finished task 0.0 in stage 34.0 (TID 61). 7542 bytes result sent to driver
19/07/31 17:14:30 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 61) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:14:30 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
19/07/31 17:14:30 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:14:30 INFO DAGScheduler: Job 23 finished: collect at utils.scala:204, took 0.014230 s
19/07/31 17:14:30 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:30 INFO DAGScheduler: Registering RDD 114 (collect at utils.scala:204)
19/07/31 17:14:30 INFO DAGScheduler: Got job 24 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:14:30 INFO DAGScheduler: Final stage: ResultStage 36 (collect at utils.scala:204)
19/07/31 17:14:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
19/07/31 17:14:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 35)
19/07/31 17:14:30 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[114] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:30 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 74.6 KB, free 909.6 MB)
19/07/31 17:14:30 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 31.8 KB, free 909.5 MB)
19/07/31 17:14:30 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:54132 (size: 31.8 KB, free: 911.6 MB)
19/07/31 17:14:30 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[114] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:30 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
19/07/31 17:14:30 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:14:30 INFO Executor: Running task 0.0 in stage 35.0 (TID 62)
19/07/31 17:14:30 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:30 INFO Executor: Finished task 0.0 in stage 35.0 (TID 62). 1687 bytes result sent to driver
19/07/31 17:14:30 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 62) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:14:30 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
19/07/31 17:14:30 INFO DAGScheduler: ShuffleMapStage 35 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:14:30 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:14:30 INFO DAGScheduler: running: Set()
19/07/31 17:14:30 INFO DAGScheduler: waiting: Set(ResultStage 36)
19/07/31 17:14:30 INFO DAGScheduler: failed: Set()
19/07/31 17:14:30 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[117] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:30 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 16.8 KB, free 909.5 MB)
19/07/31 17:14:30 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 8.0 KB, free 909.5 MB)
19/07/31 17:14:30 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:54132 (size: 8.0 KB, free: 911.6 MB)
19/07/31 17:14:30 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:30 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 36 (MapPartitionsRDD[117] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:14:30 INFO TaskSchedulerImpl: Adding task set 36.0 with 4 tasks
19/07/31 17:14:30 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 63, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:14:30 INFO TaskSetManager: Starting task 1.0 in stage 36.0 (TID 64, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:14:30 INFO TaskSetManager: Starting task 2.0 in stage 36.0 (TID 65, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:14:30 INFO TaskSetManager: Starting task 3.0 in stage 36.0 (TID 66, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:14:30 INFO Executor: Running task 0.0 in stage 36.0 (TID 63)
19/07/31 17:14:30 INFO Executor: Running task 2.0 in stage 36.0 (TID 65)
19/07/31 17:14:30 INFO Executor: Running task 3.0 in stage 36.0 (TID 66)
19/07/31 17:14:30 INFO Executor: Running task 1.0 in stage 36.0 (TID 64)
19/07/31 17:14:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:14:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/07/31 17:14:30 INFO Executor: Finished task 3.0 in stage 36.0 (TID 66). 2356 bytes result sent to driver
19/07/31 17:14:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:14:30 INFO Executor: Finished task 1.0 in stage 36.0 (TID 64). 2382 bytes result sent to driver
19/07/31 17:14:30 INFO Executor: Finished task 0.0 in stage 36.0 (TID 63). 2377 bytes result sent to driver
19/07/31 17:14:30 INFO TaskSetManager: Finished task 3.0 in stage 36.0 (TID 66) in 6 ms on localhost (executor driver) (1/4)
19/07/31 17:14:30 INFO TaskSetManager: Finished task 1.0 in stage 36.0 (TID 64) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:14:30 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 63) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:14:30 INFO Executor: Finished task 2.0 in stage 36.0 (TID 65). 2377 bytes result sent to driver
19/07/31 17:14:30 INFO TaskSetManager: Finished task 2.0 in stage 36.0 (TID 65) in 7 ms on localhost (executor driver) (4/4)
19/07/31 17:14:30 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
19/07/31 17:14:30 INFO DAGScheduler: ResultStage 36 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:14:30 INFO DAGScheduler: Job 24 finished: collect at utils.scala:204, took 0.029800 s
19/07/31 17:14:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_081`) `dbplyr_082`
ORDER BY `date`) `dbplyr_083`) `dbplyr_084`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Desktop"))
19/07/31 17:14:31 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:31 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_085`) `dbplyr_086`
ORDER BY `date`) `dbplyr_087`) `dbplyr_088`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Desktop"))
19/07/31 17:14:31 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:31 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:31 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1422 - cust_prospect_ind.nullCount#1421) > 0)
19/07/31 17:14:31 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1427 - visit_device_type.nullCount#1426) > 0)
19/07/31 17:14:31 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#1420 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#1419))
19/07/31 17:14:31 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#1425 <= Desktop) && (Desktop <= visit_device_type.upperBound#1424))
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 725
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 320
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 724
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 729
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:54132 in memory (size: 30.5 KB, free: 911.7 MB)
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 804
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:54132 in memory (size: 31.8 KB, free: 911.7 MB)
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:54132 in memory (size: 31.7 KB, free: 911.7 MB)
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 807
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 403
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 970
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 809
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 884
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 645
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 568
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 806
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:54132 in memory (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 405
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 567
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 399
19/07/31 17:14:31 INFO ContextCleaner: Cleaned shuffle 4
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 1046
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 805
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 803
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:54132 in memory (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:54132 in memory (size: 30.4 KB, free: 911.8 MB)
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 483
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 968
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 564
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 727
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:54132 in memory (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:14:31 INFO ContextCleaner: Cleaned shuffle 9
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 479
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 641
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 644
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 321
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:54132 in memory (size: 30.5 KB, free: 911.9 MB)
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 404
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:54132 in memory (size: 31.8 KB, free: 911.9 MB)
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 969
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:54132 in memory (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 319
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 566
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:54132 in memory (size: 30.4 KB, free: 911.9 MB)
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 730
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 646
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:54132 in memory (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:14:31 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 560
19/07/31 17:14:31 INFO DAGScheduler: Got job 25 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:14:31 INFO DAGScheduler: Final stage: ResultStage 37 (collect at utils.scala:204)
19/07/31 17:14:31 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:54132 in memory (size: 31.7 KB, free: 912.0 MB)
19/07/31 17:14:31 INFO DAGScheduler: Missing parents: List()
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 647
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 323
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 563
19/07/31 17:14:31 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[122] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 565
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:54132 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:14:31 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 72.1 KB, free 910.7 MB)
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 649
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 484
19/07/31 17:14:31 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.7 MB)
19/07/31 17:14:31 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:54132 (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:54132 in memory (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:14:31 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[122] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:31 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 487
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 485
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 811
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 480
19/07/31 17:14:31 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 966
19/07/31 17:14:31 INFO Executor: Running task 0.0 in stage 37.0 (TID 67)
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:54132 in memory (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:14:31 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:31 INFO Executor: Finished task 0.0 in stage 37.0 (TID 67). 6512 bytes result sent to driver
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:54132 in memory (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:14:31 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 67) in 7 ms on localhost (executor driver) (1/1)
19/07/31 17:14:31 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 324
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 810
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 973
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 728
19/07/31 17:14:31 INFO DAGScheduler: ResultStage 37 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:14:31 INFO DAGScheduler: Job 25 finished: collect at utils.scala:204, took 0.014991 s
19/07/31 17:14:31 INFO ContextCleaner: Cleaned shuffle 11
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:54132 in memory (size: 31.8 KB, free: 912.1 MB)
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 486
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 648
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 322
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 722
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:54132 in memory (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:54132 in memory (size: 30.4 KB, free: 912.1 MB)
19/07/31 17:14:31 INFO ContextCleaner: Cleaned shuffle 8
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 482
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 808
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 481
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:54132 in memory (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:14:31 INFO ContextCleaner: Cleaned shuffle 3
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 561
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 325
19/07/31 17:14:31 INFO ContextCleaner: Cleaned shuffle 5
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 643
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 318
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 562
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 967
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 972
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 402
19/07/31 17:14:31 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:54132 in memory (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:14:31 INFO DAGScheduler: Registering RDD 123 (collect at utils.scala:204)
19/07/31 17:14:31 INFO DAGScheduler: Got job 26 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:14:31 INFO DAGScheduler: Final stage: ResultStage 39 (collect at utils.scala:204)
19/07/31 17:14:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)
19/07/31 17:14:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 38)
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 401
19/07/31 17:14:31 INFO ContextCleaner: Cleaned shuffle 7
19/07/31 17:14:31 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[123] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:54132 in memory (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:14:31 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 74.5 KB, free 911.1 MB)
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 726
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 723
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 965
19/07/31 17:14:31 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 31.8 KB, free 911.1 MB)
19/07/31 17:14:31 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:54132 (size: 31.8 KB, free: 912.1 MB)
19/07/31 17:14:31 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:54132 in memory (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:14:31 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[123] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:31 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
19/07/31 17:14:31 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:14:31 INFO Executor: Running task 0.0 in stage 38.0 (TID 68)
19/07/31 17:14:31 INFO ContextCleaner: Cleaned shuffle 6
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 406
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 971
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 642
19/07/31 17:14:31 INFO ContextCleaner: Cleaned accumulator 400
19/07/31 17:14:31 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:31 INFO Executor: Finished task 0.0 in stage 38.0 (TID 68). 1687 bytes result sent to driver
19/07/31 17:14:31 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 68) in 11 ms on localhost (executor driver) (1/1)
19/07/31 17:14:31 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
19/07/31 17:14:31 INFO DAGScheduler: ShuffleMapStage 38 (collect at utils.scala:204) finished in 0.011 s
19/07/31 17:14:31 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:14:31 INFO DAGScheduler: running: Set()
19/07/31 17:14:31 INFO DAGScheduler: waiting: Set(ResultStage 39)
19/07/31 17:14:31 INFO DAGScheduler: failed: Set()
19/07/31 17:14:31 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[126] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:31 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 16.8 KB, free 911.1 MB)
19/07/31 17:14:31 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 8.0 KB, free 911.1 MB)
19/07/31 17:14:31 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:54132 (size: 8.0 KB, free: 912.1 MB)
19/07/31 17:14:31 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:31 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 39 (MapPartitionsRDD[126] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:14:31 INFO TaskSchedulerImpl: Adding task set 39.0 with 4 tasks
19/07/31 17:14:31 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 69, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:14:31 INFO TaskSetManager: Starting task 1.0 in stage 39.0 (TID 70, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:14:31 INFO TaskSetManager: Starting task 2.0 in stage 39.0 (TID 71, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:14:31 INFO TaskSetManager: Starting task 3.0 in stage 39.0 (TID 72, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:14:31 INFO Executor: Running task 0.0 in stage 39.0 (TID 69)
19/07/31 17:14:31 INFO Executor: Running task 1.0 in stage 39.0 (TID 70)
19/07/31 17:14:31 INFO Executor: Running task 2.0 in stage 39.0 (TID 71)
19/07/31 17:14:31 INFO Executor: Running task 3.0 in stage 39.0 (TID 72)
19/07/31 17:14:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:14:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:31 INFO Executor: Finished task 3.0 in stage 39.0 (TID 72). 2314 bytes result sent to driver
19/07/31 17:14:31 INFO Executor: Finished task 1.0 in stage 39.0 (TID 70). 2350 bytes result sent to driver
19/07/31 17:14:31 INFO Executor: Finished task 0.0 in stage 39.0 (TID 69). 2367 bytes result sent to driver
19/07/31 17:14:31 INFO TaskSetManager: Finished task 3.0 in stage 39.0 (TID 72) in 7 ms on localhost (executor driver) (1/4)
19/07/31 17:14:31 INFO TaskSetManager: Finished task 1.0 in stage 39.0 (TID 70) in 7 ms on localhost (executor driver) (2/4)
19/07/31 17:14:31 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 69) in 7 ms on localhost (executor driver) (3/4)
19/07/31 17:14:31 INFO Executor: Finished task 2.0 in stage 39.0 (TID 71). 2368 bytes result sent to driver
19/07/31 17:14:31 INFO TaskSetManager: Finished task 2.0 in stage 39.0 (TID 71) in 8 ms on localhost (executor driver) (4/4)
19/07/31 17:14:31 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
19/07/31 17:14:31 INFO DAGScheduler: ResultStage 39 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:14:31 INFO DAGScheduler: Job 26 finished: collect at utils.scala:204, took 0.032233 s
19/07/31 17:14:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_089`) `dbplyr_090`
ORDER BY `date`) `dbplyr_091`) `dbplyr_092`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Desktop"))
19/07/31 17:14:32 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:32 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_093`) `dbplyr_094`
ORDER BY `date`) `dbplyr_095`) `dbplyr_096`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Desktop"))
19/07/31 17:14:32 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:32 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:32 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1520 - cust_prospect_ind.nullCount#1519) > 0)
19/07/31 17:14:32 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1525 - visit_device_type.nullCount#1524) > 0)
19/07/31 17:14:32 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#1518 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#1517))
19/07/31 17:14:32 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#1523 <= Desktop) && (Desktop <= visit_device_type.upperBound#1522))
19/07/31 17:14:32 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:32 INFO DAGScheduler: Got job 27 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:14:32 INFO DAGScheduler: Final stage: ResultStage 40 (collect at utils.scala:204)
19/07/31 17:14:32 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:14:32 INFO DAGScheduler: Missing parents: List()
19/07/31 17:14:32 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[131] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:32 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 72.1 KB, free 911.0 MB)
19/07/31 17:14:32 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 30.4 KB, free 911.0 MB)
19/07/31 17:14:32 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:54132 (size: 30.4 KB, free: 912.1 MB)
19/07/31 17:14:32 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[131] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:32 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
19/07/31 17:14:32 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 73, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:14:32 INFO Executor: Running task 0.0 in stage 40.0 (TID 73)
19/07/31 17:14:32 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:32 INFO Executor: Finished task 0.0 in stage 40.0 (TID 73). 6512 bytes result sent to driver
19/07/31 17:14:32 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 73) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:14:32 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
19/07/31 17:14:32 INFO DAGScheduler: ResultStage 40 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:14:32 INFO DAGScheduler: Job 27 finished: collect at utils.scala:204, took 0.011843 s
19/07/31 17:14:32 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:32 INFO DAGScheduler: Registering RDD 132 (collect at utils.scala:204)
19/07/31 17:14:32 INFO DAGScheduler: Got job 28 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:14:32 INFO DAGScheduler: Final stage: ResultStage 42 (collect at utils.scala:204)
19/07/31 17:14:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
19/07/31 17:14:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
19/07/31 17:14:32 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[132] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:32 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 74.5 KB, free 910.9 MB)
19/07/31 17:14:32 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.9 MB)
19/07/31 17:14:32 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:54132 (size: 31.7 KB, free: 912.0 MB)
19/07/31 17:14:32 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:32 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[132] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:32 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
19/07/31 17:14:32 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 74, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:14:32 INFO Executor: Running task 0.0 in stage 41.0 (TID 74)
19/07/31 17:14:32 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:32 INFO Executor: Finished task 0.0 in stage 41.0 (TID 74). 1687 bytes result sent to driver
19/07/31 17:14:32 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 74) in 10 ms on localhost (executor driver) (1/1)
19/07/31 17:14:32 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
19/07/31 17:14:32 INFO DAGScheduler: ShuffleMapStage 41 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:14:32 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:14:32 INFO DAGScheduler: running: Set()
19/07/31 17:14:32 INFO DAGScheduler: waiting: Set(ResultStage 42)
19/07/31 17:14:32 INFO DAGScheduler: failed: Set()
19/07/31 17:14:32 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[135] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:32 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 16.8 KB, free 910.9 MB)
19/07/31 17:14:32 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.9 MB)
19/07/31 17:14:32 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:54132 (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:14:32 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:32 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 42 (MapPartitionsRDD[135] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:14:32 INFO TaskSchedulerImpl: Adding task set 42.0 with 4 tasks
19/07/31 17:14:32 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 75, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:14:32 INFO TaskSetManager: Starting task 1.0 in stage 42.0 (TID 76, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:14:32 INFO TaskSetManager: Starting task 2.0 in stage 42.0 (TID 77, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:14:32 INFO TaskSetManager: Starting task 3.0 in stage 42.0 (TID 78, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:14:32 INFO Executor: Running task 1.0 in stage 42.0 (TID 76)
19/07/31 17:14:32 INFO Executor: Running task 2.0 in stage 42.0 (TID 77)
19/07/31 17:14:32 INFO Executor: Running task 3.0 in stage 42.0 (TID 78)
19/07/31 17:14:32 INFO Executor: Running task 0.0 in stage 42.0 (TID 75)
19/07/31 17:14:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/07/31 17:14:32 INFO Executor: Finished task 3.0 in stage 42.0 (TID 78). 2359 bytes result sent to driver
19/07/31 17:14:32 INFO Executor: Finished task 2.0 in stage 42.0 (TID 77). 2330 bytes result sent to driver
19/07/31 17:14:32 INFO Executor: Finished task 1.0 in stage 42.0 (TID 76). 2308 bytes result sent to driver
19/07/31 17:14:32 INFO TaskSetManager: Finished task 3.0 in stage 42.0 (TID 78) in 6 ms on localhost (executor driver) (1/4)
19/07/31 17:14:32 INFO TaskSetManager: Finished task 2.0 in stage 42.0 (TID 77) in 6 ms on localhost (executor driver) (2/4)
19/07/31 17:14:32 INFO Executor: Finished task 0.0 in stage 42.0 (TID 75). 2369 bytes result sent to driver
19/07/31 17:14:32 INFO TaskSetManager: Finished task 1.0 in stage 42.0 (TID 76) in 7 ms on localhost (executor driver) (3/4)
19/07/31 17:14:32 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 75) in 8 ms on localhost (executor driver) (4/4)
19/07/31 17:14:32 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
19/07/31 17:14:32 INFO DAGScheduler: ResultStage 42 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:14:32 INFO DAGScheduler: Job 28 finished: collect at utils.scala:204, took 0.028684 s
19/07/31 17:14:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_097`) `dbplyr_098`
ORDER BY `date`) `dbplyr_099`) `dbplyr_100`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Desktop"))
19/07/31 17:14:33 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:33 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:33 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_101`) `dbplyr_102`
ORDER BY `date`) `dbplyr_103`) `dbplyr_104`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Desktop"))
19/07/31 17:14:33 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:33 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:33 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1618 - cust_prospect_ind.nullCount#1617) > 0)
19/07/31 17:14:33 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1623 - visit_device_type.nullCount#1622) > 0)
19/07/31 17:14:33 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#1616 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#1615))
19/07/31 17:14:33 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Desktop) generates partition filter: ((visit_device_type.lowerBound#1621 <= Desktop) && (Desktop <= visit_device_type.upperBound#1620))
19/07/31 17:14:33 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:33 INFO DAGScheduler: Got job 29 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:14:33 INFO DAGScheduler: Final stage: ResultStage 43 (collect at utils.scala:204)
19/07/31 17:14:33 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:14:33 INFO DAGScheduler: Missing parents: List()
19/07/31 17:14:33 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[140] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:33 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 72.1 KB, free 910.8 MB)
19/07/31 17:14:33 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.8 MB)
19/07/31 17:14:33 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:54132 (size: 30.5 KB, free: 912.0 MB)
19/07/31 17:14:33 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[140] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:33 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
19/07/31 17:14:33 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 79, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:14:33 INFO Executor: Running task 0.0 in stage 43.0 (TID 79)
19/07/31 17:14:33 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:33 INFO Executor: Finished task 0.0 in stage 43.0 (TID 79). 7068 bytes result sent to driver
19/07/31 17:14:33 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 79) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:14:33 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
19/07/31 17:14:33 INFO DAGScheduler: ResultStage 43 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:14:33 INFO DAGScheduler: Job 29 finished: collect at utils.scala:204, took 0.009980 s
19/07/31 17:14:33 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:33 INFO DAGScheduler: Registering RDD 141 (collect at utils.scala:204)
19/07/31 17:14:33 INFO DAGScheduler: Got job 30 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:14:33 INFO DAGScheduler: Final stage: ResultStage 45 (collect at utils.scala:204)
19/07/31 17:14:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
19/07/31 17:14:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 44)
19/07/31 17:14:33 INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[141] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:33 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 74.5 KB, free 910.7 MB)
19/07/31 17:14:33 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.7 MB)
19/07/31 17:14:33 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:54132 (size: 31.8 KB, free: 912.0 MB)
19/07/31 17:14:33 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[141] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:33 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
19/07/31 17:14:33 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 80, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:14:33 INFO Executor: Running task 0.0 in stage 44.0 (TID 80)
19/07/31 17:14:33 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:33 INFO Executor: Finished task 0.0 in stage 44.0 (TID 80). 1687 bytes result sent to driver
19/07/31 17:14:33 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 80) in 11 ms on localhost (executor driver) (1/1)
19/07/31 17:14:33 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
19/07/31 17:14:33 INFO DAGScheduler: ShuffleMapStage 44 (collect at utils.scala:204) finished in 0.011 s
19/07/31 17:14:33 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:14:33 INFO DAGScheduler: running: Set()
19/07/31 17:14:33 INFO DAGScheduler: waiting: Set(ResultStage 45)
19/07/31 17:14:33 INFO DAGScheduler: failed: Set()
19/07/31 17:14:33 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[144] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:33 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 16.8 KB, free 910.7 MB)
19/07/31 17:14:33 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.7 MB)
19/07/31 17:14:33 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:54132 (size: 8.0 KB, free: 912.0 MB)
19/07/31 17:14:33 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:33 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 45 (MapPartitionsRDD[144] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:14:33 INFO TaskSchedulerImpl: Adding task set 45.0 with 4 tasks
19/07/31 17:14:33 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 81, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:14:33 INFO TaskSetManager: Starting task 1.0 in stage 45.0 (TID 82, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:14:33 INFO TaskSetManager: Starting task 2.0 in stage 45.0 (TID 83, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:14:33 INFO TaskSetManager: Starting task 3.0 in stage 45.0 (TID 84, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:14:33 INFO Executor: Running task 0.0 in stage 45.0 (TID 81)
19/07/31 17:14:33 INFO Executor: Running task 2.0 in stage 45.0 (TID 83)
19/07/31 17:14:33 INFO Executor: Running task 1.0 in stage 45.0 (TID 82)
19/07/31 17:14:33 INFO Executor: Running task 3.0 in stage 45.0 (TID 84)
19/07/31 17:14:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:14:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:33 INFO Executor: Finished task 1.0 in stage 45.0 (TID 82). 2389 bytes result sent to driver
19/07/31 17:14:33 INFO Executor: Finished task 2.0 in stage 45.0 (TID 83). 2391 bytes result sent to driver
19/07/31 17:14:33 INFO Executor: Finished task 3.0 in stage 45.0 (TID 84). 2371 bytes result sent to driver
19/07/31 17:14:33 INFO TaskSetManager: Finished task 1.0 in stage 45.0 (TID 82) in 6 ms on localhost (executor driver) (1/4)
19/07/31 17:14:33 INFO TaskSetManager: Finished task 2.0 in stage 45.0 (TID 83) in 7 ms on localhost (executor driver) (2/4)
19/07/31 17:14:33 INFO TaskSetManager: Finished task 3.0 in stage 45.0 (TID 84) in 7 ms on localhost (executor driver) (3/4)
19/07/31 17:14:33 INFO Executor: Finished task 0.0 in stage 45.0 (TID 81). 2396 bytes result sent to driver
19/07/31 17:14:33 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 81) in 8 ms on localhost (executor driver) (4/4)
19/07/31 17:14:33 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
19/07/31 17:14:33 INFO DAGScheduler: ResultStage 45 (collect at utils.scala:204) finished in 0.008 s
19/07/31 17:14:33 INFO DAGScheduler: Job 30 finished: collect at utils.scala:204, took 0.028781 s
19/07/31 17:14:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_105`) `dbplyr_106`
ORDER BY `date`) `dbplyr_107`) `dbplyr_108`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Tablet"))
19/07/31 17:14:34 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_109`) `dbplyr_110`
ORDER BY `date`) `dbplyr_111`) `dbplyr_112`
WHERE ((`customer` = "CUSTOMER") AND (`device` = "Tablet"))
19/07/31 17:14:34 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:34 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1716 - cust_prospect_ind.nullCount#1715) > 0)
19/07/31 17:14:34 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1721 - visit_device_type.nullCount#1720) > 0)
19/07/31 17:14:34 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = CUSTOMER) generates partition filter: ((cust_prospect_ind.lowerBound#1714 <= CUSTOMER) && (CUSTOMER <= cust_prospect_ind.upperBound#1713))
19/07/31 17:14:34 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#1719 <= Tablet) && (Tablet <= visit_device_type.upperBound#1718))
19/07/31 17:14:34 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:34 INFO DAGScheduler: Got job 31 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:14:34 INFO DAGScheduler: Final stage: ResultStage 46 (collect at utils.scala:204)
19/07/31 17:14:34 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:14:34 INFO DAGScheduler: Missing parents: List()
19/07/31 17:14:34 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[149] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:34 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 72.1 KB, free 910.6 MB)
19/07/31 17:14:34 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 30.4 KB, free 910.6 MB)
19/07/31 17:14:34 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:54132 (size: 30.4 KB, free: 911.9 MB)
19/07/31 17:14:34 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[149] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:34 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
19/07/31 17:14:34 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 85, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:14:34 INFO Executor: Running task 0.0 in stage 46.0 (TID 85)
19/07/31 17:14:34 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:34 INFO Executor: Finished task 0.0 in stage 46.0 (TID 85). 6512 bytes result sent to driver
19/07/31 17:14:34 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 85) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:14:34 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
19/07/31 17:14:34 INFO DAGScheduler: ResultStage 46 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:14:34 INFO DAGScheduler: Job 31 finished: collect at utils.scala:204, took 0.010090 s
19/07/31 17:14:34 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:34 INFO DAGScheduler: Registering RDD 150 (collect at utils.scala:204)
19/07/31 17:14:34 INFO DAGScheduler: Got job 32 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:14:34 INFO DAGScheduler: Final stage: ResultStage 48 (collect at utils.scala:204)
19/07/31 17:14:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
19/07/31 17:14:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 47)
19/07/31 17:14:34 INFO DAGScheduler: Submitting ShuffleMapStage 47 (MapPartitionsRDD[150] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:34 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 74.5 KB, free 910.5 MB)
19/07/31 17:14:34 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 31.7 KB, free 910.5 MB)
19/07/31 17:14:34 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:54132 (size: 31.7 KB, free: 911.9 MB)
19/07/31 17:14:34 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[150] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:34 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
19/07/31 17:14:34 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 86, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:14:34 INFO Executor: Running task 0.0 in stage 47.0 (TID 86)
19/07/31 17:14:34 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:34 INFO Executor: Finished task 0.0 in stage 47.0 (TID 86). 1687 bytes result sent to driver
19/07/31 17:14:34 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 86) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:14:34 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
19/07/31 17:14:34 INFO DAGScheduler: ShuffleMapStage 47 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:14:34 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:14:34 INFO DAGScheduler: running: Set()
19/07/31 17:14:34 INFO DAGScheduler: waiting: Set(ResultStage 48)
19/07/31 17:14:34 INFO DAGScheduler: failed: Set()
19/07/31 17:14:34 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[153] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:34 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 16.8 KB, free 910.4 MB)
19/07/31 17:14:34 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.4 MB)
19/07/31 17:14:34 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:54132 (size: 8.0 KB, free: 911.9 MB)
19/07/31 17:14:34 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:34 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 48 (MapPartitionsRDD[153] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:14:34 INFO TaskSchedulerImpl: Adding task set 48.0 with 4 tasks
19/07/31 17:14:34 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 87, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:14:34 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 88, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:14:34 INFO TaskSetManager: Starting task 2.0 in stage 48.0 (TID 89, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:14:34 INFO TaskSetManager: Starting task 3.0 in stage 48.0 (TID 90, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:14:34 INFO Executor: Running task 0.0 in stage 48.0 (TID 87)
19/07/31 17:14:34 INFO Executor: Running task 1.0 in stage 48.0 (TID 88)
19/07/31 17:14:34 INFO Executor: Running task 3.0 in stage 48.0 (TID 90)
19/07/31 17:14:34 INFO Executor: Running task 2.0 in stage 48.0 (TID 89)
19/07/31 17:14:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
19/07/31 17:14:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
19/07/31 17:14:34 INFO Executor: Finished task 1.0 in stage 48.0 (TID 88). 2340 bytes result sent to driver
19/07/31 17:14:34 INFO Executor: Finished task 3.0 in stage 48.0 (TID 90). 2336 bytes result sent to driver
19/07/31 17:14:34 INFO Executor: Finished task 2.0 in stage 48.0 (TID 89). 2362 bytes result sent to driver
19/07/31 17:14:34 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 88) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:14:34 INFO Executor: Finished task 0.0 in stage 48.0 (TID 87). 2357 bytes result sent to driver
19/07/31 17:14:34 INFO TaskSetManager: Finished task 3.0 in stage 48.0 (TID 90) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:14:34 INFO TaskSetManager: Finished task 2.0 in stage 48.0 (TID 89) in 6 ms on localhost (executor driver) (3/4)
19/07/31 17:14:34 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 87) in 6 ms on localhost (executor driver) (4/4)
19/07/31 17:14:34 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
19/07/31 17:14:34 INFO DAGScheduler: ResultStage 48 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:14:34 INFO DAGScheduler: Job 32 finished: collect at utils.scala:204, took 0.024121 s
19/07/31 17:14:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_113`) `dbplyr_114`
ORDER BY `date`) `dbplyr_115`) `dbplyr_116`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Tablet"))
19/07/31 17:14:34 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_117`) `dbplyr_118`
ORDER BY `date`) `dbplyr_119`) `dbplyr_120`
WHERE ((`customer` = "PROSPECT") AND (`device` = "Tablet"))
19/07/31 17:14:34 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:34 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:35 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1814 - cust_prospect_ind.nullCount#1813) > 0)
19/07/31 17:14:35 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1819 - visit_device_type.nullCount#1818) > 0)
19/07/31 17:14:35 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = PROSPECT) generates partition filter: ((cust_prospect_ind.lowerBound#1812 <= PROSPECT) && (PROSPECT <= cust_prospect_ind.upperBound#1811))
19/07/31 17:14:35 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#1817 <= Tablet) && (Tablet <= visit_device_type.upperBound#1816))
19/07/31 17:14:35 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:35 INFO DAGScheduler: Got job 33 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:14:35 INFO DAGScheduler: Final stage: ResultStage 49 (collect at utils.scala:204)
19/07/31 17:14:35 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:14:35 INFO DAGScheduler: Missing parents: List()
19/07/31 17:14:35 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[158] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:35 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 72.1 KB, free 910.4 MB)
19/07/31 17:14:35 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.3 MB)
19/07/31 17:14:35 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:54132 (size: 30.5 KB, free: 911.9 MB)
19/07/31 17:14:35 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[158] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:35 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
19/07/31 17:14:35 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 91, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:14:35 INFO Executor: Running task 0.0 in stage 49.0 (TID 91)
19/07/31 17:14:35 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:35 INFO Executor: Finished task 0.0 in stage 49.0 (TID 91). 6512 bytes result sent to driver
19/07/31 17:14:35 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 91) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:14:35 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
19/07/31 17:14:35 INFO DAGScheduler: ResultStage 49 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:14:35 INFO DAGScheduler: Job 33 finished: collect at utils.scala:204, took 0.009577 s
19/07/31 17:14:35 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:35 INFO DAGScheduler: Registering RDD 159 (collect at utils.scala:204)
19/07/31 17:14:35 INFO DAGScheduler: Got job 34 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:14:35 INFO DAGScheduler: Final stage: ResultStage 51 (collect at utils.scala:204)
19/07/31 17:14:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
19/07/31 17:14:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 50)
19/07/31 17:14:35 INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[159] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:35 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 74.5 KB, free 910.3 MB)
19/07/31 17:14:35 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.2 MB)
19/07/31 17:14:35 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:54132 (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:14:35 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[159] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:35 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
19/07/31 17:14:35 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 92, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:14:35 INFO Executor: Running task 0.0 in stage 50.0 (TID 92)
19/07/31 17:14:35 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:35 INFO Executor: Finished task 0.0 in stage 50.0 (TID 92). 1687 bytes result sent to driver
19/07/31 17:14:35 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 92) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:14:35 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
19/07/31 17:14:35 INFO DAGScheduler: ShuffleMapStage 50 (collect at utils.scala:204) finished in 0.010 s
19/07/31 17:14:35 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:14:35 INFO DAGScheduler: running: Set()
19/07/31 17:14:35 INFO DAGScheduler: waiting: Set(ResultStage 51)
19/07/31 17:14:35 INFO DAGScheduler: failed: Set()
19/07/31 17:14:35 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[162] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:35 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 16.8 KB, free 910.2 MB)
19/07/31 17:14:35 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.2 MB)
19/07/31 17:14:35 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:54132 (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:14:35 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:35 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 51 (MapPartitionsRDD[162] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:14:35 INFO TaskSchedulerImpl: Adding task set 51.0 with 4 tasks
19/07/31 17:14:35 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 93, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:14:35 INFO TaskSetManager: Starting task 1.0 in stage 51.0 (TID 94, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:14:35 INFO TaskSetManager: Starting task 2.0 in stage 51.0 (TID 95, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:14:35 INFO TaskSetManager: Starting task 3.0 in stage 51.0 (TID 96, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:14:35 INFO Executor: Running task 1.0 in stage 51.0 (TID 94)
19/07/31 17:14:35 INFO Executor: Running task 2.0 in stage 51.0 (TID 95)
19/07/31 17:14:35 INFO Executor: Running task 3.0 in stage 51.0 (TID 96)
19/07/31 17:14:35 INFO Executor: Running task 0.0 in stage 51.0 (TID 93)
19/07/31 17:14:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:35 INFO Executor: Finished task 0.0 in stage 51.0 (TID 93). 2385 bytes result sent to driver
19/07/31 17:14:35 INFO Executor: Finished task 2.0 in stage 51.0 (TID 95). 2360 bytes result sent to driver
19/07/31 17:14:35 INFO Executor: Finished task 3.0 in stage 51.0 (TID 96). 2346 bytes result sent to driver
19/07/31 17:14:35 INFO Executor: Finished task 1.0 in stage 51.0 (TID 94). 2337 bytes result sent to driver
19/07/31 17:14:35 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 93) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:14:35 INFO TaskSetManager: Finished task 3.0 in stage 51.0 (TID 96) in 5 ms on localhost (executor driver) (2/4)
19/07/31 17:14:35 INFO TaskSetManager: Finished task 2.0 in stage 51.0 (TID 95) in 5 ms on localhost (executor driver) (3/4)
19/07/31 17:14:35 INFO TaskSetManager: Finished task 1.0 in stage 51.0 (TID 94) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:14:35 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
19/07/31 17:14:35 INFO DAGScheduler: ResultStage 51 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:14:35 INFO DAGScheduler: Job 34 finished: collect at utils.scala:204, took 0.024347 s
19/07/31 17:14:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_121`) `dbplyr_122`
ORDER BY `date`) `dbplyr_123`) `dbplyr_124`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Tablet"))
19/07/31 17:14:35 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:35 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, `date`, `orders` / `visitors` AS `rate`
FROM (SELECT *
FROM (SELECT `visitors`, `orders`, `customer`, `device`, to_date(`date`, "MM/dd/yy") AS `date`
FROM (SELECT `totalshoppertraffic_visitors` AS `visitors`, `digital_orders` AS `orders`, `cust_prospect_ind` AS `customer`, `visit_device_type` AS `device`, `event_dt` AS `date`
FROM `anomaly_det_dashboard_shopper_conv`) `dbplyr_125`) `dbplyr_126`
ORDER BY `date`) `dbplyr_127`) `dbplyr_128`
WHERE ((`customer` = "UNDETERMINED") AND (`device` = "Tablet"))
19/07/31 17:14:35 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:35 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:35 INFO InMemoryTableScanExec: Predicate isnotnull(cust_prospect_ind#33) generates partition filter: ((cust_prospect_ind.count#1912 - cust_prospect_ind.nullCount#1911) > 0)
19/07/31 17:14:35 INFO InMemoryTableScanExec: Predicate isnotnull(visit_device_type#34) generates partition filter: ((visit_device_type.count#1917 - visit_device_type.nullCount#1916) > 0)
19/07/31 17:14:35 INFO InMemoryTableScanExec: Predicate (cust_prospect_ind#33 = UNDETERMINED) generates partition filter: ((cust_prospect_ind.lowerBound#1910 <= UNDETERMINED) && (UNDETERMINED <= cust_prospect_ind.upperBound#1909))
19/07/31 17:14:35 INFO InMemoryTableScanExec: Predicate (visit_device_type#34 = Tablet) generates partition filter: ((visit_device_type.lowerBound#1915 <= Tablet) && (Tablet <= visit_device_type.upperBound#1914))
19/07/31 17:14:35 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:35 INFO DAGScheduler: Got job 35 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:14:35 INFO DAGScheduler: Final stage: ResultStage 52 (collect at utils.scala:204)
19/07/31 17:14:35 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:14:35 INFO DAGScheduler: Missing parents: List()
19/07/31 17:14:35 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[167] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:35 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 72.1 KB, free 910.1 MB)
19/07/31 17:14:35 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 30.5 KB, free 910.1 MB)
19/07/31 17:14:35 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:54132 (size: 30.5 KB, free: 911.8 MB)
19/07/31 17:14:35 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[167] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:35 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
19/07/31 17:14:35 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 97, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
19/07/31 17:14:35 INFO Executor: Running task 0.0 in stage 52.0 (TID 97)
19/07/31 17:14:35 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:35 INFO Executor: Finished task 0.0 in stage 52.0 (TID 97). 7068 bytes result sent to driver
19/07/31 17:14:35 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 97) in 5 ms on localhost (executor driver) (1/1)
19/07/31 17:14:35 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
19/07/31 17:14:35 INFO DAGScheduler: ResultStage 52 (collect at utils.scala:204) finished in 0.005 s
19/07/31 17:14:35 INFO DAGScheduler: Job 35 finished: collect at utils.scala:204, took 0.010749 s
19/07/31 17:14:35 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:35 INFO DAGScheduler: Registering RDD 168 (collect at utils.scala:204)
19/07/31 17:14:35 INFO DAGScheduler: Got job 36 (collect at utils.scala:204) with 4 output partitions
19/07/31 17:14:35 INFO DAGScheduler: Final stage: ResultStage 54 (collect at utils.scala:204)
19/07/31 17:14:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 53)
19/07/31 17:14:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 53)
19/07/31 17:14:35 INFO DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[168] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:35 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 74.5 KB, free 910.0 MB)
19/07/31 17:14:35 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 31.8 KB, free 910.0 MB)
19/07/31 17:14:35 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:54132 (size: 31.8 KB, free: 911.8 MB)
19/07/31 17:14:35 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[168] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:35 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
19/07/31 17:14:35 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 98, localhost, executor driver, partition 0, PROCESS_LOCAL, 5303 bytes)
19/07/31 17:14:35 INFO Executor: Running task 0.0 in stage 53.0 (TID 98)
19/07/31 17:14:35 INFO BlockManager: Found block rdd_15_0 locally
19/07/31 17:14:35 INFO Executor: Finished task 0.0 in stage 53.0 (TID 98). 1687 bytes result sent to driver
19/07/31 17:14:35 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 98) in 9 ms on localhost (executor driver) (1/1)
19/07/31 17:14:35 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
19/07/31 17:14:35 INFO DAGScheduler: ShuffleMapStage 53 (collect at utils.scala:204) finished in 0.009 s
19/07/31 17:14:35 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:14:35 INFO DAGScheduler: running: Set()
19/07/31 17:14:35 INFO DAGScheduler: waiting: Set(ResultStage 54)
19/07/31 17:14:35 INFO DAGScheduler: failed: Set()
19/07/31 17:14:35 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[171] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:35 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 16.8 KB, free 910.0 MB)
19/07/31 17:14:35 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 8.0 KB, free 910.0 MB)
19/07/31 17:14:35 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:54132 (size: 8.0 KB, free: 911.8 MB)
19/07/31 17:14:35 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:35 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 54 (MapPartitionsRDD[171] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
19/07/31 17:14:35 INFO TaskSchedulerImpl: Adding task set 54.0 with 4 tasks
19/07/31 17:14:35 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 99, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:14:35 INFO TaskSetManager: Starting task 1.0 in stage 54.0 (TID 100, localhost, executor driver, partition 1, ANY, 4726 bytes)
19/07/31 17:14:35 INFO TaskSetManager: Starting task 2.0 in stage 54.0 (TID 101, localhost, executor driver, partition 2, ANY, 4726 bytes)
19/07/31 17:14:35 INFO TaskSetManager: Starting task 3.0 in stage 54.0 (TID 102, localhost, executor driver, partition 3, ANY, 4726 bytes)
19/07/31 17:14:35 INFO Executor: Running task 3.0 in stage 54.0 (TID 102)
19/07/31 17:14:35 INFO Executor: Running task 1.0 in stage 54.0 (TID 100)
19/07/31 17:14:35 INFO Executor: Running task 2.0 in stage 54.0 (TID 101)
19/07/31 17:14:35 INFO Executor: Running task 0.0 in stage 54.0 (TID 99)
19/07/31 17:14:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:35 INFO Executor: Finished task 0.0 in stage 54.0 (TID 99). 2376 bytes result sent to driver
19/07/31 17:14:35 INFO Executor: Finished task 2.0 in stage 54.0 (TID 101). 2379 bytes result sent to driver
19/07/31 17:14:35 INFO Executor: Finished task 1.0 in stage 54.0 (TID 100). 2381 bytes result sent to driver
19/07/31 17:14:35 INFO Executor: Finished task 3.0 in stage 54.0 (TID 102). 2357 bytes result sent to driver
19/07/31 17:14:35 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 99) in 5 ms on localhost (executor driver) (1/4)
19/07/31 17:14:35 INFO TaskSetManager: Finished task 1.0 in stage 54.0 (TID 100) in 4 ms on localhost (executor driver) (2/4)
19/07/31 17:14:35 INFO TaskSetManager: Finished task 2.0 in stage 54.0 (TID 101) in 4 ms on localhost (executor driver) (3/4)
19/07/31 17:14:35 INFO TaskSetManager: Finished task 3.0 in stage 54.0 (TID 102) in 5 ms on localhost (executor driver) (4/4)
19/07/31 17:14:35 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
19/07/31 17:14:35 INFO DAGScheduler: ResultStage 54 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:14:35 INFO DAGScheduler: Job 36 finished: collect at utils.scala:204, took 0.022984 s
19/07/31 17:14:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
19/07/31 17:14:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:36 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
19/07/31 17:14:36 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
19/07/31 17:14:36 INFO CodeGenerator: Code generated in 9.012128 ms
19/07/31 17:14:36 INFO SparkContext: Starting job: collect at utils.scala:44
19/07/31 17:14:36 INFO DAGScheduler: Got job 37 (collect at utils.scala:44) with 1 output partitions
19/07/31 17:14:36 INFO DAGScheduler: Final stage: ResultStage 55 (collect at utils.scala:44)
19/07/31 17:14:36 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:14:36 INFO DAGScheduler: Missing parents: List()
19/07/31 17:14:36 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[176] at map at utils.scala:41), which has no missing parents
19/07/31 17:14:36 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 6.3 KB, free 910.0 MB)
19/07/31 17:14:36 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 3.5 KB, free 910.0 MB)
19/07/31 17:14:36 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:54132 (size: 3.5 KB, free: 911.8 MB)
19/07/31 17:14:36 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[176] at map at utils.scala:41) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:36 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
19/07/31 17:14:36 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 103, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
19/07/31 17:14:36 INFO Executor: Running task 0.0 in stage 55.0 (TID 103)
19/07/31 17:14:36 INFO Executor: Finished task 0.0 in stage 55.0 (TID 103). 1007 bytes result sent to driver
19/07/31 17:14:36 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 103) in 4 ms on localhost (executor driver) (1/1)
19/07/31 17:14:36 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
19/07/31 17:14:36 INFO DAGScheduler: ResultStage 55 (collect at utils.scala:44) finished in 0.006 s
19/07/31 17:14:36 INFO DAGScheduler: Job 37 finished: collect at utils.scala:44, took 0.011906 s
19/07/31 17:14:36 INFO SparkSqlParser: Parsing command: result
19/07/31 17:14:36 INFO SparkSqlParser: Parsing command: CACHE TABLE `result`
19/07/31 17:14:36 INFO SparkSqlParser: Parsing command: `result`
19/07/31 17:14:36 INFO SparkContext: Starting job: sql at <unknown>:0
19/07/31 17:14:36 INFO DAGScheduler: Registering RDD 184 (sql at <unknown>:0)
19/07/31 17:14:36 INFO DAGScheduler: Got job 38 (sql at <unknown>:0) with 1 output partitions
19/07/31 17:14:36 INFO DAGScheduler: Final stage: ResultStage 57 (sql at <unknown>:0)
19/07/31 17:14:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
19/07/31 17:14:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 56)
19/07/31 17:14:36 INFO DAGScheduler: Submitting ShuffleMapStage 56 (MapPartitionsRDD[184] at sql at <unknown>:0), which has no missing parents
19/07/31 17:14:36 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 28.2 KB, free 909.9 MB)
19/07/31 17:14:36 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 10.9 KB, free 909.9 MB)
19/07/31 17:14:36 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:54132 (size: 10.9 KB, free: 911.8 MB)
19/07/31 17:14:36 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 56 (MapPartitionsRDD[184] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:36 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
19/07/31 17:14:36 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 104, localhost, executor driver, partition 0, PROCESS_LOCAL, 81622 bytes)
19/07/31 17:14:36 INFO Executor: Running task 0.0 in stage 56.0 (TID 104)
19/07/31 17:14:36 INFO CodeGenerator: Code generated in 23.758284 ms
19/07/31 17:14:36 INFO CodeGenerator: Code generated in 135.37335 ms
19/07/31 17:14:37 INFO MemoryStore: Block rdd_181_0 stored as values in memory (estimated size 48.4 KB, free 909.9 MB)
19/07/31 17:14:37 INFO BlockManagerInfo: Added rdd_181_0 in memory on 127.0.0.1:54132 (size: 48.4 KB, free: 911.7 MB)
19/07/31 17:14:37 INFO Executor: Finished task 0.0 in stage 56.0 (TID 104). 2285 bytes result sent to driver
19/07/31 17:14:37 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 104) in 344 ms on localhost (executor driver) (1/1)
19/07/31 17:14:37 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
19/07/31 17:14:37 INFO DAGScheduler: ShuffleMapStage 56 (sql at <unknown>:0) finished in 0.346 s
19/07/31 17:14:37 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:14:37 INFO DAGScheduler: running: Set()
19/07/31 17:14:37 INFO DAGScheduler: waiting: Set(ResultStage 57)
19/07/31 17:14:37 INFO DAGScheduler: failed: Set()
19/07/31 17:14:37 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[187] at sql at <unknown>:0), which has no missing parents
19/07/31 17:14:37 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 7.0 KB, free 909.9 MB)
19/07/31 17:14:37 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 3.7 KB, free 909.9 MB)
19/07/31 17:14:37 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:54132 (size: 3.7 KB, free: 911.7 MB)
19/07/31 17:14:37 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[187] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:37 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
19/07/31 17:14:37 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 105, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:14:37 INFO Executor: Running task 0.0 in stage 57.0 (TID 105)
19/07/31 17:14:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:37 INFO Executor: Finished task 0.0 in stage 57.0 (TID 105). 1581 bytes result sent to driver
19/07/31 17:14:37 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 105) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:14:37 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
19/07/31 17:14:37 INFO DAGScheduler: ResultStage 57 (sql at <unknown>:0) finished in 0.007 s
19/07/31 17:14:37 INFO DAGScheduler: Job 38 finished: sql at <unknown>:0, took 0.374211 s
19/07/31 17:14:37 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `result`
19/07/31 17:14:37 INFO HiveMetaStore: 0: get_database: default
19/07/31 17:14:37 INFO audit: ugi=6jncnk4f	ip=unknown-ip-addr	cmd=get_database: default	
19/07/31 17:14:37 INFO SparkContext: Starting job: collect at utils.scala:204
19/07/31 17:14:37 INFO DAGScheduler: Registering RDD 190 (collect at utils.scala:204)
19/07/31 17:14:37 INFO DAGScheduler: Got job 39 (collect at utils.scala:204) with 1 output partitions
19/07/31 17:14:37 INFO DAGScheduler: Final stage: ResultStage 59 (collect at utils.scala:204)
19/07/31 17:14:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 58)
19/07/31 17:14:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 58)
19/07/31 17:14:37 INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[190] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:37 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 28.2 KB, free 909.8 MB)
19/07/31 17:14:37 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 10.9 KB, free 909.8 MB)
19/07/31 17:14:37 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:54132 (size: 10.9 KB, free: 911.7 MB)
19/07/31 17:14:37 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[190] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:37 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
19/07/31 17:14:37 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 106, localhost, executor driver, partition 0, PROCESS_LOCAL, 81622 bytes)
19/07/31 17:14:37 INFO Executor: Running task 0.0 in stage 58.0 (TID 106)
19/07/31 17:14:37 INFO BlockManager: Found block rdd_181_0 locally
19/07/31 17:14:37 INFO Executor: Finished task 0.0 in stage 58.0 (TID 106). 1690 bytes result sent to driver
19/07/31 17:14:37 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 106) in 15 ms on localhost (executor driver) (1/1)
19/07/31 17:14:37 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
19/07/31 17:14:37 INFO DAGScheduler: ShuffleMapStage 58 (collect at utils.scala:204) finished in 0.015 s
19/07/31 17:14:37 INFO DAGScheduler: looking for newly runnable stages
19/07/31 17:14:37 INFO DAGScheduler: running: Set()
19/07/31 17:14:37 INFO DAGScheduler: waiting: Set(ResultStage 59)
19/07/31 17:14:37 INFO DAGScheduler: failed: Set()
19/07/31 17:14:37 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[193] at collect at utils.scala:204), which has no missing parents
19/07/31 17:14:37 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 7.0 KB, free 909.8 MB)
19/07/31 17:14:37 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 3.7 KB, free 909.8 MB)
19/07/31 17:14:37 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:54132 (size: 3.7 KB, free: 911.7 MB)
19/07/31 17:14:37 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[193] at collect at utils.scala:204) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:37 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
19/07/31 17:14:37 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 107, localhost, executor driver, partition 0, ANY, 4726 bytes)
19/07/31 17:14:37 INFO Executor: Running task 0.0 in stage 59.0 (TID 107)
19/07/31 17:14:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
19/07/31 17:14:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
19/07/31 17:14:37 INFO Executor: Finished task 0.0 in stage 59.0 (TID 107). 1581 bytes result sent to driver
19/07/31 17:14:37 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 107) in 6 ms on localhost (executor driver) (1/1)
19/07/31 17:14:37 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
19/07/31 17:14:37 INFO DAGScheduler: ResultStage 59 (collect at utils.scala:204) finished in 0.006 s
19/07/31 17:14:37 INFO DAGScheduler: Job 39 finished: collect at utils.scala:204, took 0.041399 s
19/07/31 17:14:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `result` AS `zzz2`
WHERE (0 = 1)
19/07/31 17:14:37 INFO SparkSqlParser: Parsing command: SELECT *
FROM `result`
19/07/31 17:14:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 17:14:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 17:14:37 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
19/07/31 17:14:37 INFO DAGScheduler: Got job 40 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
19/07/31 17:14:37 INFO DAGScheduler: Final stage: ResultStage 60 (csv at NativeMethodAccessorImpl.java:0)
19/07/31 17:14:37 INFO DAGScheduler: Parents of final stage: List()
19/07/31 17:14:37 INFO DAGScheduler: Missing parents: List()
19/07/31 17:14:37 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[194] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
19/07/31 17:14:37 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 99.2 KB, free 909.7 MB)
19/07/31 17:14:37 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 37.2 KB, free 909.7 MB)
19/07/31 17:14:37 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:54132 (size: 37.2 KB, free: 911.7 MB)
19/07/31 17:14:37 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1006
19/07/31 17:14:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[194] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
19/07/31 17:14:37 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
19/07/31 17:14:37 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 108, localhost, executor driver, partition 0, PROCESS_LOCAL, 81633 bytes)
19/07/31 17:14:37 INFO Executor: Running task 0.0 in stage 60.0 (TID 108)
19/07/31 17:14:37 INFO BlockManager: Found block rdd_181_0 locally
19/07/31 17:14:37 INFO CodeGenerator: Code generated in 46.190698 ms
19/07/31 17:14:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
19/07/31 17:14:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
19/07/31 17:14:37 INFO FileOutputCommitter: Saved output of task 'attempt_20190731171437_0060_m_000000_0' to file:/Users/6jncnk4f/Desktop/anomaly/anomaly_result/_temporary/0/task_20190731171437_0060_m_000000
19/07/31 17:14:37 INFO SparkHadoopMapRedUtil: attempt_20190731171437_0060_m_000000_0: Committed
19/07/31 17:14:37 INFO Executor: Finished task 0.0 in stage 60.0 (TID 108). 1619 bytes result sent to driver
19/07/31 17:14:37 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 108) in 329 ms on localhost (executor driver) (1/1)
19/07/31 17:14:37 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
19/07/31 17:14:37 INFO DAGScheduler: ResultStage 60 (csv at NativeMethodAccessorImpl.java:0) finished in 0.330 s
19/07/31 17:14:37 INFO DAGScheduler: Job 40 finished: csv at NativeMethodAccessorImpl.java:0, took 0.374188 s
19/07/31 17:14:38 INFO FileFormatWriter: Job null committed.
19/07/31 17:14:39 INFO SparkContext: Invoking stop() from shutdown hook
19/07/31 17:14:39 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
19/07/31 17:14:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/07/31 17:14:39 INFO MemoryStore: MemoryStore cleared
19/07/31 17:14:39 INFO BlockManager: BlockManager stopped
19/07/31 17:14:39 INFO BlockManagerMaster: BlockManagerMaster stopped
19/07/31 17:14:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/07/31 17:14:39 INFO SparkContext: Successfully stopped SparkContext
19/07/31 17:14:39 INFO ShutdownHookManager: Shutdown hook called
19/07/31 17:14:39 INFO ShutdownHookManager: Deleting directory /private/var/folders/pv/4qkqjv9557vgg71_h_5cqz9w0000gn/T/spark-8eca7bcc-7455-4eee-bf63-cb51a0c8af88
